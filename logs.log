2023-04-29 15:28:12,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 15:28:12,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 15:28:12,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 15:28:12,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 15:28:21,842:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-29 15:32:33,807:INFO:PyCaret ClassificationExperiment
2023-04-29 15:32:33,807:INFO:Logging name: clf-default-name
2023-04-29 15:32:33,807:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 15:32:33,807:INFO:version 3.0.0
2023-04-29 15:32:33,807:INFO:Initializing setup()
2023-04-29 15:32:33,807:INFO:self.USI: dcad
2023-04-29 15:32:33,807:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'fix_imbalance', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'pipeline', 'is_multiclass', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:32:33,807:INFO:Checking environment
2023-04-29 15:32:33,809:INFO:python_version: 3.9.13
2023-04-29 15:32:33,809:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:32:33,809:INFO:machine: AMD64
2023-04-29 15:32:33,824:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:32:33,825:INFO:Memory: svmem(total=16935899136, available=6299131904, percent=62.8, used=10636767232, free=6299131904)
2023-04-29 15:32:33,825:INFO:Physical Core: 4
2023-04-29 15:32:33,825:INFO:Logical Core: 8
2023-04-29 15:32:33,825:INFO:Checking libraries
2023-04-29 15:32:33,825:INFO:System:
2023-04-29 15:32:33,825:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:32:33,825:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:32:33,825:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:32:33,825:INFO:PyCaret required dependencies:
2023-04-29 15:32:33,825:INFO:                 pip: 22.2.2
2023-04-29 15:32:33,825:INFO:          setuptools: 63.4.1
2023-04-29 15:32:33,825:INFO:             pycaret: 3.0.0
2023-04-29 15:32:33,825:INFO:             IPython: 7.31.1
2023-04-29 15:32:33,825:INFO:          ipywidgets: 7.6.5
2023-04-29 15:32:33,825:INFO:                tqdm: 4.64.1
2023-04-29 15:32:33,825:INFO:               numpy: 1.21.5
2023-04-29 15:32:33,825:INFO:              pandas: 1.4.4
2023-04-29 15:32:33,825:INFO:              jinja2: 2.11.3
2023-04-29 15:32:33,825:INFO:               scipy: 1.9.1
2023-04-29 15:32:33,826:INFO:              joblib: 1.2.0
2023-04-29 15:32:33,826:INFO:             sklearn: 1.0.2
2023-04-29 15:32:33,826:INFO:                pyod: 1.0.9
2023-04-29 15:32:33,826:INFO:            imblearn: 0.10.1
2023-04-29 15:32:33,826:INFO:   category_encoders: 2.6.0
2023-04-29 15:32:33,826:INFO:            lightgbm: 3.3.5
2023-04-29 15:32:33,826:INFO:               numba: 0.55.1
2023-04-29 15:32:33,826:INFO:            requests: 2.28.1
2023-04-29 15:32:33,826:INFO:          matplotlib: 3.5.2
2023-04-29 15:32:33,826:INFO:          scikitplot: 0.3.7
2023-04-29 15:32:33,826:INFO:         yellowbrick: 1.5
2023-04-29 15:32:33,826:INFO:              plotly: 5.9.0
2023-04-29 15:32:33,826:INFO:             kaleido: 0.2.1
2023-04-29 15:32:33,826:INFO:         statsmodels: 0.13.2
2023-04-29 15:32:33,826:INFO:              sktime: 0.17.1
2023-04-29 15:32:33,826:INFO:               tbats: 1.1.2
2023-04-29 15:32:33,827:INFO:            pmdarima: 2.0.3
2023-04-29 15:32:33,827:INFO:              psutil: 5.9.0
2023-04-29 15:32:33,827:INFO:PyCaret optional dependencies:
2023-04-29 15:32:33,837:INFO:                shap: 0.41.0
2023-04-29 15:32:33,837:INFO:           interpret: Not installed
2023-04-29 15:32:33,837:INFO:                umap: Not installed
2023-04-29 15:32:33,837:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:32:33,837:INFO:  explainerdashboard: Not installed
2023-04-29 15:32:33,837:INFO:             autoviz: Not installed
2023-04-29 15:32:33,837:INFO:           fairlearn: Not installed
2023-04-29 15:32:33,837:INFO:             xgboost: Not installed
2023-04-29 15:32:33,837:INFO:            catboost: Not installed
2023-04-29 15:32:33,837:INFO:              kmodes: Not installed
2023-04-29 15:32:33,837:INFO:             mlxtend: Not installed
2023-04-29 15:32:33,837:INFO:       statsforecast: Not installed
2023-04-29 15:32:33,838:INFO:        tune_sklearn: Not installed
2023-04-29 15:32:33,838:INFO:                 ray: Not installed
2023-04-29 15:32:33,838:INFO:            hyperopt: Not installed
2023-04-29 15:32:33,838:INFO:              optuna: Not installed
2023-04-29 15:32:33,838:INFO:               skopt: Not installed
2023-04-29 15:32:33,838:INFO:              mlflow: 2.2.1
2023-04-29 15:32:33,838:INFO:              gradio: Not installed
2023-04-29 15:32:33,838:INFO:             fastapi: Not installed
2023-04-29 15:32:33,839:INFO:             uvicorn: Not installed
2023-04-29 15:32:33,839:INFO:              m2cgen: Not installed
2023-04-29 15:32:33,839:INFO:           evidently: Not installed
2023-04-29 15:32:33,839:INFO:               fugue: Not installed
2023-04-29 15:32:33,839:INFO:           streamlit: 1.21.0
2023-04-29 15:32:33,839:INFO:             prophet: Not installed
2023-04-29 15:32:33,839:INFO:None
2023-04-29 15:32:33,839:INFO:Set up data.
2023-04-29 15:34:52,070:INFO:PyCaret ClassificationExperiment
2023-04-29 15:34:52,070:INFO:Logging name: clf-default-name
2023-04-29 15:34:52,070:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 15:34:52,071:INFO:version 3.0.0
2023-04-29 15:34:52,071:INFO:Initializing setup()
2023-04-29 15:34:52,071:INFO:self.USI: 148a
2023-04-29 15:34:52,071:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'fix_imbalance', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'pipeline', 'is_multiclass', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:34:52,071:INFO:Checking environment
2023-04-29 15:34:52,071:INFO:python_version: 3.9.13
2023-04-29 15:34:52,071:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:34:52,072:INFO:machine: AMD64
2023-04-29 15:34:52,072:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:34:52,072:INFO:Memory: svmem(total=16935899136, available=6289645568, percent=62.9, used=10646253568, free=6289645568)
2023-04-29 15:34:52,072:INFO:Physical Core: 4
2023-04-29 15:34:52,072:INFO:Logical Core: 8
2023-04-29 15:34:52,073:INFO:Checking libraries
2023-04-29 15:34:52,073:INFO:System:
2023-04-29 15:34:52,073:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:34:52,073:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:34:52,073:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:34:52,073:INFO:PyCaret required dependencies:
2023-04-29 15:34:52,074:INFO:                 pip: 22.2.2
2023-04-29 15:34:52,074:INFO:          setuptools: 63.4.1
2023-04-29 15:34:52,074:INFO:             pycaret: 3.0.0
2023-04-29 15:34:52,074:INFO:             IPython: 7.31.1
2023-04-29 15:34:52,074:INFO:          ipywidgets: 7.6.5
2023-04-29 15:34:52,074:INFO:                tqdm: 4.64.1
2023-04-29 15:34:52,075:INFO:               numpy: 1.21.5
2023-04-29 15:34:52,075:INFO:              pandas: 1.4.4
2023-04-29 15:34:52,075:INFO:              jinja2: 2.11.3
2023-04-29 15:34:52,075:INFO:               scipy: 1.9.1
2023-04-29 15:34:52,075:INFO:              joblib: 1.2.0
2023-04-29 15:34:52,075:INFO:             sklearn: 1.0.2
2023-04-29 15:34:52,076:INFO:                pyod: 1.0.9
2023-04-29 15:34:52,076:INFO:            imblearn: 0.10.1
2023-04-29 15:34:52,076:INFO:   category_encoders: 2.6.0
2023-04-29 15:34:52,076:INFO:            lightgbm: 3.3.5
2023-04-29 15:34:52,076:INFO:               numba: 0.55.1
2023-04-29 15:34:52,076:INFO:            requests: 2.28.1
2023-04-29 15:34:52,077:INFO:          matplotlib: 3.5.2
2023-04-29 15:34:52,077:INFO:          scikitplot: 0.3.7
2023-04-29 15:34:52,077:INFO:         yellowbrick: 1.5
2023-04-29 15:34:52,077:INFO:              plotly: 5.9.0
2023-04-29 15:34:52,077:INFO:             kaleido: 0.2.1
2023-04-29 15:34:52,078:INFO:         statsmodels: 0.13.2
2023-04-29 15:34:52,078:INFO:              sktime: 0.17.1
2023-04-29 15:34:52,078:INFO:               tbats: 1.1.2
2023-04-29 15:34:52,078:INFO:            pmdarima: 2.0.3
2023-04-29 15:34:52,078:INFO:              psutil: 5.9.0
2023-04-29 15:34:52,078:INFO:PyCaret optional dependencies:
2023-04-29 15:34:52,079:INFO:                shap: 0.41.0
2023-04-29 15:34:52,079:INFO:           interpret: Not installed
2023-04-29 15:34:52,079:INFO:                umap: Not installed
2023-04-29 15:34:52,079:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:34:52,079:INFO:  explainerdashboard: Not installed
2023-04-29 15:34:52,079:INFO:             autoviz: Not installed
2023-04-29 15:34:52,080:INFO:           fairlearn: Not installed
2023-04-29 15:34:52,080:INFO:             xgboost: Not installed
2023-04-29 15:34:52,080:INFO:            catboost: Not installed
2023-04-29 15:34:52,080:INFO:              kmodes: Not installed
2023-04-29 15:34:52,080:INFO:             mlxtend: Not installed
2023-04-29 15:34:52,080:INFO:       statsforecast: Not installed
2023-04-29 15:34:52,081:INFO:        tune_sklearn: Not installed
2023-04-29 15:34:52,081:INFO:                 ray: Not installed
2023-04-29 15:34:52,081:INFO:            hyperopt: Not installed
2023-04-29 15:34:52,081:INFO:              optuna: Not installed
2023-04-29 15:34:52,081:INFO:               skopt: Not installed
2023-04-29 15:34:52,081:INFO:              mlflow: 2.2.1
2023-04-29 15:34:52,082:INFO:              gradio: Not installed
2023-04-29 15:34:52,082:INFO:             fastapi: Not installed
2023-04-29 15:34:52,082:INFO:             uvicorn: Not installed
2023-04-29 15:34:52,082:INFO:              m2cgen: Not installed
2023-04-29 15:34:52,082:INFO:           evidently: Not installed
2023-04-29 15:34:52,082:INFO:               fugue: Not installed
2023-04-29 15:34:52,082:INFO:           streamlit: 1.21.0
2023-04-29 15:34:52,083:INFO:             prophet: Not installed
2023-04-29 15:34:52,083:INFO:None
2023-04-29 15:34:52,083:INFO:Set up data.
2023-04-29 15:51:32,903:INFO:PyCaret ClassificationExperiment
2023-04-29 15:51:32,903:INFO:Logging name: clf-default-name
2023-04-29 15:51:32,903:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 15:51:32,903:INFO:version 3.0.0
2023-04-29 15:51:32,903:INFO:Initializing setup()
2023-04-29 15:51:32,903:INFO:self.USI: d167
2023-04-29 15:51:32,903:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'fix_imbalance', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'pipeline', 'is_multiclass', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:51:32,903:INFO:Checking environment
2023-04-29 15:51:32,903:INFO:python_version: 3.9.13
2023-04-29 15:51:32,903:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:51:32,903:INFO:machine: AMD64
2023-04-29 15:51:32,903:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:51:32,903:INFO:Memory: svmem(total=16935899136, available=6321168384, percent=62.7, used=10614730752, free=6321168384)
2023-04-29 15:51:32,903:INFO:Physical Core: 4
2023-04-29 15:51:32,903:INFO:Logical Core: 8
2023-04-29 15:51:32,904:INFO:Checking libraries
2023-04-29 15:51:32,904:INFO:System:
2023-04-29 15:51:32,904:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:51:32,904:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:51:32,904:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:51:32,904:INFO:PyCaret required dependencies:
2023-04-29 15:51:32,904:INFO:                 pip: 22.2.2
2023-04-29 15:51:32,904:INFO:          setuptools: 63.4.1
2023-04-29 15:51:32,904:INFO:             pycaret: 3.0.0
2023-04-29 15:51:32,904:INFO:             IPython: 7.31.1
2023-04-29 15:51:32,904:INFO:          ipywidgets: 7.6.5
2023-04-29 15:51:32,904:INFO:                tqdm: 4.64.1
2023-04-29 15:51:32,904:INFO:               numpy: 1.21.5
2023-04-29 15:51:32,904:INFO:              pandas: 1.4.4
2023-04-29 15:51:32,904:INFO:              jinja2: 2.11.3
2023-04-29 15:51:32,904:INFO:               scipy: 1.9.1
2023-04-29 15:51:32,904:INFO:              joblib: 1.2.0
2023-04-29 15:51:32,904:INFO:             sklearn: 1.0.2
2023-04-29 15:51:32,904:INFO:                pyod: 1.0.9
2023-04-29 15:51:32,904:INFO:            imblearn: 0.10.1
2023-04-29 15:51:32,904:INFO:   category_encoders: 2.6.0
2023-04-29 15:51:32,904:INFO:            lightgbm: 3.3.5
2023-04-29 15:51:32,904:INFO:               numba: 0.55.1
2023-04-29 15:51:32,904:INFO:            requests: 2.28.1
2023-04-29 15:51:32,904:INFO:          matplotlib: 3.5.2
2023-04-29 15:51:32,904:INFO:          scikitplot: 0.3.7
2023-04-29 15:51:32,904:INFO:         yellowbrick: 1.5
2023-04-29 15:51:32,904:INFO:              plotly: 5.9.0
2023-04-29 15:51:32,904:INFO:             kaleido: 0.2.1
2023-04-29 15:51:32,905:INFO:         statsmodels: 0.13.2
2023-04-29 15:51:32,905:INFO:              sktime: 0.17.1
2023-04-29 15:51:32,905:INFO:               tbats: 1.1.2
2023-04-29 15:51:32,905:INFO:            pmdarima: 2.0.3
2023-04-29 15:51:32,905:INFO:              psutil: 5.9.0
2023-04-29 15:51:32,905:INFO:PyCaret optional dependencies:
2023-04-29 15:51:32,905:INFO:                shap: 0.41.0
2023-04-29 15:51:32,905:INFO:           interpret: Not installed
2023-04-29 15:51:32,905:INFO:                umap: Not installed
2023-04-29 15:51:32,905:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:51:32,905:INFO:  explainerdashboard: Not installed
2023-04-29 15:51:32,905:INFO:             autoviz: Not installed
2023-04-29 15:51:32,905:INFO:           fairlearn: Not installed
2023-04-29 15:51:32,905:INFO:             xgboost: Not installed
2023-04-29 15:51:32,905:INFO:            catboost: Not installed
2023-04-29 15:51:32,905:INFO:              kmodes: Not installed
2023-04-29 15:51:32,905:INFO:             mlxtend: Not installed
2023-04-29 15:51:32,905:INFO:       statsforecast: Not installed
2023-04-29 15:51:32,905:INFO:        tune_sklearn: Not installed
2023-04-29 15:51:32,905:INFO:                 ray: Not installed
2023-04-29 15:51:32,905:INFO:            hyperopt: Not installed
2023-04-29 15:51:32,905:INFO:              optuna: Not installed
2023-04-29 15:51:32,905:INFO:               skopt: Not installed
2023-04-29 15:51:32,905:INFO:              mlflow: 2.2.1
2023-04-29 15:51:32,905:INFO:              gradio: Not installed
2023-04-29 15:51:32,905:INFO:             fastapi: Not installed
2023-04-29 15:51:32,905:INFO:             uvicorn: Not installed
2023-04-29 15:51:32,905:INFO:              m2cgen: Not installed
2023-04-29 15:51:32,905:INFO:           evidently: Not installed
2023-04-29 15:51:32,905:INFO:               fugue: Not installed
2023-04-29 15:51:32,905:INFO:           streamlit: 1.21.0
2023-04-29 15:51:32,905:INFO:             prophet: Not installed
2023-04-29 15:51:32,905:INFO:None
2023-04-29 15:51:32,906:INFO:Set up data.
2023-04-29 15:52:29,844:INFO:PyCaret ClassificationExperiment
2023-04-29 15:52:29,844:INFO:Logging name: clf-default-name
2023-04-29 15:52:29,844:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 15:52:29,844:INFO:version 3.0.0
2023-04-29 15:52:29,844:INFO:Initializing setup()
2023-04-29 15:52:29,845:INFO:self.USI: 1b57
2023-04-29 15:52:29,845:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'fix_imbalance', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'pipeline', 'is_multiclass', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:52:29,845:INFO:Checking environment
2023-04-29 15:52:29,845:INFO:python_version: 3.9.13
2023-04-29 15:52:29,845:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:52:29,845:INFO:machine: AMD64
2023-04-29 15:52:29,845:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:52:29,845:INFO:Memory: svmem(total=16935899136, available=6389547008, percent=62.3, used=10546352128, free=6389547008)
2023-04-29 15:52:29,845:INFO:Physical Core: 4
2023-04-29 15:52:29,845:INFO:Logical Core: 8
2023-04-29 15:52:29,845:INFO:Checking libraries
2023-04-29 15:52:29,846:INFO:System:
2023-04-29 15:52:29,846:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:52:29,846:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:52:29,846:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:52:29,846:INFO:PyCaret required dependencies:
2023-04-29 15:52:29,846:INFO:                 pip: 22.2.2
2023-04-29 15:52:29,846:INFO:          setuptools: 63.4.1
2023-04-29 15:52:29,846:INFO:             pycaret: 3.0.0
2023-04-29 15:52:29,846:INFO:             IPython: 7.31.1
2023-04-29 15:52:29,846:INFO:          ipywidgets: 7.6.5
2023-04-29 15:52:29,846:INFO:                tqdm: 4.64.1
2023-04-29 15:52:29,846:INFO:               numpy: 1.21.5
2023-04-29 15:52:29,846:INFO:              pandas: 1.4.4
2023-04-29 15:52:29,846:INFO:              jinja2: 2.11.3
2023-04-29 15:52:29,846:INFO:               scipy: 1.9.1
2023-04-29 15:52:29,846:INFO:              joblib: 1.2.0
2023-04-29 15:52:29,846:INFO:             sklearn: 1.0.2
2023-04-29 15:52:29,846:INFO:                pyod: 1.0.9
2023-04-29 15:52:29,846:INFO:            imblearn: 0.10.1
2023-04-29 15:52:29,846:INFO:   category_encoders: 2.6.0
2023-04-29 15:52:29,846:INFO:            lightgbm: 3.3.5
2023-04-29 15:52:29,846:INFO:               numba: 0.55.1
2023-04-29 15:52:29,846:INFO:            requests: 2.28.1
2023-04-29 15:52:29,846:INFO:          matplotlib: 3.5.2
2023-04-29 15:52:29,846:INFO:          scikitplot: 0.3.7
2023-04-29 15:52:29,846:INFO:         yellowbrick: 1.5
2023-04-29 15:52:29,846:INFO:              plotly: 5.9.0
2023-04-29 15:52:29,846:INFO:             kaleido: 0.2.1
2023-04-29 15:52:29,846:INFO:         statsmodels: 0.13.2
2023-04-29 15:52:29,847:INFO:              sktime: 0.17.1
2023-04-29 15:52:29,847:INFO:               tbats: 1.1.2
2023-04-29 15:52:29,847:INFO:            pmdarima: 2.0.3
2023-04-29 15:52:29,847:INFO:              psutil: 5.9.0
2023-04-29 15:52:29,847:INFO:PyCaret optional dependencies:
2023-04-29 15:52:29,847:INFO:                shap: 0.41.0
2023-04-29 15:52:29,847:INFO:           interpret: Not installed
2023-04-29 15:52:29,847:INFO:                umap: Not installed
2023-04-29 15:52:29,847:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:52:29,847:INFO:  explainerdashboard: Not installed
2023-04-29 15:52:29,847:INFO:             autoviz: Not installed
2023-04-29 15:52:29,847:INFO:           fairlearn: Not installed
2023-04-29 15:52:29,847:INFO:             xgboost: Not installed
2023-04-29 15:52:29,847:INFO:            catboost: Not installed
2023-04-29 15:52:29,847:INFO:              kmodes: Not installed
2023-04-29 15:52:29,847:INFO:             mlxtend: Not installed
2023-04-29 15:52:29,847:INFO:       statsforecast: Not installed
2023-04-29 15:52:29,847:INFO:        tune_sklearn: Not installed
2023-04-29 15:52:29,847:INFO:                 ray: Not installed
2023-04-29 15:52:29,847:INFO:            hyperopt: Not installed
2023-04-29 15:52:29,847:INFO:              optuna: Not installed
2023-04-29 15:52:29,847:INFO:               skopt: Not installed
2023-04-29 15:52:29,847:INFO:              mlflow: 2.2.1
2023-04-29 15:52:29,847:INFO:              gradio: Not installed
2023-04-29 15:52:29,847:INFO:             fastapi: Not installed
2023-04-29 15:52:29,847:INFO:             uvicorn: Not installed
2023-04-29 15:52:29,847:INFO:              m2cgen: Not installed
2023-04-29 15:52:29,847:INFO:           evidently: Not installed
2023-04-29 15:52:29,847:INFO:               fugue: Not installed
2023-04-29 15:52:29,847:INFO:           streamlit: 1.21.0
2023-04-29 15:52:29,848:INFO:             prophet: Not installed
2023-04-29 15:52:29,848:INFO:None
2023-04-29 15:52:29,848:INFO:Set up data.
2023-04-29 15:53:33,366:INFO:PyCaret ClassificationExperiment
2023-04-29 15:53:33,366:INFO:Logging name: clf-default-name
2023-04-29 15:53:33,366:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 15:53:33,366:INFO:version 3.0.0
2023-04-29 15:53:33,366:INFO:Initializing setup()
2023-04-29 15:53:33,366:INFO:self.USI: 2a60
2023-04-29 15:53:33,366:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'fix_imbalance', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'pipeline', 'is_multiclass', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:53:33,367:INFO:Checking environment
2023-04-29 15:53:33,367:INFO:python_version: 3.9.13
2023-04-29 15:53:33,367:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:53:33,367:INFO:machine: AMD64
2023-04-29 15:53:33,367:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:53:33,367:INFO:Memory: svmem(total=16935899136, available=6330306560, percent=62.6, used=10605592576, free=6330306560)
2023-04-29 15:53:33,367:INFO:Physical Core: 4
2023-04-29 15:53:33,367:INFO:Logical Core: 8
2023-04-29 15:53:33,367:INFO:Checking libraries
2023-04-29 15:53:33,367:INFO:System:
2023-04-29 15:53:33,367:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:53:33,367:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:53:33,367:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:53:33,367:INFO:PyCaret required dependencies:
2023-04-29 15:53:33,367:INFO:                 pip: 22.2.2
2023-04-29 15:53:33,367:INFO:          setuptools: 63.4.1
2023-04-29 15:53:33,367:INFO:             pycaret: 3.0.0
2023-04-29 15:53:33,367:INFO:             IPython: 7.31.1
2023-04-29 15:53:33,367:INFO:          ipywidgets: 7.6.5
2023-04-29 15:53:33,367:INFO:                tqdm: 4.64.1
2023-04-29 15:53:33,367:INFO:               numpy: 1.21.5
2023-04-29 15:53:33,367:INFO:              pandas: 1.4.4
2023-04-29 15:53:33,367:INFO:              jinja2: 2.11.3
2023-04-29 15:53:33,367:INFO:               scipy: 1.9.1
2023-04-29 15:53:33,367:INFO:              joblib: 1.2.0
2023-04-29 15:53:33,367:INFO:             sklearn: 1.0.2
2023-04-29 15:53:33,368:INFO:                pyod: 1.0.9
2023-04-29 15:53:33,368:INFO:            imblearn: 0.10.1
2023-04-29 15:53:33,368:INFO:   category_encoders: 2.6.0
2023-04-29 15:53:33,368:INFO:            lightgbm: 3.3.5
2023-04-29 15:53:33,368:INFO:               numba: 0.55.1
2023-04-29 15:53:33,368:INFO:            requests: 2.28.1
2023-04-29 15:53:33,368:INFO:          matplotlib: 3.5.2
2023-04-29 15:53:33,368:INFO:          scikitplot: 0.3.7
2023-04-29 15:53:33,368:INFO:         yellowbrick: 1.5
2023-04-29 15:53:33,368:INFO:              plotly: 5.9.0
2023-04-29 15:53:33,368:INFO:             kaleido: 0.2.1
2023-04-29 15:53:33,368:INFO:         statsmodels: 0.13.2
2023-04-29 15:53:33,368:INFO:              sktime: 0.17.1
2023-04-29 15:53:33,368:INFO:               tbats: 1.1.2
2023-04-29 15:53:33,368:INFO:            pmdarima: 2.0.3
2023-04-29 15:53:33,368:INFO:              psutil: 5.9.0
2023-04-29 15:53:33,368:INFO:PyCaret optional dependencies:
2023-04-29 15:53:33,368:INFO:                shap: 0.41.0
2023-04-29 15:53:33,368:INFO:           interpret: Not installed
2023-04-29 15:53:33,368:INFO:                umap: Not installed
2023-04-29 15:53:33,368:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:53:33,368:INFO:  explainerdashboard: Not installed
2023-04-29 15:53:33,368:INFO:             autoviz: Not installed
2023-04-29 15:53:33,368:INFO:           fairlearn: Not installed
2023-04-29 15:53:33,368:INFO:             xgboost: Not installed
2023-04-29 15:53:33,368:INFO:            catboost: Not installed
2023-04-29 15:53:33,368:INFO:              kmodes: Not installed
2023-04-29 15:53:33,368:INFO:             mlxtend: Not installed
2023-04-29 15:53:33,368:INFO:       statsforecast: Not installed
2023-04-29 15:53:33,369:INFO:        tune_sklearn: Not installed
2023-04-29 15:53:33,369:INFO:                 ray: Not installed
2023-04-29 15:53:33,369:INFO:            hyperopt: Not installed
2023-04-29 15:53:33,369:INFO:              optuna: Not installed
2023-04-29 15:53:33,369:INFO:               skopt: Not installed
2023-04-29 15:53:33,369:INFO:              mlflow: 2.2.1
2023-04-29 15:53:33,369:INFO:              gradio: Not installed
2023-04-29 15:53:33,369:INFO:             fastapi: Not installed
2023-04-29 15:53:33,369:INFO:             uvicorn: Not installed
2023-04-29 15:53:33,369:INFO:              m2cgen: Not installed
2023-04-29 15:53:33,369:INFO:           evidently: Not installed
2023-04-29 15:53:33,369:INFO:               fugue: Not installed
2023-04-29 15:53:33,369:INFO:           streamlit: 1.21.0
2023-04-29 15:53:33,369:INFO:             prophet: Not installed
2023-04-29 15:53:33,369:INFO:None
2023-04-29 15:53:33,369:INFO:Set up data.
2023-04-29 15:54:33,282:INFO:PyCaret RegressionExperiment
2023-04-29 15:54:33,282:INFO:Logging name: reg-default-name
2023-04-29 15:54:33,282:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 15:54:33,282:INFO:version 3.0.0
2023-04-29 15:54:33,282:INFO:Initializing setup()
2023-04-29 15:54:33,282:INFO:self.USI: 351a
2023-04-29 15:54:33,283:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:54:33,283:INFO:Checking environment
2023-04-29 15:54:33,283:INFO:python_version: 3.9.13
2023-04-29 15:54:33,283:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:54:33,283:INFO:machine: AMD64
2023-04-29 15:54:33,283:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:54:33,283:INFO:Memory: svmem(total=16935899136, available=6391574528, percent=62.3, used=10544324608, free=6391574528)
2023-04-29 15:54:33,283:INFO:Physical Core: 4
2023-04-29 15:54:33,283:INFO:Logical Core: 8
2023-04-29 15:54:33,283:INFO:Checking libraries
2023-04-29 15:54:33,283:INFO:System:
2023-04-29 15:54:33,283:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:54:33,283:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:54:33,283:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:54:33,283:INFO:PyCaret required dependencies:
2023-04-29 15:54:33,283:INFO:                 pip: 22.2.2
2023-04-29 15:54:33,283:INFO:          setuptools: 63.4.1
2023-04-29 15:54:33,283:INFO:             pycaret: 3.0.0
2023-04-29 15:54:33,283:INFO:             IPython: 7.31.1
2023-04-29 15:54:33,283:INFO:          ipywidgets: 7.6.5
2023-04-29 15:54:33,283:INFO:                tqdm: 4.64.1
2023-04-29 15:54:33,283:INFO:               numpy: 1.21.5
2023-04-29 15:54:33,283:INFO:              pandas: 1.4.4
2023-04-29 15:54:33,283:INFO:              jinja2: 2.11.3
2023-04-29 15:54:33,284:INFO:               scipy: 1.9.1
2023-04-29 15:54:33,284:INFO:              joblib: 1.2.0
2023-04-29 15:54:33,284:INFO:             sklearn: 1.0.2
2023-04-29 15:54:33,284:INFO:                pyod: 1.0.9
2023-04-29 15:54:33,284:INFO:            imblearn: 0.10.1
2023-04-29 15:54:33,284:INFO:   category_encoders: 2.6.0
2023-04-29 15:54:33,284:INFO:            lightgbm: 3.3.5
2023-04-29 15:54:33,284:INFO:               numba: 0.55.1
2023-04-29 15:54:33,284:INFO:            requests: 2.28.1
2023-04-29 15:54:33,284:INFO:          matplotlib: 3.5.2
2023-04-29 15:54:33,284:INFO:          scikitplot: 0.3.7
2023-04-29 15:54:33,284:INFO:         yellowbrick: 1.5
2023-04-29 15:54:33,284:INFO:              plotly: 5.9.0
2023-04-29 15:54:33,284:INFO:             kaleido: 0.2.1
2023-04-29 15:54:33,285:INFO:         statsmodels: 0.13.2
2023-04-29 15:54:33,285:INFO:              sktime: 0.17.1
2023-04-29 15:54:33,285:INFO:               tbats: 1.1.2
2023-04-29 15:54:33,285:INFO:            pmdarima: 2.0.3
2023-04-29 15:54:33,285:INFO:              psutil: 5.9.0
2023-04-29 15:54:33,285:INFO:PyCaret optional dependencies:
2023-04-29 15:54:33,285:INFO:                shap: 0.41.0
2023-04-29 15:54:33,285:INFO:           interpret: Not installed
2023-04-29 15:54:33,285:INFO:                umap: Not installed
2023-04-29 15:54:33,285:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:54:33,285:INFO:  explainerdashboard: Not installed
2023-04-29 15:54:33,285:INFO:             autoviz: Not installed
2023-04-29 15:54:33,285:INFO:           fairlearn: Not installed
2023-04-29 15:54:33,285:INFO:             xgboost: Not installed
2023-04-29 15:54:33,285:INFO:            catboost: Not installed
2023-04-29 15:54:33,285:INFO:              kmodes: Not installed
2023-04-29 15:54:33,285:INFO:             mlxtend: Not installed
2023-04-29 15:54:33,285:INFO:       statsforecast: Not installed
2023-04-29 15:54:33,285:INFO:        tune_sklearn: Not installed
2023-04-29 15:54:33,285:INFO:                 ray: Not installed
2023-04-29 15:54:33,285:INFO:            hyperopt: Not installed
2023-04-29 15:54:33,285:INFO:              optuna: Not installed
2023-04-29 15:54:33,285:INFO:               skopt: Not installed
2023-04-29 15:54:33,285:INFO:              mlflow: 2.2.1
2023-04-29 15:54:33,285:INFO:              gradio: Not installed
2023-04-29 15:54:33,285:INFO:             fastapi: Not installed
2023-04-29 15:54:33,285:INFO:             uvicorn: Not installed
2023-04-29 15:54:33,285:INFO:              m2cgen: Not installed
2023-04-29 15:54:33,286:INFO:           evidently: Not installed
2023-04-29 15:54:33,286:INFO:               fugue: Not installed
2023-04-29 15:54:33,286:INFO:           streamlit: 1.21.0
2023-04-29 15:54:33,286:INFO:             prophet: Not installed
2023-04-29 15:54:33,286:INFO:None
2023-04-29 15:54:33,286:INFO:Set up data.
2023-04-29 15:59:06,253:INFO:PyCaret RegressionExperiment
2023-04-29 15:59:06,253:INFO:Logging name: reg-default-name
2023-04-29 15:59:06,253:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 15:59:06,253:INFO:version 3.0.0
2023-04-29 15:59:06,253:INFO:Initializing setup()
2023-04-29 15:59:06,253:INFO:self.USI: 244e
2023-04-29 15:59:06,253:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 15:59:06,253:INFO:Checking environment
2023-04-29 15:59:06,253:INFO:python_version: 3.9.13
2023-04-29 15:59:06,253:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 15:59:06,253:INFO:machine: AMD64
2023-04-29 15:59:06,253:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 15:59:06,253:INFO:Memory: svmem(total=16935899136, available=6486683648, percent=61.7, used=10449215488, free=6486683648)
2023-04-29 15:59:06,253:INFO:Physical Core: 4
2023-04-29 15:59:06,253:INFO:Logical Core: 8
2023-04-29 15:59:06,253:INFO:Checking libraries
2023-04-29 15:59:06,253:INFO:System:
2023-04-29 15:59:06,253:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 15:59:06,253:INFO:executable: D:\Anaconda\python.exe
2023-04-29 15:59:06,253:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 15:59:06,253:INFO:PyCaret required dependencies:
2023-04-29 15:59:06,253:INFO:                 pip: 22.2.2
2023-04-29 15:59:06,253:INFO:          setuptools: 63.4.1
2023-04-29 15:59:06,253:INFO:             pycaret: 3.0.0
2023-04-29 15:59:06,253:INFO:             IPython: 7.31.1
2023-04-29 15:59:06,253:INFO:          ipywidgets: 7.6.5
2023-04-29 15:59:06,253:INFO:                tqdm: 4.64.1
2023-04-29 15:59:06,253:INFO:               numpy: 1.21.5
2023-04-29 15:59:06,253:INFO:              pandas: 1.4.4
2023-04-29 15:59:06,253:INFO:              jinja2: 2.11.3
2023-04-29 15:59:06,253:INFO:               scipy: 1.9.1
2023-04-29 15:59:06,254:INFO:              joblib: 1.2.0
2023-04-29 15:59:06,254:INFO:             sklearn: 1.0.2
2023-04-29 15:59:06,254:INFO:                pyod: 1.0.9
2023-04-29 15:59:06,254:INFO:            imblearn: 0.10.1
2023-04-29 15:59:06,254:INFO:   category_encoders: 2.6.0
2023-04-29 15:59:06,254:INFO:            lightgbm: 3.3.5
2023-04-29 15:59:06,254:INFO:               numba: 0.55.1
2023-04-29 15:59:06,254:INFO:            requests: 2.28.1
2023-04-29 15:59:06,254:INFO:          matplotlib: 3.5.2
2023-04-29 15:59:06,254:INFO:          scikitplot: 0.3.7
2023-04-29 15:59:06,254:INFO:         yellowbrick: 1.5
2023-04-29 15:59:06,254:INFO:              plotly: 5.9.0
2023-04-29 15:59:06,254:INFO:             kaleido: 0.2.1
2023-04-29 15:59:06,254:INFO:         statsmodels: 0.13.2
2023-04-29 15:59:06,254:INFO:              sktime: 0.17.1
2023-04-29 15:59:06,254:INFO:               tbats: 1.1.2
2023-04-29 15:59:06,254:INFO:            pmdarima: 2.0.3
2023-04-29 15:59:06,254:INFO:              psutil: 5.9.0
2023-04-29 15:59:06,254:INFO:PyCaret optional dependencies:
2023-04-29 15:59:06,254:INFO:                shap: 0.41.0
2023-04-29 15:59:06,254:INFO:           interpret: Not installed
2023-04-29 15:59:06,254:INFO:                umap: Not installed
2023-04-29 15:59:06,254:INFO:    pandas_profiling: 4.1.2
2023-04-29 15:59:06,254:INFO:  explainerdashboard: Not installed
2023-04-29 15:59:06,254:INFO:             autoviz: Not installed
2023-04-29 15:59:06,254:INFO:           fairlearn: Not installed
2023-04-29 15:59:06,254:INFO:             xgboost: Not installed
2023-04-29 15:59:06,254:INFO:            catboost: Not installed
2023-04-29 15:59:06,254:INFO:              kmodes: Not installed
2023-04-29 15:59:06,254:INFO:             mlxtend: Not installed
2023-04-29 15:59:06,254:INFO:       statsforecast: Not installed
2023-04-29 15:59:06,255:INFO:        tune_sklearn: Not installed
2023-04-29 15:59:06,255:INFO:                 ray: Not installed
2023-04-29 15:59:06,255:INFO:            hyperopt: Not installed
2023-04-29 15:59:06,255:INFO:              optuna: Not installed
2023-04-29 15:59:06,255:INFO:               skopt: Not installed
2023-04-29 15:59:06,255:INFO:              mlflow: 2.2.1
2023-04-29 15:59:06,255:INFO:              gradio: Not installed
2023-04-29 15:59:06,255:INFO:             fastapi: Not installed
2023-04-29 15:59:06,255:INFO:             uvicorn: Not installed
2023-04-29 15:59:06,255:INFO:              m2cgen: Not installed
2023-04-29 15:59:06,255:INFO:           evidently: Not installed
2023-04-29 15:59:06,255:INFO:               fugue: Not installed
2023-04-29 15:59:06,255:INFO:           streamlit: 1.21.0
2023-04-29 15:59:06,255:INFO:             prophet: Not installed
2023-04-29 15:59:06,255:INFO:None
2023-04-29 15:59:06,255:INFO:Set up data.
2023-04-29 15:59:06,258:INFO:Set up train/test split.
2023-04-29 15:59:06,393:INFO:Set up index.
2023-04-29 15:59:06,393:INFO:Set up folding strategy.
2023-04-29 15:59:06,393:INFO:Assigning column types.
2023-04-29 15:59:06,397:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 15:59:06,397:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,404:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:06,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:06,917:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 15:59:06,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,027:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 15:59:07,031:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,137:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,238:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 15:59:07,247:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,299:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,352:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,454:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 15:59:07,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,669:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 15:59:07,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 15:59:07,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:07,882:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 15:59:08,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,215:INFO:Preparing preprocessing pipeline...
2023-04-29 15:59:08,215:INFO:Set up simple imputation.
2023-04-29 15:59:08,216:INFO:Set up column name cleaning.
2023-04-29 15:59:08,455:INFO:Finished creating preprocessing pipeline.
2023-04-29 15:59:08,462:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 15:59:08,462:INFO:Creating final display dataframe.
2023-04-29 15:59:08,582:INFO:Setup _display_container:                     Description             Value
0                    Session id              2578
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              244e
2023-04-29 15:59:08,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 15:59:08,908:INFO:setup() successfully completed in 2.8s...............
2023-04-29 15:59:09,029:INFO:Initializing compare_models()
2023-04-29 15:59:09,029:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 15:59:09,029:INFO:Checking exceptions
2023-04-29 15:59:09,034:INFO:Preparing display monitor
2023-04-29 15:59:09,055:INFO:Initializing Linear Regression
2023-04-29 15:59:09,056:INFO:Total runtime is 1.815160115559896e-05 minutes
2023-04-29 15:59:09,056:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:09,057:INFO:Initializing create_model()
2023-04-29 15:59:09,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:09,058:INFO:Checking exceptions
2023-04-29 15:59:09,058:INFO:Importing libraries
2023-04-29 15:59:09,058:INFO:Copying training dataset
2023-04-29 15:59:09,071:INFO:Defining folds
2023-04-29 15:59:09,071:INFO:Declaring metric variables
2023-04-29 15:59:09,071:INFO:Importing untrained model
2023-04-29 15:59:09,072:INFO:Linear Regression Imported successfully
2023-04-29 15:59:09,073:INFO:Starting cross validation
2023-04-29 15:59:09,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:19,366:INFO:Calculating mean and std
2023-04-29 15:59:19,367:INFO:Creating metrics dataframe
2023-04-29 15:59:19,775:INFO:Uploading results into container
2023-04-29 15:59:19,776:INFO:Uploading model into container now
2023-04-29 15:59:19,777:INFO:_master_model_container: 1
2023-04-29 15:59:19,777:INFO:_display_container: 2
2023-04-29 15:59:19,778:INFO:LinearRegression(n_jobs=-1)
2023-04-29 15:59:19,778:INFO:create_model() successfully completed......................................
2023-04-29 15:59:19,928:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:19,928:INFO:Creating metrics dataframe
2023-04-29 15:59:19,931:INFO:Initializing Lasso Regression
2023-04-29 15:59:19,931:INFO:Total runtime is 0.1812756061553955 minutes
2023-04-29 15:59:19,931:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:19,932:INFO:Initializing create_model()
2023-04-29 15:59:19,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:19,932:INFO:Checking exceptions
2023-04-29 15:59:19,932:INFO:Importing libraries
2023-04-29 15:59:19,932:INFO:Copying training dataset
2023-04-29 15:59:19,935:INFO:Defining folds
2023-04-29 15:59:19,935:INFO:Declaring metric variables
2023-04-29 15:59:19,935:INFO:Importing untrained model
2023-04-29 15:59:19,936:INFO:Lasso Regression Imported successfully
2023-04-29 15:59:19,936:INFO:Starting cross validation
2023-04-29 15:59:19,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:22,702:INFO:Calculating mean and std
2023-04-29 15:59:22,703:INFO:Creating metrics dataframe
2023-04-29 15:59:23,105:INFO:Uploading results into container
2023-04-29 15:59:23,106:INFO:Uploading model into container now
2023-04-29 15:59:23,107:INFO:_master_model_container: 2
2023-04-29 15:59:23,108:INFO:_display_container: 2
2023-04-29 15:59:23,108:INFO:Lasso(random_state=2578)
2023-04-29 15:59:23,108:INFO:create_model() successfully completed......................................
2023-04-29 15:59:23,255:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:23,256:INFO:Creating metrics dataframe
2023-04-29 15:59:23,267:INFO:Initializing Ridge Regression
2023-04-29 15:59:23,268:INFO:Total runtime is 0.2368884801864624 minutes
2023-04-29 15:59:23,268:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:23,269:INFO:Initializing create_model()
2023-04-29 15:59:23,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:23,269:INFO:Checking exceptions
2023-04-29 15:59:23,269:INFO:Importing libraries
2023-04-29 15:59:23,269:INFO:Copying training dataset
2023-04-29 15:59:23,279:INFO:Defining folds
2023-04-29 15:59:23,279:INFO:Declaring metric variables
2023-04-29 15:59:23,279:INFO:Importing untrained model
2023-04-29 15:59:23,279:INFO:Ridge Regression Imported successfully
2023-04-29 15:59:23,279:INFO:Starting cross validation
2023-04-29 15:59:23,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:26,306:INFO:Calculating mean and std
2023-04-29 15:59:26,308:INFO:Creating metrics dataframe
2023-04-29 15:59:26,801:INFO:Uploading results into container
2023-04-29 15:59:26,802:INFO:Uploading model into container now
2023-04-29 15:59:26,803:INFO:_master_model_container: 3
2023-04-29 15:59:26,803:INFO:_display_container: 2
2023-04-29 15:59:26,803:INFO:Ridge(random_state=2578)
2023-04-29 15:59:26,803:INFO:create_model() successfully completed......................................
2023-04-29 15:59:26,925:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:26,925:INFO:Creating metrics dataframe
2023-04-29 15:59:26,930:INFO:Initializing Elastic Net
2023-04-29 15:59:26,930:INFO:Total runtime is 0.2979125102361043 minutes
2023-04-29 15:59:26,930:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:26,930:INFO:Initializing create_model()
2023-04-29 15:59:26,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:26,930:INFO:Checking exceptions
2023-04-29 15:59:26,930:INFO:Importing libraries
2023-04-29 15:59:26,930:INFO:Copying training dataset
2023-04-29 15:59:26,933:INFO:Defining folds
2023-04-29 15:59:26,934:INFO:Declaring metric variables
2023-04-29 15:59:26,934:INFO:Importing untrained model
2023-04-29 15:59:26,934:INFO:Elastic Net Imported successfully
2023-04-29 15:59:26,935:INFO:Starting cross validation
2023-04-29 15:59:26,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:29,447:INFO:Calculating mean and std
2023-04-29 15:59:29,448:INFO:Creating metrics dataframe
2023-04-29 15:59:29,766:INFO:Uploading results into container
2023-04-29 15:59:29,767:INFO:Uploading model into container now
2023-04-29 15:59:29,767:INFO:_master_model_container: 4
2023-04-29 15:59:29,768:INFO:_display_container: 2
2023-04-29 15:59:29,768:INFO:ElasticNet(random_state=2578)
2023-04-29 15:59:29,768:INFO:create_model() successfully completed......................................
2023-04-29 15:59:29,886:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:29,886:INFO:Creating metrics dataframe
2023-04-29 15:59:29,898:INFO:Initializing Least Angle Regression
2023-04-29 15:59:29,899:INFO:Total runtime is 0.34739363988240557 minutes
2023-04-29 15:59:29,900:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:29,900:INFO:Initializing create_model()
2023-04-29 15:59:29,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:29,901:INFO:Checking exceptions
2023-04-29 15:59:29,901:INFO:Importing libraries
2023-04-29 15:59:29,901:INFO:Copying training dataset
2023-04-29 15:59:29,911:INFO:Defining folds
2023-04-29 15:59:29,911:INFO:Declaring metric variables
2023-04-29 15:59:29,911:INFO:Importing untrained model
2023-04-29 15:59:29,911:INFO:Least Angle Regression Imported successfully
2023-04-29 15:59:29,912:INFO:Starting cross validation
2023-04-29 15:59:29,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:30,150:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,150:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,150:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,151:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,152:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,152:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,152:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,153:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,898:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:30,954:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:33,810:INFO:Calculating mean and std
2023-04-29 15:59:33,820:INFO:Creating metrics dataframe
2023-04-29 15:59:34,327:INFO:Uploading results into container
2023-04-29 15:59:34,328:INFO:Uploading model into container now
2023-04-29 15:59:34,329:INFO:_master_model_container: 5
2023-04-29 15:59:34,329:INFO:_display_container: 2
2023-04-29 15:59:34,329:INFO:Lars(random_state=2578)
2023-04-29 15:59:34,329:INFO:create_model() successfully completed......................................
2023-04-29 15:59:34,495:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:34,495:INFO:Creating metrics dataframe
2023-04-29 15:59:34,508:INFO:Initializing Lasso Least Angle Regression
2023-04-29 15:59:34,509:INFO:Total runtime is 0.424228036403656 minutes
2023-04-29 15:59:34,509:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:34,509:INFO:Initializing create_model()
2023-04-29 15:59:34,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:34,510:INFO:Checking exceptions
2023-04-29 15:59:34,510:INFO:Importing libraries
2023-04-29 15:59:34,510:INFO:Copying training dataset
2023-04-29 15:59:34,515:INFO:Defining folds
2023-04-29 15:59:34,516:INFO:Declaring metric variables
2023-04-29 15:59:34,516:INFO:Importing untrained model
2023-04-29 15:59:34,517:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 15:59:34,518:INFO:Starting cross validation
2023-04-29 15:59:34,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:34,635:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,651:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,665:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,691:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,722:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,735:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,755:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:34,822:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:35,749:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:35,800:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 15:59:38,027:INFO:Calculating mean and std
2023-04-29 15:59:38,028:INFO:Creating metrics dataframe
2023-04-29 15:59:38,283:INFO:Uploading results into container
2023-04-29 15:59:38,284:INFO:Uploading model into container now
2023-04-29 15:59:38,285:INFO:_master_model_container: 6
2023-04-29 15:59:38,285:INFO:_display_container: 2
2023-04-29 15:59:38,285:INFO:LassoLars(random_state=2578)
2023-04-29 15:59:38,286:INFO:create_model() successfully completed......................................
2023-04-29 15:59:38,472:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:38,473:INFO:Creating metrics dataframe
2023-04-29 15:59:38,479:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 15:59:38,479:INFO:Total runtime is 0.4904005924860636 minutes
2023-04-29 15:59:38,479:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:38,479:INFO:Initializing create_model()
2023-04-29 15:59:38,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:38,479:INFO:Checking exceptions
2023-04-29 15:59:38,479:INFO:Importing libraries
2023-04-29 15:59:38,479:INFO:Copying training dataset
2023-04-29 15:59:38,483:INFO:Defining folds
2023-04-29 15:59:38,483:INFO:Declaring metric variables
2023-04-29 15:59:38,484:INFO:Importing untrained model
2023-04-29 15:59:38,484:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 15:59:38,484:INFO:Starting cross validation
2023-04-29 15:59:38,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:38,589:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,609:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,619:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,638:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,646:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,665:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,677:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:38,716:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:39,164:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:39,182:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 15:59:41,313:INFO:Calculating mean and std
2023-04-29 15:59:41,327:INFO:Creating metrics dataframe
2023-04-29 15:59:41,782:INFO:Uploading results into container
2023-04-29 15:59:41,783:INFO:Uploading model into container now
2023-04-29 15:59:41,784:INFO:_master_model_container: 7
2023-04-29 15:59:41,784:INFO:_display_container: 2
2023-04-29 15:59:41,784:INFO:OrthogonalMatchingPursuit()
2023-04-29 15:59:41,784:INFO:create_model() successfully completed......................................
2023-04-29 15:59:41,941:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:41,942:INFO:Creating metrics dataframe
2023-04-29 15:59:41,950:INFO:Initializing Bayesian Ridge
2023-04-29 15:59:41,950:INFO:Total runtime is 0.5482534011205037 minutes
2023-04-29 15:59:41,951:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:41,951:INFO:Initializing create_model()
2023-04-29 15:59:41,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:41,952:INFO:Checking exceptions
2023-04-29 15:59:41,952:INFO:Importing libraries
2023-04-29 15:59:41,952:INFO:Copying training dataset
2023-04-29 15:59:41,960:INFO:Defining folds
2023-04-29 15:59:41,960:INFO:Declaring metric variables
2023-04-29 15:59:41,960:INFO:Importing untrained model
2023-04-29 15:59:41,961:INFO:Bayesian Ridge Imported successfully
2023-04-29 15:59:41,962:INFO:Starting cross validation
2023-04-29 15:59:41,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:46,243:INFO:Calculating mean and std
2023-04-29 15:59:46,245:INFO:Creating metrics dataframe
2023-04-29 15:59:46,593:INFO:Uploading results into container
2023-04-29 15:59:46,594:INFO:Uploading model into container now
2023-04-29 15:59:46,594:INFO:_master_model_container: 8
2023-04-29 15:59:46,595:INFO:_display_container: 2
2023-04-29 15:59:46,595:INFO:BayesianRidge()
2023-04-29 15:59:46,595:INFO:create_model() successfully completed......................................
2023-04-29 15:59:46,738:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:46,738:INFO:Creating metrics dataframe
2023-04-29 15:59:46,743:INFO:Initializing Passive Aggressive Regressor
2023-04-29 15:59:46,744:INFO:Total runtime is 0.6281572381655375 minutes
2023-04-29 15:59:46,744:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:46,745:INFO:Initializing create_model()
2023-04-29 15:59:46,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:46,745:INFO:Checking exceptions
2023-04-29 15:59:46,745:INFO:Importing libraries
2023-04-29 15:59:46,745:INFO:Copying training dataset
2023-04-29 15:59:46,750:INFO:Defining folds
2023-04-29 15:59:46,750:INFO:Declaring metric variables
2023-04-29 15:59:46,750:INFO:Importing untrained model
2023-04-29 15:59:46,751:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 15:59:46,751:INFO:Starting cross validation
2023-04-29 15:59:46,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:49,974:INFO:Calculating mean and std
2023-04-29 15:59:49,975:INFO:Creating metrics dataframe
2023-04-29 15:59:50,415:INFO:Uploading results into container
2023-04-29 15:59:50,416:INFO:Uploading model into container now
2023-04-29 15:59:50,417:INFO:_master_model_container: 9
2023-04-29 15:59:50,417:INFO:_display_container: 2
2023-04-29 15:59:50,417:INFO:PassiveAggressiveRegressor(random_state=2578)
2023-04-29 15:59:50,417:INFO:create_model() successfully completed......................................
2023-04-29 15:59:50,561:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:50,561:INFO:Creating metrics dataframe
2023-04-29 15:59:50,568:INFO:Initializing Huber Regressor
2023-04-29 15:59:50,568:INFO:Total runtime is 0.6918889760971069 minutes
2023-04-29 15:59:50,569:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:50,570:INFO:Initializing create_model()
2023-04-29 15:59:50,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:50,570:INFO:Checking exceptions
2023-04-29 15:59:50,570:INFO:Importing libraries
2023-04-29 15:59:50,570:INFO:Copying training dataset
2023-04-29 15:59:50,579:INFO:Defining folds
2023-04-29 15:59:50,579:INFO:Declaring metric variables
2023-04-29 15:59:50,579:INFO:Importing untrained model
2023-04-29 15:59:50,580:INFO:Huber Regressor Imported successfully
2023-04-29 15:59:50,580:INFO:Starting cross validation
2023-04-29 15:59:50,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:53,772:INFO:Calculating mean and std
2023-04-29 15:59:53,773:INFO:Creating metrics dataframe
2023-04-29 15:59:54,066:INFO:Uploading results into container
2023-04-29 15:59:54,067:INFO:Uploading model into container now
2023-04-29 15:59:54,068:INFO:_master_model_container: 10
2023-04-29 15:59:54,068:INFO:_display_container: 2
2023-04-29 15:59:54,068:INFO:HuberRegressor()
2023-04-29 15:59:54,068:INFO:create_model() successfully completed......................................
2023-04-29 15:59:54,219:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:54,220:INFO:Creating metrics dataframe
2023-04-29 15:59:54,227:INFO:Initializing K Neighbors Regressor
2023-04-29 15:59:54,227:INFO:Total runtime is 0.75287100871404 minutes
2023-04-29 15:59:54,227:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:54,228:INFO:Initializing create_model()
2023-04-29 15:59:54,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:54,228:INFO:Checking exceptions
2023-04-29 15:59:54,228:INFO:Importing libraries
2023-04-29 15:59:54,228:INFO:Copying training dataset
2023-04-29 15:59:54,236:INFO:Defining folds
2023-04-29 15:59:54,236:INFO:Declaring metric variables
2023-04-29 15:59:54,236:INFO:Importing untrained model
2023-04-29 15:59:54,237:INFO:K Neighbors Regressor Imported successfully
2023-04-29 15:59:54,238:INFO:Starting cross validation
2023-04-29 15:59:54,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 15:59:57,530:INFO:Calculating mean and std
2023-04-29 15:59:57,531:INFO:Creating metrics dataframe
2023-04-29 15:59:57,814:INFO:Uploading results into container
2023-04-29 15:59:57,816:INFO:Uploading model into container now
2023-04-29 15:59:57,816:INFO:_master_model_container: 11
2023-04-29 15:59:57,816:INFO:_display_container: 2
2023-04-29 15:59:57,816:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 15:59:57,816:INFO:create_model() successfully completed......................................
2023-04-29 15:59:57,953:INFO:SubProcess create_model() end ==================================
2023-04-29 15:59:57,953:INFO:Creating metrics dataframe
2023-04-29 15:59:57,964:INFO:Initializing Decision Tree Regressor
2023-04-29 15:59:57,965:INFO:Total runtime is 0.8151485681533812 minutes
2023-04-29 15:59:57,965:INFO:SubProcess create_model() called ==================================
2023-04-29 15:59:57,965:INFO:Initializing create_model()
2023-04-29 15:59:57,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 15:59:57,966:INFO:Checking exceptions
2023-04-29 15:59:57,966:INFO:Importing libraries
2023-04-29 15:59:57,966:INFO:Copying training dataset
2023-04-29 15:59:57,974:INFO:Defining folds
2023-04-29 15:59:57,975:INFO:Declaring metric variables
2023-04-29 15:59:57,976:INFO:Importing untrained model
2023-04-29 15:59:57,976:INFO:Decision Tree Regressor Imported successfully
2023-04-29 15:59:57,976:INFO:Starting cross validation
2023-04-29 15:59:57,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:00,539:INFO:Calculating mean and std
2023-04-29 16:00:00,540:INFO:Creating metrics dataframe
2023-04-29 16:00:00,838:INFO:Uploading results into container
2023-04-29 16:00:00,839:INFO:Uploading model into container now
2023-04-29 16:00:00,839:INFO:_master_model_container: 12
2023-04-29 16:00:00,840:INFO:_display_container: 2
2023-04-29 16:00:00,840:INFO:DecisionTreeRegressor(random_state=2578)
2023-04-29 16:00:00,840:INFO:create_model() successfully completed......................................
2023-04-29 16:00:00,932:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:00,932:INFO:Creating metrics dataframe
2023-04-29 16:00:00,937:INFO:Initializing Random Forest Regressor
2023-04-29 16:00:00,937:INFO:Total runtime is 0.8646955887476602 minutes
2023-04-29 16:00:00,938:INFO:SubProcess create_model() called ==================================
2023-04-29 16:00:00,938:INFO:Initializing create_model()
2023-04-29 16:00:00,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:00,938:INFO:Checking exceptions
2023-04-29 16:00:00,938:INFO:Importing libraries
2023-04-29 16:00:00,938:INFO:Copying training dataset
2023-04-29 16:00:00,941:INFO:Defining folds
2023-04-29 16:00:00,941:INFO:Declaring metric variables
2023-04-29 16:00:00,942:INFO:Importing untrained model
2023-04-29 16:00:00,942:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:00:00,943:INFO:Starting cross validation
2023-04-29 16:00:00,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:05,114:INFO:Calculating mean and std
2023-04-29 16:00:05,115:INFO:Creating metrics dataframe
2023-04-29 16:00:05,396:INFO:Uploading results into container
2023-04-29 16:00:05,396:INFO:Uploading model into container now
2023-04-29 16:00:05,397:INFO:_master_model_container: 13
2023-04-29 16:00:05,397:INFO:_display_container: 2
2023-04-29 16:00:05,397:INFO:RandomForestRegressor(n_jobs=-1, random_state=2578)
2023-04-29 16:00:05,397:INFO:create_model() successfully completed......................................
2023-04-29 16:00:05,496:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:05,496:INFO:Creating metrics dataframe
2023-04-29 16:00:05,501:INFO:Initializing Extra Trees Regressor
2023-04-29 16:00:05,501:INFO:Total runtime is 0.9407627105712889 minutes
2023-04-29 16:00:05,501:INFO:SubProcess create_model() called ==================================
2023-04-29 16:00:05,502:INFO:Initializing create_model()
2023-04-29 16:00:05,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:05,502:INFO:Checking exceptions
2023-04-29 16:00:05,502:INFO:Importing libraries
2023-04-29 16:00:05,502:INFO:Copying training dataset
2023-04-29 16:00:05,506:INFO:Defining folds
2023-04-29 16:00:05,506:INFO:Declaring metric variables
2023-04-29 16:00:05,506:INFO:Importing untrained model
2023-04-29 16:00:05,507:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:00:05,507:INFO:Starting cross validation
2023-04-29 16:00:05,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:08,874:INFO:Calculating mean and std
2023-04-29 16:00:08,875:INFO:Creating metrics dataframe
2023-04-29 16:00:09,175:INFO:Uploading results into container
2023-04-29 16:00:09,176:INFO:Uploading model into container now
2023-04-29 16:00:09,176:INFO:_master_model_container: 14
2023-04-29 16:00:09,178:INFO:_display_container: 2
2023-04-29 16:00:09,178:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2578)
2023-04-29 16:00:09,178:INFO:create_model() successfully completed......................................
2023-04-29 16:00:09,277:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:09,277:INFO:Creating metrics dataframe
2023-04-29 16:00:09,283:INFO:Initializing AdaBoost Regressor
2023-04-29 16:00:09,283:INFO:Total runtime is 1.0037956754366555 minutes
2023-04-29 16:00:09,283:INFO:SubProcess create_model() called ==================================
2023-04-29 16:00:09,283:INFO:Initializing create_model()
2023-04-29 16:00:09,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:09,283:INFO:Checking exceptions
2023-04-29 16:00:09,283:INFO:Importing libraries
2023-04-29 16:00:09,283:INFO:Copying training dataset
2023-04-29 16:00:09,288:INFO:Defining folds
2023-04-29 16:00:09,289:INFO:Declaring metric variables
2023-04-29 16:00:09,289:INFO:Importing untrained model
2023-04-29 16:00:09,290:INFO:AdaBoost Regressor Imported successfully
2023-04-29 16:00:09,290:INFO:Starting cross validation
2023-04-29 16:00:09,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:12,375:INFO:Calculating mean and std
2023-04-29 16:00:12,376:INFO:Creating metrics dataframe
2023-04-29 16:00:12,688:INFO:Uploading results into container
2023-04-29 16:00:12,689:INFO:Uploading model into container now
2023-04-29 16:00:12,690:INFO:_master_model_container: 15
2023-04-29 16:00:12,690:INFO:_display_container: 2
2023-04-29 16:00:12,690:INFO:AdaBoostRegressor(random_state=2578)
2023-04-29 16:00:12,690:INFO:create_model() successfully completed......................................
2023-04-29 16:00:12,786:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:12,786:INFO:Creating metrics dataframe
2023-04-29 16:00:12,791:INFO:Initializing Gradient Boosting Regressor
2023-04-29 16:00:12,791:INFO:Total runtime is 1.0622724056243895 minutes
2023-04-29 16:00:12,791:INFO:SubProcess create_model() called ==================================
2023-04-29 16:00:12,791:INFO:Initializing create_model()
2023-04-29 16:00:12,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:12,791:INFO:Checking exceptions
2023-04-29 16:00:12,791:INFO:Importing libraries
2023-04-29 16:00:12,791:INFO:Copying training dataset
2023-04-29 16:00:12,796:INFO:Defining folds
2023-04-29 16:00:12,796:INFO:Declaring metric variables
2023-04-29 16:00:12,796:INFO:Importing untrained model
2023-04-29 16:00:12,796:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 16:00:12,797:INFO:Starting cross validation
2023-04-29 16:00:12,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:16,260:INFO:Calculating mean and std
2023-04-29 16:00:16,261:INFO:Creating metrics dataframe
2023-04-29 16:00:16,598:INFO:Uploading results into container
2023-04-29 16:00:16,599:INFO:Uploading model into container now
2023-04-29 16:00:16,599:INFO:_master_model_container: 16
2023-04-29 16:00:16,599:INFO:_display_container: 2
2023-04-29 16:00:16,599:INFO:GradientBoostingRegressor(random_state=2578)
2023-04-29 16:00:16,600:INFO:create_model() successfully completed......................................
2023-04-29 16:00:16,691:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:16,691:INFO:Creating metrics dataframe
2023-04-29 16:00:16,695:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 16:00:16,696:INFO:Total runtime is 1.1273451447486875 minutes
2023-04-29 16:00:16,696:INFO:SubProcess create_model() called ==================================
2023-04-29 16:00:16,696:INFO:Initializing create_model()
2023-04-29 16:00:16,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:16,696:INFO:Checking exceptions
2023-04-29 16:00:16,696:INFO:Importing libraries
2023-04-29 16:00:16,696:INFO:Copying training dataset
2023-04-29 16:00:16,700:INFO:Defining folds
2023-04-29 16:00:16,700:INFO:Declaring metric variables
2023-04-29 16:00:16,700:INFO:Importing untrained model
2023-04-29 16:00:16,700:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 16:00:16,701:INFO:Starting cross validation
2023-04-29 16:00:16,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:22,084:INFO:Calculating mean and std
2023-04-29 16:00:22,084:INFO:Creating metrics dataframe
2023-04-29 16:00:22,365:INFO:Uploading results into container
2023-04-29 16:00:22,366:INFO:Uploading model into container now
2023-04-29 16:00:22,366:INFO:_master_model_container: 17
2023-04-29 16:00:22,366:INFO:_display_container: 2
2023-04-29 16:00:22,367:INFO:LGBMRegressor(random_state=2578)
2023-04-29 16:00:22,367:INFO:create_model() successfully completed......................................
2023-04-29 16:00:22,472:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:22,472:INFO:Creating metrics dataframe
2023-04-29 16:00:22,476:INFO:Initializing Dummy Regressor
2023-04-29 16:00:22,476:INFO:Total runtime is 1.223678656419118 minutes
2023-04-29 16:00:22,476:INFO:SubProcess create_model() called ==================================
2023-04-29 16:00:22,476:INFO:Initializing create_model()
2023-04-29 16:00:22,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6CFA790>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:22,477:INFO:Checking exceptions
2023-04-29 16:00:22,477:INFO:Importing libraries
2023-04-29 16:00:22,477:INFO:Copying training dataset
2023-04-29 16:00:22,481:INFO:Defining folds
2023-04-29 16:00:22,481:INFO:Declaring metric variables
2023-04-29 16:00:22,481:INFO:Importing untrained model
2023-04-29 16:00:22,482:INFO:Dummy Regressor Imported successfully
2023-04-29 16:00:22,482:INFO:Starting cross validation
2023-04-29 16:00:22,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:00:24,937:INFO:Calculating mean and std
2023-04-29 16:00:24,938:INFO:Creating metrics dataframe
2023-04-29 16:00:25,196:INFO:Uploading results into container
2023-04-29 16:00:25,198:INFO:Uploading model into container now
2023-04-29 16:00:25,198:INFO:_master_model_container: 18
2023-04-29 16:00:25,198:INFO:_display_container: 2
2023-04-29 16:00:25,198:INFO:DummyRegressor()
2023-04-29 16:00:25,198:INFO:create_model() successfully completed......................................
2023-04-29 16:00:25,288:INFO:SubProcess create_model() end ==================================
2023-04-29 16:00:25,289:INFO:Creating metrics dataframe
2023-04-29 16:00:25,296:INFO:Initializing create_model()
2023-04-29 16:00:25,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B65D6910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=2578), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:00:25,296:INFO:Checking exceptions
2023-04-29 16:00:25,297:INFO:Importing libraries
2023-04-29 16:00:25,297:INFO:Copying training dataset
2023-04-29 16:00:25,301:INFO:Defining folds
2023-04-29 16:00:25,301:INFO:Declaring metric variables
2023-04-29 16:00:25,301:INFO:Importing untrained model
2023-04-29 16:00:25,301:INFO:Declaring custom model
2023-04-29 16:00:25,302:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:00:25,303:INFO:Cross validation set to False
2023-04-29 16:00:25,303:INFO:Fitting Model
2023-04-29 16:00:25,593:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2578)
2023-04-29 16:00:25,593:INFO:create_model() successfully completed......................................
2023-04-29 16:00:25,700:INFO:_master_model_container: 18
2023-04-29 16:00:25,701:INFO:_display_container: 2
2023-04-29 16:00:25,702:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2578)
2023-04-29 16:00:25,702:INFO:compare_models() successfully completed......................................
2023-04-29 16:02:24,707:INFO:PyCaret RegressionExperiment
2023-04-29 16:02:24,707:INFO:Logging name: reg-default-name
2023-04-29 16:02:24,707:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 16:02:24,707:INFO:version 3.0.0
2023-04-29 16:02:24,707:INFO:Initializing setup()
2023-04-29 16:02:24,707:INFO:self.USI: dce3
2023-04-29 16:02:24,707:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 16:02:24,707:INFO:Checking environment
2023-04-29 16:02:24,708:INFO:python_version: 3.9.13
2023-04-29 16:02:24,708:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 16:02:24,708:INFO:machine: AMD64
2023-04-29 16:02:24,708:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 16:02:24,708:INFO:Memory: svmem(total=16935899136, available=4947623936, percent=70.8, used=11988275200, free=4947623936)
2023-04-29 16:02:24,708:INFO:Physical Core: 4
2023-04-29 16:02:24,708:INFO:Logical Core: 8
2023-04-29 16:02:24,708:INFO:Checking libraries
2023-04-29 16:02:24,709:INFO:System:
2023-04-29 16:02:24,709:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 16:02:24,709:INFO:executable: D:\Anaconda\python.exe
2023-04-29 16:02:24,709:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 16:02:24,709:INFO:PyCaret required dependencies:
2023-04-29 16:02:24,709:INFO:                 pip: 22.2.2
2023-04-29 16:02:24,709:INFO:          setuptools: 63.4.1
2023-04-29 16:02:24,709:INFO:             pycaret: 3.0.0
2023-04-29 16:02:24,710:INFO:             IPython: 7.31.1
2023-04-29 16:02:24,710:INFO:          ipywidgets: 7.6.5
2023-04-29 16:02:24,710:INFO:                tqdm: 4.64.1
2023-04-29 16:02:24,710:INFO:               numpy: 1.21.5
2023-04-29 16:02:24,710:INFO:              pandas: 1.4.4
2023-04-29 16:02:24,710:INFO:              jinja2: 2.11.3
2023-04-29 16:02:24,710:INFO:               scipy: 1.9.1
2023-04-29 16:02:24,710:INFO:              joblib: 1.2.0
2023-04-29 16:02:24,710:INFO:             sklearn: 1.0.2
2023-04-29 16:02:24,710:INFO:                pyod: 1.0.9
2023-04-29 16:02:24,710:INFO:            imblearn: 0.10.1
2023-04-29 16:02:24,710:INFO:   category_encoders: 2.6.0
2023-04-29 16:02:24,710:INFO:            lightgbm: 3.3.5
2023-04-29 16:02:24,710:INFO:               numba: 0.55.1
2023-04-29 16:02:24,710:INFO:            requests: 2.28.1
2023-04-29 16:02:24,710:INFO:          matplotlib: 3.5.2
2023-04-29 16:02:24,710:INFO:          scikitplot: 0.3.7
2023-04-29 16:02:24,710:INFO:         yellowbrick: 1.5
2023-04-29 16:02:24,710:INFO:              plotly: 5.9.0
2023-04-29 16:02:24,710:INFO:             kaleido: 0.2.1
2023-04-29 16:02:24,710:INFO:         statsmodels: 0.13.2
2023-04-29 16:02:24,710:INFO:              sktime: 0.17.1
2023-04-29 16:02:24,710:INFO:               tbats: 1.1.2
2023-04-29 16:02:24,710:INFO:            pmdarima: 2.0.3
2023-04-29 16:02:24,710:INFO:              psutil: 5.9.0
2023-04-29 16:02:24,710:INFO:PyCaret optional dependencies:
2023-04-29 16:02:24,710:INFO:                shap: 0.41.0
2023-04-29 16:02:24,710:INFO:           interpret: Not installed
2023-04-29 16:02:24,710:INFO:                umap: Not installed
2023-04-29 16:02:24,712:INFO:    pandas_profiling: 4.1.2
2023-04-29 16:02:24,712:INFO:  explainerdashboard: Not installed
2023-04-29 16:02:24,712:INFO:             autoviz: Not installed
2023-04-29 16:02:24,712:INFO:           fairlearn: Not installed
2023-04-29 16:02:24,712:INFO:             xgboost: Not installed
2023-04-29 16:02:24,712:INFO:            catboost: Not installed
2023-04-29 16:02:24,712:INFO:              kmodes: Not installed
2023-04-29 16:02:24,712:INFO:             mlxtend: Not installed
2023-04-29 16:02:24,712:INFO:       statsforecast: Not installed
2023-04-29 16:02:24,712:INFO:        tune_sklearn: Not installed
2023-04-29 16:02:24,712:INFO:                 ray: Not installed
2023-04-29 16:02:24,712:INFO:            hyperopt: Not installed
2023-04-29 16:02:24,712:INFO:              optuna: Not installed
2023-04-29 16:02:24,712:INFO:               skopt: Not installed
2023-04-29 16:02:24,712:INFO:              mlflow: 2.2.1
2023-04-29 16:02:24,712:INFO:              gradio: Not installed
2023-04-29 16:02:24,712:INFO:             fastapi: Not installed
2023-04-29 16:02:24,712:INFO:             uvicorn: Not installed
2023-04-29 16:02:24,712:INFO:              m2cgen: Not installed
2023-04-29 16:02:24,712:INFO:           evidently: Not installed
2023-04-29 16:02:24,712:INFO:               fugue: Not installed
2023-04-29 16:02:24,712:INFO:           streamlit: 1.21.0
2023-04-29 16:02:24,712:INFO:             prophet: Not installed
2023-04-29 16:02:24,712:INFO:None
2023-04-29 16:02:24,712:INFO:Set up data.
2023-04-29 16:02:24,716:INFO:Set up train/test split.
2023-04-29 16:02:24,720:INFO:Set up index.
2023-04-29 16:02:24,720:INFO:Set up folding strategy.
2023-04-29 16:02:24,720:INFO:Assigning column types.
2023-04-29 16:02:24,722:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 16:02:24,722:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,726:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,732:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,793:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:24,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:24,845:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,849:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,853:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:24,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:24,954:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 16:02:24,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:02:24,963:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,083:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,088:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,187:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 16:02:25,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,359:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,403:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 16:02:25,469:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,622:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 16:02:25,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:02:25,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,842:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 16:02:25,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:25,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,055:INFO:Preparing preprocessing pipeline...
2023-04-29 16:02:26,055:INFO:Set up simple imputation.
2023-04-29 16:02:26,056:INFO:Set up column name cleaning.
2023-04-29 16:02:26,075:INFO:Finished creating preprocessing pipeline.
2023-04-29 16:02:26,078:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 16:02:26,079:INFO:Creating final display dataframe.
2023-04-29 16:02:26,148:INFO:Setup _display_container:                     Description             Value
0                    Session id              6608
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              dce3
2023-04-29 16:02:26,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:02:26,384:INFO:setup() successfully completed in 1.87s...............
2023-04-29 16:02:26,390:INFO:Initializing compare_models()
2023-04-29 16:02:26,390:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 16:02:26,390:INFO:Checking exceptions
2023-04-29 16:02:26,393:INFO:Preparing display monitor
2023-04-29 16:02:26,397:INFO:Initializing Linear Regression
2023-04-29 16:02:26,397:INFO:Total runtime is 0.0 minutes
2023-04-29 16:02:26,397:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:26,398:INFO:Initializing create_model()
2023-04-29 16:02:26,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:26,398:INFO:Checking exceptions
2023-04-29 16:02:26,398:INFO:Importing libraries
2023-04-29 16:02:26,398:INFO:Copying training dataset
2023-04-29 16:02:26,402:INFO:Defining folds
2023-04-29 16:02:26,402:INFO:Declaring metric variables
2023-04-29 16:02:26,403:INFO:Importing untrained model
2023-04-29 16:02:26,403:INFO:Linear Regression Imported successfully
2023-04-29 16:02:26,403:INFO:Starting cross validation
2023-04-29 16:02:26,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:28,727:INFO:Calculating mean and std
2023-04-29 16:02:28,728:INFO:Creating metrics dataframe
2023-04-29 16:02:29,041:INFO:Uploading results into container
2023-04-29 16:02:29,043:INFO:Uploading model into container now
2023-04-29 16:02:29,043:INFO:_master_model_container: 1
2023-04-29 16:02:29,043:INFO:_display_container: 2
2023-04-29 16:02:29,043:INFO:LinearRegression(n_jobs=-1)
2023-04-29 16:02:29,044:INFO:create_model() successfully completed......................................
2023-04-29 16:02:29,197:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:29,197:INFO:Creating metrics dataframe
2023-04-29 16:02:29,202:INFO:Initializing Lasso Regression
2023-04-29 16:02:29,202:INFO:Total runtime is 0.046757797400156655 minutes
2023-04-29 16:02:29,202:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:29,202:INFO:Initializing create_model()
2023-04-29 16:02:29,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:29,202:INFO:Checking exceptions
2023-04-29 16:02:29,202:INFO:Importing libraries
2023-04-29 16:02:29,203:INFO:Copying training dataset
2023-04-29 16:02:29,206:INFO:Defining folds
2023-04-29 16:02:29,207:INFO:Declaring metric variables
2023-04-29 16:02:29,207:INFO:Importing untrained model
2023-04-29 16:02:29,208:INFO:Lasso Regression Imported successfully
2023-04-29 16:02:29,208:INFO:Starting cross validation
2023-04-29 16:02:29,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:32,269:INFO:Calculating mean and std
2023-04-29 16:02:32,270:INFO:Creating metrics dataframe
2023-04-29 16:02:32,610:INFO:Uploading results into container
2023-04-29 16:02:32,611:INFO:Uploading model into container now
2023-04-29 16:02:32,612:INFO:_master_model_container: 2
2023-04-29 16:02:32,612:INFO:_display_container: 2
2023-04-29 16:02:32,612:INFO:Lasso(random_state=6608)
2023-04-29 16:02:32,612:INFO:create_model() successfully completed......................................
2023-04-29 16:02:32,743:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:32,743:INFO:Creating metrics dataframe
2023-04-29 16:02:32,756:INFO:Initializing Ridge Regression
2023-04-29 16:02:32,756:INFO:Total runtime is 0.10599201122919719 minutes
2023-04-29 16:02:32,757:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:32,757:INFO:Initializing create_model()
2023-04-29 16:02:32,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:32,758:INFO:Checking exceptions
2023-04-29 16:02:32,758:INFO:Importing libraries
2023-04-29 16:02:32,759:INFO:Copying training dataset
2023-04-29 16:02:32,768:INFO:Defining folds
2023-04-29 16:02:32,770:INFO:Declaring metric variables
2023-04-29 16:02:32,770:INFO:Importing untrained model
2023-04-29 16:02:32,771:INFO:Ridge Regression Imported successfully
2023-04-29 16:02:32,772:INFO:Starting cross validation
2023-04-29 16:02:32,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:35,686:INFO:Calculating mean and std
2023-04-29 16:02:35,688:INFO:Creating metrics dataframe
2023-04-29 16:02:36,258:INFO:Uploading results into container
2023-04-29 16:02:36,259:INFO:Uploading model into container now
2023-04-29 16:02:36,260:INFO:_master_model_container: 3
2023-04-29 16:02:36,260:INFO:_display_container: 2
2023-04-29 16:02:36,261:INFO:Ridge(random_state=6608)
2023-04-29 16:02:36,261:INFO:create_model() successfully completed......................................
2023-04-29 16:02:36,395:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:36,396:INFO:Creating metrics dataframe
2023-04-29 16:02:36,402:INFO:Initializing Elastic Net
2023-04-29 16:02:36,402:INFO:Total runtime is 0.1667531689008077 minutes
2023-04-29 16:02:36,402:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:36,403:INFO:Initializing create_model()
2023-04-29 16:02:36,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:36,403:INFO:Checking exceptions
2023-04-29 16:02:36,403:INFO:Importing libraries
2023-04-29 16:02:36,403:INFO:Copying training dataset
2023-04-29 16:02:36,407:INFO:Defining folds
2023-04-29 16:02:36,407:INFO:Declaring metric variables
2023-04-29 16:02:36,407:INFO:Importing untrained model
2023-04-29 16:02:36,408:INFO:Elastic Net Imported successfully
2023-04-29 16:02:36,409:INFO:Starting cross validation
2023-04-29 16:02:36,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:39,184:INFO:Calculating mean and std
2023-04-29 16:02:39,185:INFO:Creating metrics dataframe
2023-04-29 16:02:39,470:INFO:Uploading results into container
2023-04-29 16:02:39,470:INFO:Uploading model into container now
2023-04-29 16:02:39,471:INFO:_master_model_container: 4
2023-04-29 16:02:39,471:INFO:_display_container: 2
2023-04-29 16:02:39,471:INFO:ElasticNet(random_state=6608)
2023-04-29 16:02:39,471:INFO:create_model() successfully completed......................................
2023-04-29 16:02:39,618:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:39,618:INFO:Creating metrics dataframe
2023-04-29 16:02:39,634:INFO:Initializing Least Angle Regression
2023-04-29 16:02:39,634:INFO:Total runtime is 0.2206156849861145 minutes
2023-04-29 16:02:39,636:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:39,636:INFO:Initializing create_model()
2023-04-29 16:02:39,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:39,637:INFO:Checking exceptions
2023-04-29 16:02:39,637:INFO:Importing libraries
2023-04-29 16:02:39,637:INFO:Copying training dataset
2023-04-29 16:02:39,644:INFO:Defining folds
2023-04-29 16:02:39,644:INFO:Declaring metric variables
2023-04-29 16:02:39,645:INFO:Importing untrained model
2023-04-29 16:02:39,645:INFO:Least Angle Regression Imported successfully
2023-04-29 16:02:39,646:INFO:Starting cross validation
2023-04-29 16:02:39,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:39,727:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,746:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,776:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,783:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,801:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,819:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,834:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:39,864:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:40,262:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:40,366:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:42,836:INFO:Calculating mean and std
2023-04-29 16:02:42,838:INFO:Creating metrics dataframe
2023-04-29 16:02:43,203:INFO:Uploading results into container
2023-04-29 16:02:43,204:INFO:Uploading model into container now
2023-04-29 16:02:43,204:INFO:_master_model_container: 5
2023-04-29 16:02:43,205:INFO:_display_container: 2
2023-04-29 16:02:43,205:INFO:Lars(random_state=6608)
2023-04-29 16:02:43,206:INFO:create_model() successfully completed......................................
2023-04-29 16:02:43,343:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:43,344:INFO:Creating metrics dataframe
2023-04-29 16:02:43,349:INFO:Initializing Lasso Least Angle Regression
2023-04-29 16:02:43,349:INFO:Total runtime is 0.28253858486811323 minutes
2023-04-29 16:02:43,349:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:43,350:INFO:Initializing create_model()
2023-04-29 16:02:43,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:43,350:INFO:Checking exceptions
2023-04-29 16:02:43,350:INFO:Importing libraries
2023-04-29 16:02:43,350:INFO:Copying training dataset
2023-04-29 16:02:43,355:INFO:Defining folds
2023-04-29 16:02:43,355:INFO:Declaring metric variables
2023-04-29 16:02:43,355:INFO:Importing untrained model
2023-04-29 16:02:43,356:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 16:02:43,357:INFO:Starting cross validation
2023-04-29 16:02:43,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:43,460:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,470:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,486:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,504:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,508:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,524:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,540:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:43,557:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:44,129:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:44,134:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:02:46,344:INFO:Calculating mean and std
2023-04-29 16:02:46,345:INFO:Creating metrics dataframe
2023-04-29 16:02:46,889:INFO:Uploading results into container
2023-04-29 16:02:46,890:INFO:Uploading model into container now
2023-04-29 16:02:46,891:INFO:_master_model_container: 6
2023-04-29 16:02:46,892:INFO:_display_container: 2
2023-04-29 16:02:46,892:INFO:LassoLars(random_state=6608)
2023-04-29 16:02:46,893:INFO:create_model() successfully completed......................................
2023-04-29 16:02:47,047:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:47,048:INFO:Creating metrics dataframe
2023-04-29 16:02:47,060:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 16:02:47,060:INFO:Total runtime is 0.34438730478286744 minutes
2023-04-29 16:02:47,061:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:47,061:INFO:Initializing create_model()
2023-04-29 16:02:47,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:47,062:INFO:Checking exceptions
2023-04-29 16:02:47,063:INFO:Importing libraries
2023-04-29 16:02:47,063:INFO:Copying training dataset
2023-04-29 16:02:47,073:INFO:Defining folds
2023-04-29 16:02:47,073:INFO:Declaring metric variables
2023-04-29 16:02:47,073:INFO:Importing untrained model
2023-04-29 16:02:47,073:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 16:02:47,074:INFO:Starting cross validation
2023-04-29 16:02:47,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:47,183:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,192:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,203:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,212:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,235:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,241:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,257:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,274:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,831:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:47,836:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:02:49,851:INFO:Calculating mean and std
2023-04-29 16:02:49,852:INFO:Creating metrics dataframe
2023-04-29 16:02:50,275:INFO:Uploading results into container
2023-04-29 16:02:50,276:INFO:Uploading model into container now
2023-04-29 16:02:50,278:INFO:_master_model_container: 7
2023-04-29 16:02:50,278:INFO:_display_container: 2
2023-04-29 16:02:50,278:INFO:OrthogonalMatchingPursuit()
2023-04-29 16:02:50,278:INFO:create_model() successfully completed......................................
2023-04-29 16:02:50,419:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:50,420:INFO:Creating metrics dataframe
2023-04-29 16:02:50,432:INFO:Initializing Bayesian Ridge
2023-04-29 16:02:50,432:INFO:Total runtime is 0.40059683720270794 minutes
2023-04-29 16:02:50,432:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:50,433:INFO:Initializing create_model()
2023-04-29 16:02:50,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:50,433:INFO:Checking exceptions
2023-04-29 16:02:50,434:INFO:Importing libraries
2023-04-29 16:02:50,434:INFO:Copying training dataset
2023-04-29 16:02:50,441:INFO:Defining folds
2023-04-29 16:02:50,441:INFO:Declaring metric variables
2023-04-29 16:02:50,441:INFO:Importing untrained model
2023-04-29 16:02:50,442:INFO:Bayesian Ridge Imported successfully
2023-04-29 16:02:50,443:INFO:Starting cross validation
2023-04-29 16:02:50,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:53,690:INFO:Calculating mean and std
2023-04-29 16:02:53,691:INFO:Creating metrics dataframe
2023-04-29 16:02:54,065:INFO:Uploading results into container
2023-04-29 16:02:54,066:INFO:Uploading model into container now
2023-04-29 16:02:54,066:INFO:_master_model_container: 8
2023-04-29 16:02:54,066:INFO:_display_container: 2
2023-04-29 16:02:54,066:INFO:BayesianRidge()
2023-04-29 16:02:54,066:INFO:create_model() successfully completed......................................
2023-04-29 16:02:54,218:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:54,219:INFO:Creating metrics dataframe
2023-04-29 16:02:54,228:INFO:Initializing Passive Aggressive Regressor
2023-04-29 16:02:54,229:INFO:Total runtime is 0.4638479550679525 minutes
2023-04-29 16:02:54,229:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:54,229:INFO:Initializing create_model()
2023-04-29 16:02:54,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:54,230:INFO:Checking exceptions
2023-04-29 16:02:54,230:INFO:Importing libraries
2023-04-29 16:02:54,230:INFO:Copying training dataset
2023-04-29 16:02:54,238:INFO:Defining folds
2023-04-29 16:02:54,238:INFO:Declaring metric variables
2023-04-29 16:02:54,239:INFO:Importing untrained model
2023-04-29 16:02:54,239:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 16:02:54,239:INFO:Starting cross validation
2023-04-29 16:02:54,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:02:57,309:INFO:Calculating mean and std
2023-04-29 16:02:57,310:INFO:Creating metrics dataframe
2023-04-29 16:02:57,634:INFO:Uploading results into container
2023-04-29 16:02:57,635:INFO:Uploading model into container now
2023-04-29 16:02:57,636:INFO:_master_model_container: 9
2023-04-29 16:02:57,636:INFO:_display_container: 2
2023-04-29 16:02:57,636:INFO:PassiveAggressiveRegressor(random_state=6608)
2023-04-29 16:02:57,636:INFO:create_model() successfully completed......................................
2023-04-29 16:02:57,758:INFO:SubProcess create_model() end ==================================
2023-04-29 16:02:57,758:INFO:Creating metrics dataframe
2023-04-29 16:02:57,766:INFO:Initializing Huber Regressor
2023-04-29 16:02:57,766:INFO:Total runtime is 0.5228192408879598 minutes
2023-04-29 16:02:57,767:INFO:SubProcess create_model() called ==================================
2023-04-29 16:02:57,767:INFO:Initializing create_model()
2023-04-29 16:02:57,768:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:02:57,768:INFO:Checking exceptions
2023-04-29 16:02:57,768:INFO:Importing libraries
2023-04-29 16:02:57,768:INFO:Copying training dataset
2023-04-29 16:02:57,774:INFO:Defining folds
2023-04-29 16:02:57,774:INFO:Declaring metric variables
2023-04-29 16:02:57,774:INFO:Importing untrained model
2023-04-29 16:02:57,775:INFO:Huber Regressor Imported successfully
2023-04-29 16:02:57,777:INFO:Starting cross validation
2023-04-29 16:02:57,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:00,828:INFO:Calculating mean and std
2023-04-29 16:03:00,830:INFO:Creating metrics dataframe
2023-04-29 16:03:01,303:INFO:Uploading results into container
2023-04-29 16:03:01,305:INFO:Uploading model into container now
2023-04-29 16:03:01,305:INFO:_master_model_container: 10
2023-04-29 16:03:01,305:INFO:_display_container: 2
2023-04-29 16:03:01,305:INFO:HuberRegressor()
2023-04-29 16:03:01,305:INFO:create_model() successfully completed......................................
2023-04-29 16:03:01,446:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:01,447:INFO:Creating metrics dataframe
2023-04-29 16:03:01,456:INFO:Initializing K Neighbors Regressor
2023-04-29 16:03:01,456:INFO:Total runtime is 0.584321133295695 minutes
2023-04-29 16:03:01,456:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:01,457:INFO:Initializing create_model()
2023-04-29 16:03:01,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:01,457:INFO:Checking exceptions
2023-04-29 16:03:01,457:INFO:Importing libraries
2023-04-29 16:03:01,457:INFO:Copying training dataset
2023-04-29 16:03:01,465:INFO:Defining folds
2023-04-29 16:03:01,465:INFO:Declaring metric variables
2023-04-29 16:03:01,466:INFO:Importing untrained model
2023-04-29 16:03:01,467:INFO:K Neighbors Regressor Imported successfully
2023-04-29 16:03:01,467:INFO:Starting cross validation
2023-04-29 16:03:01,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:04,353:INFO:Calculating mean and std
2023-04-29 16:03:04,354:INFO:Creating metrics dataframe
2023-04-29 16:03:04,721:INFO:Uploading results into container
2023-04-29 16:03:04,722:INFO:Uploading model into container now
2023-04-29 16:03:04,723:INFO:_master_model_container: 11
2023-04-29 16:03:04,723:INFO:_display_container: 2
2023-04-29 16:03:04,723:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 16:03:04,723:INFO:create_model() successfully completed......................................
2023-04-29 16:03:04,861:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:04,861:INFO:Creating metrics dataframe
2023-04-29 16:03:04,870:INFO:Initializing Decision Tree Regressor
2023-04-29 16:03:04,870:INFO:Total runtime is 0.6412298242251079 minutes
2023-04-29 16:03:04,871:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:04,871:INFO:Initializing create_model()
2023-04-29 16:03:04,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:04,871:INFO:Checking exceptions
2023-04-29 16:03:04,872:INFO:Importing libraries
2023-04-29 16:03:04,872:INFO:Copying training dataset
2023-04-29 16:03:04,877:INFO:Defining folds
2023-04-29 16:03:04,878:INFO:Declaring metric variables
2023-04-29 16:03:04,878:INFO:Importing untrained model
2023-04-29 16:03:04,879:INFO:Decision Tree Regressor Imported successfully
2023-04-29 16:03:04,880:INFO:Starting cross validation
2023-04-29 16:03:04,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:07,564:INFO:Calculating mean and std
2023-04-29 16:03:07,565:INFO:Creating metrics dataframe
2023-04-29 16:03:07,880:INFO:Uploading results into container
2023-04-29 16:03:07,880:INFO:Uploading model into container now
2023-04-29 16:03:07,881:INFO:_master_model_container: 12
2023-04-29 16:03:07,881:INFO:_display_container: 2
2023-04-29 16:03:07,881:INFO:DecisionTreeRegressor(random_state=6608)
2023-04-29 16:03:07,881:INFO:create_model() successfully completed......................................
2023-04-29 16:03:08,009:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:08,010:INFO:Creating metrics dataframe
2023-04-29 16:03:08,015:INFO:Initializing Random Forest Regressor
2023-04-29 16:03:08,015:INFO:Total runtime is 0.6936377962430319 minutes
2023-04-29 16:03:08,015:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:08,015:INFO:Initializing create_model()
2023-04-29 16:03:08,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:08,015:INFO:Checking exceptions
2023-04-29 16:03:08,015:INFO:Importing libraries
2023-04-29 16:03:08,015:INFO:Copying training dataset
2023-04-29 16:03:08,018:INFO:Defining folds
2023-04-29 16:03:08,019:INFO:Declaring metric variables
2023-04-29 16:03:08,019:INFO:Importing untrained model
2023-04-29 16:03:08,019:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:03:08,020:INFO:Starting cross validation
2023-04-29 16:03:08,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:12,133:INFO:Calculating mean and std
2023-04-29 16:03:12,134:INFO:Creating metrics dataframe
2023-04-29 16:03:12,447:INFO:Uploading results into container
2023-04-29 16:03:12,448:INFO:Uploading model into container now
2023-04-29 16:03:12,448:INFO:_master_model_container: 13
2023-04-29 16:03:12,448:INFO:_display_container: 2
2023-04-29 16:03:12,448:INFO:RandomForestRegressor(n_jobs=-1, random_state=6608)
2023-04-29 16:03:12,448:INFO:create_model() successfully completed......................................
2023-04-29 16:03:12,598:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:12,599:INFO:Creating metrics dataframe
2023-04-29 16:03:12,611:INFO:Initializing Extra Trees Regressor
2023-04-29 16:03:12,611:INFO:Total runtime is 0.7702415784200033 minutes
2023-04-29 16:03:12,611:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:12,612:INFO:Initializing create_model()
2023-04-29 16:03:12,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:12,612:INFO:Checking exceptions
2023-04-29 16:03:12,612:INFO:Importing libraries
2023-04-29 16:03:12,612:INFO:Copying training dataset
2023-04-29 16:03:12,622:INFO:Defining folds
2023-04-29 16:03:12,622:INFO:Declaring metric variables
2023-04-29 16:03:12,622:INFO:Importing untrained model
2023-04-29 16:03:12,624:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:03:12,625:INFO:Starting cross validation
2023-04-29 16:03:12,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:16,796:INFO:Calculating mean and std
2023-04-29 16:03:16,797:INFO:Creating metrics dataframe
2023-04-29 16:03:17,271:INFO:Uploading results into container
2023-04-29 16:03:17,272:INFO:Uploading model into container now
2023-04-29 16:03:17,272:INFO:_master_model_container: 14
2023-04-29 16:03:17,273:INFO:_display_container: 2
2023-04-29 16:03:17,273:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6608)
2023-04-29 16:03:17,273:INFO:create_model() successfully completed......................................
2023-04-29 16:03:17,411:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:17,412:INFO:Creating metrics dataframe
2023-04-29 16:03:17,424:INFO:Initializing AdaBoost Regressor
2023-04-29 16:03:17,425:INFO:Total runtime is 0.85046812693278 minutes
2023-04-29 16:03:17,426:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:17,426:INFO:Initializing create_model()
2023-04-29 16:03:17,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:17,426:INFO:Checking exceptions
2023-04-29 16:03:17,426:INFO:Importing libraries
2023-04-29 16:03:17,426:INFO:Copying training dataset
2023-04-29 16:03:17,434:INFO:Defining folds
2023-04-29 16:03:17,434:INFO:Declaring metric variables
2023-04-29 16:03:17,435:INFO:Importing untrained model
2023-04-29 16:03:17,435:INFO:AdaBoost Regressor Imported successfully
2023-04-29 16:03:17,436:INFO:Starting cross validation
2023-04-29 16:03:17,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:20,138:INFO:Calculating mean and std
2023-04-29 16:03:20,139:INFO:Creating metrics dataframe
2023-04-29 16:03:20,420:INFO:Uploading results into container
2023-04-29 16:03:20,420:INFO:Uploading model into container now
2023-04-29 16:03:20,421:INFO:_master_model_container: 15
2023-04-29 16:03:20,421:INFO:_display_container: 2
2023-04-29 16:03:20,421:INFO:AdaBoostRegressor(random_state=6608)
2023-04-29 16:03:20,421:INFO:create_model() successfully completed......................................
2023-04-29 16:03:20,519:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:20,519:INFO:Creating metrics dataframe
2023-04-29 16:03:20,523:INFO:Initializing Gradient Boosting Regressor
2023-04-29 16:03:20,523:INFO:Total runtime is 0.9021085818608602 minutes
2023-04-29 16:03:20,523:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:20,523:INFO:Initializing create_model()
2023-04-29 16:03:20,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:20,524:INFO:Checking exceptions
2023-04-29 16:03:20,524:INFO:Importing libraries
2023-04-29 16:03:20,524:INFO:Copying training dataset
2023-04-29 16:03:20,529:INFO:Defining folds
2023-04-29 16:03:20,529:INFO:Declaring metric variables
2023-04-29 16:03:20,529:INFO:Importing untrained model
2023-04-29 16:03:20,530:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 16:03:20,530:INFO:Starting cross validation
2023-04-29 16:03:20,531:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:23,908:INFO:Calculating mean and std
2023-04-29 16:03:23,909:INFO:Creating metrics dataframe
2023-04-29 16:03:24,183:INFO:Uploading results into container
2023-04-29 16:03:24,184:INFO:Uploading model into container now
2023-04-29 16:03:24,184:INFO:_master_model_container: 16
2023-04-29 16:03:24,184:INFO:_display_container: 2
2023-04-29 16:03:24,184:INFO:GradientBoostingRegressor(random_state=6608)
2023-04-29 16:03:24,184:INFO:create_model() successfully completed......................................
2023-04-29 16:03:24,275:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:24,275:INFO:Creating metrics dataframe
2023-04-29 16:03:24,280:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 16:03:24,280:INFO:Total runtime is 0.9647207617759704 minutes
2023-04-29 16:03:24,281:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:24,281:INFO:Initializing create_model()
2023-04-29 16:03:24,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:24,281:INFO:Checking exceptions
2023-04-29 16:03:24,281:INFO:Importing libraries
2023-04-29 16:03:24,281:INFO:Copying training dataset
2023-04-29 16:03:24,285:INFO:Defining folds
2023-04-29 16:03:24,285:INFO:Declaring metric variables
2023-04-29 16:03:24,285:INFO:Importing untrained model
2023-04-29 16:03:24,286:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 16:03:24,286:INFO:Starting cross validation
2023-04-29 16:03:24,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:27,019:INFO:Calculating mean and std
2023-04-29 16:03:27,020:INFO:Creating metrics dataframe
2023-04-29 16:03:27,310:INFO:Uploading results into container
2023-04-29 16:03:27,311:INFO:Uploading model into container now
2023-04-29 16:03:27,311:INFO:_master_model_container: 17
2023-04-29 16:03:27,311:INFO:_display_container: 2
2023-04-29 16:03:27,311:INFO:LGBMRegressor(random_state=6608)
2023-04-29 16:03:27,311:INFO:create_model() successfully completed......................................
2023-04-29 16:03:27,452:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:27,452:INFO:Creating metrics dataframe
2023-04-29 16:03:27,458:INFO:Initializing Dummy Regressor
2023-04-29 16:03:27,459:INFO:Total runtime is 1.0177030165990193 minutes
2023-04-29 16:03:27,459:INFO:SubProcess create_model() called ==================================
2023-04-29 16:03:27,459:INFO:Initializing create_model()
2023-04-29 16:03:27,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B78A6EB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:27,459:INFO:Checking exceptions
2023-04-29 16:03:27,459:INFO:Importing libraries
2023-04-29 16:03:27,459:INFO:Copying training dataset
2023-04-29 16:03:27,464:INFO:Defining folds
2023-04-29 16:03:27,464:INFO:Declaring metric variables
2023-04-29 16:03:27,464:INFO:Importing untrained model
2023-04-29 16:03:27,465:INFO:Dummy Regressor Imported successfully
2023-04-29 16:03:27,465:INFO:Starting cross validation
2023-04-29 16:03:27,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:03:30,525:INFO:Calculating mean and std
2023-04-29 16:03:30,527:INFO:Creating metrics dataframe
2023-04-29 16:03:31,128:INFO:Uploading results into container
2023-04-29 16:03:31,129:INFO:Uploading model into container now
2023-04-29 16:03:31,129:INFO:_master_model_container: 18
2023-04-29 16:03:31,129:INFO:_display_container: 2
2023-04-29 16:03:31,129:INFO:DummyRegressor()
2023-04-29 16:03:31,130:INFO:create_model() successfully completed......................................
2023-04-29 16:03:31,251:INFO:SubProcess create_model() end ==================================
2023-04-29 16:03:31,251:INFO:Creating metrics dataframe
2023-04-29 16:03:31,262:INFO:Initializing create_model()
2023-04-29 16:03:31,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B67ECC10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6608), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:03:31,262:INFO:Checking exceptions
2023-04-29 16:03:31,264:INFO:Importing libraries
2023-04-29 16:03:31,264:INFO:Copying training dataset
2023-04-29 16:03:31,273:INFO:Defining folds
2023-04-29 16:03:31,273:INFO:Declaring metric variables
2023-04-29 16:03:31,274:INFO:Importing untrained model
2023-04-29 16:03:31,274:INFO:Declaring custom model
2023-04-29 16:03:31,276:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:03:31,278:INFO:Cross validation set to False
2023-04-29 16:03:31,278:INFO:Fitting Model
2023-04-29 16:03:31,749:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6608)
2023-04-29 16:03:31,749:INFO:create_model() successfully completed......................................
2023-04-29 16:03:31,957:INFO:_master_model_container: 18
2023-04-29 16:03:31,957:INFO:_display_container: 2
2023-04-29 16:03:31,958:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6608)
2023-04-29 16:03:31,958:INFO:compare_models() successfully completed......................................
2023-04-29 16:32:40,015:INFO:PyCaret RegressionExperiment
2023-04-29 16:32:40,015:INFO:Logging name: reg-default-name
2023-04-29 16:32:40,015:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 16:32:40,015:INFO:version 3.0.0
2023-04-29 16:32:40,015:INFO:Initializing setup()
2023-04-29 16:32:40,015:INFO:self.USI: 3b49
2023-04-29 16:32:40,015:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 16:32:40,015:INFO:Checking environment
2023-04-29 16:32:40,015:INFO:python_version: 3.9.13
2023-04-29 16:32:40,015:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 16:32:40,016:INFO:machine: AMD64
2023-04-29 16:32:40,016:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 16:32:40,016:INFO:Memory: svmem(total=16935899136, available=6613753856, percent=60.9, used=10322145280, free=6613753856)
2023-04-29 16:32:40,016:INFO:Physical Core: 4
2023-04-29 16:32:40,016:INFO:Logical Core: 8
2023-04-29 16:32:40,016:INFO:Checking libraries
2023-04-29 16:32:40,016:INFO:System:
2023-04-29 16:32:40,016:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 16:32:40,016:INFO:executable: D:\Anaconda\python.exe
2023-04-29 16:32:40,016:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 16:32:40,016:INFO:PyCaret required dependencies:
2023-04-29 16:32:40,016:INFO:                 pip: 22.2.2
2023-04-29 16:32:40,016:INFO:          setuptools: 63.4.1
2023-04-29 16:32:40,016:INFO:             pycaret: 3.0.0
2023-04-29 16:32:40,016:INFO:             IPython: 7.31.1
2023-04-29 16:32:40,016:INFO:          ipywidgets: 7.6.5
2023-04-29 16:32:40,016:INFO:                tqdm: 4.64.1
2023-04-29 16:32:40,016:INFO:               numpy: 1.21.5
2023-04-29 16:32:40,016:INFO:              pandas: 1.4.4
2023-04-29 16:32:40,016:INFO:              jinja2: 2.11.3
2023-04-29 16:32:40,016:INFO:               scipy: 1.9.1
2023-04-29 16:32:40,016:INFO:              joblib: 1.2.0
2023-04-29 16:32:40,016:INFO:             sklearn: 1.0.2
2023-04-29 16:32:40,016:INFO:                pyod: 1.0.9
2023-04-29 16:32:40,016:INFO:            imblearn: 0.10.1
2023-04-29 16:32:40,016:INFO:   category_encoders: 2.6.0
2023-04-29 16:32:40,016:INFO:            lightgbm: 3.3.5
2023-04-29 16:32:40,017:INFO:               numba: 0.55.1
2023-04-29 16:32:40,017:INFO:            requests: 2.28.1
2023-04-29 16:32:40,017:INFO:          matplotlib: 3.5.2
2023-04-29 16:32:40,017:INFO:          scikitplot: 0.3.7
2023-04-29 16:32:40,017:INFO:         yellowbrick: 1.5
2023-04-29 16:32:40,017:INFO:              plotly: 5.9.0
2023-04-29 16:32:40,017:INFO:             kaleido: 0.2.1
2023-04-29 16:32:40,017:INFO:         statsmodels: 0.13.2
2023-04-29 16:32:40,017:INFO:              sktime: 0.17.1
2023-04-29 16:32:40,017:INFO:               tbats: 1.1.2
2023-04-29 16:32:40,017:INFO:            pmdarima: 2.0.3
2023-04-29 16:32:40,017:INFO:              psutil: 5.9.0
2023-04-29 16:32:40,017:INFO:PyCaret optional dependencies:
2023-04-29 16:32:40,017:INFO:                shap: 0.41.0
2023-04-29 16:32:40,017:INFO:           interpret: Not installed
2023-04-29 16:32:40,017:INFO:                umap: Not installed
2023-04-29 16:32:40,017:INFO:    pandas_profiling: 4.1.2
2023-04-29 16:32:40,017:INFO:  explainerdashboard: Not installed
2023-04-29 16:32:40,017:INFO:             autoviz: Not installed
2023-04-29 16:32:40,017:INFO:           fairlearn: Not installed
2023-04-29 16:32:40,017:INFO:             xgboost: Not installed
2023-04-29 16:32:40,017:INFO:            catboost: Not installed
2023-04-29 16:32:40,017:INFO:              kmodes: Not installed
2023-04-29 16:32:40,017:INFO:             mlxtend: Not installed
2023-04-29 16:32:40,017:INFO:       statsforecast: Not installed
2023-04-29 16:32:40,017:INFO:        tune_sklearn: Not installed
2023-04-29 16:32:40,017:INFO:                 ray: Not installed
2023-04-29 16:32:40,017:INFO:            hyperopt: Not installed
2023-04-29 16:32:40,017:INFO:              optuna: Not installed
2023-04-29 16:32:40,017:INFO:               skopt: Not installed
2023-04-29 16:32:40,017:INFO:              mlflow: 2.2.1
2023-04-29 16:32:40,017:INFO:              gradio: Not installed
2023-04-29 16:32:40,018:INFO:             fastapi: Not installed
2023-04-29 16:32:40,018:INFO:             uvicorn: Not installed
2023-04-29 16:32:40,018:INFO:              m2cgen: Not installed
2023-04-29 16:32:40,018:INFO:           evidently: Not installed
2023-04-29 16:32:40,018:INFO:               fugue: Not installed
2023-04-29 16:32:40,018:INFO:           streamlit: 1.21.0
2023-04-29 16:32:40,018:INFO:             prophet: Not installed
2023-04-29 16:32:40,018:INFO:None
2023-04-29 16:32:40,018:INFO:Set up data.
2023-04-29 16:32:40,024:INFO:Set up train/test split.
2023-04-29 16:32:40,026:INFO:Set up index.
2023-04-29 16:32:40,026:INFO:Set up folding strategy.
2023-04-29 16:32:40,026:INFO:Assigning column types.
2023-04-29 16:32:40,029:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 16:32:40,029:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,033:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,139:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,146:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,265:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 16:32:40,271:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,275:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,383:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,387:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,498:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 16:32:40,507:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,562:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,618:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,724:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 16:32:40,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:32:40,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:40,951:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 16:32:41,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:41,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:32:41,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,205:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 16:32:41,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,460:INFO:Preparing preprocessing pipeline...
2023-04-29 16:32:41,460:INFO:Set up simple imputation.
2023-04-29 16:32:41,461:INFO:Set up column name cleaning.
2023-04-29 16:32:41,482:INFO:Finished creating preprocessing pipeline.
2023-04-29 16:32:41,486:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 16:32:41,487:INFO:Creating final display dataframe.
2023-04-29 16:32:41,564:INFO:Setup _display_container:                     Description             Value
0                    Session id              2722
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3b49
2023-04-29 16:32:41,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:32:41,817:INFO:setup() successfully completed in 2.0s...............
2023-04-29 16:32:41,821:INFO:Initializing compare_models()
2023-04-29 16:32:41,822:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 16:32:41,822:INFO:Checking exceptions
2023-04-29 16:32:41,825:INFO:Preparing display monitor
2023-04-29 16:32:41,829:INFO:Initializing Linear Regression
2023-04-29 16:32:41,830:INFO:Total runtime is 1.760721206665039e-05 minutes
2023-04-29 16:32:41,830:INFO:SubProcess create_model() called ==================================
2023-04-29 16:32:41,830:INFO:Initializing create_model()
2023-04-29 16:32:41,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:32:41,830:INFO:Checking exceptions
2023-04-29 16:32:41,830:INFO:Importing libraries
2023-04-29 16:32:41,830:INFO:Copying training dataset
2023-04-29 16:32:41,834:INFO:Defining folds
2023-04-29 16:32:41,834:INFO:Declaring metric variables
2023-04-29 16:32:41,835:INFO:Importing untrained model
2023-04-29 16:32:41,835:INFO:Linear Regression Imported successfully
2023-04-29 16:32:41,836:INFO:Starting cross validation
2023-04-29 16:32:41,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:32:51,750:INFO:Calculating mean and std
2023-04-29 16:32:51,751:INFO:Creating metrics dataframe
2023-04-29 16:32:52,064:INFO:Uploading results into container
2023-04-29 16:32:52,065:INFO:Uploading model into container now
2023-04-29 16:32:52,066:INFO:_master_model_container: 1
2023-04-29 16:32:52,066:INFO:_display_container: 2
2023-04-29 16:32:52,066:INFO:LinearRegression(n_jobs=-1)
2023-04-29 16:32:52,066:INFO:create_model() successfully completed......................................
2023-04-29 16:32:52,181:INFO:SubProcess create_model() end ==================================
2023-04-29 16:32:52,181:INFO:Creating metrics dataframe
2023-04-29 16:32:52,185:INFO:Initializing Lasso Regression
2023-04-29 16:32:52,185:INFO:Total runtime is 0.1725984255472819 minutes
2023-04-29 16:32:52,185:INFO:SubProcess create_model() called ==================================
2023-04-29 16:32:52,185:INFO:Initializing create_model()
2023-04-29 16:32:52,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:32:52,185:INFO:Checking exceptions
2023-04-29 16:32:52,185:INFO:Importing libraries
2023-04-29 16:32:52,185:INFO:Copying training dataset
2023-04-29 16:32:52,188:INFO:Defining folds
2023-04-29 16:32:52,188:INFO:Declaring metric variables
2023-04-29 16:32:52,188:INFO:Importing untrained model
2023-04-29 16:32:52,189:INFO:Lasso Regression Imported successfully
2023-04-29 16:32:52,189:INFO:Starting cross validation
2023-04-29 16:32:52,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:32:54,493:INFO:Calculating mean and std
2023-04-29 16:32:54,493:INFO:Creating metrics dataframe
2023-04-29 16:32:54,772:INFO:Uploading results into container
2023-04-29 16:32:54,774:INFO:Uploading model into container now
2023-04-29 16:32:54,774:INFO:_master_model_container: 2
2023-04-29 16:32:54,774:INFO:_display_container: 2
2023-04-29 16:32:54,774:INFO:Lasso(random_state=2722)
2023-04-29 16:32:54,774:INFO:create_model() successfully completed......................................
2023-04-29 16:32:54,864:INFO:SubProcess create_model() end ==================================
2023-04-29 16:32:54,864:INFO:Creating metrics dataframe
2023-04-29 16:32:54,868:INFO:Initializing Ridge Regression
2023-04-29 16:32:54,868:INFO:Total runtime is 0.21731220483779906 minutes
2023-04-29 16:32:54,868:INFO:SubProcess create_model() called ==================================
2023-04-29 16:32:54,868:INFO:Initializing create_model()
2023-04-29 16:32:54,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:32:54,868:INFO:Checking exceptions
2023-04-29 16:32:54,868:INFO:Importing libraries
2023-04-29 16:32:54,869:INFO:Copying training dataset
2023-04-29 16:32:54,871:INFO:Defining folds
2023-04-29 16:32:54,871:INFO:Declaring metric variables
2023-04-29 16:32:54,871:INFO:Importing untrained model
2023-04-29 16:32:54,872:INFO:Ridge Regression Imported successfully
2023-04-29 16:32:54,872:INFO:Starting cross validation
2023-04-29 16:32:54,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:32:57,237:INFO:Calculating mean and std
2023-04-29 16:32:57,238:INFO:Creating metrics dataframe
2023-04-29 16:32:57,530:INFO:Uploading results into container
2023-04-29 16:32:57,530:INFO:Uploading model into container now
2023-04-29 16:32:57,530:INFO:_master_model_container: 3
2023-04-29 16:32:57,530:INFO:_display_container: 2
2023-04-29 16:32:57,532:INFO:Ridge(random_state=2722)
2023-04-29 16:32:57,532:INFO:create_model() successfully completed......................................
2023-04-29 16:32:57,622:INFO:SubProcess create_model() end ==================================
2023-04-29 16:32:57,622:INFO:Creating metrics dataframe
2023-04-29 16:32:57,626:INFO:Initializing Elastic Net
2023-04-29 16:32:57,626:INFO:Total runtime is 0.2632909576098124 minutes
2023-04-29 16:32:57,626:INFO:SubProcess create_model() called ==================================
2023-04-29 16:32:57,627:INFO:Initializing create_model()
2023-04-29 16:32:57,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:32:57,627:INFO:Checking exceptions
2023-04-29 16:32:57,627:INFO:Importing libraries
2023-04-29 16:32:57,627:INFO:Copying training dataset
2023-04-29 16:32:57,631:INFO:Defining folds
2023-04-29 16:32:57,631:INFO:Declaring metric variables
2023-04-29 16:32:57,633:INFO:Importing untrained model
2023-04-29 16:32:57,633:INFO:Elastic Net Imported successfully
2023-04-29 16:32:57,633:INFO:Starting cross validation
2023-04-29 16:32:57,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:32:59,997:INFO:Calculating mean and std
2023-04-29 16:32:59,998:INFO:Creating metrics dataframe
2023-04-29 16:33:00,348:INFO:Uploading results into container
2023-04-29 16:33:00,349:INFO:Uploading model into container now
2023-04-29 16:33:00,350:INFO:_master_model_container: 4
2023-04-29 16:33:00,350:INFO:_display_container: 2
2023-04-29 16:33:00,350:INFO:ElasticNet(random_state=2722)
2023-04-29 16:33:00,350:INFO:create_model() successfully completed......................................
2023-04-29 16:33:00,445:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:00,446:INFO:Creating metrics dataframe
2023-04-29 16:33:00,450:INFO:Initializing Least Angle Regression
2023-04-29 16:33:00,450:INFO:Total runtime is 0.3103536367416382 minutes
2023-04-29 16:33:00,450:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:00,450:INFO:Initializing create_model()
2023-04-29 16:33:00,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:00,450:INFO:Checking exceptions
2023-04-29 16:33:00,450:INFO:Importing libraries
2023-04-29 16:33:00,450:INFO:Copying training dataset
2023-04-29 16:33:00,453:INFO:Defining folds
2023-04-29 16:33:00,454:INFO:Declaring metric variables
2023-04-29 16:33:00,454:INFO:Importing untrained model
2023-04-29 16:33:00,454:INFO:Least Angle Regression Imported successfully
2023-04-29 16:33:00,454:INFO:Starting cross validation
2023-04-29 16:33:00,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:00,525:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,538:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,551:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,572:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,583:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,600:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,615:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:00,630:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:01,195:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:01,262:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:02,944:INFO:Calculating mean and std
2023-04-29 16:33:02,944:INFO:Creating metrics dataframe
2023-04-29 16:33:03,326:INFO:Uploading results into container
2023-04-29 16:33:03,327:INFO:Uploading model into container now
2023-04-29 16:33:03,327:INFO:_master_model_container: 5
2023-04-29 16:33:03,328:INFO:_display_container: 2
2023-04-29 16:33:03,328:INFO:Lars(random_state=2722)
2023-04-29 16:33:03,328:INFO:create_model() successfully completed......................................
2023-04-29 16:33:03,432:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:03,433:INFO:Creating metrics dataframe
2023-04-29 16:33:03,438:INFO:Initializing Lasso Least Angle Regression
2023-04-29 16:33:03,438:INFO:Total runtime is 0.3601560513178508 minutes
2023-04-29 16:33:03,438:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:03,439:INFO:Initializing create_model()
2023-04-29 16:33:03,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:03,439:INFO:Checking exceptions
2023-04-29 16:33:03,439:INFO:Importing libraries
2023-04-29 16:33:03,439:INFO:Copying training dataset
2023-04-29 16:33:03,443:INFO:Defining folds
2023-04-29 16:33:03,444:INFO:Declaring metric variables
2023-04-29 16:33:03,444:INFO:Importing untrained model
2023-04-29 16:33:03,445:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 16:33:03,445:INFO:Starting cross validation
2023-04-29 16:33:03,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:03,537:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,541:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,558:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,572:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,593:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,614:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,638:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:03,652:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:04,385:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:04,453:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:33:06,333:INFO:Calculating mean and std
2023-04-29 16:33:06,334:INFO:Creating metrics dataframe
2023-04-29 16:33:06,702:INFO:Uploading results into container
2023-04-29 16:33:06,703:INFO:Uploading model into container now
2023-04-29 16:33:06,703:INFO:_master_model_container: 6
2023-04-29 16:33:06,703:INFO:_display_container: 2
2023-04-29 16:33:06,704:INFO:LassoLars(random_state=2722)
2023-04-29 16:33:06,704:INFO:create_model() successfully completed......................................
2023-04-29 16:33:06,807:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:06,807:INFO:Creating metrics dataframe
2023-04-29 16:33:06,814:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 16:33:06,814:INFO:Total runtime is 0.41642330090204877 minutes
2023-04-29 16:33:06,814:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:06,815:INFO:Initializing create_model()
2023-04-29 16:33:06,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:06,815:INFO:Checking exceptions
2023-04-29 16:33:06,815:INFO:Importing libraries
2023-04-29 16:33:06,815:INFO:Copying training dataset
2023-04-29 16:33:06,821:INFO:Defining folds
2023-04-29 16:33:06,822:INFO:Declaring metric variables
2023-04-29 16:33:06,822:INFO:Importing untrained model
2023-04-29 16:33:06,823:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 16:33:06,824:INFO:Starting cross validation
2023-04-29 16:33:06,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:06,881:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:06,895:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:06,914:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:06,937:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:06,950:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:06,969:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:06,983:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:07,003:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:07,700:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:07,733:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:33:09,321:INFO:Calculating mean and std
2023-04-29 16:33:09,322:INFO:Creating metrics dataframe
2023-04-29 16:33:09,698:INFO:Uploading results into container
2023-04-29 16:33:09,699:INFO:Uploading model into container now
2023-04-29 16:33:09,700:INFO:_master_model_container: 7
2023-04-29 16:33:09,700:INFO:_display_container: 2
2023-04-29 16:33:09,700:INFO:OrthogonalMatchingPursuit()
2023-04-29 16:33:09,700:INFO:create_model() successfully completed......................................
2023-04-29 16:33:09,800:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:09,800:INFO:Creating metrics dataframe
2023-04-29 16:33:09,805:INFO:Initializing Bayesian Ridge
2023-04-29 16:33:09,805:INFO:Total runtime is 0.46626593271891276 minutes
2023-04-29 16:33:09,805:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:09,805:INFO:Initializing create_model()
2023-04-29 16:33:09,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:09,805:INFO:Checking exceptions
2023-04-29 16:33:09,805:INFO:Importing libraries
2023-04-29 16:33:09,805:INFO:Copying training dataset
2023-04-29 16:33:09,808:INFO:Defining folds
2023-04-29 16:33:09,808:INFO:Declaring metric variables
2023-04-29 16:33:09,808:INFO:Importing untrained model
2023-04-29 16:33:09,809:INFO:Bayesian Ridge Imported successfully
2023-04-29 16:33:09,809:INFO:Starting cross validation
2023-04-29 16:33:09,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:12,707:INFO:Calculating mean and std
2023-04-29 16:33:12,708:INFO:Creating metrics dataframe
2023-04-29 16:33:13,020:INFO:Uploading results into container
2023-04-29 16:33:13,024:INFO:Uploading model into container now
2023-04-29 16:33:13,026:INFO:_master_model_container: 8
2023-04-29 16:33:13,026:INFO:_display_container: 2
2023-04-29 16:33:13,026:INFO:BayesianRidge()
2023-04-29 16:33:13,027:INFO:create_model() successfully completed......................................
2023-04-29 16:33:13,121:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:13,122:INFO:Creating metrics dataframe
2023-04-29 16:33:13,126:INFO:Initializing Passive Aggressive Regressor
2023-04-29 16:33:13,127:INFO:Total runtime is 0.5216175436973571 minutes
2023-04-29 16:33:13,127:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:13,127:INFO:Initializing create_model()
2023-04-29 16:33:13,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:13,127:INFO:Checking exceptions
2023-04-29 16:33:13,127:INFO:Importing libraries
2023-04-29 16:33:13,127:INFO:Copying training dataset
2023-04-29 16:33:13,130:INFO:Defining folds
2023-04-29 16:33:13,131:INFO:Declaring metric variables
2023-04-29 16:33:13,131:INFO:Importing untrained model
2023-04-29 16:33:13,132:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 16:33:13,133:INFO:Starting cross validation
2023-04-29 16:33:13,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:16,355:INFO:Calculating mean and std
2023-04-29 16:33:16,356:INFO:Creating metrics dataframe
2023-04-29 16:33:16,780:INFO:Uploading results into container
2023-04-29 16:33:16,781:INFO:Uploading model into container now
2023-04-29 16:33:16,782:INFO:_master_model_container: 9
2023-04-29 16:33:16,782:INFO:_display_container: 2
2023-04-29 16:33:16,782:INFO:PassiveAggressiveRegressor(random_state=2722)
2023-04-29 16:33:16,782:INFO:create_model() successfully completed......................................
2023-04-29 16:33:16,934:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:16,934:INFO:Creating metrics dataframe
2023-04-29 16:33:16,941:INFO:Initializing Huber Regressor
2023-04-29 16:33:16,942:INFO:Total runtime is 0.5852249145507812 minutes
2023-04-29 16:33:16,942:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:16,944:INFO:Initializing create_model()
2023-04-29 16:33:16,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:16,944:INFO:Checking exceptions
2023-04-29 16:33:16,944:INFO:Importing libraries
2023-04-29 16:33:16,944:INFO:Copying training dataset
2023-04-29 16:33:16,951:INFO:Defining folds
2023-04-29 16:33:16,951:INFO:Declaring metric variables
2023-04-29 16:33:16,951:INFO:Importing untrained model
2023-04-29 16:33:16,951:INFO:Huber Regressor Imported successfully
2023-04-29 16:33:16,953:INFO:Starting cross validation
2023-04-29 16:33:16,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:17,242:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 16:33:20,605:INFO:Calculating mean and std
2023-04-29 16:33:20,606:INFO:Creating metrics dataframe
2023-04-29 16:33:20,973:INFO:Uploading results into container
2023-04-29 16:33:20,973:INFO:Uploading model into container now
2023-04-29 16:33:20,974:INFO:_master_model_container: 10
2023-04-29 16:33:20,974:INFO:_display_container: 2
2023-04-29 16:33:20,974:INFO:HuberRegressor()
2023-04-29 16:33:20,974:INFO:create_model() successfully completed......................................
2023-04-29 16:33:21,072:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:21,072:INFO:Creating metrics dataframe
2023-04-29 16:33:21,078:INFO:Initializing K Neighbors Regressor
2023-04-29 16:33:21,078:INFO:Total runtime is 0.6541451215744017 minutes
2023-04-29 16:33:21,078:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:21,079:INFO:Initializing create_model()
2023-04-29 16:33:21,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:21,079:INFO:Checking exceptions
2023-04-29 16:33:21,079:INFO:Importing libraries
2023-04-29 16:33:21,079:INFO:Copying training dataset
2023-04-29 16:33:21,087:INFO:Defining folds
2023-04-29 16:33:21,087:INFO:Declaring metric variables
2023-04-29 16:33:21,087:INFO:Importing untrained model
2023-04-29 16:33:21,088:INFO:K Neighbors Regressor Imported successfully
2023-04-29 16:33:21,088:INFO:Starting cross validation
2023-04-29 16:33:21,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:23,861:INFO:Calculating mean and std
2023-04-29 16:33:23,863:INFO:Creating metrics dataframe
2023-04-29 16:33:24,242:INFO:Uploading results into container
2023-04-29 16:33:24,243:INFO:Uploading model into container now
2023-04-29 16:33:24,244:INFO:_master_model_container: 11
2023-04-29 16:33:24,244:INFO:_display_container: 2
2023-04-29 16:33:24,244:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 16:33:24,244:INFO:create_model() successfully completed......................................
2023-04-29 16:33:24,342:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:24,342:INFO:Creating metrics dataframe
2023-04-29 16:33:24,347:INFO:Initializing Decision Tree Regressor
2023-04-29 16:33:24,347:INFO:Total runtime is 0.7086314280827839 minutes
2023-04-29 16:33:24,348:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:24,348:INFO:Initializing create_model()
2023-04-29 16:33:24,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:24,348:INFO:Checking exceptions
2023-04-29 16:33:24,348:INFO:Importing libraries
2023-04-29 16:33:24,348:INFO:Copying training dataset
2023-04-29 16:33:24,351:INFO:Defining folds
2023-04-29 16:33:24,352:INFO:Declaring metric variables
2023-04-29 16:33:24,352:INFO:Importing untrained model
2023-04-29 16:33:24,352:INFO:Decision Tree Regressor Imported successfully
2023-04-29 16:33:24,353:INFO:Starting cross validation
2023-04-29 16:33:24,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:27,609:INFO:Calculating mean and std
2023-04-29 16:33:27,610:INFO:Creating metrics dataframe
2023-04-29 16:33:27,949:INFO:Uploading results into container
2023-04-29 16:33:27,949:INFO:Uploading model into container now
2023-04-29 16:33:27,950:INFO:_master_model_container: 12
2023-04-29 16:33:27,950:INFO:_display_container: 2
2023-04-29 16:33:27,950:INFO:DecisionTreeRegressor(random_state=2722)
2023-04-29 16:33:27,950:INFO:create_model() successfully completed......................................
2023-04-29 16:33:28,071:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:28,071:INFO:Creating metrics dataframe
2023-04-29 16:33:28,075:INFO:Initializing Random Forest Regressor
2023-04-29 16:33:28,076:INFO:Total runtime is 0.7707840085029601 minutes
2023-04-29 16:33:28,076:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:28,076:INFO:Initializing create_model()
2023-04-29 16:33:28,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:28,076:INFO:Checking exceptions
2023-04-29 16:33:28,076:INFO:Importing libraries
2023-04-29 16:33:28,076:INFO:Copying training dataset
2023-04-29 16:33:28,079:INFO:Defining folds
2023-04-29 16:33:28,079:INFO:Declaring metric variables
2023-04-29 16:33:28,080:INFO:Importing untrained model
2023-04-29 16:33:28,080:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:33:28,081:INFO:Starting cross validation
2023-04-29 16:33:28,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:32,223:INFO:Calculating mean and std
2023-04-29 16:33:32,223:INFO:Creating metrics dataframe
2023-04-29 16:33:32,635:INFO:Uploading results into container
2023-04-29 16:33:32,636:INFO:Uploading model into container now
2023-04-29 16:33:32,636:INFO:_master_model_container: 13
2023-04-29 16:33:32,636:INFO:_display_container: 2
2023-04-29 16:33:32,637:INFO:RandomForestRegressor(n_jobs=-1, random_state=2722)
2023-04-29 16:33:32,637:INFO:create_model() successfully completed......................................
2023-04-29 16:33:32,737:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:32,737:INFO:Creating metrics dataframe
2023-04-29 16:33:32,741:INFO:Initializing Extra Trees Regressor
2023-04-29 16:33:32,741:INFO:Total runtime is 0.8485278447469075 minutes
2023-04-29 16:33:32,741:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:32,741:INFO:Initializing create_model()
2023-04-29 16:33:32,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:32,741:INFO:Checking exceptions
2023-04-29 16:33:32,741:INFO:Importing libraries
2023-04-29 16:33:32,741:INFO:Copying training dataset
2023-04-29 16:33:32,744:INFO:Defining folds
2023-04-29 16:33:32,744:INFO:Declaring metric variables
2023-04-29 16:33:32,744:INFO:Importing untrained model
2023-04-29 16:33:32,746:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:33:32,747:INFO:Starting cross validation
2023-04-29 16:33:32,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:36,512:INFO:Calculating mean and std
2023-04-29 16:33:36,513:INFO:Creating metrics dataframe
2023-04-29 16:33:36,837:INFO:Uploading results into container
2023-04-29 16:33:36,838:INFO:Uploading model into container now
2023-04-29 16:33:36,838:INFO:_master_model_container: 14
2023-04-29 16:33:36,838:INFO:_display_container: 2
2023-04-29 16:33:36,839:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2722)
2023-04-29 16:33:36,839:INFO:create_model() successfully completed......................................
2023-04-29 16:33:36,937:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:36,938:INFO:Creating metrics dataframe
2023-04-29 16:33:36,942:INFO:Initializing AdaBoost Regressor
2023-04-29 16:33:36,942:INFO:Total runtime is 0.9185523390769957 minutes
2023-04-29 16:33:36,942:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:36,942:INFO:Initializing create_model()
2023-04-29 16:33:36,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:36,942:INFO:Checking exceptions
2023-04-29 16:33:36,942:INFO:Importing libraries
2023-04-29 16:33:36,942:INFO:Copying training dataset
2023-04-29 16:33:36,948:INFO:Defining folds
2023-04-29 16:33:36,948:INFO:Declaring metric variables
2023-04-29 16:33:36,948:INFO:Importing untrained model
2023-04-29 16:33:36,949:INFO:AdaBoost Regressor Imported successfully
2023-04-29 16:33:36,949:INFO:Starting cross validation
2023-04-29 16:33:36,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:40,193:INFO:Calculating mean and std
2023-04-29 16:33:40,194:INFO:Creating metrics dataframe
2023-04-29 16:33:40,527:INFO:Uploading results into container
2023-04-29 16:33:40,528:INFO:Uploading model into container now
2023-04-29 16:33:40,528:INFO:_master_model_container: 15
2023-04-29 16:33:40,528:INFO:_display_container: 2
2023-04-29 16:33:40,529:INFO:AdaBoostRegressor(random_state=2722)
2023-04-29 16:33:40,529:INFO:create_model() successfully completed......................................
2023-04-29 16:33:40,623:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:40,623:INFO:Creating metrics dataframe
2023-04-29 16:33:40,627:INFO:Initializing Gradient Boosting Regressor
2023-04-29 16:33:40,627:INFO:Total runtime is 0.979960020383199 minutes
2023-04-29 16:33:40,627:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:40,628:INFO:Initializing create_model()
2023-04-29 16:33:40,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:40,628:INFO:Checking exceptions
2023-04-29 16:33:40,628:INFO:Importing libraries
2023-04-29 16:33:40,629:INFO:Copying training dataset
2023-04-29 16:33:40,634:INFO:Defining folds
2023-04-29 16:33:40,634:INFO:Declaring metric variables
2023-04-29 16:33:40,634:INFO:Importing untrained model
2023-04-29 16:33:40,635:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 16:33:40,635:INFO:Starting cross validation
2023-04-29 16:33:40,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:44,020:INFO:Calculating mean and std
2023-04-29 16:33:44,021:INFO:Creating metrics dataframe
2023-04-29 16:33:44,390:INFO:Uploading results into container
2023-04-29 16:33:44,391:INFO:Uploading model into container now
2023-04-29 16:33:44,391:INFO:_master_model_container: 16
2023-04-29 16:33:44,391:INFO:_display_container: 2
2023-04-29 16:33:44,391:INFO:GradientBoostingRegressor(random_state=2722)
2023-04-29 16:33:44,391:INFO:create_model() successfully completed......................................
2023-04-29 16:33:44,490:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:44,490:INFO:Creating metrics dataframe
2023-04-29 16:33:44,496:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 16:33:44,497:INFO:Total runtime is 1.044466455777486 minutes
2023-04-29 16:33:44,497:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:44,497:INFO:Initializing create_model()
2023-04-29 16:33:44,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:44,497:INFO:Checking exceptions
2023-04-29 16:33:44,497:INFO:Importing libraries
2023-04-29 16:33:44,497:INFO:Copying training dataset
2023-04-29 16:33:44,501:INFO:Defining folds
2023-04-29 16:33:44,501:INFO:Declaring metric variables
2023-04-29 16:33:44,501:INFO:Importing untrained model
2023-04-29 16:33:44,502:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 16:33:44,503:INFO:Starting cross validation
2023-04-29 16:33:44,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:50,259:INFO:Calculating mean and std
2023-04-29 16:33:50,260:INFO:Creating metrics dataframe
2023-04-29 16:33:50,630:INFO:Uploading results into container
2023-04-29 16:33:50,630:INFO:Uploading model into container now
2023-04-29 16:33:50,631:INFO:_master_model_container: 17
2023-04-29 16:33:50,631:INFO:_display_container: 2
2023-04-29 16:33:50,632:INFO:LGBMRegressor(random_state=2722)
2023-04-29 16:33:50,632:INFO:create_model() successfully completed......................................
2023-04-29 16:33:50,732:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:50,732:INFO:Creating metrics dataframe
2023-04-29 16:33:50,736:INFO:Initializing Dummy Regressor
2023-04-29 16:33:50,736:INFO:Total runtime is 1.148445443312327 minutes
2023-04-29 16:33:50,736:INFO:SubProcess create_model() called ==================================
2023-04-29 16:33:50,737:INFO:Initializing create_model()
2023-04-29 16:33:50,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7008550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:50,737:INFO:Checking exceptions
2023-04-29 16:33:50,737:INFO:Importing libraries
2023-04-29 16:33:50,737:INFO:Copying training dataset
2023-04-29 16:33:50,740:INFO:Defining folds
2023-04-29 16:33:50,740:INFO:Declaring metric variables
2023-04-29 16:33:50,740:INFO:Importing untrained model
2023-04-29 16:33:50,741:INFO:Dummy Regressor Imported successfully
2023-04-29 16:33:50,741:INFO:Starting cross validation
2023-04-29 16:33:50,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:33:53,744:INFO:Calculating mean and std
2023-04-29 16:33:53,745:INFO:Creating metrics dataframe
2023-04-29 16:33:54,090:INFO:Uploading results into container
2023-04-29 16:33:54,090:INFO:Uploading model into container now
2023-04-29 16:33:54,091:INFO:_master_model_container: 18
2023-04-29 16:33:54,091:INFO:_display_container: 2
2023-04-29 16:33:54,091:INFO:DummyRegressor()
2023-04-29 16:33:54,091:INFO:create_model() successfully completed......................................
2023-04-29 16:33:54,190:INFO:SubProcess create_model() end ==================================
2023-04-29 16:33:54,190:INFO:Creating metrics dataframe
2023-04-29 16:33:54,199:INFO:Initializing create_model()
2023-04-29 16:33:54,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B66809A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=2722), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:33:54,199:INFO:Checking exceptions
2023-04-29 16:33:54,200:INFO:Importing libraries
2023-04-29 16:33:54,200:INFO:Copying training dataset
2023-04-29 16:33:54,204:INFO:Defining folds
2023-04-29 16:33:54,204:INFO:Declaring metric variables
2023-04-29 16:33:54,205:INFO:Importing untrained model
2023-04-29 16:33:54,205:INFO:Declaring custom model
2023-04-29 16:33:54,205:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:33:54,206:INFO:Cross validation set to False
2023-04-29 16:33:54,206:INFO:Fitting Model
2023-04-29 16:33:54,542:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2722)
2023-04-29 16:33:54,543:INFO:create_model() successfully completed......................................
2023-04-29 16:33:54,669:INFO:_master_model_container: 18
2023-04-29 16:33:54,670:INFO:_display_container: 2
2023-04-29 16:33:54,670:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2722)
2023-04-29 16:33:54,670:INFO:compare_models() successfully completed......................................
2023-04-29 16:39:23,401:INFO:PyCaret RegressionExperiment
2023-04-29 16:39:23,402:INFO:Logging name: reg-default-name
2023-04-29 16:39:23,402:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 16:39:23,402:INFO:version 3.0.0
2023-04-29 16:39:23,402:INFO:Initializing setup()
2023-04-29 16:39:23,402:INFO:self.USI: a2e2
2023-04-29 16:39:23,402:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 16:39:23,402:INFO:Checking environment
2023-04-29 16:39:23,402:INFO:python_version: 3.9.13
2023-04-29 16:39:23,402:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 16:39:23,402:INFO:machine: AMD64
2023-04-29 16:39:23,402:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 16:39:23,402:INFO:Memory: svmem(total=16935899136, available=6664232960, percent=60.7, used=10271666176, free=6664232960)
2023-04-29 16:39:23,402:INFO:Physical Core: 4
2023-04-29 16:39:23,402:INFO:Logical Core: 8
2023-04-29 16:39:23,402:INFO:Checking libraries
2023-04-29 16:39:23,402:INFO:System:
2023-04-29 16:39:23,402:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 16:39:23,402:INFO:executable: D:\Anaconda\python.exe
2023-04-29 16:39:23,402:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 16:39:23,402:INFO:PyCaret required dependencies:
2023-04-29 16:39:23,403:INFO:                 pip: 22.2.2
2023-04-29 16:39:23,403:INFO:          setuptools: 63.4.1
2023-04-29 16:39:23,403:INFO:             pycaret: 3.0.0
2023-04-29 16:39:23,403:INFO:             IPython: 7.31.1
2023-04-29 16:39:23,403:INFO:          ipywidgets: 7.6.5
2023-04-29 16:39:23,403:INFO:                tqdm: 4.64.1
2023-04-29 16:39:23,403:INFO:               numpy: 1.21.5
2023-04-29 16:39:23,403:INFO:              pandas: 1.4.4
2023-04-29 16:39:23,403:INFO:              jinja2: 2.11.3
2023-04-29 16:39:23,403:INFO:               scipy: 1.9.1
2023-04-29 16:39:23,403:INFO:              joblib: 1.2.0
2023-04-29 16:39:23,403:INFO:             sklearn: 1.0.2
2023-04-29 16:39:23,403:INFO:                pyod: 1.0.9
2023-04-29 16:39:23,403:INFO:            imblearn: 0.10.1
2023-04-29 16:39:23,403:INFO:   category_encoders: 2.6.0
2023-04-29 16:39:23,403:INFO:            lightgbm: 3.3.5
2023-04-29 16:39:23,403:INFO:               numba: 0.55.1
2023-04-29 16:39:23,403:INFO:            requests: 2.28.1
2023-04-29 16:39:23,403:INFO:          matplotlib: 3.5.2
2023-04-29 16:39:23,403:INFO:          scikitplot: 0.3.7
2023-04-29 16:39:23,403:INFO:         yellowbrick: 1.5
2023-04-29 16:39:23,403:INFO:              plotly: 5.9.0
2023-04-29 16:39:23,403:INFO:             kaleido: 0.2.1
2023-04-29 16:39:23,403:INFO:         statsmodels: 0.13.2
2023-04-29 16:39:23,403:INFO:              sktime: 0.17.1
2023-04-29 16:39:23,403:INFO:               tbats: 1.1.2
2023-04-29 16:39:23,403:INFO:            pmdarima: 2.0.3
2023-04-29 16:39:23,403:INFO:              psutil: 5.9.0
2023-04-29 16:39:23,403:INFO:PyCaret optional dependencies:
2023-04-29 16:39:23,403:INFO:                shap: 0.41.0
2023-04-29 16:39:23,403:INFO:           interpret: Not installed
2023-04-29 16:39:23,404:INFO:                umap: Not installed
2023-04-29 16:39:23,404:INFO:    pandas_profiling: 4.1.2
2023-04-29 16:39:23,404:INFO:  explainerdashboard: Not installed
2023-04-29 16:39:23,404:INFO:             autoviz: Not installed
2023-04-29 16:39:23,404:INFO:           fairlearn: Not installed
2023-04-29 16:39:23,404:INFO:             xgboost: Not installed
2023-04-29 16:39:23,404:INFO:            catboost: Not installed
2023-04-29 16:39:23,404:INFO:              kmodes: Not installed
2023-04-29 16:39:23,404:INFO:             mlxtend: Not installed
2023-04-29 16:39:23,404:INFO:       statsforecast: Not installed
2023-04-29 16:39:23,404:INFO:        tune_sklearn: Not installed
2023-04-29 16:39:23,404:INFO:                 ray: Not installed
2023-04-29 16:39:23,404:INFO:            hyperopt: Not installed
2023-04-29 16:39:23,404:INFO:              optuna: Not installed
2023-04-29 16:39:23,404:INFO:               skopt: Not installed
2023-04-29 16:39:23,404:INFO:              mlflow: 2.2.1
2023-04-29 16:39:23,404:INFO:              gradio: Not installed
2023-04-29 16:39:23,404:INFO:             fastapi: Not installed
2023-04-29 16:39:23,404:INFO:             uvicorn: Not installed
2023-04-29 16:39:23,404:INFO:              m2cgen: Not installed
2023-04-29 16:39:23,404:INFO:           evidently: Not installed
2023-04-29 16:39:23,404:INFO:               fugue: Not installed
2023-04-29 16:39:23,404:INFO:           streamlit: 1.21.0
2023-04-29 16:39:23,404:INFO:             prophet: Not installed
2023-04-29 16:39:23,404:INFO:None
2023-04-29 16:39:23,404:INFO:Set up data.
2023-04-29 16:39:23,408:INFO:Set up train/test split.
2023-04-29 16:39:23,410:INFO:Set up index.
2023-04-29 16:39:23,410:INFO:Set up folding strategy.
2023-04-29 16:39:23,410:INFO:Assigning column types.
2023-04-29 16:39:23,413:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 16:39:23,413:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,418:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,422:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,519:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,524:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,528:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,582:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,628:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 16:39:23,632:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,872:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 16:39:23,881:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:23,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:23,999:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,102:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,103:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 16:39:24,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,321:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 16:39:24,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:39:24,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,545:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 16:39:24,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:24,808:INFO:Preparing preprocessing pipeline...
2023-04-29 16:39:24,808:INFO:Set up simple imputation.
2023-04-29 16:39:24,808:INFO:Set up column name cleaning.
2023-04-29 16:39:24,827:INFO:Finished creating preprocessing pipeline.
2023-04-29 16:39:24,831:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 16:39:24,831:INFO:Creating final display dataframe.
2023-04-29 16:39:24,908:INFO:Setup _display_container:                     Description             Value
0                    Session id              4655
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a2e2
2023-04-29 16:39:25,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:25,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:25,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:25,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:39:25,174:INFO:setup() successfully completed in 1.98s...............
2023-04-29 16:39:25,179:INFO:Initializing compare_models()
2023-04-29 16:39:25,179:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 16:39:25,179:INFO:Checking exceptions
2023-04-29 16:39:25,181:INFO:Preparing display monitor
2023-04-29 16:39:25,184:INFO:Initializing Linear Regression
2023-04-29 16:39:25,185:INFO:Total runtime is 1.7714500427246093e-05 minutes
2023-04-29 16:39:25,185:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:25,185:INFO:Initializing create_model()
2023-04-29 16:39:25,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:25,186:INFO:Checking exceptions
2023-04-29 16:39:25,186:INFO:Importing libraries
2023-04-29 16:39:25,186:INFO:Copying training dataset
2023-04-29 16:39:25,191:INFO:Defining folds
2023-04-29 16:39:25,191:INFO:Declaring metric variables
2023-04-29 16:39:25,192:INFO:Importing untrained model
2023-04-29 16:39:25,192:INFO:Linear Regression Imported successfully
2023-04-29 16:39:25,192:INFO:Starting cross validation
2023-04-29 16:39:25,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:34,985:INFO:Calculating mean and std
2023-04-29 16:39:34,987:INFO:Creating metrics dataframe
2023-04-29 16:39:35,290:INFO:Uploading results into container
2023-04-29 16:39:35,291:INFO:Uploading model into container now
2023-04-29 16:39:35,291:INFO:_master_model_container: 1
2023-04-29 16:39:35,291:INFO:_display_container: 2
2023-04-29 16:39:35,291:INFO:LinearRegression(n_jobs=-1)
2023-04-29 16:39:35,291:INFO:create_model() successfully completed......................................
2023-04-29 16:39:35,382:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:35,382:INFO:Creating metrics dataframe
2023-04-29 16:39:35,385:INFO:Initializing Lasso Regression
2023-04-29 16:39:35,385:INFO:Total runtime is 0.17001986503601074 minutes
2023-04-29 16:39:35,385:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:35,386:INFO:Initializing create_model()
2023-04-29 16:39:35,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:35,386:INFO:Checking exceptions
2023-04-29 16:39:35,386:INFO:Importing libraries
2023-04-29 16:39:35,386:INFO:Copying training dataset
2023-04-29 16:39:35,388:INFO:Defining folds
2023-04-29 16:39:35,388:INFO:Declaring metric variables
2023-04-29 16:39:35,388:INFO:Importing untrained model
2023-04-29 16:39:35,389:INFO:Lasso Regression Imported successfully
2023-04-29 16:39:35,389:INFO:Starting cross validation
2023-04-29 16:39:35,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:37,937:INFO:Calculating mean and std
2023-04-29 16:39:37,938:INFO:Creating metrics dataframe
2023-04-29 16:39:38,331:INFO:Uploading results into container
2023-04-29 16:39:38,332:INFO:Uploading model into container now
2023-04-29 16:39:38,333:INFO:_master_model_container: 2
2023-04-29 16:39:38,333:INFO:_display_container: 2
2023-04-29 16:39:38,333:INFO:Lasso(random_state=4655)
2023-04-29 16:39:38,334:INFO:create_model() successfully completed......................................
2023-04-29 16:39:38,432:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:38,432:INFO:Creating metrics dataframe
2023-04-29 16:39:38,437:INFO:Initializing Ridge Regression
2023-04-29 16:39:38,437:INFO:Total runtime is 0.2208945075670878 minutes
2023-04-29 16:39:38,437:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:38,437:INFO:Initializing create_model()
2023-04-29 16:39:38,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:38,438:INFO:Checking exceptions
2023-04-29 16:39:38,438:INFO:Importing libraries
2023-04-29 16:39:38,438:INFO:Copying training dataset
2023-04-29 16:39:38,443:INFO:Defining folds
2023-04-29 16:39:38,443:INFO:Declaring metric variables
2023-04-29 16:39:38,444:INFO:Importing untrained model
2023-04-29 16:39:38,444:INFO:Ridge Regression Imported successfully
2023-04-29 16:39:38,444:INFO:Starting cross validation
2023-04-29 16:39:38,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:41,393:INFO:Calculating mean and std
2023-04-29 16:39:41,394:INFO:Creating metrics dataframe
2023-04-29 16:39:41,769:INFO:Uploading results into container
2023-04-29 16:39:41,770:INFO:Uploading model into container now
2023-04-29 16:39:41,771:INFO:_master_model_container: 3
2023-04-29 16:39:41,771:INFO:_display_container: 2
2023-04-29 16:39:41,771:INFO:Ridge(random_state=4655)
2023-04-29 16:39:41,771:INFO:create_model() successfully completed......................................
2023-04-29 16:39:41,868:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:41,868:INFO:Creating metrics dataframe
2023-04-29 16:39:41,872:INFO:Initializing Elastic Net
2023-04-29 16:39:41,872:INFO:Total runtime is 0.27814475297927854 minutes
2023-04-29 16:39:41,873:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:41,873:INFO:Initializing create_model()
2023-04-29 16:39:41,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:41,873:INFO:Checking exceptions
2023-04-29 16:39:41,873:INFO:Importing libraries
2023-04-29 16:39:41,873:INFO:Copying training dataset
2023-04-29 16:39:41,877:INFO:Defining folds
2023-04-29 16:39:41,877:INFO:Declaring metric variables
2023-04-29 16:39:41,878:INFO:Importing untrained model
2023-04-29 16:39:41,878:INFO:Elastic Net Imported successfully
2023-04-29 16:39:41,879:INFO:Starting cross validation
2023-04-29 16:39:41,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:44,734:INFO:Calculating mean and std
2023-04-29 16:39:44,735:INFO:Creating metrics dataframe
2023-04-29 16:39:45,166:INFO:Uploading results into container
2023-04-29 16:39:45,168:INFO:Uploading model into container now
2023-04-29 16:39:45,169:INFO:_master_model_container: 4
2023-04-29 16:39:45,169:INFO:_display_container: 2
2023-04-29 16:39:45,169:INFO:ElasticNet(random_state=4655)
2023-04-29 16:39:45,169:INFO:create_model() successfully completed......................................
2023-04-29 16:39:45,277:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:45,277:INFO:Creating metrics dataframe
2023-04-29 16:39:45,283:INFO:Initializing Least Angle Regression
2023-04-29 16:39:45,283:INFO:Total runtime is 0.33499090274175003 minutes
2023-04-29 16:39:45,283:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:45,283:INFO:Initializing create_model()
2023-04-29 16:39:45,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:45,283:INFO:Checking exceptions
2023-04-29 16:39:45,283:INFO:Importing libraries
2023-04-29 16:39:45,284:INFO:Copying training dataset
2023-04-29 16:39:45,287:INFO:Defining folds
2023-04-29 16:39:45,288:INFO:Declaring metric variables
2023-04-29 16:39:45,288:INFO:Importing untrained model
2023-04-29 16:39:45,289:INFO:Least Angle Regression Imported successfully
2023-04-29 16:39:45,289:INFO:Starting cross validation
2023-04-29 16:39:45,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:45,387:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,401:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,424:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,433:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,450:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,478:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,494:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,512:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:45,672:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 16:39:45,672:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 16:39:45,673:INFO:Data columns (total 8 columns):
2023-04-29 16:39:45,673:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 16:39:45,673:INFO:---  ------          --------------  -----  
2023-04-29 16:39:45,673:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 16:39:45,673:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 16:39:45,673:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 16:39:45,673:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 16:39:45,673:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 16:39:45,674:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 16:39:45,674:INFO: 6   VEC             1360 non-null   float64
2023-04-29 16:39:45,674:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 16:39:45,674:INFO:dtypes: float64(7), int32(1)
2023-04-29 16:39:45,674:INFO:memory usage: 79.8 KB
2023-04-29 16:39:46,273:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:46,331:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:48,306:INFO:Calculating mean and std
2023-04-29 16:39:48,307:INFO:Creating metrics dataframe
2023-04-29 16:39:48,791:INFO:Uploading results into container
2023-04-29 16:39:48,791:INFO:Uploading model into container now
2023-04-29 16:39:48,792:INFO:_master_model_container: 5
2023-04-29 16:39:48,792:INFO:_display_container: 2
2023-04-29 16:39:48,792:INFO:Lars(random_state=4655)
2023-04-29 16:39:48,792:INFO:create_model() successfully completed......................................
2023-04-29 16:39:48,898:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:48,898:INFO:Creating metrics dataframe
2023-04-29 16:39:48,905:INFO:Initializing Lasso Least Angle Regression
2023-04-29 16:39:48,905:INFO:Total runtime is 0.3953623374303181 minutes
2023-04-29 16:39:48,905:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:48,906:INFO:Initializing create_model()
2023-04-29 16:39:48,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:48,906:INFO:Checking exceptions
2023-04-29 16:39:48,906:INFO:Importing libraries
2023-04-29 16:39:48,906:INFO:Copying training dataset
2023-04-29 16:39:48,909:INFO:Defining folds
2023-04-29 16:39:48,910:INFO:Declaring metric variables
2023-04-29 16:39:48,910:INFO:Importing untrained model
2023-04-29 16:39:48,911:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 16:39:48,911:INFO:Starting cross validation
2023-04-29 16:39:48,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:48,965:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:48,977:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:48,984:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,005:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,026:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,045:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,058:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,076:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,771:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:49,814:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:39:51,804:INFO:Calculating mean and std
2023-04-29 16:39:51,805:INFO:Creating metrics dataframe
2023-04-29 16:39:52,160:INFO:Uploading results into container
2023-04-29 16:39:52,161:INFO:Uploading model into container now
2023-04-29 16:39:52,161:INFO:_master_model_container: 6
2023-04-29 16:39:52,161:INFO:_display_container: 2
2023-04-29 16:39:52,161:INFO:LassoLars(random_state=4655)
2023-04-29 16:39:52,161:INFO:create_model() successfully completed......................................
2023-04-29 16:39:52,262:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:52,262:INFO:Creating metrics dataframe
2023-04-29 16:39:52,266:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 16:39:52,266:INFO:Total runtime is 0.4513792514801025 minutes
2023-04-29 16:39:52,267:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:52,267:INFO:Initializing create_model()
2023-04-29 16:39:52,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:52,267:INFO:Checking exceptions
2023-04-29 16:39:52,267:INFO:Importing libraries
2023-04-29 16:39:52,267:INFO:Copying training dataset
2023-04-29 16:39:52,270:INFO:Defining folds
2023-04-29 16:39:52,270:INFO:Declaring metric variables
2023-04-29 16:39:52,270:INFO:Importing untrained model
2023-04-29 16:39:52,271:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 16:39:52,271:INFO:Starting cross validation
2023-04-29 16:39:52,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:52,336:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,348:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,356:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,373:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,390:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,409:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,428:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:52,442:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:53,251:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:53,286:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:39:55,562:INFO:Calculating mean and std
2023-04-29 16:39:55,563:INFO:Creating metrics dataframe
2023-04-29 16:39:55,934:INFO:Uploading results into container
2023-04-29 16:39:55,934:INFO:Uploading model into container now
2023-04-29 16:39:55,935:INFO:_master_model_container: 7
2023-04-29 16:39:55,935:INFO:_display_container: 2
2023-04-29 16:39:55,935:INFO:OrthogonalMatchingPursuit()
2023-04-29 16:39:55,935:INFO:create_model() successfully completed......................................
2023-04-29 16:39:56,027:INFO:SubProcess create_model() end ==================================
2023-04-29 16:39:56,028:INFO:Creating metrics dataframe
2023-04-29 16:39:56,031:INFO:Initializing Bayesian Ridge
2023-04-29 16:39:56,031:INFO:Total runtime is 0.5141181588172912 minutes
2023-04-29 16:39:56,032:INFO:SubProcess create_model() called ==================================
2023-04-29 16:39:56,032:INFO:Initializing create_model()
2023-04-29 16:39:56,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:39:56,032:INFO:Checking exceptions
2023-04-29 16:39:56,032:INFO:Importing libraries
2023-04-29 16:39:56,032:INFO:Copying training dataset
2023-04-29 16:39:56,035:INFO:Defining folds
2023-04-29 16:39:56,035:INFO:Declaring metric variables
2023-04-29 16:39:56,035:INFO:Importing untrained model
2023-04-29 16:39:56,036:INFO:Bayesian Ridge Imported successfully
2023-04-29 16:39:56,036:INFO:Starting cross validation
2023-04-29 16:39:56,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:39:56,847:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 16:39:56,847:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 16:39:56,847:INFO:Data columns (total 8 columns):
2023-04-29 16:39:56,847:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 16:39:56,847:INFO:---  ------          --------------  -----  
2023-04-29 16:39:56,847:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 16:39:56,847:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 16:39:56,848:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 16:39:56,848:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 16:39:56,848:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 16:39:56,848:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 16:39:56,850:INFO: 6   VEC             1360 non-null   float64
2023-04-29 16:39:56,851:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 16:39:56,851:INFO:dtypes: float64(7), int32(1)
2023-04-29 16:39:56,851:INFO:memory usage: 79.8 KB
2023-04-29 16:39:59,437:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 16:39:59,437:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 16:39:59,437:INFO:Data columns (total 8 columns):
2023-04-29 16:39:59,437:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 16:39:59,437:INFO:---  ------          --------------  -----  
2023-04-29 16:39:59,437:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 16:39:59,437:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 16:39:59,437:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 16:39:59,437:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 16:39:59,438:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 16:39:59,438:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 16:39:59,438:INFO: 6   VEC             1360 non-null   float64
2023-04-29 16:39:59,438:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 16:39:59,438:INFO:dtypes: float64(7), int32(1)
2023-04-29 16:39:59,438:INFO:memory usage: 79.8 KB
2023-04-29 16:39:59,574:INFO:Calculating mean and std
2023-04-29 16:39:59,575:INFO:Creating metrics dataframe
2023-04-29 16:39:59,868:INFO:PyCaret RegressionExperiment
2023-04-29 16:39:59,868:INFO:Logging name: reg-default-name
2023-04-29 16:39:59,868:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 16:39:59,869:INFO:version 3.0.0
2023-04-29 16:39:59,869:INFO:Initializing setup()
2023-04-29 16:39:59,869:INFO:self.USI: 0ff6
2023-04-29 16:39:59,869:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 16:39:59,869:INFO:Checking environment
2023-04-29 16:39:59,869:INFO:python_version: 3.9.13
2023-04-29 16:39:59,869:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 16:39:59,869:INFO:machine: AMD64
2023-04-29 16:39:59,869:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 16:39:59,869:INFO:Memory: svmem(total=16935899136, available=5732909056, percent=66.1, used=11202990080, free=5732909056)
2023-04-29 16:39:59,869:INFO:Physical Core: 4
2023-04-29 16:39:59,870:INFO:Logical Core: 8
2023-04-29 16:39:59,870:INFO:Checking libraries
2023-04-29 16:39:59,870:INFO:System:
2023-04-29 16:39:59,870:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 16:39:59,870:INFO:executable: D:\Anaconda\python.exe
2023-04-29 16:39:59,870:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 16:39:59,870:INFO:PyCaret required dependencies:
2023-04-29 16:39:59,870:INFO:                 pip: 22.2.2
2023-04-29 16:39:59,870:INFO:          setuptools: 63.4.1
2023-04-29 16:39:59,870:INFO:             pycaret: 3.0.0
2023-04-29 16:39:59,870:INFO:             IPython: 7.31.1
2023-04-29 16:39:59,870:INFO:          ipywidgets: 7.6.5
2023-04-29 16:39:59,870:INFO:                tqdm: 4.64.1
2023-04-29 16:39:59,871:INFO:               numpy: 1.21.5
2023-04-29 16:39:59,871:INFO:              pandas: 1.4.4
2023-04-29 16:39:59,871:INFO:              jinja2: 2.11.3
2023-04-29 16:39:59,871:INFO:               scipy: 1.9.1
2023-04-29 16:39:59,871:INFO:              joblib: 1.2.0
2023-04-29 16:39:59,871:INFO:             sklearn: 1.0.2
2023-04-29 16:39:59,871:INFO:                pyod: 1.0.9
2023-04-29 16:39:59,871:INFO:            imblearn: 0.10.1
2023-04-29 16:39:59,871:INFO:   category_encoders: 2.6.0
2023-04-29 16:39:59,871:INFO:            lightgbm: 3.3.5
2023-04-29 16:39:59,871:INFO:               numba: 0.55.1
2023-04-29 16:39:59,871:INFO:            requests: 2.28.1
2023-04-29 16:39:59,871:INFO:          matplotlib: 3.5.2
2023-04-29 16:39:59,871:INFO:          scikitplot: 0.3.7
2023-04-29 16:39:59,872:INFO:         yellowbrick: 1.5
2023-04-29 16:39:59,872:INFO:              plotly: 5.9.0
2023-04-29 16:39:59,872:INFO:             kaleido: 0.2.1
2023-04-29 16:39:59,872:INFO:         statsmodels: 0.13.2
2023-04-29 16:39:59,872:INFO:              sktime: 0.17.1
2023-04-29 16:39:59,872:INFO:               tbats: 1.1.2
2023-04-29 16:39:59,872:INFO:            pmdarima: 2.0.3
2023-04-29 16:39:59,872:INFO:              psutil: 5.9.0
2023-04-29 16:39:59,872:INFO:PyCaret optional dependencies:
2023-04-29 16:39:59,872:INFO:                shap: 0.41.0
2023-04-29 16:39:59,872:INFO:           interpret: Not installed
2023-04-29 16:39:59,872:INFO:                umap: Not installed
2023-04-29 16:39:59,872:INFO:    pandas_profiling: 4.1.2
2023-04-29 16:39:59,872:INFO:  explainerdashboard: Not installed
2023-04-29 16:39:59,873:INFO:             autoviz: Not installed
2023-04-29 16:39:59,873:INFO:           fairlearn: Not installed
2023-04-29 16:39:59,873:INFO:             xgboost: Not installed
2023-04-29 16:39:59,873:INFO:            catboost: Not installed
2023-04-29 16:39:59,873:INFO:              kmodes: Not installed
2023-04-29 16:39:59,873:INFO:             mlxtend: Not installed
2023-04-29 16:39:59,873:INFO:       statsforecast: Not installed
2023-04-29 16:39:59,873:INFO:        tune_sklearn: Not installed
2023-04-29 16:39:59,873:INFO:                 ray: Not installed
2023-04-29 16:39:59,873:INFO:            hyperopt: Not installed
2023-04-29 16:39:59,873:INFO:              optuna: Not installed
2023-04-29 16:39:59,873:INFO:               skopt: Not installed
2023-04-29 16:39:59,874:INFO:              mlflow: 2.2.1
2023-04-29 16:39:59,874:INFO:              gradio: Not installed
2023-04-29 16:39:59,874:INFO:             fastapi: Not installed
2023-04-29 16:39:59,874:INFO:             uvicorn: Not installed
2023-04-29 16:39:59,874:INFO:              m2cgen: Not installed
2023-04-29 16:39:59,874:INFO:           evidently: Not installed
2023-04-29 16:39:59,874:INFO:               fugue: Not installed
2023-04-29 16:39:59,874:INFO:           streamlit: 1.21.0
2023-04-29 16:39:59,874:INFO:             prophet: Not installed
2023-04-29 16:39:59,874:INFO:None
2023-04-29 16:39:59,874:INFO:Set up data.
2023-04-29 16:39:59,879:INFO:Set up train/test split.
2023-04-29 16:39:59,882:INFO:Set up index.
2023-04-29 16:39:59,882:INFO:Set up folding strategy.
2023-04-29 16:39:59,882:INFO:Assigning column types.
2023-04-29 16:39:59,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 16:39:59,886:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:39:59,891:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:39:59,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:39:59,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,005:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,006:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,011:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,016:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,142:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 16:40:00,147:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,269:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,379:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 16:40:00,387:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,501:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,563:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,612:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,613:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 16:40:00,680:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,840:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,841:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 16:40:00,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:00,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:00,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,034:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:40:01,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,083:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 16:40:01,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,310:INFO:Preparing preprocessing pipeline...
2023-04-29 16:40:01,310:INFO:Set up simple imputation.
2023-04-29 16:40:01,311:INFO:Set up column name cleaning.
2023-04-29 16:40:01,336:INFO:Finished creating preprocessing pipeline.
2023-04-29 16:40:01,340:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 16:40:01,340:INFO:Creating final display dataframe.
2023-04-29 16:40:01,491:INFO:Setup _display_container:                     Description             Value
0                    Session id              5976
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0ff6
2023-04-29 16:40:01,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:40:01,765:INFO:setup() successfully completed in 2.32s...............
2023-04-29 16:40:01,770:INFO:Initializing compare_models()
2023-04-29 16:40:01,771:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 16:40:01,771:INFO:Checking exceptions
2023-04-29 16:40:01,773:INFO:Preparing display monitor
2023-04-29 16:40:01,776:INFO:Initializing Linear Regression
2023-04-29 16:40:01,776:INFO:Total runtime is 0.0 minutes
2023-04-29 16:40:01,776:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:01,776:INFO:Initializing create_model()
2023-04-29 16:40:01,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:01,776:INFO:Checking exceptions
2023-04-29 16:40:01,777:INFO:Importing libraries
2023-04-29 16:40:01,777:INFO:Copying training dataset
2023-04-29 16:40:01,782:INFO:Defining folds
2023-04-29 16:40:01,782:INFO:Declaring metric variables
2023-04-29 16:40:01,782:INFO:Importing untrained model
2023-04-29 16:40:01,783:INFO:Linear Regression Imported successfully
2023-04-29 16:40:01,783:INFO:Starting cross validation
2023-04-29 16:40:01,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:01,933:INFO:Uploading results into container
2023-04-29 16:40:01,934:INFO:Uploading model into container now
2023-04-29 16:40:01,935:INFO:_master_model_container: 8
2023-04-29 16:40:01,935:INFO:_display_container: 2
2023-04-29 16:40:01,935:INFO:BayesianRidge()
2023-04-29 16:40:01,935:INFO:create_model() successfully completed......................................
2023-04-29 16:40:02,052:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:02,052:INFO:Creating metrics dataframe
2023-04-29 16:40:02,058:INFO:Initializing Passive Aggressive Regressor
2023-04-29 16:40:02,058:INFO:Total runtime is 0.6145719289779662 minutes
2023-04-29 16:40:02,058:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:02,059:INFO:Initializing create_model()
2023-04-29 16:40:02,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:02,060:INFO:Checking exceptions
2023-04-29 16:40:02,060:INFO:Importing libraries
2023-04-29 16:40:02,060:INFO:Copying training dataset
2023-04-29 16:40:02,073:INFO:Defining folds
2023-04-29 16:40:02,073:INFO:Declaring metric variables
2023-04-29 16:40:02,074:INFO:Importing untrained model
2023-04-29 16:40:02,074:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 16:40:02,075:INFO:Starting cross validation
2023-04-29 16:40:02,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:05,510:INFO:Calculating mean and std
2023-04-29 16:40:05,512:INFO:Creating metrics dataframe
2023-04-29 16:40:05,812:INFO:Uploading results into container
2023-04-29 16:40:05,812:INFO:Uploading model into container now
2023-04-29 16:40:05,813:INFO:_master_model_container: 1
2023-04-29 16:40:05,813:INFO:_display_container: 2
2023-04-29 16:40:05,814:INFO:LinearRegression(n_jobs=-1)
2023-04-29 16:40:05,814:INFO:create_model() successfully completed......................................
2023-04-29 16:40:05,908:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:05,908:INFO:Creating metrics dataframe
2023-04-29 16:40:05,913:INFO:Initializing Lasso Regression
2023-04-29 16:40:05,913:INFO:Total runtime is 0.0689575711886088 minutes
2023-04-29 16:40:05,913:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:05,914:INFO:Initializing create_model()
2023-04-29 16:40:05,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:05,914:INFO:Checking exceptions
2023-04-29 16:40:05,914:INFO:Importing libraries
2023-04-29 16:40:05,914:INFO:Copying training dataset
2023-04-29 16:40:05,918:INFO:Defining folds
2023-04-29 16:40:05,918:INFO:Declaring metric variables
2023-04-29 16:40:05,919:INFO:Importing untrained model
2023-04-29 16:40:05,919:INFO:Lasso Regression Imported successfully
2023-04-29 16:40:05,919:INFO:Starting cross validation
2023-04-29 16:40:05,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:08,456:INFO:Calculating mean and std
2023-04-29 16:40:08,457:INFO:Creating metrics dataframe
2023-04-29 16:40:08,779:INFO:Uploading results into container
2023-04-29 16:40:08,780:INFO:Uploading model into container now
2023-04-29 16:40:08,780:INFO:_master_model_container: 9
2023-04-29 16:40:08,780:INFO:_display_container: 2
2023-04-29 16:40:08,781:INFO:PassiveAggressiveRegressor(random_state=4655)
2023-04-29 16:40:08,781:INFO:create_model() successfully completed......................................
2023-04-29 16:40:08,875:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:08,875:INFO:Creating metrics dataframe
2023-04-29 16:40:08,880:INFO:Initializing Huber Regressor
2023-04-29 16:40:08,880:INFO:Total runtime is 0.7282779653867084 minutes
2023-04-29 16:40:08,880:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:08,880:INFO:Initializing create_model()
2023-04-29 16:40:08,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:08,880:INFO:Checking exceptions
2023-04-29 16:40:08,880:INFO:Importing libraries
2023-04-29 16:40:08,880:INFO:Copying training dataset
2023-04-29 16:40:08,884:INFO:Defining folds
2023-04-29 16:40:08,884:INFO:Declaring metric variables
2023-04-29 16:40:08,884:INFO:Importing untrained model
2023-04-29 16:40:08,884:INFO:Huber Regressor Imported successfully
2023-04-29 16:40:08,885:INFO:Starting cross validation
2023-04-29 16:40:08,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:11,881:INFO:Calculating mean and std
2023-04-29 16:40:11,883:INFO:Creating metrics dataframe
2023-04-29 16:40:12,242:INFO:Uploading results into container
2023-04-29 16:40:12,243:INFO:Uploading model into container now
2023-04-29 16:40:12,244:INFO:_master_model_container: 2
2023-04-29 16:40:12,244:INFO:_display_container: 2
2023-04-29 16:40:12,244:INFO:Lasso(random_state=5976)
2023-04-29 16:40:12,245:INFO:create_model() successfully completed......................................
2023-04-29 16:40:12,352:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:12,352:INFO:Creating metrics dataframe
2023-04-29 16:40:12,356:INFO:Initializing Ridge Regression
2023-04-29 16:40:12,356:INFO:Total runtime is 0.17633161942164105 minutes
2023-04-29 16:40:12,357:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:12,357:INFO:Initializing create_model()
2023-04-29 16:40:12,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:12,357:INFO:Checking exceptions
2023-04-29 16:40:12,357:INFO:Importing libraries
2023-04-29 16:40:12,357:INFO:Copying training dataset
2023-04-29 16:40:12,360:INFO:Defining folds
2023-04-29 16:40:12,361:INFO:Declaring metric variables
2023-04-29 16:40:12,361:INFO:Importing untrained model
2023-04-29 16:40:12,361:INFO:Ridge Regression Imported successfully
2023-04-29 16:40:12,362:INFO:Starting cross validation
2023-04-29 16:40:12,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:15,984:INFO:Calculating mean and std
2023-04-29 16:40:15,985:INFO:Creating metrics dataframe
2023-04-29 16:40:16,552:INFO:Uploading results into container
2023-04-29 16:40:16,554:INFO:Uploading model into container now
2023-04-29 16:40:16,554:INFO:_master_model_container: 10
2023-04-29 16:40:16,554:INFO:_display_container: 2
2023-04-29 16:40:16,554:INFO:HuberRegressor()
2023-04-29 16:40:16,555:INFO:create_model() successfully completed......................................
2023-04-29 16:40:16,704:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:16,704:INFO:Creating metrics dataframe
2023-04-29 16:40:16,716:INFO:Initializing K Neighbors Regressor
2023-04-29 16:40:16,716:INFO:Total runtime is 0.858863870302836 minutes
2023-04-29 16:40:16,716:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:16,716:INFO:Initializing create_model()
2023-04-29 16:40:16,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:16,717:INFO:Checking exceptions
2023-04-29 16:40:16,717:INFO:Importing libraries
2023-04-29 16:40:16,717:INFO:Copying training dataset
2023-04-29 16:40:16,726:INFO:Defining folds
2023-04-29 16:40:16,727:INFO:Declaring metric variables
2023-04-29 16:40:16,727:INFO:Importing untrained model
2023-04-29 16:40:16,727:INFO:K Neighbors Regressor Imported successfully
2023-04-29 16:40:16,728:INFO:Starting cross validation
2023-04-29 16:40:16,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:20,401:INFO:Calculating mean and std
2023-04-29 16:40:20,403:INFO:Creating metrics dataframe
2023-04-29 16:40:20,852:INFO:Uploading results into container
2023-04-29 16:40:20,852:INFO:Uploading model into container now
2023-04-29 16:40:20,853:INFO:_master_model_container: 3
2023-04-29 16:40:20,853:INFO:_display_container: 2
2023-04-29 16:40:20,853:INFO:Ridge(random_state=5976)
2023-04-29 16:40:20,853:INFO:create_model() successfully completed......................................
2023-04-29 16:40:21,010:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:21,010:INFO:Creating metrics dataframe
2023-04-29 16:40:21,023:INFO:Initializing Elastic Net
2023-04-29 16:40:21,024:INFO:Total runtime is 0.3208013971646627 minutes
2023-04-29 16:40:21,024:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:21,025:INFO:Initializing create_model()
2023-04-29 16:40:21,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:21,025:INFO:Checking exceptions
2023-04-29 16:40:21,025:INFO:Importing libraries
2023-04-29 16:40:21,025:INFO:Copying training dataset
2023-04-29 16:40:21,032:INFO:Defining folds
2023-04-29 16:40:21,032:INFO:Declaring metric variables
2023-04-29 16:40:21,033:INFO:Importing untrained model
2023-04-29 16:40:21,033:INFO:Elastic Net Imported successfully
2023-04-29 16:40:21,033:INFO:Starting cross validation
2023-04-29 16:40:21,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:24,550:INFO:Calculating mean and std
2023-04-29 16:40:24,552:INFO:Creating metrics dataframe
2023-04-29 16:40:24,948:INFO:Uploading results into container
2023-04-29 16:40:24,949:INFO:Uploading model into container now
2023-04-29 16:40:24,949:INFO:_master_model_container: 11
2023-04-29 16:40:24,950:INFO:_display_container: 2
2023-04-29 16:40:24,950:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 16:40:24,950:INFO:create_model() successfully completed......................................
2023-04-29 16:40:25,090:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:25,091:INFO:Creating metrics dataframe
2023-04-29 16:40:25,101:INFO:Initializing Decision Tree Regressor
2023-04-29 16:40:25,101:INFO:Total runtime is 0.9986299395561217 minutes
2023-04-29 16:40:25,102:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:25,103:INFO:Initializing create_model()
2023-04-29 16:40:25,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:25,104:INFO:Checking exceptions
2023-04-29 16:40:25,104:INFO:Importing libraries
2023-04-29 16:40:25,104:INFO:Copying training dataset
2023-04-29 16:40:25,123:INFO:Defining folds
2023-04-29 16:40:25,124:INFO:Declaring metric variables
2023-04-29 16:40:25,124:INFO:Importing untrained model
2023-04-29 16:40:25,125:INFO:Decision Tree Regressor Imported successfully
2023-04-29 16:40:25,126:INFO:Starting cross validation
2023-04-29 16:40:25,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:28,923:INFO:Calculating mean and std
2023-04-29 16:40:28,925:INFO:Creating metrics dataframe
2023-04-29 16:40:29,319:INFO:Uploading results into container
2023-04-29 16:40:29,320:INFO:Uploading model into container now
2023-04-29 16:40:29,321:INFO:_master_model_container: 4
2023-04-29 16:40:29,321:INFO:_display_container: 2
2023-04-29 16:40:29,321:INFO:ElasticNet(random_state=5976)
2023-04-29 16:40:29,321:INFO:create_model() successfully completed......................................
2023-04-29 16:40:29,465:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:29,465:INFO:Creating metrics dataframe
2023-04-29 16:40:29,470:INFO:Initializing Least Angle Regression
2023-04-29 16:40:29,470:INFO:Total runtime is 0.461572810014089 minutes
2023-04-29 16:40:29,470:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:29,470:INFO:Initializing create_model()
2023-04-29 16:40:29,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:29,470:INFO:Checking exceptions
2023-04-29 16:40:29,470:INFO:Importing libraries
2023-04-29 16:40:29,470:INFO:Copying training dataset
2023-04-29 16:40:29,475:INFO:Defining folds
2023-04-29 16:40:29,475:INFO:Declaring metric variables
2023-04-29 16:40:29,476:INFO:Importing untrained model
2023-04-29 16:40:29,477:INFO:Least Angle Regression Imported successfully
2023-04-29 16:40:29,477:INFO:Starting cross validation
2023-04-29 16:40:29,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:29,883:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,895:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,906:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,928:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,949:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,963:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,978:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:29,998:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:30,703:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:30,715:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:32,955:INFO:Calculating mean and std
2023-04-29 16:40:32,956:INFO:Creating metrics dataframe
2023-04-29 16:40:33,334:INFO:Uploading results into container
2023-04-29 16:40:33,335:INFO:Uploading model into container now
2023-04-29 16:40:33,335:INFO:_master_model_container: 12
2023-04-29 16:40:33,335:INFO:_display_container: 2
2023-04-29 16:40:33,336:INFO:DecisionTreeRegressor(random_state=4655)
2023-04-29 16:40:33,336:INFO:create_model() successfully completed......................................
2023-04-29 16:40:33,464:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:33,464:INFO:Creating metrics dataframe
2023-04-29 16:40:33,471:INFO:Initializing Random Forest Regressor
2023-04-29 16:40:33,472:INFO:Total runtime is 1.138141091664632 minutes
2023-04-29 16:40:33,472:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:33,472:INFO:Initializing create_model()
2023-04-29 16:40:33,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:33,473:INFO:Checking exceptions
2023-04-29 16:40:33,473:INFO:Importing libraries
2023-04-29 16:40:33,473:INFO:Copying training dataset
2023-04-29 16:40:33,478:INFO:Defining folds
2023-04-29 16:40:33,478:INFO:Declaring metric variables
2023-04-29 16:40:33,479:INFO:Importing untrained model
2023-04-29 16:40:33,480:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:40:33,480:INFO:Starting cross validation
2023-04-29 16:40:33,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:38,275:INFO:Calculating mean and std
2023-04-29 16:40:38,277:INFO:Creating metrics dataframe
2023-04-29 16:40:38,635:INFO:Uploading results into container
2023-04-29 16:40:38,635:INFO:Uploading model into container now
2023-04-29 16:40:38,636:INFO:_master_model_container: 5
2023-04-29 16:40:38,636:INFO:_display_container: 2
2023-04-29 16:40:38,636:INFO:Lars(random_state=5976)
2023-04-29 16:40:38,636:INFO:create_model() successfully completed......................................
2023-04-29 16:40:38,764:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:38,764:INFO:Creating metrics dataframe
2023-04-29 16:40:38,769:INFO:Initializing Lasso Least Angle Regression
2023-04-29 16:40:38,769:INFO:Total runtime is 0.6165555596351624 minutes
2023-04-29 16:40:38,769:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:38,769:INFO:Initializing create_model()
2023-04-29 16:40:38,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:38,770:INFO:Checking exceptions
2023-04-29 16:40:38,770:INFO:Importing libraries
2023-04-29 16:40:38,770:INFO:Copying training dataset
2023-04-29 16:40:38,775:INFO:Defining folds
2023-04-29 16:40:38,775:INFO:Declaring metric variables
2023-04-29 16:40:38,775:INFO:Importing untrained model
2023-04-29 16:40:38,776:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 16:40:38,776:INFO:Starting cross validation
2023-04-29 16:40:38,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:39,193:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,203:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,209:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,232:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,243:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,257:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,273:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,287:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:39,973:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:40,038:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:40:42,421:INFO:Calculating mean and std
2023-04-29 16:40:42,423:INFO:Creating metrics dataframe
2023-04-29 16:40:42,768:INFO:Uploading results into container
2023-04-29 16:40:42,769:INFO:Uploading model into container now
2023-04-29 16:40:42,770:INFO:_master_model_container: 13
2023-04-29 16:40:42,770:INFO:_display_container: 2
2023-04-29 16:40:42,771:INFO:RandomForestRegressor(n_jobs=-1, random_state=4655)
2023-04-29 16:40:42,771:INFO:create_model() successfully completed......................................
2023-04-29 16:40:42,910:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:42,911:INFO:Creating metrics dataframe
2023-04-29 16:40:42,917:INFO:Initializing Extra Trees Regressor
2023-04-29 16:40:42,917:INFO:Total runtime is 1.2955563982327778 minutes
2023-04-29 16:40:42,918:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:42,918:INFO:Initializing create_model()
2023-04-29 16:40:42,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:42,918:INFO:Checking exceptions
2023-04-29 16:40:42,918:INFO:Importing libraries
2023-04-29 16:40:42,918:INFO:Copying training dataset
2023-04-29 16:40:42,927:INFO:Defining folds
2023-04-29 16:40:42,927:INFO:Declaring metric variables
2023-04-29 16:40:42,928:INFO:Importing untrained model
2023-04-29 16:40:42,928:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:40:42,929:INFO:Starting cross validation
2023-04-29 16:40:42,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:47,614:INFO:Calculating mean and std
2023-04-29 16:40:47,615:INFO:Creating metrics dataframe
2023-04-29 16:40:47,995:INFO:Uploading results into container
2023-04-29 16:40:47,996:INFO:Uploading model into container now
2023-04-29 16:40:47,996:INFO:_master_model_container: 6
2023-04-29 16:40:47,996:INFO:_display_container: 2
2023-04-29 16:40:47,997:INFO:LassoLars(random_state=5976)
2023-04-29 16:40:47,997:INFO:create_model() successfully completed......................................
2023-04-29 16:40:48,144:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:48,144:INFO:Creating metrics dataframe
2023-04-29 16:40:48,155:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 16:40:48,155:INFO:Total runtime is 0.7729908029238384 minutes
2023-04-29 16:40:48,157:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:48,157:INFO:Initializing create_model()
2023-04-29 16:40:48,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:48,157:INFO:Checking exceptions
2023-04-29 16:40:48,158:INFO:Importing libraries
2023-04-29 16:40:48,158:INFO:Copying training dataset
2023-04-29 16:40:48,165:INFO:Defining folds
2023-04-29 16:40:48,165:INFO:Declaring metric variables
2023-04-29 16:40:48,166:INFO:Importing untrained model
2023-04-29 16:40:48,166:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 16:40:48,168:INFO:Starting cross validation
2023-04-29 16:40:48,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:48,268:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,281:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,287:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,304:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,316:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,331:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,345:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:48,361:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:49,102:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:49,125:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:40:52,018:INFO:Calculating mean and std
2023-04-29 16:40:52,020:INFO:Creating metrics dataframe
2023-04-29 16:40:52,381:INFO:Uploading results into container
2023-04-29 16:40:52,381:INFO:Uploading model into container now
2023-04-29 16:40:52,382:INFO:_master_model_container: 14
2023-04-29 16:40:52,382:INFO:_display_container: 2
2023-04-29 16:40:52,382:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4655)
2023-04-29 16:40:52,382:INFO:create_model() successfully completed......................................
2023-04-29 16:40:52,502:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:52,502:INFO:Creating metrics dataframe
2023-04-29 16:40:52,507:INFO:Initializing AdaBoost Regressor
2023-04-29 16:40:52,507:INFO:Total runtime is 1.4553878545761108 minutes
2023-04-29 16:40:52,508:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:52,508:INFO:Initializing create_model()
2023-04-29 16:40:52,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:52,508:INFO:Checking exceptions
2023-04-29 16:40:52,508:INFO:Importing libraries
2023-04-29 16:40:52,509:INFO:Copying training dataset
2023-04-29 16:40:52,512:INFO:Defining folds
2023-04-29 16:40:52,512:INFO:Declaring metric variables
2023-04-29 16:40:52,512:INFO:Importing untrained model
2023-04-29 16:40:52,513:INFO:AdaBoost Regressor Imported successfully
2023-04-29 16:40:52,513:INFO:Starting cross validation
2023-04-29 16:40:52,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:40:56,523:INFO:Calculating mean and std
2023-04-29 16:40:56,525:INFO:Creating metrics dataframe
2023-04-29 16:40:56,935:INFO:Uploading results into container
2023-04-29 16:40:56,936:INFO:Uploading model into container now
2023-04-29 16:40:56,937:INFO:_master_model_container: 7
2023-04-29 16:40:56,937:INFO:_display_container: 2
2023-04-29 16:40:56,937:INFO:OrthogonalMatchingPursuit()
2023-04-29 16:40:56,937:INFO:create_model() successfully completed......................................
2023-04-29 16:40:57,087:INFO:SubProcess create_model() end ==================================
2023-04-29 16:40:57,088:INFO:Creating metrics dataframe
2023-04-29 16:40:57,097:INFO:Initializing Bayesian Ridge
2023-04-29 16:40:57,097:INFO:Total runtime is 0.922018051147461 minutes
2023-04-29 16:40:57,097:INFO:SubProcess create_model() called ==================================
2023-04-29 16:40:57,097:INFO:Initializing create_model()
2023-04-29 16:40:57,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:40:57,097:INFO:Checking exceptions
2023-04-29 16:40:57,097:INFO:Importing libraries
2023-04-29 16:40:57,097:INFO:Copying training dataset
2023-04-29 16:40:57,102:INFO:Defining folds
2023-04-29 16:40:57,102:INFO:Declaring metric variables
2023-04-29 16:40:57,102:INFO:Importing untrained model
2023-04-29 16:40:57,103:INFO:Bayesian Ridge Imported successfully
2023-04-29 16:40:57,104:INFO:Starting cross validation
2023-04-29 16:40:57,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:00,853:INFO:Calculating mean and std
2023-04-29 16:41:00,855:INFO:Creating metrics dataframe
2023-04-29 16:41:01,254:INFO:Uploading results into container
2023-04-29 16:41:01,255:INFO:Uploading model into container now
2023-04-29 16:41:01,255:INFO:_master_model_container: 15
2023-04-29 16:41:01,255:INFO:_display_container: 2
2023-04-29 16:41:01,256:INFO:AdaBoostRegressor(random_state=4655)
2023-04-29 16:41:01,256:INFO:create_model() successfully completed......................................
2023-04-29 16:41:01,412:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:01,412:INFO:Creating metrics dataframe
2023-04-29 16:41:01,428:INFO:Initializing Gradient Boosting Regressor
2023-04-29 16:41:01,428:INFO:Total runtime is 1.6040790716807047 minutes
2023-04-29 16:41:01,428:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:01,429:INFO:Initializing create_model()
2023-04-29 16:41:01,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:01,429:INFO:Checking exceptions
2023-04-29 16:41:01,429:INFO:Importing libraries
2023-04-29 16:41:01,429:INFO:Copying training dataset
2023-04-29 16:41:01,436:INFO:Defining folds
2023-04-29 16:41:01,436:INFO:Declaring metric variables
2023-04-29 16:41:01,436:INFO:Importing untrained model
2023-04-29 16:41:01,437:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 16:41:01,439:INFO:Starting cross validation
2023-04-29 16:41:01,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:05,523:INFO:Calculating mean and std
2023-04-29 16:41:05,525:INFO:Creating metrics dataframe
2023-04-29 16:41:05,974:INFO:Uploading results into container
2023-04-29 16:41:05,975:INFO:Uploading model into container now
2023-04-29 16:41:05,975:INFO:_master_model_container: 8
2023-04-29 16:41:05,975:INFO:_display_container: 2
2023-04-29 16:41:05,976:INFO:BayesianRidge()
2023-04-29 16:41:05,976:INFO:create_model() successfully completed......................................
2023-04-29 16:41:06,127:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:06,127:INFO:Creating metrics dataframe
2023-04-29 16:41:06,132:INFO:Initializing Passive Aggressive Regressor
2023-04-29 16:41:06,132:INFO:Total runtime is 1.0726006150245668 minutes
2023-04-29 16:41:06,132:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:06,133:INFO:Initializing create_model()
2023-04-29 16:41:06,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:06,133:INFO:Checking exceptions
2023-04-29 16:41:06,133:INFO:Importing libraries
2023-04-29 16:41:06,133:INFO:Copying training dataset
2023-04-29 16:41:06,140:INFO:Defining folds
2023-04-29 16:41:06,140:INFO:Declaring metric variables
2023-04-29 16:41:06,140:INFO:Importing untrained model
2023-04-29 16:41:06,141:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 16:41:06,141:INFO:Starting cross validation
2023-04-29 16:41:06,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:09,969:INFO:Calculating mean and std
2023-04-29 16:41:09,969:INFO:Creating metrics dataframe
2023-04-29 16:41:10,401:INFO:Uploading results into container
2023-04-29 16:41:10,402:INFO:Uploading model into container now
2023-04-29 16:41:10,403:INFO:_master_model_container: 16
2023-04-29 16:41:10,403:INFO:_display_container: 2
2023-04-29 16:41:10,403:INFO:GradientBoostingRegressor(random_state=4655)
2023-04-29 16:41:10,404:INFO:create_model() successfully completed......................................
2023-04-29 16:41:10,552:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:10,553:INFO:Creating metrics dataframe
2023-04-29 16:41:10,559:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 16:41:10,559:INFO:Total runtime is 1.7562530716260274 minutes
2023-04-29 16:41:10,559:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:10,560:INFO:Initializing create_model()
2023-04-29 16:41:10,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:10,560:INFO:Checking exceptions
2023-04-29 16:41:10,560:INFO:Importing libraries
2023-04-29 16:41:10,560:INFO:Copying training dataset
2023-04-29 16:41:10,566:INFO:Defining folds
2023-04-29 16:41:10,567:INFO:Declaring metric variables
2023-04-29 16:41:10,567:INFO:Importing untrained model
2023-04-29 16:41:10,567:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 16:41:10,568:INFO:Starting cross validation
2023-04-29 16:41:10,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:16,277:INFO:Calculating mean and std
2023-04-29 16:41:16,278:INFO:Creating metrics dataframe
2023-04-29 16:41:16,717:INFO:Uploading results into container
2023-04-29 16:41:16,717:INFO:Uploading model into container now
2023-04-29 16:41:16,718:INFO:_master_model_container: 9
2023-04-29 16:41:16,718:INFO:_display_container: 2
2023-04-29 16:41:16,719:INFO:PassiveAggressiveRegressor(random_state=5976)
2023-04-29 16:41:16,719:INFO:create_model() successfully completed......................................
2023-04-29 16:41:16,886:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:16,887:INFO:Creating metrics dataframe
2023-04-29 16:41:16,892:INFO:Initializing Huber Regressor
2023-04-29 16:41:16,892:INFO:Total runtime is 1.2519325335820517 minutes
2023-04-29 16:41:16,892:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:16,893:INFO:Initializing create_model()
2023-04-29 16:41:16,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:16,893:INFO:Checking exceptions
2023-04-29 16:41:16,893:INFO:Importing libraries
2023-04-29 16:41:16,893:INFO:Copying training dataset
2023-04-29 16:41:16,900:INFO:Defining folds
2023-04-29 16:41:16,900:INFO:Declaring metric variables
2023-04-29 16:41:16,901:INFO:Importing untrained model
2023-04-29 16:41:16,902:INFO:Huber Regressor Imported successfully
2023-04-29 16:41:16,903:INFO:Starting cross validation
2023-04-29 16:41:16,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:20,758:INFO:Calculating mean and std
2023-04-29 16:41:20,759:INFO:Creating metrics dataframe
2023-04-29 16:41:21,210:INFO:Uploading results into container
2023-04-29 16:41:21,210:INFO:Uploading model into container now
2023-04-29 16:41:21,211:INFO:_master_model_container: 17
2023-04-29 16:41:21,211:INFO:_display_container: 2
2023-04-29 16:41:21,212:INFO:LGBMRegressor(random_state=4655)
2023-04-29 16:41:21,212:INFO:create_model() successfully completed......................................
2023-04-29 16:41:21,365:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:21,366:INFO:Creating metrics dataframe
2023-04-29 16:41:21,379:INFO:Initializing Dummy Regressor
2023-04-29 16:41:21,379:INFO:Total runtime is 1.9365853627522787 minutes
2023-04-29 16:41:21,380:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:21,380:INFO:Initializing create_model()
2023-04-29 16:41:21,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B93A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:21,380:INFO:Checking exceptions
2023-04-29 16:41:21,380:INFO:Importing libraries
2023-04-29 16:41:21,380:INFO:Copying training dataset
2023-04-29 16:41:21,387:INFO:Defining folds
2023-04-29 16:41:21,387:INFO:Declaring metric variables
2023-04-29 16:41:21,387:INFO:Importing untrained model
2023-04-29 16:41:21,388:INFO:Dummy Regressor Imported successfully
2023-04-29 16:41:21,389:INFO:Starting cross validation
2023-04-29 16:41:21,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:25,273:INFO:Calculating mean and std
2023-04-29 16:41:25,275:INFO:Creating metrics dataframe
2023-04-29 16:41:25,758:INFO:Uploading results into container
2023-04-29 16:41:25,759:INFO:Uploading model into container now
2023-04-29 16:41:25,760:INFO:_master_model_container: 10
2023-04-29 16:41:25,760:INFO:_display_container: 2
2023-04-29 16:41:25,760:INFO:HuberRegressor()
2023-04-29 16:41:25,760:INFO:create_model() successfully completed......................................
2023-04-29 16:41:25,910:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:25,911:INFO:Creating metrics dataframe
2023-04-29 16:41:25,916:INFO:Initializing K Neighbors Regressor
2023-04-29 16:41:25,916:INFO:Total runtime is 1.4023365020751954 minutes
2023-04-29 16:41:25,917:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:25,917:INFO:Initializing create_model()
2023-04-29 16:41:25,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:25,918:INFO:Checking exceptions
2023-04-29 16:41:25,918:INFO:Importing libraries
2023-04-29 16:41:25,918:INFO:Copying training dataset
2023-04-29 16:41:25,930:INFO:Defining folds
2023-04-29 16:41:25,931:INFO:Declaring metric variables
2023-04-29 16:41:25,932:INFO:Importing untrained model
2023-04-29 16:41:25,933:INFO:K Neighbors Regressor Imported successfully
2023-04-29 16:41:25,933:INFO:Starting cross validation
2023-04-29 16:41:25,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:29,798:INFO:Calculating mean and std
2023-04-29 16:41:29,800:INFO:Creating metrics dataframe
2023-04-29 16:41:30,279:INFO:Uploading results into container
2023-04-29 16:41:30,280:INFO:Uploading model into container now
2023-04-29 16:41:30,280:INFO:_master_model_container: 18
2023-04-29 16:41:30,280:INFO:_display_container: 2
2023-04-29 16:41:30,280:INFO:DummyRegressor()
2023-04-29 16:41:30,280:INFO:create_model() successfully completed......................................
2023-04-29 16:41:30,415:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:30,415:INFO:Creating metrics dataframe
2023-04-29 16:41:30,424:INFO:Initializing create_model()
2023-04-29 16:41:30,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B78A66A0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=4655), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:30,424:INFO:Checking exceptions
2023-04-29 16:41:30,425:INFO:Importing libraries
2023-04-29 16:41:30,425:INFO:Copying training dataset
2023-04-29 16:41:30,428:INFO:Defining folds
2023-04-29 16:41:30,428:INFO:Declaring metric variables
2023-04-29 16:41:30,428:INFO:Importing untrained model
2023-04-29 16:41:30,429:INFO:Declaring custom model
2023-04-29 16:41:30,429:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:41:30,430:INFO:Cross validation set to False
2023-04-29 16:41:30,430:INFO:Fitting Model
2023-04-29 16:41:31,235:INFO:RandomForestRegressor(n_jobs=-1, random_state=4655)
2023-04-29 16:41:31,236:INFO:create_model() successfully completed......................................
2023-04-29 16:41:31,408:INFO:                                    Model     MAE     MSE    RMSE      R2  \
2023-04-29 16:41:31,408:INFO:rf                Random Forest Regressor  0.0648  0.0451  0.2033  0.9313   
2023-04-29 16:41:31,409:INFO:et                  Extra Trees Regressor  0.0655  0.0489  0.2160  0.9268   
2023-04-29 16:41:31,409:INFO:lightgbm  Light Gradient Boosting Machine  0.0849  0.0595  0.2317  0.9093   
2023-04-29 16:41:31,409:INFO:gbr           Gradient Boosting Regressor  0.1243  0.0660  0.2514  0.9004   
2023-04-29 16:41:31,410:INFO:dt                Decision Tree Regressor  0.0494  0.0620  0.2358  0.8991   
2023-04-29 16:41:31,410:INFO:knn                 K Neighbors Regressor  0.1587  0.1168  0.3375  0.8243   
2023-04-29 16:41:31,410:INFO:ada                    AdaBoost Regressor  0.3068  0.1584  0.3966  0.7663   
2023-04-29 16:41:31,410:INFO:br                         Bayesian Ridge  0.3988  0.2959  0.5398  0.5632   
2023-04-29 16:41:31,410:INFO:ridge                    Ridge Regression  0.3987  0.2960  0.5399  0.5630   
2023-04-29 16:41:31,411:INFO:lr                      Linear Regression  0.3987  0.2961  0.5399  0.5629   
2023-04-29 16:41:31,411:INFO:lar                Least Angle Regression  0.4109  0.3138  0.5548  0.5404   
2023-04-29 16:41:31,411:INFO:omp           Orthogonal Matching Pursuit  0.4461  0.3624  0.5976  0.4683   
2023-04-29 16:41:31,411:INFO:huber                     Huber Regressor  0.3614  0.3658  0.5961  0.4650   
2023-04-29 16:41:31,412:INFO:par          Passive Aggressive Regressor  0.4621  0.3808  0.6094  0.4392   
2023-04-29 16:41:31,412:INFO:en                            Elastic Net  0.4859  0.4452  0.6649  0.3482   
2023-04-29 16:41:31,412:INFO:lasso                    Lasso Regression  0.5656  0.6326  0.7928  0.0738   
2023-04-29 16:41:31,412:INFO:llar         Lasso Least Angle Regression  0.5566  0.6890  0.8277 -0.0099   
2023-04-29 16:41:31,413:INFO:dummy                     Dummy Regressor  0.5566  0.6890  0.8277 -0.0099   
2023-04-29 16:41:31,413:INFO:
2023-04-29 16:41:31,413:INFO:           RMSLE    MAPE  TT (Sec)  
2023-04-29 16:41:31,413:INFO:rf        0.0343  0.0132     0.894  
2023-04-29 16:41:31,413:INFO:et        0.0370  0.0135     0.909  
2023-04-29 16:41:31,413:INFO:lightgbm  0.0400  0.0175     1.019  
2023-04-29 16:41:31,414:INFO:gbr       0.0434  0.0259     0.853  
2023-04-29 16:41:31,414:INFO:dt        0.0397  0.0096     0.783  
2023-04-29 16:41:31,414:INFO:knn       0.0573  0.0324     0.782  
2023-04-29 16:41:31,415:INFO:ada       0.0681  0.0644     0.834  
2023-04-29 16:41:31,415:INFO:br        0.0968  0.0850     0.354  
2023-04-29 16:41:31,415:INFO:ridge     0.0969  0.0849     0.295  
2023-04-29 16:41:31,416:INFO:lr        0.0969  0.0849     0.979  
2023-04-29 16:41:31,416:INFO:lar       0.0988  0.0863     0.301  
2023-04-29 16:41:31,416:INFO:omp       0.1099  0.0953     0.329  
2023-04-29 16:41:31,416:INFO:huber     0.1210  0.0732     0.710  
2023-04-29 16:41:31,417:INFO:par       0.1064  0.0944     0.638  
2023-04-29 16:41:31,417:INFO:en        0.1192  0.1078     0.285  
2023-04-29 16:41:31,417:INFO:lasso     0.1414  0.1270     0.255  
2023-04-29 16:41:31,417:INFO:llar      0.1469  0.1255     0.289  
2023-04-29 16:41:31,417:INFO:dummy     0.1469  0.1255     0.841  
2023-04-29 16:41:31,417:INFO:_master_model_container: 18
2023-04-29 16:41:31,417:INFO:_display_container: 2
2023-04-29 16:41:31,419:INFO:RandomForestRegressor(n_jobs=-1, random_state=4655)
2023-04-29 16:41:31,420:INFO:compare_models() successfully completed......................................
2023-04-29 16:41:34,526:INFO:Calculating mean and std
2023-04-29 16:41:34,527:INFO:Creating metrics dataframe
2023-04-29 16:41:34,959:INFO:Uploading results into container
2023-04-29 16:41:34,959:INFO:Uploading model into container now
2023-04-29 16:41:34,960:INFO:_master_model_container: 11
2023-04-29 16:41:34,960:INFO:_display_container: 2
2023-04-29 16:41:34,960:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 16:41:34,960:INFO:create_model() successfully completed......................................
2023-04-29 16:41:35,119:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:35,119:INFO:Creating metrics dataframe
2023-04-29 16:41:35,133:INFO:Initializing Decision Tree Regressor
2023-04-29 16:41:35,134:INFO:Total runtime is 1.5559609333674114 minutes
2023-04-29 16:41:35,135:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:35,135:INFO:Initializing create_model()
2023-04-29 16:41:35,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:35,136:INFO:Checking exceptions
2023-04-29 16:41:35,136:INFO:Importing libraries
2023-04-29 16:41:35,136:INFO:Copying training dataset
2023-04-29 16:41:35,141:INFO:Defining folds
2023-04-29 16:41:35,142:INFO:Declaring metric variables
2023-04-29 16:41:35,142:INFO:Importing untrained model
2023-04-29 16:41:35,143:INFO:Decision Tree Regressor Imported successfully
2023-04-29 16:41:35,143:INFO:Starting cross validation
2023-04-29 16:41:35,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:39,073:INFO:Calculating mean and std
2023-04-29 16:41:39,074:INFO:Creating metrics dataframe
2023-04-29 16:41:39,458:INFO:Uploading results into container
2023-04-29 16:41:39,458:INFO:Uploading model into container now
2023-04-29 16:41:39,459:INFO:_master_model_container: 12
2023-04-29 16:41:39,459:INFO:_display_container: 2
2023-04-29 16:41:39,459:INFO:DecisionTreeRegressor(random_state=5976)
2023-04-29 16:41:39,459:INFO:create_model() successfully completed......................................
2023-04-29 16:41:39,606:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:39,606:INFO:Creating metrics dataframe
2023-04-29 16:41:39,618:INFO:Initializing Random Forest Regressor
2023-04-29 16:41:39,618:INFO:Total runtime is 1.6307077964146932 minutes
2023-04-29 16:41:39,619:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:39,621:INFO:Initializing create_model()
2023-04-29 16:41:39,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:39,622:INFO:Checking exceptions
2023-04-29 16:41:39,622:INFO:Importing libraries
2023-04-29 16:41:39,622:INFO:Copying training dataset
2023-04-29 16:41:39,631:INFO:Defining folds
2023-04-29 16:41:39,631:INFO:Declaring metric variables
2023-04-29 16:41:39,632:INFO:Importing untrained model
2023-04-29 16:41:39,633:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:41:39,634:INFO:Starting cross validation
2023-04-29 16:41:39,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:44,478:INFO:Calculating mean and std
2023-04-29 16:41:44,480:INFO:Creating metrics dataframe
2023-04-29 16:41:44,944:INFO:Uploading results into container
2023-04-29 16:41:44,945:INFO:Uploading model into container now
2023-04-29 16:41:44,945:INFO:_master_model_container: 13
2023-04-29 16:41:44,945:INFO:_display_container: 2
2023-04-29 16:41:44,946:INFO:RandomForestRegressor(n_jobs=-1, random_state=5976)
2023-04-29 16:41:44,946:INFO:create_model() successfully completed......................................
2023-04-29 16:41:45,093:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:45,093:INFO:Creating metrics dataframe
2023-04-29 16:41:45,099:INFO:Initializing Extra Trees Regressor
2023-04-29 16:41:45,099:INFO:Total runtime is 1.7220486720403037 minutes
2023-04-29 16:41:45,100:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:45,100:INFO:Initializing create_model()
2023-04-29 16:41:45,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:45,100:INFO:Checking exceptions
2023-04-29 16:41:45,100:INFO:Importing libraries
2023-04-29 16:41:45,100:INFO:Copying training dataset
2023-04-29 16:41:45,105:INFO:Defining folds
2023-04-29 16:41:45,105:INFO:Declaring metric variables
2023-04-29 16:41:45,106:INFO:Importing untrained model
2023-04-29 16:41:45,106:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:41:45,106:INFO:Starting cross validation
2023-04-29 16:41:45,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:49,781:INFO:Calculating mean and std
2023-04-29 16:41:49,782:INFO:Creating metrics dataframe
2023-04-29 16:41:50,267:INFO:Uploading results into container
2023-04-29 16:41:50,268:INFO:Uploading model into container now
2023-04-29 16:41:50,269:INFO:_master_model_container: 14
2023-04-29 16:41:50,269:INFO:_display_container: 2
2023-04-29 16:41:50,270:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5976)
2023-04-29 16:41:50,270:INFO:create_model() successfully completed......................................
2023-04-29 16:41:50,435:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:50,436:INFO:Creating metrics dataframe
2023-04-29 16:41:50,447:INFO:Initializing AdaBoost Regressor
2023-04-29 16:41:50,448:INFO:Total runtime is 1.8111870567003887 minutes
2023-04-29 16:41:50,448:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:50,448:INFO:Initializing create_model()
2023-04-29 16:41:50,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:50,448:INFO:Checking exceptions
2023-04-29 16:41:50,448:INFO:Importing libraries
2023-04-29 16:41:50,449:INFO:Copying training dataset
2023-04-29 16:41:50,456:INFO:Defining folds
2023-04-29 16:41:50,457:INFO:Declaring metric variables
2023-04-29 16:41:50,457:INFO:Importing untrained model
2023-04-29 16:41:50,458:INFO:AdaBoost Regressor Imported successfully
2023-04-29 16:41:50,460:INFO:Starting cross validation
2023-04-29 16:41:50,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:54,572:INFO:Calculating mean and std
2023-04-29 16:41:54,574:INFO:Creating metrics dataframe
2023-04-29 16:41:55,049:INFO:Uploading results into container
2023-04-29 16:41:55,050:INFO:Uploading model into container now
2023-04-29 16:41:55,051:INFO:_master_model_container: 15
2023-04-29 16:41:55,051:INFO:_display_container: 2
2023-04-29 16:41:55,052:INFO:AdaBoostRegressor(random_state=5976)
2023-04-29 16:41:55,052:INFO:create_model() successfully completed......................................
2023-04-29 16:41:55,214:INFO:SubProcess create_model() end ==================================
2023-04-29 16:41:55,215:INFO:Creating metrics dataframe
2023-04-29 16:41:55,221:INFO:Initializing Gradient Boosting Regressor
2023-04-29 16:41:55,221:INFO:Total runtime is 1.8907430251439414 minutes
2023-04-29 16:41:55,222:INFO:SubProcess create_model() called ==================================
2023-04-29 16:41:55,222:INFO:Initializing create_model()
2023-04-29 16:41:55,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:41:55,222:INFO:Checking exceptions
2023-04-29 16:41:55,222:INFO:Importing libraries
2023-04-29 16:41:55,223:INFO:Copying training dataset
2023-04-29 16:41:55,227:INFO:Defining folds
2023-04-29 16:41:55,227:INFO:Declaring metric variables
2023-04-29 16:41:55,227:INFO:Importing untrained model
2023-04-29 16:41:55,227:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 16:41:55,227:INFO:Starting cross validation
2023-04-29 16:41:55,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:41:59,899:INFO:Calculating mean and std
2023-04-29 16:41:59,900:INFO:Creating metrics dataframe
2023-04-29 16:42:00,434:INFO:Uploading results into container
2023-04-29 16:42:00,435:INFO:Uploading model into container now
2023-04-29 16:42:00,435:INFO:_master_model_container: 16
2023-04-29 16:42:00,435:INFO:_display_container: 2
2023-04-29 16:42:00,435:INFO:GradientBoostingRegressor(random_state=5976)
2023-04-29 16:42:00,436:INFO:create_model() successfully completed......................................
2023-04-29 16:42:00,573:INFO:SubProcess create_model() end ==================================
2023-04-29 16:42:00,574:INFO:Creating metrics dataframe
2023-04-29 16:42:00,588:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 16:42:00,589:INFO:Total runtime is 1.980213562647502 minutes
2023-04-29 16:42:00,589:INFO:SubProcess create_model() called ==================================
2023-04-29 16:42:00,589:INFO:Initializing create_model()
2023-04-29 16:42:00,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:42:00,590:INFO:Checking exceptions
2023-04-29 16:42:00,590:INFO:Importing libraries
2023-04-29 16:42:00,590:INFO:Copying training dataset
2023-04-29 16:42:00,599:INFO:Defining folds
2023-04-29 16:42:00,599:INFO:Declaring metric variables
2023-04-29 16:42:00,600:INFO:Importing untrained model
2023-04-29 16:42:00,601:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 16:42:00,601:INFO:Starting cross validation
2023-04-29 16:42:00,604:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:42:04,972:INFO:Calculating mean and std
2023-04-29 16:42:04,974:INFO:Creating metrics dataframe
2023-04-29 16:42:05,447:INFO:Uploading results into container
2023-04-29 16:42:05,449:INFO:Uploading model into container now
2023-04-29 16:42:05,449:INFO:_master_model_container: 17
2023-04-29 16:42:05,449:INFO:_display_container: 2
2023-04-29 16:42:05,450:INFO:LGBMRegressor(random_state=5976)
2023-04-29 16:42:05,450:INFO:create_model() successfully completed......................................
2023-04-29 16:42:05,582:INFO:SubProcess create_model() end ==================================
2023-04-29 16:42:05,582:INFO:Creating metrics dataframe
2023-04-29 16:42:05,603:INFO:Initializing Dummy Regressor
2023-04-29 16:42:05,603:INFO:Total runtime is 2.0637753287951153 minutes
2023-04-29 16:42:05,604:INFO:SubProcess create_model() called ==================================
2023-04-29 16:42:05,605:INFO:Initializing create_model()
2023-04-29 16:42:05,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6FF9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:42:05,605:INFO:Checking exceptions
2023-04-29 16:42:05,605:INFO:Importing libraries
2023-04-29 16:42:05,605:INFO:Copying training dataset
2023-04-29 16:42:05,616:INFO:Defining folds
2023-04-29 16:42:05,617:INFO:Declaring metric variables
2023-04-29 16:42:05,617:INFO:Importing untrained model
2023-04-29 16:42:05,618:INFO:Dummy Regressor Imported successfully
2023-04-29 16:42:05,618:INFO:Starting cross validation
2023-04-29 16:42:05,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:42:09,663:INFO:Calculating mean and std
2023-04-29 16:42:09,665:INFO:Creating metrics dataframe
2023-04-29 16:42:10,132:INFO:Uploading results into container
2023-04-29 16:42:10,133:INFO:Uploading model into container now
2023-04-29 16:42:10,133:INFO:_master_model_container: 18
2023-04-29 16:42:10,133:INFO:_display_container: 2
2023-04-29 16:42:10,134:INFO:DummyRegressor()
2023-04-29 16:42:10,134:INFO:create_model() successfully completed......................................
2023-04-29 16:42:10,267:INFO:SubProcess create_model() end ==================================
2023-04-29 16:42:10,267:INFO:Creating metrics dataframe
2023-04-29 16:42:10,284:INFO:Initializing create_model()
2023-04-29 16:42:10,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=RandomForestRegressor(n_jobs=-1, random_state=5976), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:42:10,284:INFO:Checking exceptions
2023-04-29 16:42:10,286:INFO:Importing libraries
2023-04-29 16:42:10,286:INFO:Copying training dataset
2023-04-29 16:42:10,292:INFO:Defining folds
2023-04-29 16:42:10,292:INFO:Declaring metric variables
2023-04-29 16:42:10,292:INFO:Importing untrained model
2023-04-29 16:42:10,292:INFO:Declaring custom model
2023-04-29 16:42:10,294:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:42:10,295:INFO:Cross validation set to False
2023-04-29 16:42:10,295:INFO:Fitting Model
2023-04-29 16:42:11,106:INFO:RandomForestRegressor(n_jobs=-1, random_state=5976)
2023-04-29 16:42:11,107:INFO:create_model() successfully completed......................................
2023-04-29 16:42:11,301:INFO:_master_model_container: 18
2023-04-29 16:42:11,301:INFO:_display_container: 2
2023-04-29 16:42:11,302:INFO:RandomForestRegressor(n_jobs=-1, random_state=5976)
2023-04-29 16:42:11,302:INFO:compare_models() successfully completed......................................
2023-04-29 16:42:11,328:INFO:Initializing predict_model()
2023-04-29 16:42:11,328:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B68BD070>, estimator=                                    Model  ...  TT (Sec)
rf                Random Forest Regressor  ...     0.484
et                  Extra Trees Regressor  ...     0.467
dt                Decision Tree Regressor  ...     0.393
lightgbm  Light Gradient Boosting Machine  ...     0.437
gbr           Gradient Boosting Regressor  ...     0.467
knn                 K Neighbors Regressor  ...     0.859
ada                    AdaBoost Regressor  ...     0.411
br                         Bayesian Ridge  ...     0.842
ridge                    Ridge Regression  ...     0.804
lr                      Linear Regression  ...     0.373
lar                Least Angle Regression  ...     0.880
omp           Orthogonal Matching Pursuit  ...     0.835
huber                     Huber Regressor  ...     0.837
en                            Elastic Net  ...     0.789
par          Passive Aggressive Regressor  ...     1.014
lasso                    Lasso Regression  ...     0.596
llar         Lasso Least Angle Regression  ...     0.884
dummy                     Dummy Regressor  ...     0.404

[18 rows x 8 columns], probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B6773160>)
2023-04-29 16:42:11,328:INFO:Checking exceptions
2023-04-29 16:42:11,328:INFO:Preloading libraries
2023-04-29 16:42:11,328:INFO:Set up data.
2023-04-29 16:42:11,339:INFO:Set up index.
2023-04-29 16:58:32,465:INFO:PyCaret RegressionExperiment
2023-04-29 16:58:32,465:INFO:Logging name: reg-default-name
2023-04-29 16:58:32,465:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 16:58:32,465:INFO:version 3.0.0
2023-04-29 16:58:32,465:INFO:Initializing setup()
2023-04-29 16:58:32,465:INFO:self.USI: d34a
2023-04-29 16:58:32,465:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 16:58:32,465:INFO:Checking environment
2023-04-29 16:58:32,465:INFO:python_version: 3.9.13
2023-04-29 16:58:32,465:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 16:58:32,465:INFO:machine: AMD64
2023-04-29 16:58:32,465:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 16:58:32,465:INFO:Memory: svmem(total=16935899136, available=6703489024, percent=60.4, used=10232410112, free=6703489024)
2023-04-29 16:58:32,465:INFO:Physical Core: 4
2023-04-29 16:58:32,465:INFO:Logical Core: 8
2023-04-29 16:58:32,465:INFO:Checking libraries
2023-04-29 16:58:32,465:INFO:System:
2023-04-29 16:58:32,465:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 16:58:32,466:INFO:executable: D:\Anaconda\python.exe
2023-04-29 16:58:32,466:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 16:58:32,466:INFO:PyCaret required dependencies:
2023-04-29 16:58:32,466:INFO:                 pip: 22.2.2
2023-04-29 16:58:32,466:INFO:          setuptools: 63.4.1
2023-04-29 16:58:32,466:INFO:             pycaret: 3.0.0
2023-04-29 16:58:32,466:INFO:             IPython: 7.31.1
2023-04-29 16:58:32,466:INFO:          ipywidgets: 7.6.5
2023-04-29 16:58:32,467:INFO:                tqdm: 4.64.1
2023-04-29 16:58:32,467:INFO:               numpy: 1.21.5
2023-04-29 16:58:32,467:INFO:              pandas: 1.4.4
2023-04-29 16:58:32,467:INFO:              jinja2: 2.11.3
2023-04-29 16:58:32,467:INFO:               scipy: 1.9.1
2023-04-29 16:58:32,467:INFO:              joblib: 1.2.0
2023-04-29 16:58:32,467:INFO:             sklearn: 1.0.2
2023-04-29 16:58:32,467:INFO:                pyod: 1.0.9
2023-04-29 16:58:32,467:INFO:            imblearn: 0.10.1
2023-04-29 16:58:32,467:INFO:   category_encoders: 2.6.0
2023-04-29 16:58:32,468:INFO:            lightgbm: 3.3.5
2023-04-29 16:58:32,468:INFO:               numba: 0.55.1
2023-04-29 16:58:32,468:INFO:            requests: 2.28.1
2023-04-29 16:58:32,468:INFO:          matplotlib: 3.5.2
2023-04-29 16:58:32,468:INFO:          scikitplot: 0.3.7
2023-04-29 16:58:32,468:INFO:         yellowbrick: 1.5
2023-04-29 16:58:32,468:INFO:              plotly: 5.9.0
2023-04-29 16:58:32,468:INFO:             kaleido: 0.2.1
2023-04-29 16:58:32,468:INFO:         statsmodels: 0.13.2
2023-04-29 16:58:32,468:INFO:              sktime: 0.17.1
2023-04-29 16:58:32,469:INFO:               tbats: 1.1.2
2023-04-29 16:58:32,469:INFO:            pmdarima: 2.0.3
2023-04-29 16:58:32,469:INFO:              psutil: 5.9.0
2023-04-29 16:58:32,469:INFO:PyCaret optional dependencies:
2023-04-29 16:58:32,469:INFO:                shap: 0.41.0
2023-04-29 16:58:32,469:INFO:           interpret: Not installed
2023-04-29 16:58:32,469:INFO:                umap: Not installed
2023-04-29 16:58:32,469:INFO:    pandas_profiling: 4.1.2
2023-04-29 16:58:32,470:INFO:  explainerdashboard: Not installed
2023-04-29 16:58:32,470:INFO:             autoviz: Not installed
2023-04-29 16:58:32,470:INFO:           fairlearn: Not installed
2023-04-29 16:58:32,470:INFO:             xgboost: Not installed
2023-04-29 16:58:32,470:INFO:            catboost: Not installed
2023-04-29 16:58:32,470:INFO:              kmodes: Not installed
2023-04-29 16:58:32,470:INFO:             mlxtend: Not installed
2023-04-29 16:58:32,470:INFO:       statsforecast: Not installed
2023-04-29 16:58:32,471:INFO:        tune_sklearn: Not installed
2023-04-29 16:58:32,471:INFO:                 ray: Not installed
2023-04-29 16:58:32,471:INFO:            hyperopt: Not installed
2023-04-29 16:58:32,471:INFO:              optuna: Not installed
2023-04-29 16:58:32,471:INFO:               skopt: Not installed
2023-04-29 16:58:32,471:INFO:              mlflow: 2.2.1
2023-04-29 16:58:32,471:INFO:              gradio: Not installed
2023-04-29 16:58:32,471:INFO:             fastapi: Not installed
2023-04-29 16:58:32,471:INFO:             uvicorn: Not installed
2023-04-29 16:58:32,472:INFO:              m2cgen: Not installed
2023-04-29 16:58:32,472:INFO:           evidently: Not installed
2023-04-29 16:58:32,472:INFO:               fugue: Not installed
2023-04-29 16:58:32,472:INFO:           streamlit: 1.21.0
2023-04-29 16:58:32,472:INFO:             prophet: Not installed
2023-04-29 16:58:32,472:INFO:None
2023-04-29 16:58:32,472:INFO:Set up data.
2023-04-29 16:58:32,480:INFO:Set up train/test split.
2023-04-29 16:58:32,487:INFO:Set up index.
2023-04-29 16:58:32,487:INFO:Set up folding strategy.
2023-04-29 16:58:32,487:INFO:Assigning column types.
2023-04-29 16:58:32,492:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 16:58:32,493:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:32,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:32,691:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,710:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:32,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:32,911:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 16:58:32,922:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:58:32,933:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,117:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,121:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,312:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,314:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 16:58:33,330:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,584:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 16:58:33,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:33,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:33,925:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:34,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 16:58:34,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,034:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 16:58:34,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:34,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 16:58:34,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,482:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 16:58:34,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:34,913:INFO:Preparing preprocessing pipeline...
2023-04-29 16:58:34,913:INFO:Set up simple imputation.
2023-04-29 16:58:34,914:INFO:Set up column name cleaning.
2023-04-29 16:58:34,958:INFO:Finished creating preprocessing pipeline.
2023-04-29 16:58:34,968:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 16:58:34,968:INFO:Creating final display dataframe.
2023-04-29 16:58:35,045:INFO:Setup _display_container:                     Description             Value
0                    Session id              7122
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d34a
2023-04-29 16:58:35,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:35,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:35,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:35,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 16:58:35,448:INFO:setup() successfully completed in 3.35s...............
2023-04-29 16:58:35,454:INFO:Initializing compare_models()
2023-04-29 16:58:35,454:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 16:58:35,455:INFO:Checking exceptions
2023-04-29 16:58:35,458:INFO:Preparing display monitor
2023-04-29 16:58:35,462:INFO:Initializing Linear Regression
2023-04-29 16:58:35,462:INFO:Total runtime is 0.0 minutes
2023-04-29 16:58:35,462:INFO:SubProcess create_model() called ==================================
2023-04-29 16:58:35,463:INFO:Initializing create_model()
2023-04-29 16:58:35,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:58:35,463:INFO:Checking exceptions
2023-04-29 16:58:35,463:INFO:Importing libraries
2023-04-29 16:58:35,463:INFO:Copying training dataset
2023-04-29 16:58:35,470:INFO:Defining folds
2023-04-29 16:58:35,470:INFO:Declaring metric variables
2023-04-29 16:58:35,471:INFO:Importing untrained model
2023-04-29 16:58:35,471:INFO:Linear Regression Imported successfully
2023-04-29 16:58:35,472:INFO:Starting cross validation
2023-04-29 16:58:35,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:58:47,414:INFO:Calculating mean and std
2023-04-29 16:58:47,415:INFO:Creating metrics dataframe
2023-04-29 16:58:47,808:INFO:Uploading results into container
2023-04-29 16:58:47,809:INFO:Uploading model into container now
2023-04-29 16:58:47,809:INFO:_master_model_container: 1
2023-04-29 16:58:47,809:INFO:_display_container: 2
2023-04-29 16:58:47,810:INFO:LinearRegression(n_jobs=-1)
2023-04-29 16:58:47,810:INFO:create_model() successfully completed......................................
2023-04-29 16:58:47,966:INFO:SubProcess create_model() end ==================================
2023-04-29 16:58:47,966:INFO:Creating metrics dataframe
2023-04-29 16:58:47,971:INFO:Initializing Lasso Regression
2023-04-29 16:58:47,972:INFO:Total runtime is 0.20849642753601075 minutes
2023-04-29 16:58:47,972:INFO:SubProcess create_model() called ==================================
2023-04-29 16:58:47,972:INFO:Initializing create_model()
2023-04-29 16:58:47,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:58:47,972:INFO:Checking exceptions
2023-04-29 16:58:47,972:INFO:Importing libraries
2023-04-29 16:58:47,972:INFO:Copying training dataset
2023-04-29 16:58:47,982:INFO:Defining folds
2023-04-29 16:58:47,982:INFO:Declaring metric variables
2023-04-29 16:58:47,982:INFO:Importing untrained model
2023-04-29 16:58:47,983:INFO:Lasso Regression Imported successfully
2023-04-29 16:58:47,983:INFO:Starting cross validation
2023-04-29 16:58:47,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:58:52,330:INFO:Calculating mean and std
2023-04-29 16:58:52,331:INFO:Creating metrics dataframe
2023-04-29 16:58:52,774:INFO:Uploading results into container
2023-04-29 16:58:52,775:INFO:Uploading model into container now
2023-04-29 16:58:52,776:INFO:_master_model_container: 2
2023-04-29 16:58:52,776:INFO:_display_container: 2
2023-04-29 16:58:52,776:INFO:Lasso(random_state=7122)
2023-04-29 16:58:52,776:INFO:create_model() successfully completed......................................
2023-04-29 16:58:52,896:INFO:SubProcess create_model() end ==================================
2023-04-29 16:58:52,896:INFO:Creating metrics dataframe
2023-04-29 16:58:52,906:INFO:Initializing Ridge Regression
2023-04-29 16:58:52,907:INFO:Total runtime is 0.2907486359278361 minutes
2023-04-29 16:58:52,907:INFO:SubProcess create_model() called ==================================
2023-04-29 16:58:52,909:INFO:Initializing create_model()
2023-04-29 16:58:52,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:58:52,909:INFO:Checking exceptions
2023-04-29 16:58:52,909:INFO:Importing libraries
2023-04-29 16:58:52,909:INFO:Copying training dataset
2023-04-29 16:58:52,916:INFO:Defining folds
2023-04-29 16:58:52,917:INFO:Declaring metric variables
2023-04-29 16:58:52,917:INFO:Importing untrained model
2023-04-29 16:58:52,918:INFO:Ridge Regression Imported successfully
2023-04-29 16:58:52,919:INFO:Starting cross validation
2023-04-29 16:58:52,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:58:56,394:INFO:Calculating mean and std
2023-04-29 16:58:56,395:INFO:Creating metrics dataframe
2023-04-29 16:58:56,747:INFO:Uploading results into container
2023-04-29 16:58:56,748:INFO:Uploading model into container now
2023-04-29 16:58:56,748:INFO:_master_model_container: 3
2023-04-29 16:58:56,749:INFO:_display_container: 2
2023-04-29 16:58:56,749:INFO:Ridge(random_state=7122)
2023-04-29 16:58:56,749:INFO:create_model() successfully completed......................................
2023-04-29 16:58:56,843:INFO:SubProcess create_model() end ==================================
2023-04-29 16:58:56,843:INFO:Creating metrics dataframe
2023-04-29 16:58:56,848:INFO:Initializing Elastic Net
2023-04-29 16:58:56,848:INFO:Total runtime is 0.3564275145530701 minutes
2023-04-29 16:58:56,848:INFO:SubProcess create_model() called ==================================
2023-04-29 16:58:56,849:INFO:Initializing create_model()
2023-04-29 16:58:56,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:58:56,849:INFO:Checking exceptions
2023-04-29 16:58:56,849:INFO:Importing libraries
2023-04-29 16:58:56,849:INFO:Copying training dataset
2023-04-29 16:58:56,856:INFO:Defining folds
2023-04-29 16:58:56,857:INFO:Declaring metric variables
2023-04-29 16:58:56,857:INFO:Importing untrained model
2023-04-29 16:58:56,858:INFO:Elastic Net Imported successfully
2023-04-29 16:58:56,858:INFO:Starting cross validation
2023-04-29 16:58:56,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:00,604:INFO:Calculating mean and std
2023-04-29 16:59:00,605:INFO:Creating metrics dataframe
2023-04-29 16:59:01,048:INFO:Uploading results into container
2023-04-29 16:59:01,049:INFO:Uploading model into container now
2023-04-29 16:59:01,049:INFO:_master_model_container: 4
2023-04-29 16:59:01,050:INFO:_display_container: 2
2023-04-29 16:59:01,050:INFO:ElasticNet(random_state=7122)
2023-04-29 16:59:01,050:INFO:create_model() successfully completed......................................
2023-04-29 16:59:01,189:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:01,190:INFO:Creating metrics dataframe
2023-04-29 16:59:01,202:INFO:Initializing Least Angle Regression
2023-04-29 16:59:01,202:INFO:Total runtime is 0.42899311780929567 minutes
2023-04-29 16:59:01,203:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:01,204:INFO:Initializing create_model()
2023-04-29 16:59:01,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:01,204:INFO:Checking exceptions
2023-04-29 16:59:01,204:INFO:Importing libraries
2023-04-29 16:59:01,204:INFO:Copying training dataset
2023-04-29 16:59:01,213:INFO:Defining folds
2023-04-29 16:59:01,213:INFO:Declaring metric variables
2023-04-29 16:59:01,213:INFO:Importing untrained model
2023-04-29 16:59:01,214:INFO:Least Angle Regression Imported successfully
2023-04-29 16:59:01,214:INFO:Starting cross validation
2023-04-29 16:59:01,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:01,337:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,349:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,360:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,376:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,393:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,406:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,425:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:01,437:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:02,204:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:02,216:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:04,989:INFO:Calculating mean and std
2023-04-29 16:59:04,991:INFO:Creating metrics dataframe
2023-04-29 16:59:05,425:INFO:Uploading results into container
2023-04-29 16:59:05,425:INFO:Uploading model into container now
2023-04-29 16:59:05,426:INFO:_master_model_container: 5
2023-04-29 16:59:05,426:INFO:_display_container: 2
2023-04-29 16:59:05,426:INFO:Lars(random_state=7122)
2023-04-29 16:59:05,426:INFO:create_model() successfully completed......................................
2023-04-29 16:59:05,533:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:05,534:INFO:Creating metrics dataframe
2023-04-29 16:59:05,539:INFO:Initializing Lasso Least Angle Regression
2023-04-29 16:59:05,539:INFO:Total runtime is 0.5012732307116191 minutes
2023-04-29 16:59:05,540:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:05,540:INFO:Initializing create_model()
2023-04-29 16:59:05,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:05,540:INFO:Checking exceptions
2023-04-29 16:59:05,540:INFO:Importing libraries
2023-04-29 16:59:05,540:INFO:Copying training dataset
2023-04-29 16:59:05,543:INFO:Defining folds
2023-04-29 16:59:05,543:INFO:Declaring metric variables
2023-04-29 16:59:05,544:INFO:Importing untrained model
2023-04-29 16:59:05,544:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 16:59:05,545:INFO:Starting cross validation
2023-04-29 16:59:05,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:05,658:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,671:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,681:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,691:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,710:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,720:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,737:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:05,756:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:06,524:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:06,537:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 16:59:09,861:INFO:Calculating mean and std
2023-04-29 16:59:09,862:INFO:Creating metrics dataframe
2023-04-29 16:59:10,330:INFO:Uploading results into container
2023-04-29 16:59:10,330:INFO:Uploading model into container now
2023-04-29 16:59:10,331:INFO:_master_model_container: 6
2023-04-29 16:59:10,331:INFO:_display_container: 2
2023-04-29 16:59:10,331:INFO:LassoLars(random_state=7122)
2023-04-29 16:59:10,332:INFO:create_model() successfully completed......................................
2023-04-29 16:59:10,485:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:10,486:INFO:Creating metrics dataframe
2023-04-29 16:59:10,497:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 16:59:10,497:INFO:Total runtime is 0.5839179396629334 minutes
2023-04-29 16:59:10,498:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:10,498:INFO:Initializing create_model()
2023-04-29 16:59:10,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:10,499:INFO:Checking exceptions
2023-04-29 16:59:10,499:INFO:Importing libraries
2023-04-29 16:59:10,499:INFO:Copying training dataset
2023-04-29 16:59:10,508:INFO:Defining folds
2023-04-29 16:59:10,508:INFO:Declaring metric variables
2023-04-29 16:59:10,509:INFO:Importing untrained model
2023-04-29 16:59:10,509:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 16:59:10,510:INFO:Starting cross validation
2023-04-29 16:59:10,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:10,635:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,651:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,664:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,683:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,684:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,704:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,722:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:10,735:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:11,526:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:11,539:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 16:59:14,912:INFO:Calculating mean and std
2023-04-29 16:59:14,913:INFO:Creating metrics dataframe
2023-04-29 16:59:15,376:INFO:Uploading results into container
2023-04-29 16:59:15,377:INFO:Uploading model into container now
2023-04-29 16:59:15,377:INFO:_master_model_container: 7
2023-04-29 16:59:15,377:INFO:_display_container: 2
2023-04-29 16:59:15,377:INFO:OrthogonalMatchingPursuit()
2023-04-29 16:59:15,378:INFO:create_model() successfully completed......................................
2023-04-29 16:59:15,497:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:15,497:INFO:Creating metrics dataframe
2023-04-29 16:59:15,506:INFO:Initializing Bayesian Ridge
2023-04-29 16:59:15,506:INFO:Total runtime is 0.6674036383628845 minutes
2023-04-29 16:59:15,506:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:15,507:INFO:Initializing create_model()
2023-04-29 16:59:15,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:15,507:INFO:Checking exceptions
2023-04-29 16:59:15,507:INFO:Importing libraries
2023-04-29 16:59:15,507:INFO:Copying training dataset
2023-04-29 16:59:15,514:INFO:Defining folds
2023-04-29 16:59:15,514:INFO:Declaring metric variables
2023-04-29 16:59:15,514:INFO:Importing untrained model
2023-04-29 16:59:15,515:INFO:Bayesian Ridge Imported successfully
2023-04-29 16:59:15,515:INFO:Starting cross validation
2023-04-29 16:59:15,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:18,999:INFO:Calculating mean and std
2023-04-29 16:59:19,000:INFO:Creating metrics dataframe
2023-04-29 16:59:19,426:INFO:Uploading results into container
2023-04-29 16:59:19,427:INFO:Uploading model into container now
2023-04-29 16:59:19,428:INFO:_master_model_container: 8
2023-04-29 16:59:19,428:INFO:_display_container: 2
2023-04-29 16:59:19,428:INFO:BayesianRidge()
2023-04-29 16:59:19,428:INFO:create_model() successfully completed......................................
2023-04-29 16:59:19,538:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:19,538:INFO:Creating metrics dataframe
2023-04-29 16:59:19,545:INFO:Initializing Passive Aggressive Regressor
2023-04-29 16:59:19,545:INFO:Total runtime is 0.7347047408421834 minutes
2023-04-29 16:59:19,545:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:19,545:INFO:Initializing create_model()
2023-04-29 16:59:19,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:19,545:INFO:Checking exceptions
2023-04-29 16:59:19,546:INFO:Importing libraries
2023-04-29 16:59:19,546:INFO:Copying training dataset
2023-04-29 16:59:19,552:INFO:Defining folds
2023-04-29 16:59:19,552:INFO:Declaring metric variables
2023-04-29 16:59:19,552:INFO:Importing untrained model
2023-04-29 16:59:19,552:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 16:59:19,553:INFO:Starting cross validation
2023-04-29 16:59:19,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:23,955:INFO:Calculating mean and std
2023-04-29 16:59:23,955:INFO:Creating metrics dataframe
2023-04-29 16:59:24,337:INFO:Uploading results into container
2023-04-29 16:59:24,338:INFO:Uploading model into container now
2023-04-29 16:59:24,338:INFO:_master_model_container: 9
2023-04-29 16:59:24,339:INFO:_display_container: 2
2023-04-29 16:59:24,340:INFO:PassiveAggressiveRegressor(random_state=7122)
2023-04-29 16:59:24,340:INFO:create_model() successfully completed......................................
2023-04-29 16:59:24,457:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:24,457:INFO:Creating metrics dataframe
2023-04-29 16:59:24,466:INFO:Initializing Huber Regressor
2023-04-29 16:59:24,466:INFO:Total runtime is 0.8167286753654479 minutes
2023-04-29 16:59:24,466:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:24,467:INFO:Initializing create_model()
2023-04-29 16:59:24,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:24,468:INFO:Checking exceptions
2023-04-29 16:59:24,468:INFO:Importing libraries
2023-04-29 16:59:24,468:INFO:Copying training dataset
2023-04-29 16:59:24,473:INFO:Defining folds
2023-04-29 16:59:24,473:INFO:Declaring metric variables
2023-04-29 16:59:24,474:INFO:Importing untrained model
2023-04-29 16:59:24,475:INFO:Huber Regressor Imported successfully
2023-04-29 16:59:24,476:INFO:Starting cross validation
2023-04-29 16:59:24,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:28,740:INFO:Calculating mean and std
2023-04-29 16:59:28,741:INFO:Creating metrics dataframe
2023-04-29 16:59:29,120:INFO:Uploading results into container
2023-04-29 16:59:29,121:INFO:Uploading model into container now
2023-04-29 16:59:29,121:INFO:_master_model_container: 10
2023-04-29 16:59:29,121:INFO:_display_container: 2
2023-04-29 16:59:29,121:INFO:HuberRegressor()
2023-04-29 16:59:29,121:INFO:create_model() successfully completed......................................
2023-04-29 16:59:29,242:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:29,242:INFO:Creating metrics dataframe
2023-04-29 16:59:29,253:INFO:Initializing K Neighbors Regressor
2023-04-29 16:59:29,253:INFO:Total runtime is 0.8965164383252461 minutes
2023-04-29 16:59:29,253:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:29,254:INFO:Initializing create_model()
2023-04-29 16:59:29,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:29,254:INFO:Checking exceptions
2023-04-29 16:59:29,254:INFO:Importing libraries
2023-04-29 16:59:29,254:INFO:Copying training dataset
2023-04-29 16:59:29,258:INFO:Defining folds
2023-04-29 16:59:29,258:INFO:Declaring metric variables
2023-04-29 16:59:29,259:INFO:Importing untrained model
2023-04-29 16:59:29,259:INFO:K Neighbors Regressor Imported successfully
2023-04-29 16:59:29,259:INFO:Starting cross validation
2023-04-29 16:59:29,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:33,508:INFO:Calculating mean and std
2023-04-29 16:59:33,509:INFO:Creating metrics dataframe
2023-04-29 16:59:33,914:INFO:Uploading results into container
2023-04-29 16:59:33,914:INFO:Uploading model into container now
2023-04-29 16:59:33,915:INFO:_master_model_container: 11
2023-04-29 16:59:33,915:INFO:_display_container: 2
2023-04-29 16:59:33,916:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 16:59:33,916:INFO:create_model() successfully completed......................................
2023-04-29 16:59:34,048:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:34,048:INFO:Creating metrics dataframe
2023-04-29 16:59:34,057:INFO:Initializing Decision Tree Regressor
2023-04-29 16:59:34,058:INFO:Total runtime is 0.9765792330106099 minutes
2023-04-29 16:59:34,058:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:34,058:INFO:Initializing create_model()
2023-04-29 16:59:34,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:34,059:INFO:Checking exceptions
2023-04-29 16:59:34,059:INFO:Importing libraries
2023-04-29 16:59:34,059:INFO:Copying training dataset
2023-04-29 16:59:34,062:INFO:Defining folds
2023-04-29 16:59:34,064:INFO:Declaring metric variables
2023-04-29 16:59:34,064:INFO:Importing untrained model
2023-04-29 16:59:34,064:INFO:Decision Tree Regressor Imported successfully
2023-04-29 16:59:34,065:INFO:Starting cross validation
2023-04-29 16:59:34,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:38,351:INFO:Calculating mean and std
2023-04-29 16:59:38,353:INFO:Creating metrics dataframe
2023-04-29 16:59:38,758:INFO:Uploading results into container
2023-04-29 16:59:38,759:INFO:Uploading model into container now
2023-04-29 16:59:38,759:INFO:_master_model_container: 12
2023-04-29 16:59:38,759:INFO:_display_container: 2
2023-04-29 16:59:38,760:INFO:DecisionTreeRegressor(random_state=7122)
2023-04-29 16:59:38,760:INFO:create_model() successfully completed......................................
2023-04-29 16:59:38,885:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:38,885:INFO:Creating metrics dataframe
2023-04-29 16:59:38,888:INFO:Initializing Random Forest Regressor
2023-04-29 16:59:38,888:INFO:Total runtime is 1.0570980827013652 minutes
2023-04-29 16:59:38,889:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:38,889:INFO:Initializing create_model()
2023-04-29 16:59:38,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:38,889:INFO:Checking exceptions
2023-04-29 16:59:38,889:INFO:Importing libraries
2023-04-29 16:59:38,889:INFO:Copying training dataset
2023-04-29 16:59:38,892:INFO:Defining folds
2023-04-29 16:59:38,892:INFO:Declaring metric variables
2023-04-29 16:59:38,892:INFO:Importing untrained model
2023-04-29 16:59:38,893:INFO:Random Forest Regressor Imported successfully
2023-04-29 16:59:38,893:INFO:Starting cross validation
2023-04-29 16:59:38,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:44,142:INFO:Calculating mean and std
2023-04-29 16:59:44,143:INFO:Creating metrics dataframe
2023-04-29 16:59:44,525:INFO:Uploading results into container
2023-04-29 16:59:44,526:INFO:Uploading model into container now
2023-04-29 16:59:44,526:INFO:_master_model_container: 13
2023-04-29 16:59:44,526:INFO:_display_container: 2
2023-04-29 16:59:44,527:INFO:RandomForestRegressor(n_jobs=-1, random_state=7122)
2023-04-29 16:59:44,527:INFO:create_model() successfully completed......................................
2023-04-29 16:59:44,675:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:44,675:INFO:Creating metrics dataframe
2023-04-29 16:59:44,685:INFO:Initializing Extra Trees Regressor
2023-04-29 16:59:44,686:INFO:Total runtime is 1.1537352283795674 minutes
2023-04-29 16:59:44,686:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:44,687:INFO:Initializing create_model()
2023-04-29 16:59:44,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:44,688:INFO:Checking exceptions
2023-04-29 16:59:44,688:INFO:Importing libraries
2023-04-29 16:59:44,688:INFO:Copying training dataset
2023-04-29 16:59:44,695:INFO:Defining folds
2023-04-29 16:59:44,695:INFO:Declaring metric variables
2023-04-29 16:59:44,696:INFO:Importing untrained model
2023-04-29 16:59:44,697:INFO:Extra Trees Regressor Imported successfully
2023-04-29 16:59:44,697:INFO:Starting cross validation
2023-04-29 16:59:44,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:49,610:INFO:Calculating mean and std
2023-04-29 16:59:49,612:INFO:Creating metrics dataframe
2023-04-29 16:59:50,048:INFO:Uploading results into container
2023-04-29 16:59:50,049:INFO:Uploading model into container now
2023-04-29 16:59:50,050:INFO:_master_model_container: 14
2023-04-29 16:59:50,050:INFO:_display_container: 2
2023-04-29 16:59:50,050:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7122)
2023-04-29 16:59:50,050:INFO:create_model() successfully completed......................................
2023-04-29 16:59:50,182:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:50,183:INFO:Creating metrics dataframe
2023-04-29 16:59:50,187:INFO:Initializing AdaBoost Regressor
2023-04-29 16:59:50,187:INFO:Total runtime is 1.2454068144162496 minutes
2023-04-29 16:59:50,188:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:50,188:INFO:Initializing create_model()
2023-04-29 16:59:50,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:50,188:INFO:Checking exceptions
2023-04-29 16:59:50,189:INFO:Importing libraries
2023-04-29 16:59:50,189:INFO:Copying training dataset
2023-04-29 16:59:50,195:INFO:Defining folds
2023-04-29 16:59:50,196:INFO:Declaring metric variables
2023-04-29 16:59:50,196:INFO:Importing untrained model
2023-04-29 16:59:50,197:INFO:AdaBoost Regressor Imported successfully
2023-04-29 16:59:50,197:INFO:Starting cross validation
2023-04-29 16:59:50,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 16:59:54,660:INFO:Calculating mean and std
2023-04-29 16:59:54,661:INFO:Creating metrics dataframe
2023-04-29 16:59:55,134:INFO:Uploading results into container
2023-04-29 16:59:55,134:INFO:Uploading model into container now
2023-04-29 16:59:55,134:INFO:_master_model_container: 15
2023-04-29 16:59:55,134:INFO:_display_container: 2
2023-04-29 16:59:55,135:INFO:AdaBoostRegressor(random_state=7122)
2023-04-29 16:59:55,135:INFO:create_model() successfully completed......................................
2023-04-29 16:59:55,293:INFO:SubProcess create_model() end ==================================
2023-04-29 16:59:55,293:INFO:Creating metrics dataframe
2023-04-29 16:59:55,303:INFO:Initializing Gradient Boosting Regressor
2023-04-29 16:59:55,303:INFO:Total runtime is 1.3306714057922362 minutes
2023-04-29 16:59:55,303:INFO:SubProcess create_model() called ==================================
2023-04-29 16:59:55,304:INFO:Initializing create_model()
2023-04-29 16:59:55,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 16:59:55,304:INFO:Checking exceptions
2023-04-29 16:59:55,304:INFO:Importing libraries
2023-04-29 16:59:55,304:INFO:Copying training dataset
2023-04-29 16:59:55,310:INFO:Defining folds
2023-04-29 16:59:55,311:INFO:Declaring metric variables
2023-04-29 16:59:55,311:INFO:Importing untrained model
2023-04-29 16:59:55,312:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 16:59:55,313:INFO:Starting cross validation
2023-04-29 16:59:55,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:00:00,299:INFO:Calculating mean and std
2023-04-29 17:00:00,300:INFO:Creating metrics dataframe
2023-04-29 17:00:00,764:INFO:Uploading results into container
2023-04-29 17:00:00,764:INFO:Uploading model into container now
2023-04-29 17:00:00,765:INFO:_master_model_container: 16
2023-04-29 17:00:00,765:INFO:_display_container: 2
2023-04-29 17:00:00,765:INFO:GradientBoostingRegressor(random_state=7122)
2023-04-29 17:00:00,765:INFO:create_model() successfully completed......................................
2023-04-29 17:00:00,884:INFO:SubProcess create_model() end ==================================
2023-04-29 17:00:00,885:INFO:Creating metrics dataframe
2023-04-29 17:00:00,898:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:00:00,898:INFO:Total runtime is 1.423920464515686 minutes
2023-04-29 17:00:00,898:INFO:SubProcess create_model() called ==================================
2023-04-29 17:00:00,899:INFO:Initializing create_model()
2023-04-29 17:00:00,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:00:00,899:INFO:Checking exceptions
2023-04-29 17:00:00,899:INFO:Importing libraries
2023-04-29 17:00:00,899:INFO:Copying training dataset
2023-04-29 17:00:00,908:INFO:Defining folds
2023-04-29 17:00:00,908:INFO:Declaring metric variables
2023-04-29 17:00:00,909:INFO:Importing untrained model
2023-04-29 17:00:00,910:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:00:00,912:INFO:Starting cross validation
2023-04-29 17:00:00,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:00:08,022:INFO:Calculating mean and std
2023-04-29 17:00:08,023:INFO:Creating metrics dataframe
2023-04-29 17:00:08,417:INFO:Uploading results into container
2023-04-29 17:00:08,418:INFO:Uploading model into container now
2023-04-29 17:00:08,419:INFO:_master_model_container: 17
2023-04-29 17:00:08,419:INFO:_display_container: 2
2023-04-29 17:00:08,419:INFO:LGBMRegressor(random_state=7122)
2023-04-29 17:00:08,419:INFO:create_model() successfully completed......................................
2023-04-29 17:00:08,530:INFO:SubProcess create_model() end ==================================
2023-04-29 17:00:08,530:INFO:Creating metrics dataframe
2023-04-29 17:00:08,545:INFO:Initializing Dummy Regressor
2023-04-29 17:00:08,545:INFO:Total runtime is 1.551371371746063 minutes
2023-04-29 17:00:08,546:INFO:SubProcess create_model() called ==================================
2023-04-29 17:00:08,546:INFO:Initializing create_model()
2023-04-29 17:00:08,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B7A84B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:00:08,546:INFO:Checking exceptions
2023-04-29 17:00:08,546:INFO:Importing libraries
2023-04-29 17:00:08,547:INFO:Copying training dataset
2023-04-29 17:00:08,551:INFO:Defining folds
2023-04-29 17:00:08,551:INFO:Declaring metric variables
2023-04-29 17:00:08,551:INFO:Importing untrained model
2023-04-29 17:00:08,551:INFO:Dummy Regressor Imported successfully
2023-04-29 17:00:08,552:INFO:Starting cross validation
2023-04-29 17:00:08,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:00:13,079:INFO:Calculating mean and std
2023-04-29 17:00:13,080:INFO:Creating metrics dataframe
2023-04-29 17:00:13,468:INFO:Uploading results into container
2023-04-29 17:00:13,469:INFO:Uploading model into container now
2023-04-29 17:00:13,469:INFO:_master_model_container: 18
2023-04-29 17:00:13,469:INFO:_display_container: 2
2023-04-29 17:00:13,470:INFO:DummyRegressor()
2023-04-29 17:00:13,470:INFO:create_model() successfully completed......................................
2023-04-29 17:00:13,588:INFO:SubProcess create_model() end ==================================
2023-04-29 17:00:13,589:INFO:Creating metrics dataframe
2023-04-29 17:00:13,599:INFO:Initializing create_model()
2023-04-29 17:00:13,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=7122), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:00:13,599:INFO:Checking exceptions
2023-04-29 17:00:13,600:INFO:Importing libraries
2023-04-29 17:00:13,600:INFO:Copying training dataset
2023-04-29 17:00:13,604:INFO:Defining folds
2023-04-29 17:00:13,604:INFO:Declaring metric variables
2023-04-29 17:00:13,604:INFO:Importing untrained model
2023-04-29 17:00:13,604:INFO:Declaring custom model
2023-04-29 17:00:13,605:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:00:13,606:INFO:Cross validation set to False
2023-04-29 17:00:13,607:INFO:Fitting Model
2023-04-29 17:00:14,208:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7122)
2023-04-29 17:00:14,208:INFO:create_model() successfully completed......................................
2023-04-29 17:00:14,381:INFO:_master_model_container: 18
2023-04-29 17:00:14,381:INFO:_display_container: 2
2023-04-29 17:00:14,383:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7122)
2023-04-29 17:00:14,383:INFO:compare_models() successfully completed......................................
2023-04-29 17:00:14,389:INFO:Initializing predict_model()
2023-04-29 17:00:14,390:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EE0EB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=7122), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B68C0EE0>)
2023-04-29 17:00:14,390:INFO:Checking exceptions
2023-04-29 17:00:14,390:INFO:Preloading libraries
2023-04-29 17:00:14,390:INFO:Set up data.
2023-04-29 17:00:14,399:INFO:Set up index.
2023-04-29 17:03:37,650:INFO:PyCaret RegressionExperiment
2023-04-29 17:03:37,650:INFO:Logging name: reg-default-name
2023-04-29 17:03:37,651:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:03:37,651:INFO:version 3.0.0
2023-04-29 17:03:37,651:INFO:Initializing setup()
2023-04-29 17:03:37,651:INFO:self.USI: 4f58
2023-04-29 17:03:37,651:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:03:37,651:INFO:Checking environment
2023-04-29 17:03:37,651:INFO:python_version: 3.9.13
2023-04-29 17:03:37,652:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:03:37,652:INFO:machine: AMD64
2023-04-29 17:03:37,652:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:03:37,652:INFO:Memory: svmem(total=16935899136, available=5716844544, percent=66.2, used=11219054592, free=5716844544)
2023-04-29 17:03:37,652:INFO:Physical Core: 4
2023-04-29 17:03:37,652:INFO:Logical Core: 8
2023-04-29 17:03:37,652:INFO:Checking libraries
2023-04-29 17:03:37,652:INFO:System:
2023-04-29 17:03:37,652:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:03:37,652:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:03:37,652:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:03:37,652:INFO:PyCaret required dependencies:
2023-04-29 17:03:37,652:INFO:                 pip: 22.2.2
2023-04-29 17:03:37,652:INFO:          setuptools: 63.4.1
2023-04-29 17:03:37,652:INFO:             pycaret: 3.0.0
2023-04-29 17:03:37,652:INFO:             IPython: 7.31.1
2023-04-29 17:03:37,652:INFO:          ipywidgets: 7.6.5
2023-04-29 17:03:37,652:INFO:                tqdm: 4.64.1
2023-04-29 17:03:37,652:INFO:               numpy: 1.21.5
2023-04-29 17:03:37,652:INFO:              pandas: 1.4.4
2023-04-29 17:03:37,652:INFO:              jinja2: 2.11.3
2023-04-29 17:03:37,652:INFO:               scipy: 1.9.1
2023-04-29 17:03:37,652:INFO:              joblib: 1.2.0
2023-04-29 17:03:37,652:INFO:             sklearn: 1.0.2
2023-04-29 17:03:37,652:INFO:                pyod: 1.0.9
2023-04-29 17:03:37,653:INFO:            imblearn: 0.10.1
2023-04-29 17:03:37,653:INFO:   category_encoders: 2.6.0
2023-04-29 17:03:37,653:INFO:            lightgbm: 3.3.5
2023-04-29 17:03:37,653:INFO:               numba: 0.55.1
2023-04-29 17:03:37,653:INFO:            requests: 2.28.1
2023-04-29 17:03:37,653:INFO:          matplotlib: 3.5.2
2023-04-29 17:03:37,653:INFO:          scikitplot: 0.3.7
2023-04-29 17:03:37,653:INFO:         yellowbrick: 1.5
2023-04-29 17:03:37,653:INFO:              plotly: 5.9.0
2023-04-29 17:03:37,653:INFO:             kaleido: 0.2.1
2023-04-29 17:03:37,653:INFO:         statsmodels: 0.13.2
2023-04-29 17:03:37,653:INFO:              sktime: 0.17.1
2023-04-29 17:03:37,653:INFO:               tbats: 1.1.2
2023-04-29 17:03:37,653:INFO:            pmdarima: 2.0.3
2023-04-29 17:03:37,653:INFO:              psutil: 5.9.0
2023-04-29 17:03:37,653:INFO:PyCaret optional dependencies:
2023-04-29 17:03:37,653:INFO:                shap: 0.41.0
2023-04-29 17:03:37,653:INFO:           interpret: Not installed
2023-04-29 17:03:37,653:INFO:                umap: Not installed
2023-04-29 17:03:37,653:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:03:37,653:INFO:  explainerdashboard: Not installed
2023-04-29 17:03:37,653:INFO:             autoviz: Not installed
2023-04-29 17:03:37,653:INFO:           fairlearn: Not installed
2023-04-29 17:03:37,653:INFO:             xgboost: Not installed
2023-04-29 17:03:37,653:INFO:            catboost: Not installed
2023-04-29 17:03:37,653:INFO:              kmodes: Not installed
2023-04-29 17:03:37,653:INFO:             mlxtend: Not installed
2023-04-29 17:03:37,653:INFO:       statsforecast: Not installed
2023-04-29 17:03:37,653:INFO:        tune_sklearn: Not installed
2023-04-29 17:03:37,653:INFO:                 ray: Not installed
2023-04-29 17:03:37,653:INFO:            hyperopt: Not installed
2023-04-29 17:03:37,654:INFO:              optuna: Not installed
2023-04-29 17:03:37,654:INFO:               skopt: Not installed
2023-04-29 17:03:37,654:INFO:              mlflow: 2.2.1
2023-04-29 17:03:37,654:INFO:              gradio: Not installed
2023-04-29 17:03:37,654:INFO:             fastapi: Not installed
2023-04-29 17:03:37,654:INFO:             uvicorn: Not installed
2023-04-29 17:03:37,654:INFO:              m2cgen: Not installed
2023-04-29 17:03:37,654:INFO:           evidently: Not installed
2023-04-29 17:03:37,654:INFO:               fugue: Not installed
2023-04-29 17:03:37,654:INFO:           streamlit: 1.21.0
2023-04-29 17:03:37,654:INFO:             prophet: Not installed
2023-04-29 17:03:37,654:INFO:None
2023-04-29 17:03:37,654:INFO:Set up data.
2023-04-29 17:03:37,659:INFO:Set up train/test split.
2023-04-29 17:03:37,661:INFO:Set up index.
2023-04-29 17:03:37,661:INFO:Set up folding strategy.
2023-04-29 17:03:37,661:INFO:Assigning column types.
2023-04-29 17:03:37,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:03:37,665:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,671:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,676:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:37,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:37,792:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,797:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,802:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:37,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:37,919:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:03:37,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:03:37,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,061:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,181:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:03:38,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,444:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:03:38,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,712:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:03:38,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:03:38,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:38,961:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:03:39,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,212:INFO:Preparing preprocessing pipeline...
2023-04-29 17:03:39,214:INFO:Set up simple imputation.
2023-04-29 17:03:39,221:INFO:Set up column name cleaning.
2023-04-29 17:03:39,258:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:03:39,262:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:03:39,262:INFO:Creating final display dataframe.
2023-04-29 17:03:39,345:INFO:Setup _display_container:                     Description             Value
0                    Session id              6572
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4f58
2023-04-29 17:03:39,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:03:39,605:INFO:setup() successfully completed in 2.3s...............
2023-04-29 17:03:39,611:INFO:Initializing compare_models()
2023-04-29 17:03:39,611:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:03:39,611:INFO:Checking exceptions
2023-04-29 17:03:39,612:INFO:Preparing display monitor
2023-04-29 17:03:39,618:INFO:Initializing Linear Regression
2023-04-29 17:03:39,619:INFO:Total runtime is 1.7130374908447264e-05 minutes
2023-04-29 17:03:39,619:INFO:SubProcess create_model() called ==================================
2023-04-29 17:03:39,619:INFO:Initializing create_model()
2023-04-29 17:03:39,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:03:39,619:INFO:Checking exceptions
2023-04-29 17:03:39,620:INFO:Importing libraries
2023-04-29 17:03:39,620:INFO:Copying training dataset
2023-04-29 17:03:39,626:INFO:Defining folds
2023-04-29 17:03:39,626:INFO:Declaring metric variables
2023-04-29 17:03:39,626:INFO:Importing untrained model
2023-04-29 17:03:39,627:INFO:Linear Regression Imported successfully
2023-04-29 17:03:39,627:INFO:Starting cross validation
2023-04-29 17:03:39,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:03:43,112:INFO:Calculating mean and std
2023-04-29 17:03:43,112:INFO:Creating metrics dataframe
2023-04-29 17:03:43,556:INFO:Uploading results into container
2023-04-29 17:03:43,556:INFO:Uploading model into container now
2023-04-29 17:03:43,556:INFO:_master_model_container: 1
2023-04-29 17:03:43,557:INFO:_display_container: 2
2023-04-29 17:03:43,557:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:03:43,557:INFO:create_model() successfully completed......................................
2023-04-29 17:03:43,662:INFO:SubProcess create_model() end ==================================
2023-04-29 17:03:43,662:INFO:Creating metrics dataframe
2023-04-29 17:03:43,667:INFO:Initializing Lasso Regression
2023-04-29 17:03:43,667:INFO:Total runtime is 0.06748948097229003 minutes
2023-04-29 17:03:43,667:INFO:SubProcess create_model() called ==================================
2023-04-29 17:03:43,667:INFO:Initializing create_model()
2023-04-29 17:03:43,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:03:43,667:INFO:Checking exceptions
2023-04-29 17:03:43,667:INFO:Importing libraries
2023-04-29 17:03:43,667:INFO:Copying training dataset
2023-04-29 17:03:43,671:INFO:Defining folds
2023-04-29 17:03:43,671:INFO:Declaring metric variables
2023-04-29 17:03:43,671:INFO:Importing untrained model
2023-04-29 17:03:43,672:INFO:Lasso Regression Imported successfully
2023-04-29 17:03:43,673:INFO:Starting cross validation
2023-04-29 17:03:43,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:03:47,289:INFO:Calculating mean and std
2023-04-29 17:03:47,290:INFO:Creating metrics dataframe
2023-04-29 17:03:47,671:INFO:Uploading results into container
2023-04-29 17:03:47,672:INFO:Uploading model into container now
2023-04-29 17:03:47,672:INFO:_master_model_container: 2
2023-04-29 17:03:47,672:INFO:_display_container: 2
2023-04-29 17:03:47,672:INFO:Lasso(random_state=6572)
2023-04-29 17:03:47,672:INFO:create_model() successfully completed......................................
2023-04-29 17:03:47,769:INFO:SubProcess create_model() end ==================================
2023-04-29 17:03:47,769:INFO:Creating metrics dataframe
2023-04-29 17:03:47,773:INFO:Initializing Ridge Regression
2023-04-29 17:03:47,773:INFO:Total runtime is 0.13592265844345092 minutes
2023-04-29 17:03:47,774:INFO:SubProcess create_model() called ==================================
2023-04-29 17:03:47,774:INFO:Initializing create_model()
2023-04-29 17:03:47,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:03:47,774:INFO:Checking exceptions
2023-04-29 17:03:47,774:INFO:Importing libraries
2023-04-29 17:03:47,774:INFO:Copying training dataset
2023-04-29 17:03:47,777:INFO:Defining folds
2023-04-29 17:03:47,777:INFO:Declaring metric variables
2023-04-29 17:03:47,777:INFO:Importing untrained model
2023-04-29 17:03:47,778:INFO:Ridge Regression Imported successfully
2023-04-29 17:03:47,778:INFO:Starting cross validation
2023-04-29 17:03:47,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:03:50,859:INFO:Calculating mean and std
2023-04-29 17:03:50,860:INFO:Creating metrics dataframe
2023-04-29 17:03:51,246:INFO:Uploading results into container
2023-04-29 17:03:51,246:INFO:Uploading model into container now
2023-04-29 17:03:51,247:INFO:_master_model_container: 3
2023-04-29 17:03:51,247:INFO:_display_container: 2
2023-04-29 17:03:51,247:INFO:Ridge(random_state=6572)
2023-04-29 17:03:51,248:INFO:create_model() successfully completed......................................
2023-04-29 17:03:51,341:INFO:SubProcess create_model() end ==================================
2023-04-29 17:03:51,341:INFO:Creating metrics dataframe
2023-04-29 17:03:51,345:INFO:Initializing Elastic Net
2023-04-29 17:03:51,345:INFO:Total runtime is 0.19545642932256063 minutes
2023-04-29 17:03:51,345:INFO:SubProcess create_model() called ==================================
2023-04-29 17:03:51,345:INFO:Initializing create_model()
2023-04-29 17:03:51,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:03:51,345:INFO:Checking exceptions
2023-04-29 17:03:51,345:INFO:Importing libraries
2023-04-29 17:03:51,346:INFO:Copying training dataset
2023-04-29 17:03:51,349:INFO:Defining folds
2023-04-29 17:03:51,349:INFO:Declaring metric variables
2023-04-29 17:03:51,349:INFO:Importing untrained model
2023-04-29 17:03:51,350:INFO:Elastic Net Imported successfully
2023-04-29 17:03:51,350:INFO:Starting cross validation
2023-04-29 17:03:51,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:03:54,485:INFO:Calculating mean and std
2023-04-29 17:03:54,485:INFO:Creating metrics dataframe
2023-04-29 17:03:54,898:INFO:Uploading results into container
2023-04-29 17:03:54,899:INFO:Uploading model into container now
2023-04-29 17:03:54,900:INFO:_master_model_container: 4
2023-04-29 17:03:54,900:INFO:_display_container: 2
2023-04-29 17:03:54,900:INFO:ElasticNet(random_state=6572)
2023-04-29 17:03:54,900:INFO:create_model() successfully completed......................................
2023-04-29 17:03:54,991:INFO:SubProcess create_model() end ==================================
2023-04-29 17:03:54,991:INFO:Creating metrics dataframe
2023-04-29 17:03:54,996:INFO:Initializing Least Angle Regression
2023-04-29 17:03:54,996:INFO:Total runtime is 0.2563059727350871 minutes
2023-04-29 17:03:54,996:INFO:SubProcess create_model() called ==================================
2023-04-29 17:03:54,997:INFO:Initializing create_model()
2023-04-29 17:03:54,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:03:54,997:INFO:Checking exceptions
2023-04-29 17:03:54,997:INFO:Importing libraries
2023-04-29 17:03:54,997:INFO:Copying training dataset
2023-04-29 17:03:55,002:INFO:Defining folds
2023-04-29 17:03:55,002:INFO:Declaring metric variables
2023-04-29 17:03:55,002:INFO:Importing untrained model
2023-04-29 17:03:55,003:INFO:Least Angle Regression Imported successfully
2023-04-29 17:03:55,004:INFO:Starting cross validation
2023-04-29 17:03:55,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:03:55,065:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,078:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,086:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,101:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,113:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,141:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,146:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,163:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,947:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:55,987:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:03:58,184:INFO:Calculating mean and std
2023-04-29 17:03:58,185:INFO:Creating metrics dataframe
2023-04-29 17:03:58,568:INFO:Uploading results into container
2023-04-29 17:03:58,569:INFO:Uploading model into container now
2023-04-29 17:03:58,570:INFO:_master_model_container: 5
2023-04-29 17:03:58,570:INFO:_display_container: 2
2023-04-29 17:03:58,570:INFO:Lars(random_state=6572)
2023-04-29 17:03:58,570:INFO:create_model() successfully completed......................................
2023-04-29 17:03:58,668:INFO:SubProcess create_model() end ==================================
2023-04-29 17:03:58,668:INFO:Creating metrics dataframe
2023-04-29 17:03:58,671:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:03:58,671:INFO:Total runtime is 0.31755404074986776 minutes
2023-04-29 17:03:58,672:INFO:SubProcess create_model() called ==================================
2023-04-29 17:03:58,672:INFO:Initializing create_model()
2023-04-29 17:03:58,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:03:58,673:INFO:Checking exceptions
2023-04-29 17:03:58,673:INFO:Importing libraries
2023-04-29 17:03:58,673:INFO:Copying training dataset
2023-04-29 17:03:58,676:INFO:Defining folds
2023-04-29 17:03:58,676:INFO:Declaring metric variables
2023-04-29 17:03:58,676:INFO:Importing untrained model
2023-04-29 17:03:58,677:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:03:58,677:INFO:Starting cross validation
2023-04-29 17:03:58,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:03:58,730:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,736:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,751:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,766:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,786:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,804:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,822:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:58,835:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:59,644:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:03:59,666:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:04:01,904:INFO:Calculating mean and std
2023-04-29 17:04:01,905:INFO:Creating metrics dataframe
2023-04-29 17:04:02,310:INFO:Uploading results into container
2023-04-29 17:04:02,311:INFO:Uploading model into container now
2023-04-29 17:04:02,311:INFO:_master_model_container: 6
2023-04-29 17:04:02,311:INFO:_display_container: 2
2023-04-29 17:04:02,311:INFO:LassoLars(random_state=6572)
2023-04-29 17:04:02,312:INFO:create_model() successfully completed......................................
2023-04-29 17:04:02,411:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:02,412:INFO:Creating metrics dataframe
2023-04-29 17:04:02,417:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:04:02,417:INFO:Total runtime is 0.3799866835276286 minutes
2023-04-29 17:04:02,417:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:02,417:INFO:Initializing create_model()
2023-04-29 17:04:02,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:02,417:INFO:Checking exceptions
2023-04-29 17:04:02,417:INFO:Importing libraries
2023-04-29 17:04:02,417:INFO:Copying training dataset
2023-04-29 17:04:02,420:INFO:Defining folds
2023-04-29 17:04:02,420:INFO:Declaring metric variables
2023-04-29 17:04:02,421:INFO:Importing untrained model
2023-04-29 17:04:02,421:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:04:02,421:INFO:Starting cross validation
2023-04-29 17:04:02,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:02,472:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,486:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,499:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,511:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,528:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,544:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,558:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:02,575:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:03,404:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:03,434:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:04:05,588:INFO:Calculating mean and std
2023-04-29 17:04:05,590:INFO:Creating metrics dataframe
2023-04-29 17:04:05,980:INFO:Uploading results into container
2023-04-29 17:04:05,981:INFO:Uploading model into container now
2023-04-29 17:04:05,982:INFO:_master_model_container: 7
2023-04-29 17:04:05,982:INFO:_display_container: 2
2023-04-29 17:04:05,982:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:04:05,982:INFO:create_model() successfully completed......................................
2023-04-29 17:04:06,078:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:06,078:INFO:Creating metrics dataframe
2023-04-29 17:04:06,084:INFO:Initializing Bayesian Ridge
2023-04-29 17:04:06,084:INFO:Total runtime is 0.4411073605219523 minutes
2023-04-29 17:04:06,084:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:06,084:INFO:Initializing create_model()
2023-04-29 17:04:06,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:06,084:INFO:Checking exceptions
2023-04-29 17:04:06,085:INFO:Importing libraries
2023-04-29 17:04:06,085:INFO:Copying training dataset
2023-04-29 17:04:06,089:INFO:Defining folds
2023-04-29 17:04:06,089:INFO:Declaring metric variables
2023-04-29 17:04:06,089:INFO:Importing untrained model
2023-04-29 17:04:06,090:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:04:06,090:INFO:Starting cross validation
2023-04-29 17:04:06,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:09,381:INFO:Calculating mean and std
2023-04-29 17:04:09,382:INFO:Creating metrics dataframe
2023-04-29 17:04:09,773:INFO:Uploading results into container
2023-04-29 17:04:09,774:INFO:Uploading model into container now
2023-04-29 17:04:09,774:INFO:_master_model_container: 8
2023-04-29 17:04:09,774:INFO:_display_container: 2
2023-04-29 17:04:09,775:INFO:BayesianRidge()
2023-04-29 17:04:09,775:INFO:create_model() successfully completed......................................
2023-04-29 17:04:09,871:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:09,871:INFO:Creating metrics dataframe
2023-04-29 17:04:09,875:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:04:09,875:INFO:Total runtime is 0.5042869448661804 minutes
2023-04-29 17:04:09,875:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:09,876:INFO:Initializing create_model()
2023-04-29 17:04:09,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:09,876:INFO:Checking exceptions
2023-04-29 17:04:09,876:INFO:Importing libraries
2023-04-29 17:04:09,876:INFO:Copying training dataset
2023-04-29 17:04:09,880:INFO:Defining folds
2023-04-29 17:04:09,880:INFO:Declaring metric variables
2023-04-29 17:04:09,881:INFO:Importing untrained model
2023-04-29 17:04:09,881:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:04:09,881:INFO:Starting cross validation
2023-04-29 17:04:09,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:13,183:INFO:Calculating mean and std
2023-04-29 17:04:13,184:INFO:Creating metrics dataframe
2023-04-29 17:04:13,586:INFO:Uploading results into container
2023-04-29 17:04:13,587:INFO:Uploading model into container now
2023-04-29 17:04:13,587:INFO:_master_model_container: 9
2023-04-29 17:04:13,587:INFO:_display_container: 2
2023-04-29 17:04:13,587:INFO:PassiveAggressiveRegressor(random_state=6572)
2023-04-29 17:04:13,587:INFO:create_model() successfully completed......................................
2023-04-29 17:04:13,686:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:13,687:INFO:Creating metrics dataframe
2023-04-29 17:04:13,690:INFO:Initializing Huber Regressor
2023-04-29 17:04:13,690:INFO:Total runtime is 0.5678663810094198 minutes
2023-04-29 17:04:13,690:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:13,690:INFO:Initializing create_model()
2023-04-29 17:04:13,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:13,691:INFO:Checking exceptions
2023-04-29 17:04:13,691:INFO:Importing libraries
2023-04-29 17:04:13,691:INFO:Copying training dataset
2023-04-29 17:04:13,694:INFO:Defining folds
2023-04-29 17:04:13,695:INFO:Declaring metric variables
2023-04-29 17:04:13,695:INFO:Importing untrained model
2023-04-29 17:04:13,695:INFO:Huber Regressor Imported successfully
2023-04-29 17:04:13,696:INFO:Starting cross validation
2023-04-29 17:04:13,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:13,898:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:04:17,120:INFO:Calculating mean and std
2023-04-29 17:04:17,121:INFO:Creating metrics dataframe
2023-04-29 17:04:17,522:INFO:Uploading results into container
2023-04-29 17:04:17,523:INFO:Uploading model into container now
2023-04-29 17:04:17,523:INFO:_master_model_container: 10
2023-04-29 17:04:17,523:INFO:_display_container: 2
2023-04-29 17:04:17,523:INFO:HuberRegressor()
2023-04-29 17:04:17,523:INFO:create_model() successfully completed......................................
2023-04-29 17:04:17,620:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:17,620:INFO:Creating metrics dataframe
2023-04-29 17:04:17,624:INFO:Initializing K Neighbors Regressor
2023-04-29 17:04:17,624:INFO:Total runtime is 0.6334435025850932 minutes
2023-04-29 17:04:17,624:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:17,624:INFO:Initializing create_model()
2023-04-29 17:04:17,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:17,624:INFO:Checking exceptions
2023-04-29 17:04:17,624:INFO:Importing libraries
2023-04-29 17:04:17,625:INFO:Copying training dataset
2023-04-29 17:04:17,629:INFO:Defining folds
2023-04-29 17:04:17,629:INFO:Declaring metric variables
2023-04-29 17:04:17,629:INFO:Importing untrained model
2023-04-29 17:04:17,630:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:04:17,630:INFO:Starting cross validation
2023-04-29 17:04:17,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:20,922:INFO:Calculating mean and std
2023-04-29 17:04:20,923:INFO:Creating metrics dataframe
2023-04-29 17:04:21,317:INFO:Uploading results into container
2023-04-29 17:04:21,319:INFO:Uploading model into container now
2023-04-29 17:04:21,319:INFO:_master_model_container: 11
2023-04-29 17:04:21,319:INFO:_display_container: 2
2023-04-29 17:04:21,320:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:04:21,320:INFO:create_model() successfully completed......................................
2023-04-29 17:04:21,416:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:21,416:INFO:Creating metrics dataframe
2023-04-29 17:04:21,420:INFO:Initializing Decision Tree Regressor
2023-04-29 17:04:21,420:INFO:Total runtime is 0.696705412864685 minutes
2023-04-29 17:04:21,420:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:21,420:INFO:Initializing create_model()
2023-04-29 17:04:21,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:21,420:INFO:Checking exceptions
2023-04-29 17:04:21,420:INFO:Importing libraries
2023-04-29 17:04:21,420:INFO:Copying training dataset
2023-04-29 17:04:21,423:INFO:Defining folds
2023-04-29 17:04:21,424:INFO:Declaring metric variables
2023-04-29 17:04:21,424:INFO:Importing untrained model
2023-04-29 17:04:21,424:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:04:21,425:INFO:Starting cross validation
2023-04-29 17:04:21,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:24,702:INFO:Calculating mean and std
2023-04-29 17:04:24,704:INFO:Creating metrics dataframe
2023-04-29 17:04:25,121:INFO:Uploading results into container
2023-04-29 17:04:25,122:INFO:Uploading model into container now
2023-04-29 17:04:25,122:INFO:_master_model_container: 12
2023-04-29 17:04:25,122:INFO:_display_container: 2
2023-04-29 17:04:25,123:INFO:DecisionTreeRegressor(random_state=6572)
2023-04-29 17:04:25,123:INFO:create_model() successfully completed......................................
2023-04-29 17:04:25,229:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:25,229:INFO:Creating metrics dataframe
2023-04-29 17:04:25,237:INFO:Initializing Random Forest Regressor
2023-04-29 17:04:25,237:INFO:Total runtime is 0.760316773255666 minutes
2023-04-29 17:04:25,238:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:25,238:INFO:Initializing create_model()
2023-04-29 17:04:25,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:25,238:INFO:Checking exceptions
2023-04-29 17:04:25,238:INFO:Importing libraries
2023-04-29 17:04:25,238:INFO:Copying training dataset
2023-04-29 17:04:25,244:INFO:Defining folds
2023-04-29 17:04:25,244:INFO:Declaring metric variables
2023-04-29 17:04:25,244:INFO:Importing untrained model
2023-04-29 17:04:25,245:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:04:25,245:INFO:Starting cross validation
2023-04-29 17:04:25,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:29,724:INFO:Calculating mean and std
2023-04-29 17:04:29,725:INFO:Creating metrics dataframe
2023-04-29 17:04:30,123:INFO:Uploading results into container
2023-04-29 17:04:30,124:INFO:Uploading model into container now
2023-04-29 17:04:30,124:INFO:_master_model_container: 13
2023-04-29 17:04:30,124:INFO:_display_container: 2
2023-04-29 17:04:30,125:INFO:RandomForestRegressor(n_jobs=-1, random_state=6572)
2023-04-29 17:04:30,125:INFO:create_model() successfully completed......................................
2023-04-29 17:04:30,219:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:30,219:INFO:Creating metrics dataframe
2023-04-29 17:04:30,222:INFO:Initializing Extra Trees Regressor
2023-04-29 17:04:30,223:INFO:Total runtime is 0.843419071038564 minutes
2023-04-29 17:04:30,223:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:30,223:INFO:Initializing create_model()
2023-04-29 17:04:30,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:30,223:INFO:Checking exceptions
2023-04-29 17:04:30,223:INFO:Importing libraries
2023-04-29 17:04:30,223:INFO:Copying training dataset
2023-04-29 17:04:30,227:INFO:Defining folds
2023-04-29 17:04:30,227:INFO:Declaring metric variables
2023-04-29 17:04:30,227:INFO:Importing untrained model
2023-04-29 17:04:30,228:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:04:30,228:INFO:Starting cross validation
2023-04-29 17:04:30,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:34,485:INFO:Calculating mean and std
2023-04-29 17:04:34,486:INFO:Creating metrics dataframe
2023-04-29 17:04:34,894:INFO:Uploading results into container
2023-04-29 17:04:34,895:INFO:Uploading model into container now
2023-04-29 17:04:34,896:INFO:_master_model_container: 14
2023-04-29 17:04:34,896:INFO:_display_container: 2
2023-04-29 17:04:34,896:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6572)
2023-04-29 17:04:34,896:INFO:create_model() successfully completed......................................
2023-04-29 17:04:34,991:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:34,992:INFO:Creating metrics dataframe
2023-04-29 17:04:34,996:INFO:Initializing AdaBoost Regressor
2023-04-29 17:04:34,996:INFO:Total runtime is 0.9229729175567626 minutes
2023-04-29 17:04:34,997:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:34,997:INFO:Initializing create_model()
2023-04-29 17:04:34,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:34,997:INFO:Checking exceptions
2023-04-29 17:04:34,997:INFO:Importing libraries
2023-04-29 17:04:34,997:INFO:Copying training dataset
2023-04-29 17:04:35,000:INFO:Defining folds
2023-04-29 17:04:35,000:INFO:Declaring metric variables
2023-04-29 17:04:35,001:INFO:Importing untrained model
2023-04-29 17:04:35,001:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:04:35,001:INFO:Starting cross validation
2023-04-29 17:04:35,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:38,744:INFO:Calculating mean and std
2023-04-29 17:04:38,745:INFO:Creating metrics dataframe
2023-04-29 17:04:39,170:INFO:Uploading results into container
2023-04-29 17:04:39,171:INFO:Uploading model into container now
2023-04-29 17:04:39,172:INFO:_master_model_container: 15
2023-04-29 17:04:39,172:INFO:_display_container: 2
2023-04-29 17:04:39,172:INFO:AdaBoostRegressor(random_state=6572)
2023-04-29 17:04:39,172:INFO:create_model() successfully completed......................................
2023-04-29 17:04:39,268:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:39,269:INFO:Creating metrics dataframe
2023-04-29 17:04:39,272:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:04:39,272:INFO:Total runtime is 0.9942299207051594 minutes
2023-04-29 17:04:39,273:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:39,273:INFO:Initializing create_model()
2023-04-29 17:04:39,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:39,273:INFO:Checking exceptions
2023-04-29 17:04:39,273:INFO:Importing libraries
2023-04-29 17:04:39,273:INFO:Copying training dataset
2023-04-29 17:04:39,277:INFO:Defining folds
2023-04-29 17:04:39,277:INFO:Declaring metric variables
2023-04-29 17:04:39,277:INFO:Importing untrained model
2023-04-29 17:04:39,278:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:04:39,278:INFO:Starting cross validation
2023-04-29 17:04:39,279:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:43,354:INFO:Calculating mean and std
2023-04-29 17:04:43,354:INFO:Creating metrics dataframe
2023-04-29 17:04:43,775:INFO:Uploading results into container
2023-04-29 17:04:43,776:INFO:Uploading model into container now
2023-04-29 17:04:43,777:INFO:_master_model_container: 16
2023-04-29 17:04:43,777:INFO:_display_container: 2
2023-04-29 17:04:43,777:INFO:GradientBoostingRegressor(random_state=6572)
2023-04-29 17:04:43,777:INFO:create_model() successfully completed......................................
2023-04-29 17:04:43,872:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:43,873:INFO:Creating metrics dataframe
2023-04-29 17:04:43,877:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:04:43,878:INFO:Total runtime is 1.0710049589474995 minutes
2023-04-29 17:04:43,878:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:43,878:INFO:Initializing create_model()
2023-04-29 17:04:43,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:43,878:INFO:Checking exceptions
2023-04-29 17:04:43,878:INFO:Importing libraries
2023-04-29 17:04:43,878:INFO:Copying training dataset
2023-04-29 17:04:43,881:INFO:Defining folds
2023-04-29 17:04:43,881:INFO:Declaring metric variables
2023-04-29 17:04:43,882:INFO:Importing untrained model
2023-04-29 17:04:43,882:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:04:43,882:INFO:Starting cross validation
2023-04-29 17:04:43,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:47,760:INFO:Calculating mean and std
2023-04-29 17:04:47,760:INFO:Creating metrics dataframe
2023-04-29 17:04:48,187:INFO:Uploading results into container
2023-04-29 17:04:48,187:INFO:Uploading model into container now
2023-04-29 17:04:48,188:INFO:_master_model_container: 17
2023-04-29 17:04:48,188:INFO:_display_container: 2
2023-04-29 17:04:48,188:INFO:LGBMRegressor(random_state=6572)
2023-04-29 17:04:48,188:INFO:create_model() successfully completed......................................
2023-04-29 17:04:48,287:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:48,287:INFO:Creating metrics dataframe
2023-04-29 17:04:48,292:INFO:Initializing Dummy Regressor
2023-04-29 17:04:48,292:INFO:Total runtime is 1.144565729300181 minutes
2023-04-29 17:04:48,292:INFO:SubProcess create_model() called ==================================
2023-04-29 17:04:48,292:INFO:Initializing create_model()
2023-04-29 17:04:48,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12D30>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:48,293:INFO:Checking exceptions
2023-04-29 17:04:48,293:INFO:Importing libraries
2023-04-29 17:04:48,293:INFO:Copying training dataset
2023-04-29 17:04:48,296:INFO:Defining folds
2023-04-29 17:04:48,296:INFO:Declaring metric variables
2023-04-29 17:04:48,296:INFO:Importing untrained model
2023-04-29 17:04:48,297:INFO:Dummy Regressor Imported successfully
2023-04-29 17:04:48,297:INFO:Starting cross validation
2023-04-29 17:04:48,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:04:51,883:INFO:Calculating mean and std
2023-04-29 17:04:51,884:INFO:Creating metrics dataframe
2023-04-29 17:04:52,323:INFO:Uploading results into container
2023-04-29 17:04:52,324:INFO:Uploading model into container now
2023-04-29 17:04:52,325:INFO:_master_model_container: 18
2023-04-29 17:04:52,325:INFO:_display_container: 2
2023-04-29 17:04:52,325:INFO:DummyRegressor()
2023-04-29 17:04:52,325:INFO:create_model() successfully completed......................................
2023-04-29 17:04:52,420:INFO:SubProcess create_model() end ==================================
2023-04-29 17:04:52,420:INFO:Creating metrics dataframe
2023-04-29 17:04:52,428:INFO:Initializing create_model()
2023-04-29 17:04:52,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6572), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:04:52,429:INFO:Checking exceptions
2023-04-29 17:04:52,430:INFO:Importing libraries
2023-04-29 17:04:52,430:INFO:Copying training dataset
2023-04-29 17:04:52,435:INFO:Defining folds
2023-04-29 17:04:52,435:INFO:Declaring metric variables
2023-04-29 17:04:52,435:INFO:Importing untrained model
2023-04-29 17:04:52,435:INFO:Declaring custom model
2023-04-29 17:04:52,436:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:04:52,436:INFO:Cross validation set to False
2023-04-29 17:04:52,436:INFO:Fitting Model
2023-04-29 17:04:52,832:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6572)
2023-04-29 17:04:52,832:INFO:create_model() successfully completed......................................
2023-04-29 17:04:52,958:INFO:_master_model_container: 18
2023-04-29 17:04:52,958:INFO:_display_container: 2
2023-04-29 17:04:52,959:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6572)
2023-04-29 17:04:52,959:INFO:compare_models() successfully completed......................................
2023-04-29 17:04:52,964:INFO:Initializing predict_model()
2023-04-29 17:04:52,964:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B7903D00>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6572), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B7971310>)
2023-04-29 17:04:52,964:INFO:Checking exceptions
2023-04-29 17:04:52,964:INFO:Preloading libraries
2023-04-29 17:04:52,964:INFO:Set up data.
2023-04-29 17:04:52,969:INFO:Set up index.
2023-04-29 17:10:58,530:INFO:PyCaret RegressionExperiment
2023-04-29 17:10:58,530:INFO:Logging name: reg-default-name
2023-04-29 17:10:58,530:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:10:58,530:INFO:version 3.0.0
2023-04-29 17:10:58,530:INFO:Initializing setup()
2023-04-29 17:10:58,530:INFO:self.USI: ae32
2023-04-29 17:10:58,530:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:10:58,530:INFO:Checking environment
2023-04-29 17:10:58,530:INFO:python_version: 3.9.13
2023-04-29 17:10:58,530:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:10:58,530:INFO:machine: AMD64
2023-04-29 17:10:58,530:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:10:58,530:INFO:Memory: svmem(total=16935899136, available=6931820544, percent=59.1, used=10004078592, free=6931820544)
2023-04-29 17:10:58,530:INFO:Physical Core: 4
2023-04-29 17:10:58,531:INFO:Logical Core: 8
2023-04-29 17:10:58,531:INFO:Checking libraries
2023-04-29 17:10:58,531:INFO:System:
2023-04-29 17:10:58,531:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:10:58,531:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:10:58,531:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:10:58,531:INFO:PyCaret required dependencies:
2023-04-29 17:10:58,531:INFO:                 pip: 22.2.2
2023-04-29 17:10:58,531:INFO:          setuptools: 63.4.1
2023-04-29 17:10:58,531:INFO:             pycaret: 3.0.0
2023-04-29 17:10:58,531:INFO:             IPython: 7.31.1
2023-04-29 17:10:58,531:INFO:          ipywidgets: 7.6.5
2023-04-29 17:10:58,531:INFO:                tqdm: 4.64.1
2023-04-29 17:10:58,531:INFO:               numpy: 1.21.5
2023-04-29 17:10:58,531:INFO:              pandas: 1.4.4
2023-04-29 17:10:58,531:INFO:              jinja2: 2.11.3
2023-04-29 17:10:58,531:INFO:               scipy: 1.9.1
2023-04-29 17:10:58,531:INFO:              joblib: 1.2.0
2023-04-29 17:10:58,531:INFO:             sklearn: 1.0.2
2023-04-29 17:10:58,531:INFO:                pyod: 1.0.9
2023-04-29 17:10:58,531:INFO:            imblearn: 0.10.1
2023-04-29 17:10:58,531:INFO:   category_encoders: 2.6.0
2023-04-29 17:10:58,531:INFO:            lightgbm: 3.3.5
2023-04-29 17:10:58,531:INFO:               numba: 0.55.1
2023-04-29 17:10:58,531:INFO:            requests: 2.28.1
2023-04-29 17:10:58,531:INFO:          matplotlib: 3.5.2
2023-04-29 17:10:58,531:INFO:          scikitplot: 0.3.7
2023-04-29 17:10:58,531:INFO:         yellowbrick: 1.5
2023-04-29 17:10:58,531:INFO:              plotly: 5.9.0
2023-04-29 17:10:58,532:INFO:             kaleido: 0.2.1
2023-04-29 17:10:58,532:INFO:         statsmodels: 0.13.2
2023-04-29 17:10:58,532:INFO:              sktime: 0.17.1
2023-04-29 17:10:58,532:INFO:               tbats: 1.1.2
2023-04-29 17:10:58,532:INFO:            pmdarima: 2.0.3
2023-04-29 17:10:58,532:INFO:              psutil: 5.9.0
2023-04-29 17:10:58,532:INFO:PyCaret optional dependencies:
2023-04-29 17:10:58,532:INFO:                shap: 0.41.0
2023-04-29 17:10:58,532:INFO:           interpret: Not installed
2023-04-29 17:10:58,532:INFO:                umap: Not installed
2023-04-29 17:10:58,532:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:10:58,532:INFO:  explainerdashboard: Not installed
2023-04-29 17:10:58,532:INFO:             autoviz: Not installed
2023-04-29 17:10:58,532:INFO:           fairlearn: Not installed
2023-04-29 17:10:58,532:INFO:             xgboost: Not installed
2023-04-29 17:10:58,532:INFO:            catboost: Not installed
2023-04-29 17:10:58,532:INFO:              kmodes: Not installed
2023-04-29 17:10:58,532:INFO:             mlxtend: Not installed
2023-04-29 17:10:58,532:INFO:       statsforecast: Not installed
2023-04-29 17:10:58,532:INFO:        tune_sklearn: Not installed
2023-04-29 17:10:58,532:INFO:                 ray: Not installed
2023-04-29 17:10:58,532:INFO:            hyperopt: Not installed
2023-04-29 17:10:58,532:INFO:              optuna: Not installed
2023-04-29 17:10:58,532:INFO:               skopt: Not installed
2023-04-29 17:10:58,532:INFO:              mlflow: 2.2.1
2023-04-29 17:10:58,532:INFO:              gradio: Not installed
2023-04-29 17:10:58,532:INFO:             fastapi: Not installed
2023-04-29 17:10:58,532:INFO:             uvicorn: Not installed
2023-04-29 17:10:58,532:INFO:              m2cgen: Not installed
2023-04-29 17:10:58,532:INFO:           evidently: Not installed
2023-04-29 17:10:58,532:INFO:               fugue: Not installed
2023-04-29 17:10:58,532:INFO:           streamlit: 1.21.0
2023-04-29 17:10:58,533:INFO:             prophet: Not installed
2023-04-29 17:10:58,533:INFO:None
2023-04-29 17:10:58,533:INFO:Set up data.
2023-04-29 17:10:58,536:INFO:Set up train/test split.
2023-04-29 17:10:58,538:INFO:Set up index.
2023-04-29 17:10:58,539:INFO:Set up folding strategy.
2023-04-29 17:10:58,539:INFO:Assigning column types.
2023-04-29 17:10:58,541:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:10:58,541:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,546:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,551:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,664:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:58,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:58,665:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,669:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,675:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:58,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:58,788:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:10:58,795:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,800:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,908:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:58,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:58,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:10:58,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,037:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:10:59,047:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,286:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:10:59,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,524:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:10:59,601:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:10:59,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,773:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:10:59,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:10:59,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,015:INFO:Preparing preprocessing pipeline...
2023-04-29 17:11:00,016:INFO:Set up simple imputation.
2023-04-29 17:11:00,016:INFO:Set up column name cleaning.
2023-04-29 17:11:00,054:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:11:00,059:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:11:00,059:INFO:Creating final display dataframe.
2023-04-29 17:11:00,140:INFO:Setup _display_container:                     Description             Value
0                    Session id              4116
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ae32
2023-04-29 17:11:00,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:11:00,392:INFO:setup() successfully completed in 2.18s...............
2023-04-29 17:11:00,399:INFO:Initializing compare_models()
2023-04-29 17:11:00,399:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:11:00,399:INFO:Checking exceptions
2023-04-29 17:11:00,401:INFO:Preparing display monitor
2023-04-29 17:11:00,404:INFO:Initializing Linear Regression
2023-04-29 17:11:00,404:INFO:Total runtime is 0.0 minutes
2023-04-29 17:11:00,404:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:00,405:INFO:Initializing create_model()
2023-04-29 17:11:00,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:00,405:INFO:Checking exceptions
2023-04-29 17:11:00,405:INFO:Importing libraries
2023-04-29 17:11:00,405:INFO:Copying training dataset
2023-04-29 17:11:00,408:INFO:Defining folds
2023-04-29 17:11:00,408:INFO:Declaring metric variables
2023-04-29 17:11:00,408:INFO:Importing untrained model
2023-04-29 17:11:00,409:INFO:Linear Regression Imported successfully
2023-04-29 17:11:00,409:INFO:Starting cross validation
2023-04-29 17:11:00,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:13,191:INFO:Calculating mean and std
2023-04-29 17:11:13,192:INFO:Creating metrics dataframe
2023-04-29 17:11:13,713:INFO:Uploading results into container
2023-04-29 17:11:13,714:INFO:Uploading model into container now
2023-04-29 17:11:13,714:INFO:_master_model_container: 1
2023-04-29 17:11:13,714:INFO:_display_container: 2
2023-04-29 17:11:13,714:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:11:13,714:INFO:create_model() successfully completed......................................
2023-04-29 17:11:13,842:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:13,843:INFO:Creating metrics dataframe
2023-04-29 17:11:13,854:INFO:Initializing Lasso Regression
2023-04-29 17:11:13,854:INFO:Total runtime is 0.2241607666015625 minutes
2023-04-29 17:11:13,855:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:13,855:INFO:Initializing create_model()
2023-04-29 17:11:13,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:13,855:INFO:Checking exceptions
2023-04-29 17:11:13,855:INFO:Importing libraries
2023-04-29 17:11:13,855:INFO:Copying training dataset
2023-04-29 17:11:13,863:INFO:Defining folds
2023-04-29 17:11:13,864:INFO:Declaring metric variables
2023-04-29 17:11:13,864:INFO:Importing untrained model
2023-04-29 17:11:13,865:INFO:Lasso Regression Imported successfully
2023-04-29 17:11:13,865:INFO:Starting cross validation
2023-04-29 17:11:13,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:19,387:INFO:Calculating mean and std
2023-04-29 17:11:19,387:INFO:Creating metrics dataframe
2023-04-29 17:11:19,977:INFO:Uploading results into container
2023-04-29 17:11:19,977:INFO:Uploading model into container now
2023-04-29 17:11:19,978:INFO:_master_model_container: 2
2023-04-29 17:11:19,978:INFO:_display_container: 2
2023-04-29 17:11:19,978:INFO:Lasso(random_state=4116)
2023-04-29 17:11:19,978:INFO:create_model() successfully completed......................................
2023-04-29 17:11:20,125:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:20,126:INFO:Creating metrics dataframe
2023-04-29 17:11:20,130:INFO:Initializing Ridge Regression
2023-04-29 17:11:20,130:INFO:Total runtime is 0.3287637670834859 minutes
2023-04-29 17:11:20,130:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:20,130:INFO:Initializing create_model()
2023-04-29 17:11:20,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:20,130:INFO:Checking exceptions
2023-04-29 17:11:20,130:INFO:Importing libraries
2023-04-29 17:11:20,130:INFO:Copying training dataset
2023-04-29 17:11:20,133:INFO:Defining folds
2023-04-29 17:11:20,134:INFO:Declaring metric variables
2023-04-29 17:11:20,134:INFO:Importing untrained model
2023-04-29 17:11:20,134:INFO:Ridge Regression Imported successfully
2023-04-29 17:11:20,135:INFO:Starting cross validation
2023-04-29 17:11:20,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:24,937:INFO:Calculating mean and std
2023-04-29 17:11:24,938:INFO:Creating metrics dataframe
2023-04-29 17:11:25,505:INFO:Uploading results into container
2023-04-29 17:11:25,507:INFO:Uploading model into container now
2023-04-29 17:11:25,507:INFO:_master_model_container: 3
2023-04-29 17:11:25,507:INFO:_display_container: 2
2023-04-29 17:11:25,508:INFO:Ridge(random_state=4116)
2023-04-29 17:11:25,508:INFO:create_model() successfully completed......................................
2023-04-29 17:11:25,676:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:25,677:INFO:Creating metrics dataframe
2023-04-29 17:11:25,681:INFO:Initializing Elastic Net
2023-04-29 17:11:25,681:INFO:Total runtime is 0.421285088857015 minutes
2023-04-29 17:11:25,682:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:25,682:INFO:Initializing create_model()
2023-04-29 17:11:25,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:25,682:INFO:Checking exceptions
2023-04-29 17:11:25,683:INFO:Importing libraries
2023-04-29 17:11:25,683:INFO:Copying training dataset
2023-04-29 17:11:25,686:INFO:Defining folds
2023-04-29 17:11:25,686:INFO:Declaring metric variables
2023-04-29 17:11:25,687:INFO:Importing untrained model
2023-04-29 17:11:25,688:INFO:Elastic Net Imported successfully
2023-04-29 17:11:25,689:INFO:Starting cross validation
2023-04-29 17:11:25,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:30,149:INFO:Calculating mean and std
2023-04-29 17:11:30,150:INFO:Creating metrics dataframe
2023-04-29 17:11:30,820:INFO:Uploading results into container
2023-04-29 17:11:30,821:INFO:Uploading model into container now
2023-04-29 17:11:30,822:INFO:_master_model_container: 4
2023-04-29 17:11:30,822:INFO:_display_container: 2
2023-04-29 17:11:30,823:INFO:ElasticNet(random_state=4116)
2023-04-29 17:11:30,823:INFO:create_model() successfully completed......................................
2023-04-29 17:11:30,958:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:30,959:INFO:Creating metrics dataframe
2023-04-29 17:11:30,974:INFO:Initializing Least Angle Regression
2023-04-29 17:11:30,974:INFO:Total runtime is 0.5094923337300619 minutes
2023-04-29 17:11:30,975:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:30,976:INFO:Initializing create_model()
2023-04-29 17:11:30,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:30,976:INFO:Checking exceptions
2023-04-29 17:11:30,976:INFO:Importing libraries
2023-04-29 17:11:30,977:INFO:Copying training dataset
2023-04-29 17:11:30,983:INFO:Defining folds
2023-04-29 17:11:30,984:INFO:Declaring metric variables
2023-04-29 17:11:30,984:INFO:Importing untrained model
2023-04-29 17:11:30,984:INFO:Least Angle Regression Imported successfully
2023-04-29 17:11:30,985:INFO:Starting cross validation
2023-04-29 17:11:30,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:31,088:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,109:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,114:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,130:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,142:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,155:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,178:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:31,194:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:32,172:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:32,296:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:36,041:INFO:Calculating mean and std
2023-04-29 17:11:36,043:INFO:Creating metrics dataframe
2023-04-29 17:11:36,616:INFO:Uploading results into container
2023-04-29 17:11:36,617:INFO:Uploading model into container now
2023-04-29 17:11:36,617:INFO:_master_model_container: 5
2023-04-29 17:11:36,617:INFO:_display_container: 2
2023-04-29 17:11:36,618:INFO:Lars(random_state=4116)
2023-04-29 17:11:36,618:INFO:create_model() successfully completed......................................
2023-04-29 17:11:36,743:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:36,743:INFO:Creating metrics dataframe
2023-04-29 17:11:36,748:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:11:36,748:INFO:Total runtime is 0.6057381153106689 minutes
2023-04-29 17:11:36,748:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:36,748:INFO:Initializing create_model()
2023-04-29 17:11:36,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:36,748:INFO:Checking exceptions
2023-04-29 17:11:36,748:INFO:Importing libraries
2023-04-29 17:11:36,748:INFO:Copying training dataset
2023-04-29 17:11:36,751:INFO:Defining folds
2023-04-29 17:11:36,751:INFO:Declaring metric variables
2023-04-29 17:11:36,752:INFO:Importing untrained model
2023-04-29 17:11:36,754:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:11:36,754:INFO:Starting cross validation
2023-04-29 17:11:36,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:36,854:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,863:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,890:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,908:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,920:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,936:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,959:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:36,975:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:37,944:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:37,991:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:11:41,714:INFO:Calculating mean and std
2023-04-29 17:11:41,715:INFO:Creating metrics dataframe
2023-04-29 17:11:42,297:INFO:Uploading results into container
2023-04-29 17:11:42,298:INFO:Uploading model into container now
2023-04-29 17:11:42,298:INFO:_master_model_container: 6
2023-04-29 17:11:42,298:INFO:_display_container: 2
2023-04-29 17:11:42,299:INFO:LassoLars(random_state=4116)
2023-04-29 17:11:42,299:INFO:create_model() successfully completed......................................
2023-04-29 17:11:42,452:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:42,452:INFO:Creating metrics dataframe
2023-04-29 17:11:42,462:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:11:42,463:INFO:Total runtime is 0.7009756922721863 minutes
2023-04-29 17:11:42,463:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:42,463:INFO:Initializing create_model()
2023-04-29 17:11:42,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:42,463:INFO:Checking exceptions
2023-04-29 17:11:42,463:INFO:Importing libraries
2023-04-29 17:11:42,463:INFO:Copying training dataset
2023-04-29 17:11:42,469:INFO:Defining folds
2023-04-29 17:11:42,469:INFO:Declaring metric variables
2023-04-29 17:11:42,469:INFO:Importing untrained model
2023-04-29 17:11:42,470:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:11:42,470:INFO:Starting cross validation
2023-04-29 17:11:42,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:42,570:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,589:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,597:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,611:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,625:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,657:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,676:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:42,694:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:43,920:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:43,937:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:11:48,195:INFO:Calculating mean and std
2023-04-29 17:11:48,196:INFO:Creating metrics dataframe
2023-04-29 17:11:48,738:INFO:Uploading results into container
2023-04-29 17:11:48,740:INFO:Uploading model into container now
2023-04-29 17:11:48,741:INFO:_master_model_container: 7
2023-04-29 17:11:48,741:INFO:_display_container: 2
2023-04-29 17:11:48,741:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:11:48,741:INFO:create_model() successfully completed......................................
2023-04-29 17:11:48,863:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:48,863:INFO:Creating metrics dataframe
2023-04-29 17:11:48,871:INFO:Initializing Bayesian Ridge
2023-04-29 17:11:48,871:INFO:Total runtime is 0.8077764789263407 minutes
2023-04-29 17:11:48,871:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:48,872:INFO:Initializing create_model()
2023-04-29 17:11:48,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:48,872:INFO:Checking exceptions
2023-04-29 17:11:48,872:INFO:Importing libraries
2023-04-29 17:11:48,872:INFO:Copying training dataset
2023-04-29 17:11:48,880:INFO:Defining folds
2023-04-29 17:11:48,880:INFO:Declaring metric variables
2023-04-29 17:11:48,880:INFO:Importing untrained model
2023-04-29 17:11:48,881:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:11:48,881:INFO:Starting cross validation
2023-04-29 17:11:48,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:54,098:INFO:Calculating mean and std
2023-04-29 17:11:54,098:INFO:Creating metrics dataframe
2023-04-29 17:11:54,620:INFO:Uploading results into container
2023-04-29 17:11:54,621:INFO:Uploading model into container now
2023-04-29 17:11:54,622:INFO:_master_model_container: 8
2023-04-29 17:11:54,622:INFO:_display_container: 2
2023-04-29 17:11:54,622:INFO:BayesianRidge()
2023-04-29 17:11:54,622:INFO:create_model() successfully completed......................................
2023-04-29 17:11:54,760:INFO:SubProcess create_model() end ==================================
2023-04-29 17:11:54,760:INFO:Creating metrics dataframe
2023-04-29 17:11:54,768:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:11:54,768:INFO:Total runtime is 0.9060612161954245 minutes
2023-04-29 17:11:54,768:INFO:SubProcess create_model() called ==================================
2023-04-29 17:11:54,769:INFO:Initializing create_model()
2023-04-29 17:11:54,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:11:54,769:INFO:Checking exceptions
2023-04-29 17:11:54,770:INFO:Importing libraries
2023-04-29 17:11:54,770:INFO:Copying training dataset
2023-04-29 17:11:54,778:INFO:Defining folds
2023-04-29 17:11:54,778:INFO:Declaring metric variables
2023-04-29 17:11:54,779:INFO:Importing untrained model
2023-04-29 17:11:54,779:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:11:54,779:INFO:Starting cross validation
2023-04-29 17:11:54,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:11:59,866:INFO:Calculating mean and std
2023-04-29 17:11:59,867:INFO:Creating metrics dataframe
2023-04-29 17:12:00,470:INFO:Uploading results into container
2023-04-29 17:12:00,471:INFO:Uploading model into container now
2023-04-29 17:12:00,471:INFO:_master_model_container: 9
2023-04-29 17:12:00,472:INFO:_display_container: 2
2023-04-29 17:12:00,472:INFO:PassiveAggressiveRegressor(random_state=4116)
2023-04-29 17:12:00,472:INFO:create_model() successfully completed......................................
2023-04-29 17:12:00,612:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:00,612:INFO:Creating metrics dataframe
2023-04-29 17:12:00,621:INFO:Initializing Huber Regressor
2023-04-29 17:12:00,621:INFO:Total runtime is 1.003622078895569 minutes
2023-04-29 17:12:00,621:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:00,622:INFO:Initializing create_model()
2023-04-29 17:12:00,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:00,622:INFO:Checking exceptions
2023-04-29 17:12:00,622:INFO:Importing libraries
2023-04-29 17:12:00,622:INFO:Copying training dataset
2023-04-29 17:12:00,628:INFO:Defining folds
2023-04-29 17:12:00,628:INFO:Declaring metric variables
2023-04-29 17:12:00,628:INFO:Importing untrained model
2023-04-29 17:12:00,629:INFO:Huber Regressor Imported successfully
2023-04-29 17:12:00,629:INFO:Starting cross validation
2023-04-29 17:12:00,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:00,865:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:12:05,389:INFO:Calculating mean and std
2023-04-29 17:12:05,391:INFO:Creating metrics dataframe
2023-04-29 17:12:05,945:INFO:Uploading results into container
2023-04-29 17:12:05,946:INFO:Uploading model into container now
2023-04-29 17:12:05,946:INFO:_master_model_container: 10
2023-04-29 17:12:05,946:INFO:_display_container: 2
2023-04-29 17:12:05,947:INFO:HuberRegressor()
2023-04-29 17:12:05,947:INFO:create_model() successfully completed......................................
2023-04-29 17:12:06,104:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:06,105:INFO:Creating metrics dataframe
2023-04-29 17:12:06,120:INFO:Initializing K Neighbors Regressor
2023-04-29 17:12:06,120:INFO:Total runtime is 1.0952643473943076 minutes
2023-04-29 17:12:06,120:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:06,120:INFO:Initializing create_model()
2023-04-29 17:12:06,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:06,121:INFO:Checking exceptions
2023-04-29 17:12:06,121:INFO:Importing libraries
2023-04-29 17:12:06,121:INFO:Copying training dataset
2023-04-29 17:12:06,126:INFO:Defining folds
2023-04-29 17:12:06,126:INFO:Declaring metric variables
2023-04-29 17:12:06,128:INFO:Importing untrained model
2023-04-29 17:12:06,129:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:12:06,129:INFO:Starting cross validation
2023-04-29 17:12:06,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:11,251:INFO:Calculating mean and std
2023-04-29 17:12:11,252:INFO:Creating metrics dataframe
2023-04-29 17:12:11,798:INFO:Uploading results into container
2023-04-29 17:12:11,799:INFO:Uploading model into container now
2023-04-29 17:12:11,799:INFO:_master_model_container: 11
2023-04-29 17:12:11,799:INFO:_display_container: 2
2023-04-29 17:12:11,800:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:12:11,800:INFO:create_model() successfully completed......................................
2023-04-29 17:12:11,943:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:11,943:INFO:Creating metrics dataframe
2023-04-29 17:12:11,949:INFO:Initializing Decision Tree Regressor
2023-04-29 17:12:11,949:INFO:Total runtime is 1.1924131274223329 minutes
2023-04-29 17:12:11,949:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:11,950:INFO:Initializing create_model()
2023-04-29 17:12:11,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:11,950:INFO:Checking exceptions
2023-04-29 17:12:11,950:INFO:Importing libraries
2023-04-29 17:12:11,950:INFO:Copying training dataset
2023-04-29 17:12:11,955:INFO:Defining folds
2023-04-29 17:12:11,955:INFO:Declaring metric variables
2023-04-29 17:12:11,955:INFO:Importing untrained model
2023-04-29 17:12:11,956:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:12:11,958:INFO:Starting cross validation
2023-04-29 17:12:11,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:17,250:INFO:Calculating mean and std
2023-04-29 17:12:17,251:INFO:Creating metrics dataframe
2023-04-29 17:12:17,806:INFO:Uploading results into container
2023-04-29 17:12:17,807:INFO:Uploading model into container now
2023-04-29 17:12:17,808:INFO:_master_model_container: 12
2023-04-29 17:12:17,808:INFO:_display_container: 2
2023-04-29 17:12:17,808:INFO:DecisionTreeRegressor(random_state=4116)
2023-04-29 17:12:17,808:INFO:create_model() successfully completed......................................
2023-04-29 17:12:17,931:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:17,932:INFO:Creating metrics dataframe
2023-04-29 17:12:17,936:INFO:Initializing Random Forest Regressor
2023-04-29 17:12:17,936:INFO:Total runtime is 1.292195761203766 minutes
2023-04-29 17:12:17,936:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:17,936:INFO:Initializing create_model()
2023-04-29 17:12:17,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:17,937:INFO:Checking exceptions
2023-04-29 17:12:17,937:INFO:Importing libraries
2023-04-29 17:12:17,937:INFO:Copying training dataset
2023-04-29 17:12:17,941:INFO:Defining folds
2023-04-29 17:12:17,941:INFO:Declaring metric variables
2023-04-29 17:12:17,941:INFO:Importing untrained model
2023-04-29 17:12:17,942:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:12:17,942:INFO:Starting cross validation
2023-04-29 17:12:17,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:22,658:INFO:Calculating mean and std
2023-04-29 17:12:22,659:INFO:Creating metrics dataframe
2023-04-29 17:12:23,112:INFO:Uploading results into container
2023-04-29 17:12:23,113:INFO:Uploading model into container now
2023-04-29 17:12:23,113:INFO:_master_model_container: 13
2023-04-29 17:12:23,113:INFO:_display_container: 2
2023-04-29 17:12:23,114:INFO:RandomForestRegressor(n_jobs=-1, random_state=4116)
2023-04-29 17:12:23,114:INFO:create_model() successfully completed......................................
2023-04-29 17:12:23,204:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:23,204:INFO:Creating metrics dataframe
2023-04-29 17:12:23,209:INFO:Initializing Extra Trees Regressor
2023-04-29 17:12:23,209:INFO:Total runtime is 1.3800819555918378 minutes
2023-04-29 17:12:23,209:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:23,210:INFO:Initializing create_model()
2023-04-29 17:12:23,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:23,210:INFO:Checking exceptions
2023-04-29 17:12:23,210:INFO:Importing libraries
2023-04-29 17:12:23,210:INFO:Copying training dataset
2023-04-29 17:12:23,215:INFO:Defining folds
2023-04-29 17:12:23,216:INFO:Declaring metric variables
2023-04-29 17:12:23,216:INFO:Importing untrained model
2023-04-29 17:12:23,216:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:12:23,217:INFO:Starting cross validation
2023-04-29 17:12:23,217:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:27,852:INFO:Calculating mean and std
2023-04-29 17:12:27,853:INFO:Creating metrics dataframe
2023-04-29 17:12:28,323:INFO:Uploading results into container
2023-04-29 17:12:28,324:INFO:Uploading model into container now
2023-04-29 17:12:28,324:INFO:_master_model_container: 14
2023-04-29 17:12:28,324:INFO:_display_container: 2
2023-04-29 17:12:28,324:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4116)
2023-04-29 17:12:28,324:INFO:create_model() successfully completed......................................
2023-04-29 17:12:28,422:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:28,422:INFO:Creating metrics dataframe
2023-04-29 17:12:28,426:INFO:Initializing AdaBoost Regressor
2023-04-29 17:12:28,426:INFO:Total runtime is 1.4670242746671043 minutes
2023-04-29 17:12:28,426:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:28,427:INFO:Initializing create_model()
2023-04-29 17:12:28,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:28,427:INFO:Checking exceptions
2023-04-29 17:12:28,427:INFO:Importing libraries
2023-04-29 17:12:28,427:INFO:Copying training dataset
2023-04-29 17:12:28,430:INFO:Defining folds
2023-04-29 17:12:28,430:INFO:Declaring metric variables
2023-04-29 17:12:28,430:INFO:Importing untrained model
2023-04-29 17:12:28,431:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:12:28,431:INFO:Starting cross validation
2023-04-29 17:12:28,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:32,558:INFO:Calculating mean and std
2023-04-29 17:12:32,559:INFO:Creating metrics dataframe
2023-04-29 17:12:33,020:INFO:Uploading results into container
2023-04-29 17:12:33,021:INFO:Uploading model into container now
2023-04-29 17:12:33,022:INFO:_master_model_container: 15
2023-04-29 17:12:33,022:INFO:_display_container: 2
2023-04-29 17:12:33,022:INFO:AdaBoostRegressor(random_state=4116)
2023-04-29 17:12:33,022:INFO:create_model() successfully completed......................................
2023-04-29 17:12:33,115:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:33,115:INFO:Creating metrics dataframe
2023-04-29 17:12:33,119:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:12:33,119:INFO:Total runtime is 1.5452553470929467 minutes
2023-04-29 17:12:33,120:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:33,120:INFO:Initializing create_model()
2023-04-29 17:12:33,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:33,120:INFO:Checking exceptions
2023-04-29 17:12:33,120:INFO:Importing libraries
2023-04-29 17:12:33,120:INFO:Copying training dataset
2023-04-29 17:12:33,123:INFO:Defining folds
2023-04-29 17:12:33,123:INFO:Declaring metric variables
2023-04-29 17:12:33,123:INFO:Importing untrained model
2023-04-29 17:12:33,124:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:12:33,124:INFO:Starting cross validation
2023-04-29 17:12:33,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:37,381:INFO:Calculating mean and std
2023-04-29 17:12:37,382:INFO:Creating metrics dataframe
2023-04-29 17:12:37,916:INFO:Uploading results into container
2023-04-29 17:12:37,916:INFO:Uploading model into container now
2023-04-29 17:12:37,917:INFO:_master_model_container: 16
2023-04-29 17:12:37,917:INFO:_display_container: 2
2023-04-29 17:12:37,917:INFO:GradientBoostingRegressor(random_state=4116)
2023-04-29 17:12:37,917:INFO:create_model() successfully completed......................................
2023-04-29 17:12:38,014:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:38,014:INFO:Creating metrics dataframe
2023-04-29 17:12:38,018:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:12:38,018:INFO:Total runtime is 1.6269005537033083 minutes
2023-04-29 17:12:38,018:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:38,018:INFO:Initializing create_model()
2023-04-29 17:12:38,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:38,018:INFO:Checking exceptions
2023-04-29 17:12:38,019:INFO:Importing libraries
2023-04-29 17:12:38,019:INFO:Copying training dataset
2023-04-29 17:12:38,022:INFO:Defining folds
2023-04-29 17:12:38,022:INFO:Declaring metric variables
2023-04-29 17:12:38,022:INFO:Importing untrained model
2023-04-29 17:12:38,023:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:12:38,023:INFO:Starting cross validation
2023-04-29 17:12:38,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:44,008:INFO:Calculating mean and std
2023-04-29 17:12:44,009:INFO:Creating metrics dataframe
2023-04-29 17:12:44,483:INFO:Uploading results into container
2023-04-29 17:12:44,483:INFO:Uploading model into container now
2023-04-29 17:12:44,484:INFO:_master_model_container: 17
2023-04-29 17:12:44,484:INFO:_display_container: 2
2023-04-29 17:12:44,484:INFO:LGBMRegressor(random_state=4116)
2023-04-29 17:12:44,484:INFO:create_model() successfully completed......................................
2023-04-29 17:12:44,579:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:44,579:INFO:Creating metrics dataframe
2023-04-29 17:12:44,584:INFO:Initializing Dummy Regressor
2023-04-29 17:12:44,584:INFO:Total runtime is 1.736325756708781 minutes
2023-04-29 17:12:44,584:INFO:SubProcess create_model() called ==================================
2023-04-29 17:12:44,585:INFO:Initializing create_model()
2023-04-29 17:12:44,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6B51460>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:44,585:INFO:Checking exceptions
2023-04-29 17:12:44,585:INFO:Importing libraries
2023-04-29 17:12:44,585:INFO:Copying training dataset
2023-04-29 17:12:44,589:INFO:Defining folds
2023-04-29 17:12:44,589:INFO:Declaring metric variables
2023-04-29 17:12:44,589:INFO:Importing untrained model
2023-04-29 17:12:44,590:INFO:Dummy Regressor Imported successfully
2023-04-29 17:12:44,590:INFO:Starting cross validation
2023-04-29 17:12:44,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:12:48,402:INFO:Calculating mean and std
2023-04-29 17:12:48,403:INFO:Creating metrics dataframe
2023-04-29 17:12:48,919:INFO:Uploading results into container
2023-04-29 17:12:48,920:INFO:Uploading model into container now
2023-04-29 17:12:48,921:INFO:_master_model_container: 18
2023-04-29 17:12:48,921:INFO:_display_container: 2
2023-04-29 17:12:48,921:INFO:DummyRegressor()
2023-04-29 17:12:48,921:INFO:create_model() successfully completed......................................
2023-04-29 17:12:49,025:INFO:SubProcess create_model() end ==================================
2023-04-29 17:12:49,026:INFO:Creating metrics dataframe
2023-04-29 17:12:49,034:INFO:Initializing create_model()
2023-04-29 17:12:49,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4116), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:12:49,034:INFO:Checking exceptions
2023-04-29 17:12:49,035:INFO:Importing libraries
2023-04-29 17:12:49,035:INFO:Copying training dataset
2023-04-29 17:12:49,038:INFO:Defining folds
2023-04-29 17:12:49,038:INFO:Declaring metric variables
2023-04-29 17:12:49,038:INFO:Importing untrained model
2023-04-29 17:12:49,038:INFO:Declaring custom model
2023-04-29 17:12:49,039:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:12:49,039:INFO:Cross validation set to False
2023-04-29 17:12:49,039:INFO:Fitting Model
2023-04-29 17:12:49,509:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4116)
2023-04-29 17:12:49,509:INFO:create_model() successfully completed......................................
2023-04-29 17:12:49,627:INFO:_master_model_container: 18
2023-04-29 17:12:49,627:INFO:_display_container: 2
2023-04-29 17:12:49,628:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4116)
2023-04-29 17:12:49,628:INFO:compare_models() successfully completed......................................
2023-04-29 17:12:49,632:INFO:Initializing predict_model()
2023-04-29 17:12:49,632:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6CF18E0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4116), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B6C843A0>)
2023-04-29 17:12:49,632:INFO:Checking exceptions
2023-04-29 17:12:49,632:INFO:Preloading libraries
2023-04-29 17:12:49,632:INFO:Set up data.
2023-04-29 17:12:49,637:INFO:Set up index.
2023-04-29 17:15:48,510:INFO:PyCaret RegressionExperiment
2023-04-29 17:15:48,510:INFO:Logging name: reg-default-name
2023-04-29 17:15:48,510:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:15:48,510:INFO:version 3.0.0
2023-04-29 17:15:48,510:INFO:Initializing setup()
2023-04-29 17:15:48,510:INFO:self.USI: 5a5b
2023-04-29 17:15:48,510:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:15:48,510:INFO:Checking environment
2023-04-29 17:15:48,510:INFO:python_version: 3.9.13
2023-04-29 17:15:48,510:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:15:48,510:INFO:machine: AMD64
2023-04-29 17:15:48,510:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:15:48,510:INFO:Memory: svmem(total=16935899136, available=5796712448, percent=65.8, used=11139186688, free=5796712448)
2023-04-29 17:15:48,511:INFO:Physical Core: 4
2023-04-29 17:15:48,511:INFO:Logical Core: 8
2023-04-29 17:15:48,511:INFO:Checking libraries
2023-04-29 17:15:48,511:INFO:System:
2023-04-29 17:15:48,511:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:15:48,511:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:15:48,511:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:15:48,511:INFO:PyCaret required dependencies:
2023-04-29 17:15:48,511:INFO:                 pip: 22.2.2
2023-04-29 17:15:48,511:INFO:          setuptools: 63.4.1
2023-04-29 17:15:48,511:INFO:             pycaret: 3.0.0
2023-04-29 17:15:48,511:INFO:             IPython: 7.31.1
2023-04-29 17:15:48,511:INFO:          ipywidgets: 7.6.5
2023-04-29 17:15:48,511:INFO:                tqdm: 4.64.1
2023-04-29 17:15:48,511:INFO:               numpy: 1.21.5
2023-04-29 17:15:48,511:INFO:              pandas: 1.4.4
2023-04-29 17:15:48,511:INFO:              jinja2: 2.11.3
2023-04-29 17:15:48,511:INFO:               scipy: 1.9.1
2023-04-29 17:15:48,511:INFO:              joblib: 1.2.0
2023-04-29 17:15:48,511:INFO:             sklearn: 1.0.2
2023-04-29 17:15:48,511:INFO:                pyod: 1.0.9
2023-04-29 17:15:48,511:INFO:            imblearn: 0.10.1
2023-04-29 17:15:48,511:INFO:   category_encoders: 2.6.0
2023-04-29 17:15:48,511:INFO:            lightgbm: 3.3.5
2023-04-29 17:15:48,511:INFO:               numba: 0.55.1
2023-04-29 17:15:48,511:INFO:            requests: 2.28.1
2023-04-29 17:15:48,511:INFO:          matplotlib: 3.5.2
2023-04-29 17:15:48,511:INFO:          scikitplot: 0.3.7
2023-04-29 17:15:48,511:INFO:         yellowbrick: 1.5
2023-04-29 17:15:48,511:INFO:              plotly: 5.9.0
2023-04-29 17:15:48,511:INFO:             kaleido: 0.2.1
2023-04-29 17:15:48,512:INFO:         statsmodels: 0.13.2
2023-04-29 17:15:48,512:INFO:              sktime: 0.17.1
2023-04-29 17:15:48,512:INFO:               tbats: 1.1.2
2023-04-29 17:15:48,512:INFO:            pmdarima: 2.0.3
2023-04-29 17:15:48,512:INFO:              psutil: 5.9.0
2023-04-29 17:15:48,512:INFO:PyCaret optional dependencies:
2023-04-29 17:15:48,512:INFO:                shap: 0.41.0
2023-04-29 17:15:48,512:INFO:           interpret: Not installed
2023-04-29 17:15:48,512:INFO:                umap: Not installed
2023-04-29 17:15:48,512:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:15:48,512:INFO:  explainerdashboard: Not installed
2023-04-29 17:15:48,512:INFO:             autoviz: Not installed
2023-04-29 17:15:48,512:INFO:           fairlearn: Not installed
2023-04-29 17:15:48,512:INFO:             xgboost: Not installed
2023-04-29 17:15:48,512:INFO:            catboost: Not installed
2023-04-29 17:15:48,512:INFO:              kmodes: Not installed
2023-04-29 17:15:48,512:INFO:             mlxtend: Not installed
2023-04-29 17:15:48,512:INFO:       statsforecast: Not installed
2023-04-29 17:15:48,512:INFO:        tune_sklearn: Not installed
2023-04-29 17:15:48,512:INFO:                 ray: Not installed
2023-04-29 17:15:48,512:INFO:            hyperopt: Not installed
2023-04-29 17:15:48,512:INFO:              optuna: Not installed
2023-04-29 17:15:48,512:INFO:               skopt: Not installed
2023-04-29 17:15:48,512:INFO:              mlflow: 2.2.1
2023-04-29 17:15:48,512:INFO:              gradio: Not installed
2023-04-29 17:15:48,512:INFO:             fastapi: Not installed
2023-04-29 17:15:48,512:INFO:             uvicorn: Not installed
2023-04-29 17:15:48,512:INFO:              m2cgen: Not installed
2023-04-29 17:15:48,512:INFO:           evidently: Not installed
2023-04-29 17:15:48,512:INFO:               fugue: Not installed
2023-04-29 17:15:48,512:INFO:           streamlit: 1.21.0
2023-04-29 17:15:48,512:INFO:             prophet: Not installed
2023-04-29 17:15:48,513:INFO:None
2023-04-29 17:15:48,513:INFO:Set up data.
2023-04-29 17:15:48,516:INFO:Set up train/test split.
2023-04-29 17:15:48,518:INFO:Set up index.
2023-04-29 17:15:48,518:INFO:Set up folding strategy.
2023-04-29 17:15:48,518:INFO:Assigning column types.
2023-04-29 17:15:48,521:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:15:48,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,525:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,530:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,631:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,635:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,736:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:15:48,740:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,749:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,851:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,857:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:48,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:48,958:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:15:48,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,075:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,169:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:15:49,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,377:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:15:49,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,545:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:15:49,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,590:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:15:49,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:49,800:INFO:Preparing preprocessing pipeline...
2023-04-29 17:15:49,800:INFO:Set up simple imputation.
2023-04-29 17:15:49,800:INFO:Set up column name cleaning.
2023-04-29 17:15:49,818:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:15:49,822:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:15:49,822:INFO:Creating final display dataframe.
2023-04-29 17:15:49,887:INFO:Setup _display_container:                     Description             Value
0                    Session id              4632
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5a5b
2023-04-29 17:15:50,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:50,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:50,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:50,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:15:50,115:INFO:setup() successfully completed in 1.88s...............
2023-04-29 17:15:50,128:INFO:Initializing compare_models()
2023-04-29 17:15:50,128:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:15:50,128:INFO:Checking exceptions
2023-04-29 17:15:50,132:INFO:Preparing display monitor
2023-04-29 17:15:50,137:INFO:Initializing Linear Regression
2023-04-29 17:15:50,137:INFO:Total runtime is 0.0 minutes
2023-04-29 17:15:50,138:INFO:SubProcess create_model() called ==================================
2023-04-29 17:15:50,138:INFO:Initializing create_model()
2023-04-29 17:15:50,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:15:50,138:INFO:Checking exceptions
2023-04-29 17:15:50,138:INFO:Importing libraries
2023-04-29 17:15:50,138:INFO:Copying training dataset
2023-04-29 17:15:50,144:INFO:Defining folds
2023-04-29 17:15:50,144:INFO:Declaring metric variables
2023-04-29 17:15:50,144:INFO:Importing untrained model
2023-04-29 17:15:50,144:INFO:Linear Regression Imported successfully
2023-04-29 17:15:50,144:INFO:Starting cross validation
2023-04-29 17:15:50,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:15:53,782:INFO:Calculating mean and std
2023-04-29 17:15:53,783:INFO:Creating metrics dataframe
2023-04-29 17:15:54,244:INFO:Uploading results into container
2023-04-29 17:15:54,245:INFO:Uploading model into container now
2023-04-29 17:15:54,245:INFO:_master_model_container: 1
2023-04-29 17:15:54,245:INFO:_display_container: 2
2023-04-29 17:15:54,245:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:15:54,246:INFO:create_model() successfully completed......................................
2023-04-29 17:15:54,373:INFO:SubProcess create_model() end ==================================
2023-04-29 17:15:54,374:INFO:Creating metrics dataframe
2023-04-29 17:15:54,380:INFO:Initializing Lasso Regression
2023-04-29 17:15:54,380:INFO:Total runtime is 0.0707268754641215 minutes
2023-04-29 17:15:54,380:INFO:SubProcess create_model() called ==================================
2023-04-29 17:15:54,381:INFO:Initializing create_model()
2023-04-29 17:15:54,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:15:54,381:INFO:Checking exceptions
2023-04-29 17:15:54,381:INFO:Importing libraries
2023-04-29 17:15:54,381:INFO:Copying training dataset
2023-04-29 17:15:54,388:INFO:Defining folds
2023-04-29 17:15:54,388:INFO:Declaring metric variables
2023-04-29 17:15:54,389:INFO:Importing untrained model
2023-04-29 17:15:54,390:INFO:Lasso Regression Imported successfully
2023-04-29 17:15:54,391:INFO:Starting cross validation
2023-04-29 17:15:54,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:15:58,239:INFO:Calculating mean and std
2023-04-29 17:15:58,240:INFO:Creating metrics dataframe
2023-04-29 17:15:58,686:INFO:Uploading results into container
2023-04-29 17:15:58,687:INFO:Uploading model into container now
2023-04-29 17:15:58,687:INFO:_master_model_container: 2
2023-04-29 17:15:58,688:INFO:_display_container: 2
2023-04-29 17:15:58,688:INFO:Lasso(random_state=4632)
2023-04-29 17:15:58,689:INFO:create_model() successfully completed......................................
2023-04-29 17:15:58,826:INFO:SubProcess create_model() end ==================================
2023-04-29 17:15:58,826:INFO:Creating metrics dataframe
2023-04-29 17:15:58,831:INFO:Initializing Ridge Regression
2023-04-29 17:15:58,831:INFO:Total runtime is 0.14490214586257935 minutes
2023-04-29 17:15:58,831:INFO:SubProcess create_model() called ==================================
2023-04-29 17:15:58,832:INFO:Initializing create_model()
2023-04-29 17:15:58,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:15:58,832:INFO:Checking exceptions
2023-04-29 17:15:58,832:INFO:Importing libraries
2023-04-29 17:15:58,832:INFO:Copying training dataset
2023-04-29 17:15:58,835:INFO:Defining folds
2023-04-29 17:15:58,835:INFO:Declaring metric variables
2023-04-29 17:15:58,836:INFO:Importing untrained model
2023-04-29 17:15:58,837:INFO:Ridge Regression Imported successfully
2023-04-29 17:15:58,838:INFO:Starting cross validation
2023-04-29 17:15:58,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:02,937:INFO:Calculating mean and std
2023-04-29 17:16:02,938:INFO:Creating metrics dataframe
2023-04-29 17:16:03,409:INFO:Uploading results into container
2023-04-29 17:16:03,409:INFO:Uploading model into container now
2023-04-29 17:16:03,409:INFO:_master_model_container: 3
2023-04-29 17:16:03,409:INFO:_display_container: 2
2023-04-29 17:16:03,410:INFO:Ridge(random_state=4632)
2023-04-29 17:16:03,410:INFO:create_model() successfully completed......................................
2023-04-29 17:16:03,537:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:03,538:INFO:Creating metrics dataframe
2023-04-29 17:16:03,542:INFO:Initializing Elastic Net
2023-04-29 17:16:03,542:INFO:Total runtime is 0.22342662413915 minutes
2023-04-29 17:16:03,542:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:03,542:INFO:Initializing create_model()
2023-04-29 17:16:03,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:03,543:INFO:Checking exceptions
2023-04-29 17:16:03,543:INFO:Importing libraries
2023-04-29 17:16:03,543:INFO:Copying training dataset
2023-04-29 17:16:03,546:INFO:Defining folds
2023-04-29 17:16:03,547:INFO:Declaring metric variables
2023-04-29 17:16:03,547:INFO:Importing untrained model
2023-04-29 17:16:03,547:INFO:Elastic Net Imported successfully
2023-04-29 17:16:03,548:INFO:Starting cross validation
2023-04-29 17:16:03,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:07,338:INFO:Calculating mean and std
2023-04-29 17:16:07,338:INFO:Creating metrics dataframe
2023-04-29 17:16:07,771:INFO:Uploading results into container
2023-04-29 17:16:07,772:INFO:Uploading model into container now
2023-04-29 17:16:07,772:INFO:_master_model_container: 4
2023-04-29 17:16:07,772:INFO:_display_container: 2
2023-04-29 17:16:07,773:INFO:ElasticNet(random_state=4632)
2023-04-29 17:16:07,773:INFO:create_model() successfully completed......................................
2023-04-29 17:16:07,909:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:07,909:INFO:Creating metrics dataframe
2023-04-29 17:16:07,912:INFO:Initializing Least Angle Regression
2023-04-29 17:16:07,912:INFO:Total runtime is 0.2962632695833842 minutes
2023-04-29 17:16:07,912:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:07,913:INFO:Initializing create_model()
2023-04-29 17:16:07,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:07,913:INFO:Checking exceptions
2023-04-29 17:16:07,913:INFO:Importing libraries
2023-04-29 17:16:07,913:INFO:Copying training dataset
2023-04-29 17:16:07,916:INFO:Defining folds
2023-04-29 17:16:07,916:INFO:Declaring metric variables
2023-04-29 17:16:07,916:INFO:Importing untrained model
2023-04-29 17:16:07,917:INFO:Least Angle Regression Imported successfully
2023-04-29 17:16:07,918:INFO:Starting cross validation
2023-04-29 17:16:07,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:08,039:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,043:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,061:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,067:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,082:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,097:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,107:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,118:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,846:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:08,859:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:11,895:INFO:Calculating mean and std
2023-04-29 17:16:11,895:INFO:Creating metrics dataframe
2023-04-29 17:16:12,372:INFO:Uploading results into container
2023-04-29 17:16:12,373:INFO:Uploading model into container now
2023-04-29 17:16:12,373:INFO:_master_model_container: 5
2023-04-29 17:16:12,373:INFO:_display_container: 2
2023-04-29 17:16:12,373:INFO:Lars(random_state=4632)
2023-04-29 17:16:12,373:INFO:create_model() successfully completed......................................
2023-04-29 17:16:12,513:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:12,513:INFO:Creating metrics dataframe
2023-04-29 17:16:12,525:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:16:12,526:INFO:Total runtime is 0.3731544613838196 minutes
2023-04-29 17:16:12,526:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:12,527:INFO:Initializing create_model()
2023-04-29 17:16:12,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:12,528:INFO:Checking exceptions
2023-04-29 17:16:12,528:INFO:Importing libraries
2023-04-29 17:16:12,528:INFO:Copying training dataset
2023-04-29 17:16:12,535:INFO:Defining folds
2023-04-29 17:16:12,535:INFO:Declaring metric variables
2023-04-29 17:16:12,535:INFO:Importing untrained model
2023-04-29 17:16:12,536:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:16:12,537:INFO:Starting cross validation
2023-04-29 17:16:12,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:12,638:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,651:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,666:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,675:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,702:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,702:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,715:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:12,728:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:13,415:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:13,468:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:16:16,312:INFO:Calculating mean and std
2023-04-29 17:16:16,313:INFO:Creating metrics dataframe
2023-04-29 17:16:17,076:INFO:Uploading results into container
2023-04-29 17:16:17,077:INFO:Uploading model into container now
2023-04-29 17:16:17,077:INFO:_master_model_container: 6
2023-04-29 17:16:17,078:INFO:_display_container: 2
2023-04-29 17:16:17,078:INFO:LassoLars(random_state=4632)
2023-04-29 17:16:17,078:INFO:create_model() successfully completed......................................
2023-04-29 17:16:17,205:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:17,205:INFO:Creating metrics dataframe
2023-04-29 17:16:17,208:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:16:17,208:INFO:Total runtime is 0.45119853417078654 minutes
2023-04-29 17:16:17,209:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:17,209:INFO:Initializing create_model()
2023-04-29 17:16:17,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:17,209:INFO:Checking exceptions
2023-04-29 17:16:17,209:INFO:Importing libraries
2023-04-29 17:16:17,209:INFO:Copying training dataset
2023-04-29 17:16:17,212:INFO:Defining folds
2023-04-29 17:16:17,213:INFO:Declaring metric variables
2023-04-29 17:16:17,213:INFO:Importing untrained model
2023-04-29 17:16:17,214:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:16:17,216:INFO:Starting cross validation
2023-04-29 17:16:17,217:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:17,303:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,314:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,324:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,338:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,346:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,362:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,380:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:17,389:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:18,121:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:18,124:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:16:20,970:INFO:Calculating mean and std
2023-04-29 17:16:20,972:INFO:Creating metrics dataframe
2023-04-29 17:16:21,807:INFO:Uploading results into container
2023-04-29 17:16:21,809:INFO:Uploading model into container now
2023-04-29 17:16:21,810:INFO:_master_model_container: 7
2023-04-29 17:16:21,810:INFO:_display_container: 2
2023-04-29 17:16:21,810:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:16:21,811:INFO:create_model() successfully completed......................................
2023-04-29 17:16:21,957:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:21,958:INFO:Creating metrics dataframe
2023-04-29 17:16:21,971:INFO:Initializing Bayesian Ridge
2023-04-29 17:16:21,971:INFO:Total runtime is 0.5305662910143534 minutes
2023-04-29 17:16:21,971:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:21,972:INFO:Initializing create_model()
2023-04-29 17:16:21,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:21,972:INFO:Checking exceptions
2023-04-29 17:16:21,972:INFO:Importing libraries
2023-04-29 17:16:21,972:INFO:Copying training dataset
2023-04-29 17:16:21,979:INFO:Defining folds
2023-04-29 17:16:21,979:INFO:Declaring metric variables
2023-04-29 17:16:21,979:INFO:Importing untrained model
2023-04-29 17:16:21,980:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:16:21,980:INFO:Starting cross validation
2023-04-29 17:16:21,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:25,923:INFO:Calculating mean and std
2023-04-29 17:16:25,923:INFO:Creating metrics dataframe
2023-04-29 17:16:26,849:INFO:Uploading results into container
2023-04-29 17:16:26,851:INFO:Uploading model into container now
2023-04-29 17:16:26,851:INFO:_master_model_container: 8
2023-04-29 17:16:26,852:INFO:_display_container: 2
2023-04-29 17:16:26,852:INFO:BayesianRidge()
2023-04-29 17:16:26,852:INFO:create_model() successfully completed......................................
2023-04-29 17:16:26,982:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:26,983:INFO:Creating metrics dataframe
2023-04-29 17:16:26,987:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:16:26,987:INFO:Total runtime is 0.6141696373621622 minutes
2023-04-29 17:16:26,988:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:26,988:INFO:Initializing create_model()
2023-04-29 17:16:26,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:26,988:INFO:Checking exceptions
2023-04-29 17:16:26,988:INFO:Importing libraries
2023-04-29 17:16:26,988:INFO:Copying training dataset
2023-04-29 17:16:26,992:INFO:Defining folds
2023-04-29 17:16:26,992:INFO:Declaring metric variables
2023-04-29 17:16:26,993:INFO:Importing untrained model
2023-04-29 17:16:26,993:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:16:26,994:INFO:Starting cross validation
2023-04-29 17:16:26,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:30,872:INFO:Calculating mean and std
2023-04-29 17:16:30,873:INFO:Creating metrics dataframe
2023-04-29 17:16:31,698:INFO:Uploading results into container
2023-04-29 17:16:31,699:INFO:Uploading model into container now
2023-04-29 17:16:31,700:INFO:_master_model_container: 9
2023-04-29 17:16:31,700:INFO:_display_container: 2
2023-04-29 17:16:31,701:INFO:PassiveAggressiveRegressor(random_state=4632)
2023-04-29 17:16:31,701:INFO:create_model() successfully completed......................................
2023-04-29 17:16:31,813:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:31,814:INFO:Creating metrics dataframe
2023-04-29 17:16:31,818:INFO:Initializing Huber Regressor
2023-04-29 17:16:31,818:INFO:Total runtime is 0.6946946779886881 minutes
2023-04-29 17:16:31,818:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:31,819:INFO:Initializing create_model()
2023-04-29 17:16:31,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:31,819:INFO:Checking exceptions
2023-04-29 17:16:31,819:INFO:Importing libraries
2023-04-29 17:16:31,819:INFO:Copying training dataset
2023-04-29 17:16:31,823:INFO:Defining folds
2023-04-29 17:16:31,823:INFO:Declaring metric variables
2023-04-29 17:16:31,824:INFO:Importing untrained model
2023-04-29 17:16:31,824:INFO:Huber Regressor Imported successfully
2023-04-29 17:16:31,824:INFO:Starting cross validation
2023-04-29 17:16:31,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:35,821:INFO:Calculating mean and std
2023-04-29 17:16:35,822:INFO:Creating metrics dataframe
2023-04-29 17:16:36,726:INFO:Uploading results into container
2023-04-29 17:16:36,727:INFO:Uploading model into container now
2023-04-29 17:16:36,728:INFO:_master_model_container: 10
2023-04-29 17:16:36,728:INFO:_display_container: 2
2023-04-29 17:16:36,728:INFO:HuberRegressor()
2023-04-29 17:16:36,728:INFO:create_model() successfully completed......................................
2023-04-29 17:16:36,858:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:36,858:INFO:Creating metrics dataframe
2023-04-29 17:16:36,862:INFO:Initializing K Neighbors Regressor
2023-04-29 17:16:36,863:INFO:Total runtime is 0.7787773132324218 minutes
2023-04-29 17:16:36,863:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:36,863:INFO:Initializing create_model()
2023-04-29 17:16:36,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:36,863:INFO:Checking exceptions
2023-04-29 17:16:36,863:INFO:Importing libraries
2023-04-29 17:16:36,863:INFO:Copying training dataset
2023-04-29 17:16:36,867:INFO:Defining folds
2023-04-29 17:16:36,867:INFO:Declaring metric variables
2023-04-29 17:16:36,867:INFO:Importing untrained model
2023-04-29 17:16:36,868:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:16:36,868:INFO:Starting cross validation
2023-04-29 17:16:36,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:41,349:INFO:Calculating mean and std
2023-04-29 17:16:41,349:INFO:Creating metrics dataframe
2023-04-29 17:16:42,105:INFO:Uploading results into container
2023-04-29 17:16:42,105:INFO:Uploading model into container now
2023-04-29 17:16:42,106:INFO:_master_model_container: 11
2023-04-29 17:16:42,106:INFO:_display_container: 2
2023-04-29 17:16:42,107:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:16:42,107:INFO:create_model() successfully completed......................................
2023-04-29 17:16:42,251:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:42,252:INFO:Creating metrics dataframe
2023-04-29 17:16:42,255:INFO:Initializing Decision Tree Regressor
2023-04-29 17:16:42,256:INFO:Total runtime is 0.8686479608217874 minutes
2023-04-29 17:16:42,256:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:42,256:INFO:Initializing create_model()
2023-04-29 17:16:42,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:42,256:INFO:Checking exceptions
2023-04-29 17:16:42,256:INFO:Importing libraries
2023-04-29 17:16:42,256:INFO:Copying training dataset
2023-04-29 17:16:42,260:INFO:Defining folds
2023-04-29 17:16:42,260:INFO:Declaring metric variables
2023-04-29 17:16:42,262:INFO:Importing untrained model
2023-04-29 17:16:42,263:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:16:42,263:INFO:Starting cross validation
2023-04-29 17:16:42,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:46,418:INFO:Calculating mean and std
2023-04-29 17:16:46,419:INFO:Creating metrics dataframe
2023-04-29 17:16:47,138:INFO:Uploading results into container
2023-04-29 17:16:47,138:INFO:Uploading model into container now
2023-04-29 17:16:47,139:INFO:_master_model_container: 12
2023-04-29 17:16:47,139:INFO:_display_container: 2
2023-04-29 17:16:47,140:INFO:DecisionTreeRegressor(random_state=4632)
2023-04-29 17:16:47,140:INFO:create_model() successfully completed......................................
2023-04-29 17:16:47,261:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:47,261:INFO:Creating metrics dataframe
2023-04-29 17:16:47,265:INFO:Initializing Random Forest Regressor
2023-04-29 17:16:47,265:INFO:Total runtime is 0.952147082487742 minutes
2023-04-29 17:16:47,265:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:47,265:INFO:Initializing create_model()
2023-04-29 17:16:47,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:47,265:INFO:Checking exceptions
2023-04-29 17:16:47,265:INFO:Importing libraries
2023-04-29 17:16:47,265:INFO:Copying training dataset
2023-04-29 17:16:47,268:INFO:Defining folds
2023-04-29 17:16:47,269:INFO:Declaring metric variables
2023-04-29 17:16:47,269:INFO:Importing untrained model
2023-04-29 17:16:47,269:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:16:47,270:INFO:Starting cross validation
2023-04-29 17:16:47,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:52,235:INFO:Calculating mean and std
2023-04-29 17:16:52,237:INFO:Creating metrics dataframe
2023-04-29 17:16:52,665:INFO:Uploading results into container
2023-04-29 17:16:52,666:INFO:Uploading model into container now
2023-04-29 17:16:52,666:INFO:_master_model_container: 13
2023-04-29 17:16:52,666:INFO:_display_container: 2
2023-04-29 17:16:52,666:INFO:RandomForestRegressor(n_jobs=-1, random_state=4632)
2023-04-29 17:16:52,666:INFO:create_model() successfully completed......................................
2023-04-29 17:16:52,799:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:52,799:INFO:Creating metrics dataframe
2023-04-29 17:16:52,803:INFO:Initializing Extra Trees Regressor
2023-04-29 17:16:52,803:INFO:Total runtime is 1.0444456934928894 minutes
2023-04-29 17:16:52,803:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:52,803:INFO:Initializing create_model()
2023-04-29 17:16:52,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:52,804:INFO:Checking exceptions
2023-04-29 17:16:52,804:INFO:Importing libraries
2023-04-29 17:16:52,804:INFO:Copying training dataset
2023-04-29 17:16:52,807:INFO:Defining folds
2023-04-29 17:16:52,808:INFO:Declaring metric variables
2023-04-29 17:16:52,808:INFO:Importing untrained model
2023-04-29 17:16:52,808:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:16:52,809:INFO:Starting cross validation
2023-04-29 17:16:52,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:16:57,920:INFO:Calculating mean and std
2023-04-29 17:16:57,921:INFO:Creating metrics dataframe
2023-04-29 17:16:58,352:INFO:Uploading results into container
2023-04-29 17:16:58,352:INFO:Uploading model into container now
2023-04-29 17:16:58,353:INFO:_master_model_container: 14
2023-04-29 17:16:58,353:INFO:_display_container: 2
2023-04-29 17:16:58,353:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4632)
2023-04-29 17:16:58,353:INFO:create_model() successfully completed......................................
2023-04-29 17:16:58,493:INFO:SubProcess create_model() end ==================================
2023-04-29 17:16:58,494:INFO:Creating metrics dataframe
2023-04-29 17:16:58,500:INFO:Initializing AdaBoost Regressor
2023-04-29 17:16:58,501:INFO:Total runtime is 1.1394136746724446 minutes
2023-04-29 17:16:58,501:INFO:SubProcess create_model() called ==================================
2023-04-29 17:16:58,501:INFO:Initializing create_model()
2023-04-29 17:16:58,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:16:58,501:INFO:Checking exceptions
2023-04-29 17:16:58,501:INFO:Importing libraries
2023-04-29 17:16:58,501:INFO:Copying training dataset
2023-04-29 17:16:58,506:INFO:Defining folds
2023-04-29 17:16:58,506:INFO:Declaring metric variables
2023-04-29 17:16:58,507:INFO:Importing untrained model
2023-04-29 17:16:58,508:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:16:58,508:INFO:Starting cross validation
2023-04-29 17:16:58,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:17:03,367:INFO:Calculating mean and std
2023-04-29 17:17:03,368:INFO:Creating metrics dataframe
2023-04-29 17:17:03,825:INFO:Uploading results into container
2023-04-29 17:17:03,825:INFO:Uploading model into container now
2023-04-29 17:17:03,826:INFO:_master_model_container: 15
2023-04-29 17:17:03,826:INFO:_display_container: 2
2023-04-29 17:17:03,826:INFO:AdaBoostRegressor(random_state=4632)
2023-04-29 17:17:03,826:INFO:create_model() successfully completed......................................
2023-04-29 17:17:03,949:INFO:SubProcess create_model() end ==================================
2023-04-29 17:17:03,949:INFO:Creating metrics dataframe
2023-04-29 17:17:03,953:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:17:03,953:INFO:Total runtime is 1.2302737832069397 minutes
2023-04-29 17:17:03,953:INFO:SubProcess create_model() called ==================================
2023-04-29 17:17:03,953:INFO:Initializing create_model()
2023-04-29 17:17:03,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:17:03,953:INFO:Checking exceptions
2023-04-29 17:17:03,954:INFO:Importing libraries
2023-04-29 17:17:03,954:INFO:Copying training dataset
2023-04-29 17:17:03,957:INFO:Defining folds
2023-04-29 17:17:03,957:INFO:Declaring metric variables
2023-04-29 17:17:03,957:INFO:Importing untrained model
2023-04-29 17:17:03,958:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:17:03,959:INFO:Starting cross validation
2023-04-29 17:17:03,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:17:08,764:INFO:Calculating mean and std
2023-04-29 17:17:08,765:INFO:Creating metrics dataframe
2023-04-29 17:17:09,219:INFO:Uploading results into container
2023-04-29 17:17:09,219:INFO:Uploading model into container now
2023-04-29 17:17:09,220:INFO:_master_model_container: 16
2023-04-29 17:17:09,220:INFO:_display_container: 2
2023-04-29 17:17:09,220:INFO:GradientBoostingRegressor(random_state=4632)
2023-04-29 17:17:09,220:INFO:create_model() successfully completed......................................
2023-04-29 17:17:09,375:INFO:SubProcess create_model() end ==================================
2023-04-29 17:17:09,375:INFO:Creating metrics dataframe
2023-04-29 17:17:09,380:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:17:09,380:INFO:Total runtime is 1.3207315921783447 minutes
2023-04-29 17:17:09,380:INFO:SubProcess create_model() called ==================================
2023-04-29 17:17:09,380:INFO:Initializing create_model()
2023-04-29 17:17:09,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:17:09,380:INFO:Checking exceptions
2023-04-29 17:17:09,380:INFO:Importing libraries
2023-04-29 17:17:09,380:INFO:Copying training dataset
2023-04-29 17:17:09,383:INFO:Defining folds
2023-04-29 17:17:09,383:INFO:Declaring metric variables
2023-04-29 17:17:09,384:INFO:Importing untrained model
2023-04-29 17:17:09,385:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:17:09,385:INFO:Starting cross validation
2023-04-29 17:17:09,385:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:17:13,841:INFO:Calculating mean and std
2023-04-29 17:17:13,842:INFO:Creating metrics dataframe
2023-04-29 17:17:14,301:INFO:Uploading results into container
2023-04-29 17:17:14,302:INFO:Uploading model into container now
2023-04-29 17:17:14,302:INFO:_master_model_container: 17
2023-04-29 17:17:14,303:INFO:_display_container: 2
2023-04-29 17:17:14,304:INFO:LGBMRegressor(random_state=4632)
2023-04-29 17:17:14,304:INFO:create_model() successfully completed......................................
2023-04-29 17:17:14,427:INFO:SubProcess create_model() end ==================================
2023-04-29 17:17:14,428:INFO:Creating metrics dataframe
2023-04-29 17:17:14,433:INFO:Initializing Dummy Regressor
2023-04-29 17:17:14,433:INFO:Total runtime is 1.404946478207906 minutes
2023-04-29 17:17:14,433:INFO:SubProcess create_model() called ==================================
2023-04-29 17:17:14,434:INFO:Initializing create_model()
2023-04-29 17:17:14,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E0E9A0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:17:14,434:INFO:Checking exceptions
2023-04-29 17:17:14,434:INFO:Importing libraries
2023-04-29 17:17:14,434:INFO:Copying training dataset
2023-04-29 17:17:14,438:INFO:Defining folds
2023-04-29 17:17:14,438:INFO:Declaring metric variables
2023-04-29 17:17:14,438:INFO:Importing untrained model
2023-04-29 17:17:14,438:INFO:Dummy Regressor Imported successfully
2023-04-29 17:17:14,439:INFO:Starting cross validation
2023-04-29 17:17:14,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:17:18,711:INFO:Calculating mean and std
2023-04-29 17:17:18,712:INFO:Creating metrics dataframe
2023-04-29 17:17:19,148:INFO:Uploading results into container
2023-04-29 17:17:19,149:INFO:Uploading model into container now
2023-04-29 17:17:19,149:INFO:_master_model_container: 18
2023-04-29 17:17:19,149:INFO:_display_container: 2
2023-04-29 17:17:19,150:INFO:DummyRegressor()
2023-04-29 17:17:19,150:INFO:create_model() successfully completed......................................
2023-04-29 17:17:19,277:INFO:SubProcess create_model() end ==================================
2023-04-29 17:17:19,277:INFO:Creating metrics dataframe
2023-04-29 17:17:19,287:INFO:Initializing create_model()
2023-04-29 17:17:19,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4632), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:17:19,287:INFO:Checking exceptions
2023-04-29 17:17:19,287:INFO:Importing libraries
2023-04-29 17:17:19,287:INFO:Copying training dataset
2023-04-29 17:17:19,290:INFO:Defining folds
2023-04-29 17:17:19,290:INFO:Declaring metric variables
2023-04-29 17:17:19,290:INFO:Importing untrained model
2023-04-29 17:17:19,290:INFO:Declaring custom model
2023-04-29 17:17:19,290:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:17:19,291:INFO:Cross validation set to False
2023-04-29 17:17:19,291:INFO:Fitting Model
2023-04-29 17:17:20,035:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4632)
2023-04-29 17:17:20,035:INFO:create_model() successfully completed......................................
2023-04-29 17:17:20,186:INFO:_master_model_container: 18
2023-04-29 17:17:20,186:INFO:_display_container: 2
2023-04-29 17:17:20,187:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4632)
2023-04-29 17:17:20,188:INFO:compare_models() successfully completed......................................
2023-04-29 17:17:20,193:INFO:Initializing predict_model()
2023-04-29 17:17:20,194:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B79D7E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4632), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B8D75D30>)
2023-04-29 17:17:20,194:INFO:Checking exceptions
2023-04-29 17:17:20,194:INFO:Preloading libraries
2023-04-29 17:17:20,195:INFO:Set up data.
2023-04-29 17:17:20,208:INFO:Set up index.
2023-04-29 17:19:28,891:INFO:PyCaret RegressionExperiment
2023-04-29 17:19:28,891:INFO:Logging name: reg-default-name
2023-04-29 17:19:28,892:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:19:28,892:INFO:version 3.0.0
2023-04-29 17:19:28,892:INFO:Initializing setup()
2023-04-29 17:19:28,892:INFO:self.USI: 83da
2023-04-29 17:19:28,892:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:19:28,892:INFO:Checking environment
2023-04-29 17:19:28,892:INFO:python_version: 3.9.13
2023-04-29 17:19:28,892:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:19:28,892:INFO:machine: AMD64
2023-04-29 17:19:28,892:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:19:28,892:INFO:Memory: svmem(total=16935899136, available=5914214400, percent=65.1, used=11021684736, free=5914214400)
2023-04-29 17:19:28,892:INFO:Physical Core: 4
2023-04-29 17:19:28,893:INFO:Logical Core: 8
2023-04-29 17:19:28,893:INFO:Checking libraries
2023-04-29 17:19:28,893:INFO:System:
2023-04-29 17:19:28,893:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:19:28,893:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:19:28,893:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:19:28,893:INFO:PyCaret required dependencies:
2023-04-29 17:19:28,893:INFO:                 pip: 22.2.2
2023-04-29 17:19:28,893:INFO:          setuptools: 63.4.1
2023-04-29 17:19:28,893:INFO:             pycaret: 3.0.0
2023-04-29 17:19:28,893:INFO:             IPython: 7.31.1
2023-04-29 17:19:28,893:INFO:          ipywidgets: 7.6.5
2023-04-29 17:19:28,893:INFO:                tqdm: 4.64.1
2023-04-29 17:19:28,893:INFO:               numpy: 1.21.5
2023-04-29 17:19:28,893:INFO:              pandas: 1.4.4
2023-04-29 17:19:28,893:INFO:              jinja2: 2.11.3
2023-04-29 17:19:28,893:INFO:               scipy: 1.9.1
2023-04-29 17:19:28,893:INFO:              joblib: 1.2.0
2023-04-29 17:19:28,893:INFO:             sklearn: 1.0.2
2023-04-29 17:19:28,893:INFO:                pyod: 1.0.9
2023-04-29 17:19:28,893:INFO:            imblearn: 0.10.1
2023-04-29 17:19:28,893:INFO:   category_encoders: 2.6.0
2023-04-29 17:19:28,893:INFO:            lightgbm: 3.3.5
2023-04-29 17:19:28,893:INFO:               numba: 0.55.1
2023-04-29 17:19:28,893:INFO:            requests: 2.28.1
2023-04-29 17:19:28,893:INFO:          matplotlib: 3.5.2
2023-04-29 17:19:28,893:INFO:          scikitplot: 0.3.7
2023-04-29 17:19:28,893:INFO:         yellowbrick: 1.5
2023-04-29 17:19:28,893:INFO:              plotly: 5.9.0
2023-04-29 17:19:28,893:INFO:             kaleido: 0.2.1
2023-04-29 17:19:28,893:INFO:         statsmodels: 0.13.2
2023-04-29 17:19:28,894:INFO:              sktime: 0.17.1
2023-04-29 17:19:28,894:INFO:               tbats: 1.1.2
2023-04-29 17:19:28,894:INFO:            pmdarima: 2.0.3
2023-04-29 17:19:28,894:INFO:              psutil: 5.9.0
2023-04-29 17:19:28,894:INFO:PyCaret optional dependencies:
2023-04-29 17:19:28,894:INFO:                shap: 0.41.0
2023-04-29 17:19:28,894:INFO:           interpret: Not installed
2023-04-29 17:19:28,894:INFO:                umap: Not installed
2023-04-29 17:19:28,894:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:19:28,894:INFO:  explainerdashboard: Not installed
2023-04-29 17:19:28,894:INFO:             autoviz: Not installed
2023-04-29 17:19:28,894:INFO:           fairlearn: Not installed
2023-04-29 17:19:28,894:INFO:             xgboost: Not installed
2023-04-29 17:19:28,895:INFO:            catboost: Not installed
2023-04-29 17:19:28,895:INFO:              kmodes: Not installed
2023-04-29 17:19:28,895:INFO:             mlxtend: Not installed
2023-04-29 17:19:28,895:INFO:       statsforecast: Not installed
2023-04-29 17:19:28,895:INFO:        tune_sklearn: Not installed
2023-04-29 17:19:28,895:INFO:                 ray: Not installed
2023-04-29 17:19:28,895:INFO:            hyperopt: Not installed
2023-04-29 17:19:28,895:INFO:              optuna: Not installed
2023-04-29 17:19:28,895:INFO:               skopt: Not installed
2023-04-29 17:19:28,895:INFO:              mlflow: 2.2.1
2023-04-29 17:19:28,895:INFO:              gradio: Not installed
2023-04-29 17:19:28,895:INFO:             fastapi: Not installed
2023-04-29 17:19:28,895:INFO:             uvicorn: Not installed
2023-04-29 17:19:28,895:INFO:              m2cgen: Not installed
2023-04-29 17:19:28,895:INFO:           evidently: Not installed
2023-04-29 17:19:28,895:INFO:               fugue: Not installed
2023-04-29 17:19:28,895:INFO:           streamlit: 1.21.0
2023-04-29 17:19:28,895:INFO:             prophet: Not installed
2023-04-29 17:19:28,895:INFO:None
2023-04-29 17:19:28,895:INFO:Set up data.
2023-04-29 17:19:28,899:INFO:Set up train/test split.
2023-04-29 17:19:28,901:INFO:Set up index.
2023-04-29 17:19:28,901:INFO:Set up folding strategy.
2023-04-29 17:19:28,901:INFO:Assigning column types.
2023-04-29 17:19:28,903:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:19:28,903:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:19:28,907:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:19:28,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:19:28,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,023:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,027:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,127:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:19:29,133:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,245:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,249:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,356:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:19:29,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,477:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,574:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:19:29,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,792:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:19:29,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:29,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:29,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:19:30,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,004:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:19:30,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,223:INFO:Preparing preprocessing pipeline...
2023-04-29 17:19:30,223:INFO:Set up simple imputation.
2023-04-29 17:19:30,224:INFO:Set up column name cleaning.
2023-04-29 17:19:30,241:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:19:30,245:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:19:30,245:INFO:Creating final display dataframe.
2023-04-29 17:19:30,306:INFO:Setup _display_container:                     Description             Value
0                    Session id              8554
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              83da
2023-04-29 17:19:30,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:19:30,529:INFO:setup() successfully completed in 1.92s...............
2023-04-29 17:19:30,534:INFO:Initializing compare_models()
2023-04-29 17:19:30,534:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:19:30,534:INFO:Checking exceptions
2023-04-29 17:19:30,536:INFO:Preparing display monitor
2023-04-29 17:19:30,541:INFO:Initializing Linear Regression
2023-04-29 17:19:30,542:INFO:Total runtime is 1.5997886657714842e-05 minutes
2023-04-29 17:19:30,542:INFO:SubProcess create_model() called ==================================
2023-04-29 17:19:30,542:INFO:Initializing create_model()
2023-04-29 17:19:30,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:19:30,542:INFO:Checking exceptions
2023-04-29 17:19:30,542:INFO:Importing libraries
2023-04-29 17:19:30,542:INFO:Copying training dataset
2023-04-29 17:19:30,548:INFO:Defining folds
2023-04-29 17:19:30,548:INFO:Declaring metric variables
2023-04-29 17:19:30,548:INFO:Importing untrained model
2023-04-29 17:19:30,549:INFO:Linear Regression Imported successfully
2023-04-29 17:19:30,549:INFO:Starting cross validation
2023-04-29 17:19:30,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:19:34,816:INFO:Calculating mean and std
2023-04-29 17:19:34,818:INFO:Creating metrics dataframe
2023-04-29 17:19:35,588:INFO:Uploading results into container
2023-04-29 17:19:35,589:INFO:Uploading model into container now
2023-04-29 17:19:35,589:INFO:_master_model_container: 1
2023-04-29 17:19:35,590:INFO:_display_container: 2
2023-04-29 17:19:35,590:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:19:35,590:INFO:create_model() successfully completed......................................
2023-04-29 17:19:35,735:INFO:SubProcess create_model() end ==================================
2023-04-29 17:19:35,735:INFO:Creating metrics dataframe
2023-04-29 17:19:35,742:INFO:Initializing Lasso Regression
2023-04-29 17:19:35,743:INFO:Total runtime is 0.08670332034428914 minutes
2023-04-29 17:19:35,743:INFO:SubProcess create_model() called ==================================
2023-04-29 17:19:35,744:INFO:Initializing create_model()
2023-04-29 17:19:35,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:19:35,744:INFO:Checking exceptions
2023-04-29 17:19:35,744:INFO:Importing libraries
2023-04-29 17:19:35,745:INFO:Copying training dataset
2023-04-29 17:19:35,753:INFO:Defining folds
2023-04-29 17:19:35,754:INFO:Declaring metric variables
2023-04-29 17:19:35,754:INFO:Importing untrained model
2023-04-29 17:19:35,754:INFO:Lasso Regression Imported successfully
2023-04-29 17:19:35,755:INFO:Starting cross validation
2023-04-29 17:19:35,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:19:40,821:INFO:Calculating mean and std
2023-04-29 17:19:40,823:INFO:Creating metrics dataframe
2023-04-29 17:19:41,495:INFO:Uploading results into container
2023-04-29 17:19:41,495:INFO:Uploading model into container now
2023-04-29 17:19:41,496:INFO:_master_model_container: 2
2023-04-29 17:19:41,496:INFO:_display_container: 2
2023-04-29 17:19:41,496:INFO:Lasso(random_state=8554)
2023-04-29 17:19:41,496:INFO:create_model() successfully completed......................................
2023-04-29 17:19:41,651:INFO:SubProcess create_model() end ==================================
2023-04-29 17:19:41,652:INFO:Creating metrics dataframe
2023-04-29 17:19:41,663:INFO:Initializing Ridge Regression
2023-04-29 17:19:41,663:INFO:Total runtime is 0.18536413908004762 minutes
2023-04-29 17:19:41,664:INFO:SubProcess create_model() called ==================================
2023-04-29 17:19:41,665:INFO:Initializing create_model()
2023-04-29 17:19:41,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:19:41,665:INFO:Checking exceptions
2023-04-29 17:19:41,666:INFO:Importing libraries
2023-04-29 17:19:41,666:INFO:Copying training dataset
2023-04-29 17:19:41,676:INFO:Defining folds
2023-04-29 17:19:41,676:INFO:Declaring metric variables
2023-04-29 17:19:41,676:INFO:Importing untrained model
2023-04-29 17:19:41,677:INFO:Ridge Regression Imported successfully
2023-04-29 17:19:41,678:INFO:Starting cross validation
2023-04-29 17:19:41,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:19:46,708:INFO:Calculating mean and std
2023-04-29 17:19:46,710:INFO:Creating metrics dataframe
2023-04-29 17:19:47,311:INFO:Uploading results into container
2023-04-29 17:19:47,312:INFO:Uploading model into container now
2023-04-29 17:19:47,312:INFO:_master_model_container: 3
2023-04-29 17:19:47,312:INFO:_display_container: 2
2023-04-29 17:19:47,313:INFO:Ridge(random_state=8554)
2023-04-29 17:19:47,313:INFO:create_model() successfully completed......................................
2023-04-29 17:19:47,460:INFO:SubProcess create_model() end ==================================
2023-04-29 17:19:47,461:INFO:Creating metrics dataframe
2023-04-29 17:19:47,470:INFO:Initializing Elastic Net
2023-04-29 17:19:47,470:INFO:Total runtime is 0.2821468114852905 minutes
2023-04-29 17:19:47,470:INFO:SubProcess create_model() called ==================================
2023-04-29 17:19:47,471:INFO:Initializing create_model()
2023-04-29 17:19:47,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:19:47,471:INFO:Checking exceptions
2023-04-29 17:19:47,471:INFO:Importing libraries
2023-04-29 17:19:47,471:INFO:Copying training dataset
2023-04-29 17:19:47,479:INFO:Defining folds
2023-04-29 17:19:47,479:INFO:Declaring metric variables
2023-04-29 17:19:47,480:INFO:Importing untrained model
2023-04-29 17:19:47,480:INFO:Elastic Net Imported successfully
2023-04-29 17:19:47,480:INFO:Starting cross validation
2023-04-29 17:19:47,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:19:52,370:INFO:Calculating mean and std
2023-04-29 17:19:52,371:INFO:Creating metrics dataframe
2023-04-29 17:19:52,843:INFO:Uploading results into container
2023-04-29 17:19:52,844:INFO:Uploading model into container now
2023-04-29 17:19:52,845:INFO:_master_model_container: 4
2023-04-29 17:19:52,845:INFO:_display_container: 2
2023-04-29 17:19:52,846:INFO:ElasticNet(random_state=8554)
2023-04-29 17:19:52,846:INFO:create_model() successfully completed......................................
2023-04-29 17:19:52,973:INFO:SubProcess create_model() end ==================================
2023-04-29 17:19:52,973:INFO:Creating metrics dataframe
2023-04-29 17:19:52,983:INFO:Initializing Least Angle Regression
2023-04-29 17:19:52,984:INFO:Total runtime is 0.3740483562151591 minutes
2023-04-29 17:19:52,984:INFO:SubProcess create_model() called ==================================
2023-04-29 17:19:52,984:INFO:Initializing create_model()
2023-04-29 17:19:52,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:19:52,984:INFO:Checking exceptions
2023-04-29 17:19:52,984:INFO:Importing libraries
2023-04-29 17:19:52,985:INFO:Copying training dataset
2023-04-29 17:19:52,995:INFO:Defining folds
2023-04-29 17:19:52,995:INFO:Declaring metric variables
2023-04-29 17:19:52,995:INFO:Importing untrained model
2023-04-29 17:19:52,996:INFO:Least Angle Regression Imported successfully
2023-04-29 17:19:52,996:INFO:Starting cross validation
2023-04-29 17:19:52,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:19:53,104:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,111:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,123:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,136:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,149:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,166:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,175:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:53,190:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:54,033:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:54,082:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:19:57,811:INFO:Calculating mean and std
2023-04-29 17:19:57,813:INFO:Creating metrics dataframe
2023-04-29 17:19:58,299:INFO:Uploading results into container
2023-04-29 17:19:58,300:INFO:Uploading model into container now
2023-04-29 17:19:58,301:INFO:_master_model_container: 5
2023-04-29 17:19:58,301:INFO:_display_container: 2
2023-04-29 17:19:58,302:INFO:Lars(random_state=8554)
2023-04-29 17:19:58,302:INFO:create_model() successfully completed......................................
2023-04-29 17:19:58,431:INFO:SubProcess create_model() end ==================================
2023-04-29 17:19:58,431:INFO:Creating metrics dataframe
2023-04-29 17:19:58,436:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:19:58,436:INFO:Total runtime is 0.4649142305056254 minutes
2023-04-29 17:19:58,436:INFO:SubProcess create_model() called ==================================
2023-04-29 17:19:58,436:INFO:Initializing create_model()
2023-04-29 17:19:58,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:19:58,436:INFO:Checking exceptions
2023-04-29 17:19:58,436:INFO:Importing libraries
2023-04-29 17:19:58,436:INFO:Copying training dataset
2023-04-29 17:19:58,440:INFO:Defining folds
2023-04-29 17:19:58,440:INFO:Declaring metric variables
2023-04-29 17:19:58,440:INFO:Importing untrained model
2023-04-29 17:19:58,440:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:19:58,441:INFO:Starting cross validation
2023-04-29 17:19:58,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:19:58,528:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,536:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,550:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,571:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,582:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,597:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,613:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:58,633:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:59,539:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:19:59,615:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:20:03,492:INFO:Calculating mean and std
2023-04-29 17:20:03,493:INFO:Creating metrics dataframe
2023-04-29 17:20:03,976:INFO:Uploading results into container
2023-04-29 17:20:03,977:INFO:Uploading model into container now
2023-04-29 17:20:03,977:INFO:_master_model_container: 6
2023-04-29 17:20:03,977:INFO:_display_container: 2
2023-04-29 17:20:03,978:INFO:LassoLars(random_state=8554)
2023-04-29 17:20:03,978:INFO:create_model() successfully completed......................................
2023-04-29 17:20:04,115:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:04,115:INFO:Creating metrics dataframe
2023-04-29 17:20:04,125:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:20:04,125:INFO:Total runtime is 0.5597305774688721 minutes
2023-04-29 17:20:04,125:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:04,126:INFO:Initializing create_model()
2023-04-29 17:20:04,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:04,126:INFO:Checking exceptions
2023-04-29 17:20:04,127:INFO:Importing libraries
2023-04-29 17:20:04,127:INFO:Copying training dataset
2023-04-29 17:20:04,136:INFO:Defining folds
2023-04-29 17:20:04,136:INFO:Declaring metric variables
2023-04-29 17:20:04,136:INFO:Importing untrained model
2023-04-29 17:20:04,137:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:20:04,137:INFO:Starting cross validation
2023-04-29 17:20:04,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:04,244:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,255:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,266:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,278:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,293:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,312:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,328:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:04,351:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:05,262:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:05,348:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:20:09,313:INFO:Calculating mean and std
2023-04-29 17:20:09,315:INFO:Creating metrics dataframe
2023-04-29 17:20:09,856:INFO:Uploading results into container
2023-04-29 17:20:09,857:INFO:Uploading model into container now
2023-04-29 17:20:09,858:INFO:_master_model_container: 7
2023-04-29 17:20:09,858:INFO:_display_container: 2
2023-04-29 17:20:09,858:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:20:09,858:INFO:create_model() successfully completed......................................
2023-04-29 17:20:10,010:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:10,010:INFO:Creating metrics dataframe
2023-04-29 17:20:10,015:INFO:Initializing Bayesian Ridge
2023-04-29 17:20:10,015:INFO:Total runtime is 0.6579054911931357 minutes
2023-04-29 17:20:10,015:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:10,015:INFO:Initializing create_model()
2023-04-29 17:20:10,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:10,016:INFO:Checking exceptions
2023-04-29 17:20:10,016:INFO:Importing libraries
2023-04-29 17:20:10,016:INFO:Copying training dataset
2023-04-29 17:20:10,019:INFO:Defining folds
2023-04-29 17:20:10,019:INFO:Declaring metric variables
2023-04-29 17:20:10,020:INFO:Importing untrained model
2023-04-29 17:20:10,020:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:20:10,020:INFO:Starting cross validation
2023-04-29 17:20:10,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:15,067:INFO:Calculating mean and std
2023-04-29 17:20:15,068:INFO:Creating metrics dataframe
2023-04-29 17:20:15,668:INFO:Uploading results into container
2023-04-29 17:20:15,669:INFO:Uploading model into container now
2023-04-29 17:20:15,669:INFO:_master_model_container: 8
2023-04-29 17:20:15,669:INFO:_display_container: 2
2023-04-29 17:20:15,670:INFO:BayesianRidge()
2023-04-29 17:20:15,670:INFO:create_model() successfully completed......................................
2023-04-29 17:20:15,823:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:15,824:INFO:Creating metrics dataframe
2023-04-29 17:20:15,828:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:20:15,829:INFO:Total runtime is 0.7547953327496848 minutes
2023-04-29 17:20:15,829:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:15,830:INFO:Initializing create_model()
2023-04-29 17:20:15,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:15,830:INFO:Checking exceptions
2023-04-29 17:20:15,831:INFO:Importing libraries
2023-04-29 17:20:15,831:INFO:Copying training dataset
2023-04-29 17:20:15,837:INFO:Defining folds
2023-04-29 17:20:15,837:INFO:Declaring metric variables
2023-04-29 17:20:15,838:INFO:Importing untrained model
2023-04-29 17:20:15,839:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:20:15,840:INFO:Starting cross validation
2023-04-29 17:20:15,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:20,605:INFO:Calculating mean and std
2023-04-29 17:20:20,607:INFO:Creating metrics dataframe
2023-04-29 17:20:21,248:INFO:Uploading results into container
2023-04-29 17:20:21,248:INFO:Uploading model into container now
2023-04-29 17:20:21,249:INFO:_master_model_container: 9
2023-04-29 17:20:21,249:INFO:_display_container: 2
2023-04-29 17:20:21,249:INFO:PassiveAggressiveRegressor(random_state=8554)
2023-04-29 17:20:21,249:INFO:create_model() successfully completed......................................
2023-04-29 17:20:21,400:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:21,400:INFO:Creating metrics dataframe
2023-04-29 17:20:21,420:INFO:Initializing Huber Regressor
2023-04-29 17:20:21,420:INFO:Total runtime is 0.8479780753453574 minutes
2023-04-29 17:20:21,421:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:21,421:INFO:Initializing create_model()
2023-04-29 17:20:21,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:21,422:INFO:Checking exceptions
2023-04-29 17:20:21,422:INFO:Importing libraries
2023-04-29 17:20:21,422:INFO:Copying training dataset
2023-04-29 17:20:21,429:INFO:Defining folds
2023-04-29 17:20:21,430:INFO:Declaring metric variables
2023-04-29 17:20:21,430:INFO:Importing untrained model
2023-04-29 17:20:21,431:INFO:Huber Regressor Imported successfully
2023-04-29 17:20:21,431:INFO:Starting cross validation
2023-04-29 17:20:21,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:26,530:INFO:Calculating mean and std
2023-04-29 17:20:26,531:INFO:Creating metrics dataframe
2023-04-29 17:20:27,379:INFO:Uploading results into container
2023-04-29 17:20:27,380:INFO:Uploading model into container now
2023-04-29 17:20:27,381:INFO:_master_model_container: 10
2023-04-29 17:20:27,381:INFO:_display_container: 2
2023-04-29 17:20:27,382:INFO:HuberRegressor()
2023-04-29 17:20:27,382:INFO:create_model() successfully completed......................................
2023-04-29 17:20:27,580:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:27,581:INFO:Creating metrics dataframe
2023-04-29 17:20:27,601:INFO:Initializing K Neighbors Regressor
2023-04-29 17:20:27,601:INFO:Total runtime is 0.9509951551755271 minutes
2023-04-29 17:20:27,602:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:27,603:INFO:Initializing create_model()
2023-04-29 17:20:27,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:27,604:INFO:Checking exceptions
2023-04-29 17:20:27,604:INFO:Importing libraries
2023-04-29 17:20:27,605:INFO:Copying training dataset
2023-04-29 17:20:27,620:INFO:Defining folds
2023-04-29 17:20:27,621:INFO:Declaring metric variables
2023-04-29 17:20:27,621:INFO:Importing untrained model
2023-04-29 17:20:27,623:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:20:27,624:INFO:Starting cross validation
2023-04-29 17:20:27,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:36,123:INFO:Calculating mean and std
2023-04-29 17:20:36,124:INFO:Creating metrics dataframe
2023-04-29 17:20:36,695:INFO:Uploading results into container
2023-04-29 17:20:36,695:INFO:Uploading model into container now
2023-04-29 17:20:36,696:INFO:_master_model_container: 11
2023-04-29 17:20:36,696:INFO:_display_container: 2
2023-04-29 17:20:36,696:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:20:36,696:INFO:create_model() successfully completed......................................
2023-04-29 17:20:36,867:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:36,867:INFO:Creating metrics dataframe
2023-04-29 17:20:36,878:INFO:Initializing Decision Tree Regressor
2023-04-29 17:20:36,878:INFO:Total runtime is 1.1056142648061118 minutes
2023-04-29 17:20:36,879:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:36,880:INFO:Initializing create_model()
2023-04-29 17:20:36,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:36,880:INFO:Checking exceptions
2023-04-29 17:20:36,880:INFO:Importing libraries
2023-04-29 17:20:36,880:INFO:Copying training dataset
2023-04-29 17:20:36,888:INFO:Defining folds
2023-04-29 17:20:36,888:INFO:Declaring metric variables
2023-04-29 17:20:36,888:INFO:Importing untrained model
2023-04-29 17:20:36,890:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:20:36,890:INFO:Starting cross validation
2023-04-29 17:20:36,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:42,307:INFO:Calculating mean and std
2023-04-29 17:20:42,308:INFO:Creating metrics dataframe
2023-04-29 17:20:42,812:INFO:Uploading results into container
2023-04-29 17:20:42,813:INFO:Uploading model into container now
2023-04-29 17:20:42,813:INFO:_master_model_container: 12
2023-04-29 17:20:42,813:INFO:_display_container: 2
2023-04-29 17:20:42,813:INFO:DecisionTreeRegressor(random_state=8554)
2023-04-29 17:20:42,814:INFO:create_model() successfully completed......................................
2023-04-29 17:20:42,955:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:42,955:INFO:Creating metrics dataframe
2023-04-29 17:20:42,960:INFO:Initializing Random Forest Regressor
2023-04-29 17:20:42,960:INFO:Total runtime is 1.206974263985952 minutes
2023-04-29 17:20:42,960:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:42,961:INFO:Initializing create_model()
2023-04-29 17:20:42,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:42,961:INFO:Checking exceptions
2023-04-29 17:20:42,961:INFO:Importing libraries
2023-04-29 17:20:42,961:INFO:Copying training dataset
2023-04-29 17:20:42,964:INFO:Defining folds
2023-04-29 17:20:42,964:INFO:Declaring metric variables
2023-04-29 17:20:42,965:INFO:Importing untrained model
2023-04-29 17:20:42,966:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:20:42,966:INFO:Starting cross validation
2023-04-29 17:20:42,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:20:49,756:INFO:Calculating mean and std
2023-04-29 17:20:49,757:INFO:Creating metrics dataframe
2023-04-29 17:20:50,373:INFO:Uploading results into container
2023-04-29 17:20:50,373:INFO:Uploading model into container now
2023-04-29 17:20:50,374:INFO:_master_model_container: 13
2023-04-29 17:20:50,374:INFO:_display_container: 2
2023-04-29 17:20:50,374:INFO:RandomForestRegressor(n_jobs=-1, random_state=8554)
2023-04-29 17:20:50,374:INFO:create_model() successfully completed......................................
2023-04-29 17:20:50,524:INFO:SubProcess create_model() end ==================================
2023-04-29 17:20:50,524:INFO:Creating metrics dataframe
2023-04-29 17:20:50,533:INFO:Initializing Extra Trees Regressor
2023-04-29 17:20:50,533:INFO:Total runtime is 1.33320582707723 minutes
2023-04-29 17:20:50,534:INFO:SubProcess create_model() called ==================================
2023-04-29 17:20:50,534:INFO:Initializing create_model()
2023-04-29 17:20:50,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:20:50,535:INFO:Checking exceptions
2023-04-29 17:20:50,535:INFO:Importing libraries
2023-04-29 17:20:50,535:INFO:Copying training dataset
2023-04-29 17:20:50,542:INFO:Defining folds
2023-04-29 17:20:50,543:INFO:Declaring metric variables
2023-04-29 17:20:50,543:INFO:Importing untrained model
2023-04-29 17:20:50,543:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:20:50,544:INFO:Starting cross validation
2023-04-29 17:20:50,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:21:04,036:INFO:Calculating mean and std
2023-04-29 17:21:04,038:INFO:Creating metrics dataframe
2023-04-29 17:21:05,066:INFO:Uploading results into container
2023-04-29 17:21:05,067:INFO:Uploading model into container now
2023-04-29 17:21:05,068:INFO:_master_model_container: 14
2023-04-29 17:21:05,069:INFO:_display_container: 2
2023-04-29 17:21:05,069:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8554)
2023-04-29 17:21:05,069:INFO:create_model() successfully completed......................................
2023-04-29 17:21:05,230:INFO:SubProcess create_model() end ==================================
2023-04-29 17:21:05,230:INFO:Creating metrics dataframe
2023-04-29 17:21:05,240:INFO:Initializing AdaBoost Regressor
2023-04-29 17:21:05,241:INFO:Total runtime is 1.5783290584882101 minutes
2023-04-29 17:21:05,241:INFO:SubProcess create_model() called ==================================
2023-04-29 17:21:05,242:INFO:Initializing create_model()
2023-04-29 17:21:05,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:21:05,243:INFO:Checking exceptions
2023-04-29 17:21:05,243:INFO:Importing libraries
2023-04-29 17:21:05,243:INFO:Copying training dataset
2023-04-29 17:21:05,255:INFO:Defining folds
2023-04-29 17:21:05,255:INFO:Declaring metric variables
2023-04-29 17:21:05,256:INFO:Importing untrained model
2023-04-29 17:21:05,256:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:21:05,256:INFO:Starting cross validation
2023-04-29 17:21:05,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:21:10,840:INFO:Calculating mean and std
2023-04-29 17:21:10,842:INFO:Creating metrics dataframe
2023-04-29 17:21:11,468:INFO:Uploading results into container
2023-04-29 17:21:11,469:INFO:Uploading model into container now
2023-04-29 17:21:11,469:INFO:_master_model_container: 15
2023-04-29 17:21:11,469:INFO:_display_container: 2
2023-04-29 17:21:11,469:INFO:AdaBoostRegressor(random_state=8554)
2023-04-29 17:21:11,469:INFO:create_model() successfully completed......................................
2023-04-29 17:21:11,616:INFO:SubProcess create_model() end ==================================
2023-04-29 17:21:11,616:INFO:Creating metrics dataframe
2023-04-29 17:21:11,623:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:21:11,623:INFO:Total runtime is 1.6846910119056702 minutes
2023-04-29 17:21:11,623:INFO:SubProcess create_model() called ==================================
2023-04-29 17:21:11,624:INFO:Initializing create_model()
2023-04-29 17:21:11,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:21:11,624:INFO:Checking exceptions
2023-04-29 17:21:11,624:INFO:Importing libraries
2023-04-29 17:21:11,624:INFO:Copying training dataset
2023-04-29 17:21:11,629:INFO:Defining folds
2023-04-29 17:21:11,629:INFO:Declaring metric variables
2023-04-29 17:21:11,629:INFO:Importing untrained model
2023-04-29 17:21:11,630:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:21:11,630:INFO:Starting cross validation
2023-04-29 17:21:11,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:21:17,924:INFO:Calculating mean and std
2023-04-29 17:21:17,925:INFO:Creating metrics dataframe
2023-04-29 17:21:18,593:INFO:Uploading results into container
2023-04-29 17:21:18,594:INFO:Uploading model into container now
2023-04-29 17:21:18,595:INFO:_master_model_container: 16
2023-04-29 17:21:18,595:INFO:_display_container: 2
2023-04-29 17:21:18,595:INFO:GradientBoostingRegressor(random_state=8554)
2023-04-29 17:21:18,595:INFO:create_model() successfully completed......................................
2023-04-29 17:21:18,745:INFO:SubProcess create_model() end ==================================
2023-04-29 17:21:18,745:INFO:Creating metrics dataframe
2023-04-29 17:21:18,754:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:21:18,755:INFO:Total runtime is 1.8035706241925558 minutes
2023-04-29 17:21:18,755:INFO:SubProcess create_model() called ==================================
2023-04-29 17:21:18,756:INFO:Initializing create_model()
2023-04-29 17:21:18,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:21:18,757:INFO:Checking exceptions
2023-04-29 17:21:18,757:INFO:Importing libraries
2023-04-29 17:21:18,757:INFO:Copying training dataset
2023-04-29 17:21:18,764:INFO:Defining folds
2023-04-29 17:21:18,765:INFO:Declaring metric variables
2023-04-29 17:21:18,765:INFO:Importing untrained model
2023-04-29 17:21:18,765:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:21:18,766:INFO:Starting cross validation
2023-04-29 17:21:18,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:21:25,911:INFO:Calculating mean and std
2023-04-29 17:21:25,912:INFO:Creating metrics dataframe
2023-04-29 17:21:26,745:INFO:Uploading results into container
2023-04-29 17:21:26,747:INFO:Uploading model into container now
2023-04-29 17:21:26,748:INFO:_master_model_container: 17
2023-04-29 17:21:26,748:INFO:_display_container: 2
2023-04-29 17:21:26,748:INFO:LGBMRegressor(random_state=8554)
2023-04-29 17:21:26,749:INFO:create_model() successfully completed......................................
2023-04-29 17:21:26,926:INFO:SubProcess create_model() end ==================================
2023-04-29 17:21:26,926:INFO:Creating metrics dataframe
2023-04-29 17:21:26,936:INFO:Initializing Dummy Regressor
2023-04-29 17:21:26,937:INFO:Total runtime is 1.9399250825246175 minutes
2023-04-29 17:21:26,937:INFO:SubProcess create_model() called ==================================
2023-04-29 17:21:26,937:INFO:Initializing create_model()
2023-04-29 17:21:26,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6DB84F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:21:26,937:INFO:Checking exceptions
2023-04-29 17:21:26,938:INFO:Importing libraries
2023-04-29 17:21:26,938:INFO:Copying training dataset
2023-04-29 17:21:26,941:INFO:Defining folds
2023-04-29 17:21:26,941:INFO:Declaring metric variables
2023-04-29 17:21:26,941:INFO:Importing untrained model
2023-04-29 17:21:26,941:INFO:Dummy Regressor Imported successfully
2023-04-29 17:21:26,942:INFO:Starting cross validation
2023-04-29 17:21:26,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:21:31,246:INFO:Calculating mean and std
2023-04-29 17:21:31,247:INFO:Creating metrics dataframe
2023-04-29 17:21:31,726:INFO:Uploading results into container
2023-04-29 17:21:31,727:INFO:Uploading model into container now
2023-04-29 17:21:31,728:INFO:_master_model_container: 18
2023-04-29 17:21:31,728:INFO:_display_container: 2
2023-04-29 17:21:31,728:INFO:DummyRegressor()
2023-04-29 17:21:31,728:INFO:create_model() successfully completed......................................
2023-04-29 17:21:31,823:INFO:SubProcess create_model() end ==================================
2023-04-29 17:21:31,823:INFO:Creating metrics dataframe
2023-04-29 17:21:31,829:INFO:Initializing create_model()
2023-04-29 17:21:31,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=RandomForestRegressor(n_jobs=-1, random_state=8554), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:21:31,829:INFO:Checking exceptions
2023-04-29 17:21:31,830:INFO:Importing libraries
2023-04-29 17:21:31,830:INFO:Copying training dataset
2023-04-29 17:21:31,835:INFO:Defining folds
2023-04-29 17:21:31,835:INFO:Declaring metric variables
2023-04-29 17:21:31,835:INFO:Importing untrained model
2023-04-29 17:21:31,835:INFO:Declaring custom model
2023-04-29 17:21:31,836:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:21:31,837:INFO:Cross validation set to False
2023-04-29 17:21:31,837:INFO:Fitting Model
2023-04-29 17:21:32,406:INFO:RandomForestRegressor(n_jobs=-1, random_state=8554)
2023-04-29 17:21:32,407:INFO:create_model() successfully completed......................................
2023-04-29 17:21:32,529:INFO:_master_model_container: 18
2023-04-29 17:21:32,530:INFO:_display_container: 2
2023-04-29 17:21:32,530:INFO:RandomForestRegressor(n_jobs=-1, random_state=8554)
2023-04-29 17:21:32,530:INFO:compare_models() successfully completed......................................
2023-04-29 17:21:32,535:INFO:Initializing predict_model()
2023-04-29 17:21:32,535:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6C14B20>, estimator=RandomForestRegressor(n_jobs=-1, random_state=8554), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B71A5160>)
2023-04-29 17:21:32,535:INFO:Checking exceptions
2023-04-29 17:21:32,535:INFO:Preloading libraries
2023-04-29 17:21:32,535:INFO:Set up data.
2023-04-29 17:21:32,539:INFO:Set up index.
2023-04-29 17:28:29,641:INFO:PyCaret RegressionExperiment
2023-04-29 17:28:29,642:INFO:Logging name: reg-default-name
2023-04-29 17:28:29,642:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:28:29,642:INFO:version 3.0.0
2023-04-29 17:28:29,642:INFO:Initializing setup()
2023-04-29 17:28:29,642:INFO:self.USI: e365
2023-04-29 17:28:29,642:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:28:29,642:INFO:Checking environment
2023-04-29 17:28:29,642:INFO:python_version: 3.9.13
2023-04-29 17:28:29,642:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:28:29,642:INFO:machine: AMD64
2023-04-29 17:28:29,642:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:28:29,642:INFO:Memory: svmem(total=16935899136, available=6872932352, percent=59.4, used=10062966784, free=6872932352)
2023-04-29 17:28:29,642:INFO:Physical Core: 4
2023-04-29 17:28:29,642:INFO:Logical Core: 8
2023-04-29 17:28:29,643:INFO:Checking libraries
2023-04-29 17:28:29,643:INFO:System:
2023-04-29 17:28:29,643:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:28:29,643:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:28:29,643:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:28:29,643:INFO:PyCaret required dependencies:
2023-04-29 17:28:29,643:INFO:                 pip: 22.2.2
2023-04-29 17:28:29,643:INFO:          setuptools: 63.4.1
2023-04-29 17:28:29,643:INFO:             pycaret: 3.0.0
2023-04-29 17:28:29,643:INFO:             IPython: 7.31.1
2023-04-29 17:28:29,643:INFO:          ipywidgets: 7.6.5
2023-04-29 17:28:29,643:INFO:                tqdm: 4.64.1
2023-04-29 17:28:29,643:INFO:               numpy: 1.21.5
2023-04-29 17:28:29,643:INFO:              pandas: 1.4.4
2023-04-29 17:28:29,643:INFO:              jinja2: 2.11.3
2023-04-29 17:28:29,643:INFO:               scipy: 1.9.1
2023-04-29 17:28:29,643:INFO:              joblib: 1.2.0
2023-04-29 17:28:29,643:INFO:             sklearn: 1.0.2
2023-04-29 17:28:29,643:INFO:                pyod: 1.0.9
2023-04-29 17:28:29,643:INFO:            imblearn: 0.10.1
2023-04-29 17:28:29,643:INFO:   category_encoders: 2.6.0
2023-04-29 17:28:29,644:INFO:            lightgbm: 3.3.5
2023-04-29 17:28:29,644:INFO:               numba: 0.55.1
2023-04-29 17:28:29,644:INFO:            requests: 2.28.1
2023-04-29 17:28:29,644:INFO:          matplotlib: 3.5.2
2023-04-29 17:28:29,644:INFO:          scikitplot: 0.3.7
2023-04-29 17:28:29,644:INFO:         yellowbrick: 1.5
2023-04-29 17:28:29,644:INFO:              plotly: 5.9.0
2023-04-29 17:28:29,644:INFO:             kaleido: 0.2.1
2023-04-29 17:28:29,644:INFO:         statsmodels: 0.13.2
2023-04-29 17:28:29,644:INFO:              sktime: 0.17.1
2023-04-29 17:28:29,644:INFO:               tbats: 1.1.2
2023-04-29 17:28:29,644:INFO:            pmdarima: 2.0.3
2023-04-29 17:28:29,644:INFO:              psutil: 5.9.0
2023-04-29 17:28:29,644:INFO:PyCaret optional dependencies:
2023-04-29 17:28:29,644:INFO:                shap: 0.41.0
2023-04-29 17:28:29,644:INFO:           interpret: Not installed
2023-04-29 17:28:29,644:INFO:                umap: Not installed
2023-04-29 17:28:29,644:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:28:29,644:INFO:  explainerdashboard: Not installed
2023-04-29 17:28:29,644:INFO:             autoviz: Not installed
2023-04-29 17:28:29,644:INFO:           fairlearn: Not installed
2023-04-29 17:28:29,645:INFO:             xgboost: Not installed
2023-04-29 17:28:29,645:INFO:            catboost: Not installed
2023-04-29 17:28:29,645:INFO:              kmodes: Not installed
2023-04-29 17:28:29,645:INFO:             mlxtend: Not installed
2023-04-29 17:28:29,645:INFO:       statsforecast: Not installed
2023-04-29 17:28:29,645:INFO:        tune_sklearn: Not installed
2023-04-29 17:28:29,645:INFO:                 ray: Not installed
2023-04-29 17:28:29,645:INFO:            hyperopt: Not installed
2023-04-29 17:28:29,645:INFO:              optuna: Not installed
2023-04-29 17:28:29,645:INFO:               skopt: Not installed
2023-04-29 17:28:29,645:INFO:              mlflow: 2.2.1
2023-04-29 17:28:29,645:INFO:              gradio: Not installed
2023-04-29 17:28:29,645:INFO:             fastapi: Not installed
2023-04-29 17:28:29,645:INFO:             uvicorn: Not installed
2023-04-29 17:28:29,645:INFO:              m2cgen: Not installed
2023-04-29 17:28:29,645:INFO:           evidently: Not installed
2023-04-29 17:28:29,645:INFO:               fugue: Not installed
2023-04-29 17:28:29,645:INFO:           streamlit: 1.21.0
2023-04-29 17:28:29,645:INFO:             prophet: Not installed
2023-04-29 17:28:29,645:INFO:None
2023-04-29 17:28:29,645:INFO:Set up data.
2023-04-29 17:28:29,648:INFO:Set up train/test split.
2023-04-29 17:28:29,651:INFO:Set up index.
2023-04-29 17:28:29,651:INFO:Set up folding strategy.
2023-04-29 17:28:29,651:INFO:Assigning column types.
2023-04-29 17:28:29,653:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:28:29,653:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,657:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,662:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:29,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:29,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:29,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:29,929:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:28:29,934:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,938:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:28:29,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,045:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,049:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,146:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:28:30,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,262:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,358:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:28:30,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,582:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:28:30,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,775:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:28:30,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,820:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:28:30,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:30,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,073:INFO:Preparing preprocessing pipeline...
2023-04-29 17:28:31,073:INFO:Set up simple imputation.
2023-04-29 17:28:31,073:INFO:Set up column name cleaning.
2023-04-29 17:28:31,094:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:28:31,099:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:28:31,099:INFO:Creating final display dataframe.
2023-04-29 17:28:31,174:INFO:Setup _display_container:                     Description             Value
0                    Session id              7909
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e365
2023-04-29 17:28:31,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:28:31,441:INFO:setup() successfully completed in 2.17s...............
2023-04-29 17:28:31,446:INFO:Initializing compare_models()
2023-04-29 17:28:31,446:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:28:31,446:INFO:Checking exceptions
2023-04-29 17:28:31,450:INFO:Preparing display monitor
2023-04-29 17:28:31,453:INFO:Initializing Linear Regression
2023-04-29 17:28:31,453:INFO:Total runtime is 0.0 minutes
2023-04-29 17:28:31,454:INFO:SubProcess create_model() called ==================================
2023-04-29 17:28:31,454:INFO:Initializing create_model()
2023-04-29 17:28:31,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:28:31,454:INFO:Checking exceptions
2023-04-29 17:28:31,454:INFO:Importing libraries
2023-04-29 17:28:31,454:INFO:Copying training dataset
2023-04-29 17:28:31,457:INFO:Defining folds
2023-04-29 17:28:31,457:INFO:Declaring metric variables
2023-04-29 17:28:31,457:INFO:Importing untrained model
2023-04-29 17:28:31,458:INFO:Linear Regression Imported successfully
2023-04-29 17:28:31,458:INFO:Starting cross validation
2023-04-29 17:28:31,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:28:43,562:INFO:Calculating mean and std
2023-04-29 17:28:43,564:INFO:Creating metrics dataframe
2023-04-29 17:28:44,148:INFO:Uploading results into container
2023-04-29 17:28:44,148:INFO:Uploading model into container now
2023-04-29 17:28:44,149:INFO:_master_model_container: 1
2023-04-29 17:28:44,149:INFO:_display_container: 2
2023-04-29 17:28:44,149:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:28:44,149:INFO:create_model() successfully completed......................................
2023-04-29 17:28:44,252:INFO:SubProcess create_model() end ==================================
2023-04-29 17:28:44,252:INFO:Creating metrics dataframe
2023-04-29 17:28:44,254:INFO:Initializing Lasso Regression
2023-04-29 17:28:44,255:INFO:Total runtime is 0.21338255802790324 minutes
2023-04-29 17:28:44,255:INFO:SubProcess create_model() called ==================================
2023-04-29 17:28:44,255:INFO:Initializing create_model()
2023-04-29 17:28:44,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:28:44,255:INFO:Checking exceptions
2023-04-29 17:28:44,255:INFO:Importing libraries
2023-04-29 17:28:44,255:INFO:Copying training dataset
2023-04-29 17:28:44,261:INFO:Defining folds
2023-04-29 17:28:44,261:INFO:Declaring metric variables
2023-04-29 17:28:44,261:INFO:Importing untrained model
2023-04-29 17:28:44,262:INFO:Lasso Regression Imported successfully
2023-04-29 17:28:44,262:INFO:Starting cross validation
2023-04-29 17:28:44,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:28:48,929:INFO:Calculating mean and std
2023-04-29 17:28:48,930:INFO:Creating metrics dataframe
2023-04-29 17:28:49,478:INFO:Uploading results into container
2023-04-29 17:28:49,478:INFO:Uploading model into container now
2023-04-29 17:28:49,479:INFO:_master_model_container: 2
2023-04-29 17:28:49,479:INFO:_display_container: 2
2023-04-29 17:28:49,479:INFO:Lasso(random_state=7909)
2023-04-29 17:28:49,479:INFO:create_model() successfully completed......................................
2023-04-29 17:28:49,587:INFO:SubProcess create_model() end ==================================
2023-04-29 17:28:49,587:INFO:Creating metrics dataframe
2023-04-29 17:28:49,594:INFO:Initializing Ridge Regression
2023-04-29 17:28:49,594:INFO:Total runtime is 0.3023591200510661 minutes
2023-04-29 17:28:49,595:INFO:SubProcess create_model() called ==================================
2023-04-29 17:28:49,595:INFO:Initializing create_model()
2023-04-29 17:28:49,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:28:49,595:INFO:Checking exceptions
2023-04-29 17:28:49,595:INFO:Importing libraries
2023-04-29 17:28:49,595:INFO:Copying training dataset
2023-04-29 17:28:49,599:INFO:Defining folds
2023-04-29 17:28:49,599:INFO:Declaring metric variables
2023-04-29 17:28:49,599:INFO:Importing untrained model
2023-04-29 17:28:49,599:INFO:Ridge Regression Imported successfully
2023-04-29 17:28:49,600:INFO:Starting cross validation
2023-04-29 17:28:49,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:28:53,832:INFO:Calculating mean and std
2023-04-29 17:28:53,833:INFO:Creating metrics dataframe
2023-04-29 17:28:54,311:INFO:Uploading results into container
2023-04-29 17:28:54,313:INFO:Uploading model into container now
2023-04-29 17:28:54,313:INFO:_master_model_container: 3
2023-04-29 17:28:54,313:INFO:_display_container: 2
2023-04-29 17:28:54,313:INFO:Ridge(random_state=7909)
2023-04-29 17:28:54,313:INFO:create_model() successfully completed......................................
2023-04-29 17:28:54,412:INFO:SubProcess create_model() end ==================================
2023-04-29 17:28:54,412:INFO:Creating metrics dataframe
2023-04-29 17:28:54,416:INFO:Initializing Elastic Net
2023-04-29 17:28:54,416:INFO:Total runtime is 0.3827287991841634 minutes
2023-04-29 17:28:54,416:INFO:SubProcess create_model() called ==================================
2023-04-29 17:28:54,417:INFO:Initializing create_model()
2023-04-29 17:28:54,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:28:54,417:INFO:Checking exceptions
2023-04-29 17:28:54,417:INFO:Importing libraries
2023-04-29 17:28:54,417:INFO:Copying training dataset
2023-04-29 17:28:54,420:INFO:Defining folds
2023-04-29 17:28:54,420:INFO:Declaring metric variables
2023-04-29 17:28:54,421:INFO:Importing untrained model
2023-04-29 17:28:54,421:INFO:Elastic Net Imported successfully
2023-04-29 17:28:54,422:INFO:Starting cross validation
2023-04-29 17:28:54,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:28:58,625:INFO:Calculating mean and std
2023-04-29 17:28:58,627:INFO:Creating metrics dataframe
2023-04-29 17:28:59,173:INFO:Uploading results into container
2023-04-29 17:28:59,175:INFO:Uploading model into container now
2023-04-29 17:28:59,175:INFO:_master_model_container: 4
2023-04-29 17:28:59,176:INFO:_display_container: 2
2023-04-29 17:28:59,176:INFO:ElasticNet(random_state=7909)
2023-04-29 17:28:59,176:INFO:create_model() successfully completed......................................
2023-04-29 17:28:59,297:INFO:SubProcess create_model() end ==================================
2023-04-29 17:28:59,297:INFO:Creating metrics dataframe
2023-04-29 17:28:59,302:INFO:Initializing Least Angle Regression
2023-04-29 17:28:59,303:INFO:Total runtime is 0.4641773621241252 minutes
2023-04-29 17:28:59,303:INFO:SubProcess create_model() called ==================================
2023-04-29 17:28:59,303:INFO:Initializing create_model()
2023-04-29 17:28:59,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:28:59,304:INFO:Checking exceptions
2023-04-29 17:28:59,304:INFO:Importing libraries
2023-04-29 17:28:59,304:INFO:Copying training dataset
2023-04-29 17:28:59,312:INFO:Defining folds
2023-04-29 17:28:59,312:INFO:Declaring metric variables
2023-04-29 17:28:59,312:INFO:Importing untrained model
2023-04-29 17:28:59,313:INFO:Least Angle Regression Imported successfully
2023-04-29 17:28:59,313:INFO:Starting cross validation
2023-04-29 17:28:59,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:28:59,383:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,402:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,410:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,438:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,446:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,476:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,483:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:28:59,511:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:00,653:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:00,666:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:04,629:INFO:Calculating mean and std
2023-04-29 17:29:04,630:INFO:Creating metrics dataframe
2023-04-29 17:29:05,133:INFO:Uploading results into container
2023-04-29 17:29:05,134:INFO:Uploading model into container now
2023-04-29 17:29:05,134:INFO:_master_model_container: 5
2023-04-29 17:29:05,135:INFO:_display_container: 2
2023-04-29 17:29:05,135:INFO:Lars(random_state=7909)
2023-04-29 17:29:05,135:INFO:create_model() successfully completed......................................
2023-04-29 17:29:05,231:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:05,231:INFO:Creating metrics dataframe
2023-04-29 17:29:05,235:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:29:05,235:INFO:Total runtime is 0.5630387624104818 minutes
2023-04-29 17:29:05,236:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:05,236:INFO:Initializing create_model()
2023-04-29 17:29:05,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:05,236:INFO:Checking exceptions
2023-04-29 17:29:05,236:INFO:Importing libraries
2023-04-29 17:29:05,236:INFO:Copying training dataset
2023-04-29 17:29:05,239:INFO:Defining folds
2023-04-29 17:29:05,239:INFO:Declaring metric variables
2023-04-29 17:29:05,240:INFO:Importing untrained model
2023-04-29 17:29:05,240:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:29:05,240:INFO:Starting cross validation
2023-04-29 17:29:05,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:05,336:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,354:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,371:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,390:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,409:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,428:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,451:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:05,465:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:06,549:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:06,566:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:29:09,433:INFO:Calculating mean and std
2023-04-29 17:29:09,434:INFO:Creating metrics dataframe
2023-04-29 17:29:09,929:INFO:Uploading results into container
2023-04-29 17:29:09,930:INFO:Uploading model into container now
2023-04-29 17:29:09,930:INFO:_master_model_container: 6
2023-04-29 17:29:09,930:INFO:_display_container: 2
2023-04-29 17:29:09,930:INFO:LassoLars(random_state=7909)
2023-04-29 17:29:09,930:INFO:create_model() successfully completed......................................
2023-04-29 17:29:10,029:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:10,029:INFO:Creating metrics dataframe
2023-04-29 17:29:10,032:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:29:10,033:INFO:Total runtime is 0.643002446492513 minutes
2023-04-29 17:29:10,033:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:10,033:INFO:Initializing create_model()
2023-04-29 17:29:10,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:10,033:INFO:Checking exceptions
2023-04-29 17:29:10,033:INFO:Importing libraries
2023-04-29 17:29:10,033:INFO:Copying training dataset
2023-04-29 17:29:10,037:INFO:Defining folds
2023-04-29 17:29:10,037:INFO:Declaring metric variables
2023-04-29 17:29:10,038:INFO:Importing untrained model
2023-04-29 17:29:10,039:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:29:10,039:INFO:Starting cross validation
2023-04-29 17:29:10,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:10,088:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,108:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,124:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,135:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,151:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,170:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,197:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:10,218:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:11,264:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:11,333:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:29:14,367:INFO:Calculating mean and std
2023-04-29 17:29:14,368:INFO:Creating metrics dataframe
2023-04-29 17:29:14,879:INFO:Uploading results into container
2023-04-29 17:29:14,879:INFO:Uploading model into container now
2023-04-29 17:29:14,880:INFO:_master_model_container: 7
2023-04-29 17:29:14,880:INFO:_display_container: 2
2023-04-29 17:29:14,880:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:29:14,880:INFO:create_model() successfully completed......................................
2023-04-29 17:29:14,979:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:14,979:INFO:Creating metrics dataframe
2023-04-29 17:29:14,983:INFO:Initializing Bayesian Ridge
2023-04-29 17:29:14,983:INFO:Total runtime is 0.7255058765411377 minutes
2023-04-29 17:29:14,983:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:14,983:INFO:Initializing create_model()
2023-04-29 17:29:14,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:14,983:INFO:Checking exceptions
2023-04-29 17:29:14,984:INFO:Importing libraries
2023-04-29 17:29:14,984:INFO:Copying training dataset
2023-04-29 17:29:14,987:INFO:Defining folds
2023-04-29 17:29:14,988:INFO:Declaring metric variables
2023-04-29 17:29:14,988:INFO:Importing untrained model
2023-04-29 17:29:14,989:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:29:14,989:INFO:Starting cross validation
2023-04-29 17:29:14,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:19,209:INFO:Calculating mean and std
2023-04-29 17:29:19,210:INFO:Creating metrics dataframe
2023-04-29 17:29:19,691:INFO:Uploading results into container
2023-04-29 17:29:19,691:INFO:Uploading model into container now
2023-04-29 17:29:19,692:INFO:_master_model_container: 8
2023-04-29 17:29:19,692:INFO:_display_container: 2
2023-04-29 17:29:19,692:INFO:BayesianRidge()
2023-04-29 17:29:19,692:INFO:create_model() successfully completed......................................
2023-04-29 17:29:19,791:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:19,791:INFO:Creating metrics dataframe
2023-04-29 17:29:19,795:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:29:19,795:INFO:Total runtime is 0.8057032783826192 minutes
2023-04-29 17:29:19,795:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:19,795:INFO:Initializing create_model()
2023-04-29 17:29:19,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:19,795:INFO:Checking exceptions
2023-04-29 17:29:19,795:INFO:Importing libraries
2023-04-29 17:29:19,795:INFO:Copying training dataset
2023-04-29 17:29:19,798:INFO:Defining folds
2023-04-29 17:29:19,799:INFO:Declaring metric variables
2023-04-29 17:29:19,799:INFO:Importing untrained model
2023-04-29 17:29:19,800:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:29:19,800:INFO:Starting cross validation
2023-04-29 17:29:19,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:23,863:INFO:Calculating mean and std
2023-04-29 17:29:23,864:INFO:Creating metrics dataframe
2023-04-29 17:29:24,426:INFO:Uploading results into container
2023-04-29 17:29:24,427:INFO:Uploading model into container now
2023-04-29 17:29:24,428:INFO:_master_model_container: 9
2023-04-29 17:29:24,428:INFO:_display_container: 2
2023-04-29 17:29:24,428:INFO:PassiveAggressiveRegressor(random_state=7909)
2023-04-29 17:29:24,428:INFO:create_model() successfully completed......................................
2023-04-29 17:29:24,529:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:24,529:INFO:Creating metrics dataframe
2023-04-29 17:29:24,533:INFO:Initializing Huber Regressor
2023-04-29 17:29:24,533:INFO:Total runtime is 0.8846690217653911 minutes
2023-04-29 17:29:24,533:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:24,533:INFO:Initializing create_model()
2023-04-29 17:29:24,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:24,534:INFO:Checking exceptions
2023-04-29 17:29:24,534:INFO:Importing libraries
2023-04-29 17:29:24,534:INFO:Copying training dataset
2023-04-29 17:29:24,538:INFO:Defining folds
2023-04-29 17:29:24,538:INFO:Declaring metric variables
2023-04-29 17:29:24,538:INFO:Importing untrained model
2023-04-29 17:29:24,539:INFO:Huber Regressor Imported successfully
2023-04-29 17:29:24,539:INFO:Starting cross validation
2023-04-29 17:29:24,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:29,012:INFO:Calculating mean and std
2023-04-29 17:29:29,014:INFO:Creating metrics dataframe
2023-04-29 17:29:29,510:INFO:Uploading results into container
2023-04-29 17:29:29,511:INFO:Uploading model into container now
2023-04-29 17:29:29,512:INFO:_master_model_container: 10
2023-04-29 17:29:29,512:INFO:_display_container: 2
2023-04-29 17:29:29,512:INFO:HuberRegressor()
2023-04-29 17:29:29,512:INFO:create_model() successfully completed......................................
2023-04-29 17:29:29,611:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:29,611:INFO:Creating metrics dataframe
2023-04-29 17:29:29,614:INFO:Initializing K Neighbors Regressor
2023-04-29 17:29:29,614:INFO:Total runtime is 0.9693596442540487 minutes
2023-04-29 17:29:29,614:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:29,616:INFO:Initializing create_model()
2023-04-29 17:29:29,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:29,616:INFO:Checking exceptions
2023-04-29 17:29:29,616:INFO:Importing libraries
2023-04-29 17:29:29,616:INFO:Copying training dataset
2023-04-29 17:29:29,620:INFO:Defining folds
2023-04-29 17:29:29,621:INFO:Declaring metric variables
2023-04-29 17:29:29,622:INFO:Importing untrained model
2023-04-29 17:29:29,622:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:29:29,622:INFO:Starting cross validation
2023-04-29 17:29:29,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:33,760:INFO:Calculating mean and std
2023-04-29 17:29:33,762:INFO:Creating metrics dataframe
2023-04-29 17:29:34,250:INFO:Uploading results into container
2023-04-29 17:29:34,251:INFO:Uploading model into container now
2023-04-29 17:29:34,251:INFO:_master_model_container: 11
2023-04-29 17:29:34,251:INFO:_display_container: 2
2023-04-29 17:29:34,251:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:29:34,252:INFO:create_model() successfully completed......................................
2023-04-29 17:29:34,352:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:34,352:INFO:Creating metrics dataframe
2023-04-29 17:29:34,357:INFO:Initializing Decision Tree Regressor
2023-04-29 17:29:34,357:INFO:Total runtime is 1.048412346839905 minutes
2023-04-29 17:29:34,357:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:34,357:INFO:Initializing create_model()
2023-04-29 17:29:34,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:34,358:INFO:Checking exceptions
2023-04-29 17:29:34,358:INFO:Importing libraries
2023-04-29 17:29:34,358:INFO:Copying training dataset
2023-04-29 17:29:34,361:INFO:Defining folds
2023-04-29 17:29:34,361:INFO:Declaring metric variables
2023-04-29 17:29:34,361:INFO:Importing untrained model
2023-04-29 17:29:34,361:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:29:34,362:INFO:Starting cross validation
2023-04-29 17:29:34,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:38,418:INFO:Calculating mean and std
2023-04-29 17:29:38,420:INFO:Creating metrics dataframe
2023-04-29 17:29:38,914:INFO:Uploading results into container
2023-04-29 17:29:38,915:INFO:Uploading model into container now
2023-04-29 17:29:38,915:INFO:_master_model_container: 12
2023-04-29 17:29:38,915:INFO:_display_container: 2
2023-04-29 17:29:38,915:INFO:DecisionTreeRegressor(random_state=7909)
2023-04-29 17:29:38,915:INFO:create_model() successfully completed......................................
2023-04-29 17:29:39,018:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:39,018:INFO:Creating metrics dataframe
2023-04-29 17:29:39,022:INFO:Initializing Random Forest Regressor
2023-04-29 17:29:39,022:INFO:Total runtime is 1.1261621912320456 minutes
2023-04-29 17:29:39,022:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:39,022:INFO:Initializing create_model()
2023-04-29 17:29:39,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:39,022:INFO:Checking exceptions
2023-04-29 17:29:39,023:INFO:Importing libraries
2023-04-29 17:29:39,023:INFO:Copying training dataset
2023-04-29 17:29:39,027:INFO:Defining folds
2023-04-29 17:29:39,028:INFO:Declaring metric variables
2023-04-29 17:29:39,028:INFO:Importing untrained model
2023-04-29 17:29:39,028:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:29:39,029:INFO:Starting cross validation
2023-04-29 17:29:39,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:44,362:INFO:Calculating mean and std
2023-04-29 17:29:44,363:INFO:Creating metrics dataframe
2023-04-29 17:29:44,863:INFO:Uploading results into container
2023-04-29 17:29:44,864:INFO:Uploading model into container now
2023-04-29 17:29:44,864:INFO:_master_model_container: 13
2023-04-29 17:29:44,864:INFO:_display_container: 2
2023-04-29 17:29:44,865:INFO:RandomForestRegressor(n_jobs=-1, random_state=7909)
2023-04-29 17:29:44,865:INFO:create_model() successfully completed......................................
2023-04-29 17:29:44,966:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:44,966:INFO:Creating metrics dataframe
2023-04-29 17:29:44,971:INFO:Initializing Extra Trees Regressor
2023-04-29 17:29:44,971:INFO:Total runtime is 1.225306272506714 minutes
2023-04-29 17:29:44,971:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:44,972:INFO:Initializing create_model()
2023-04-29 17:29:44,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:44,972:INFO:Checking exceptions
2023-04-29 17:29:44,972:INFO:Importing libraries
2023-04-29 17:29:44,972:INFO:Copying training dataset
2023-04-29 17:29:44,974:INFO:Defining folds
2023-04-29 17:29:44,975:INFO:Declaring metric variables
2023-04-29 17:29:44,975:INFO:Importing untrained model
2023-04-29 17:29:44,975:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:29:44,976:INFO:Starting cross validation
2023-04-29 17:29:44,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:50,135:INFO:Calculating mean and std
2023-04-29 17:29:50,136:INFO:Creating metrics dataframe
2023-04-29 17:29:50,641:INFO:Uploading results into container
2023-04-29 17:29:50,642:INFO:Uploading model into container now
2023-04-29 17:29:50,643:INFO:_master_model_container: 14
2023-04-29 17:29:50,643:INFO:_display_container: 2
2023-04-29 17:29:50,643:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7909)
2023-04-29 17:29:50,643:INFO:create_model() successfully completed......................................
2023-04-29 17:29:50,740:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:50,740:INFO:Creating metrics dataframe
2023-04-29 17:29:50,744:INFO:Initializing AdaBoost Regressor
2023-04-29 17:29:50,744:INFO:Total runtime is 1.3215188900629682 minutes
2023-04-29 17:29:50,744:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:50,744:INFO:Initializing create_model()
2023-04-29 17:29:50,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:50,744:INFO:Checking exceptions
2023-04-29 17:29:50,744:INFO:Importing libraries
2023-04-29 17:29:50,744:INFO:Copying training dataset
2023-04-29 17:29:50,747:INFO:Defining folds
2023-04-29 17:29:50,747:INFO:Declaring metric variables
2023-04-29 17:29:50,748:INFO:Importing untrained model
2023-04-29 17:29:50,748:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:29:50,749:INFO:Starting cross validation
2023-04-29 17:29:50,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:29:55,472:INFO:Calculating mean and std
2023-04-29 17:29:55,473:INFO:Creating metrics dataframe
2023-04-29 17:29:55,974:INFO:Uploading results into container
2023-04-29 17:29:55,976:INFO:Uploading model into container now
2023-04-29 17:29:55,976:INFO:_master_model_container: 15
2023-04-29 17:29:55,976:INFO:_display_container: 2
2023-04-29 17:29:55,977:INFO:AdaBoostRegressor(random_state=7909)
2023-04-29 17:29:55,977:INFO:create_model() successfully completed......................................
2023-04-29 17:29:56,076:INFO:SubProcess create_model() end ==================================
2023-04-29 17:29:56,077:INFO:Creating metrics dataframe
2023-04-29 17:29:56,080:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:29:56,080:INFO:Total runtime is 1.4104566335678104 minutes
2023-04-29 17:29:56,081:INFO:SubProcess create_model() called ==================================
2023-04-29 17:29:56,081:INFO:Initializing create_model()
2023-04-29 17:29:56,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:29:56,081:INFO:Checking exceptions
2023-04-29 17:29:56,081:INFO:Importing libraries
2023-04-29 17:29:56,081:INFO:Copying training dataset
2023-04-29 17:29:56,085:INFO:Defining folds
2023-04-29 17:29:56,085:INFO:Declaring metric variables
2023-04-29 17:29:56,085:INFO:Importing untrained model
2023-04-29 17:29:56,086:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:29:56,086:INFO:Starting cross validation
2023-04-29 17:29:56,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:30:01,647:INFO:Calculating mean and std
2023-04-29 17:30:01,647:INFO:Creating metrics dataframe
2023-04-29 17:30:02,284:INFO:Uploading results into container
2023-04-29 17:30:02,286:INFO:Uploading model into container now
2023-04-29 17:30:02,286:INFO:_master_model_container: 16
2023-04-29 17:30:02,286:INFO:_display_container: 2
2023-04-29 17:30:02,287:INFO:GradientBoostingRegressor(random_state=7909)
2023-04-29 17:30:02,287:INFO:create_model() successfully completed......................................
2023-04-29 17:30:02,405:INFO:SubProcess create_model() end ==================================
2023-04-29 17:30:02,405:INFO:Creating metrics dataframe
2023-04-29 17:30:02,409:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:30:02,410:INFO:Total runtime is 1.515935035546621 minutes
2023-04-29 17:30:02,410:INFO:SubProcess create_model() called ==================================
2023-04-29 17:30:02,410:INFO:Initializing create_model()
2023-04-29 17:30:02,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:30:02,410:INFO:Checking exceptions
2023-04-29 17:30:02,410:INFO:Importing libraries
2023-04-29 17:30:02,410:INFO:Copying training dataset
2023-04-29 17:30:02,413:INFO:Defining folds
2023-04-29 17:30:02,413:INFO:Declaring metric variables
2023-04-29 17:30:02,413:INFO:Importing untrained model
2023-04-29 17:30:02,414:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:30:02,414:INFO:Starting cross validation
2023-04-29 17:30:02,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:30:11,024:INFO:Calculating mean and std
2023-04-29 17:30:11,025:INFO:Creating metrics dataframe
2023-04-29 17:30:11,693:INFO:Uploading results into container
2023-04-29 17:30:11,694:INFO:Uploading model into container now
2023-04-29 17:30:11,695:INFO:_master_model_container: 17
2023-04-29 17:30:11,695:INFO:_display_container: 2
2023-04-29 17:30:11,696:INFO:LGBMRegressor(random_state=7909)
2023-04-29 17:30:11,696:INFO:create_model() successfully completed......................................
2023-04-29 17:30:11,858:INFO:SubProcess create_model() end ==================================
2023-04-29 17:30:11,859:INFO:Creating metrics dataframe
2023-04-29 17:30:11,877:INFO:Initializing Dummy Regressor
2023-04-29 17:30:11,877:INFO:Total runtime is 1.6737483580907189 minutes
2023-04-29 17:30:11,877:INFO:SubProcess create_model() called ==================================
2023-04-29 17:30:11,878:INFO:Initializing create_model()
2023-04-29 17:30:11,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68C9B50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:30:11,878:INFO:Checking exceptions
2023-04-29 17:30:11,878:INFO:Importing libraries
2023-04-29 17:30:11,880:INFO:Copying training dataset
2023-04-29 17:30:11,889:INFO:Defining folds
2023-04-29 17:30:11,889:INFO:Declaring metric variables
2023-04-29 17:30:11,890:INFO:Importing untrained model
2023-04-29 17:30:11,890:INFO:Dummy Regressor Imported successfully
2023-04-29 17:30:11,891:INFO:Starting cross validation
2023-04-29 17:30:11,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:30:18,024:INFO:Calculating mean and std
2023-04-29 17:30:18,025:INFO:Creating metrics dataframe
2023-04-29 17:30:18,584:INFO:Uploading results into container
2023-04-29 17:30:18,585:INFO:Uploading model into container now
2023-04-29 17:30:18,585:INFO:_master_model_container: 18
2023-04-29 17:30:18,585:INFO:_display_container: 2
2023-04-29 17:30:18,586:INFO:DummyRegressor()
2023-04-29 17:30:18,586:INFO:create_model() successfully completed......................................
2023-04-29 17:30:18,705:INFO:SubProcess create_model() end ==================================
2023-04-29 17:30:18,705:INFO:Creating metrics dataframe
2023-04-29 17:30:18,713:INFO:Initializing create_model()
2023-04-29 17:30:18,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7909), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:30:18,713:INFO:Checking exceptions
2023-04-29 17:30:18,715:INFO:Importing libraries
2023-04-29 17:30:18,715:INFO:Copying training dataset
2023-04-29 17:30:18,720:INFO:Defining folds
2023-04-29 17:30:18,720:INFO:Declaring metric variables
2023-04-29 17:30:18,720:INFO:Importing untrained model
2023-04-29 17:30:18,720:INFO:Declaring custom model
2023-04-29 17:30:18,721:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:30:18,721:INFO:Cross validation set to False
2023-04-29 17:30:18,721:INFO:Fitting Model
2023-04-29 17:30:19,316:INFO:RandomForestRegressor(n_jobs=-1, random_state=7909)
2023-04-29 17:30:19,316:INFO:create_model() successfully completed......................................
2023-04-29 17:30:19,444:INFO:_master_model_container: 18
2023-04-29 17:30:19,444:INFO:_display_container: 2
2023-04-29 17:30:19,444:INFO:RandomForestRegressor(n_jobs=-1, random_state=7909)
2023-04-29 17:30:19,445:INFO:compare_models() successfully completed......................................
2023-04-29 17:30:19,450:INFO:Initializing predict_model()
2023-04-29 17:30:19,450:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6D58D90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7909), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B77590D0>)
2023-04-29 17:30:19,450:INFO:Checking exceptions
2023-04-29 17:30:19,450:INFO:Preloading libraries
2023-04-29 17:30:19,450:INFO:Set up data.
2023-04-29 17:30:19,456:INFO:Set up index.
2023-04-29 17:31:54,170:INFO:PyCaret RegressionExperiment
2023-04-29 17:31:54,170:INFO:Logging name: reg-default-name
2023-04-29 17:31:54,170:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:31:54,170:INFO:version 3.0.0
2023-04-29 17:31:54,170:INFO:Initializing setup()
2023-04-29 17:31:54,171:INFO:self.USI: 36a4
2023-04-29 17:31:54,171:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:31:54,171:INFO:Checking environment
2023-04-29 17:31:54,171:INFO:python_version: 3.9.13
2023-04-29 17:31:54,171:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:31:54,171:INFO:machine: AMD64
2023-04-29 17:31:54,171:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:31:54,171:INFO:Memory: svmem(total=16935899136, available=5369077760, percent=68.3, used=11566821376, free=5369077760)
2023-04-29 17:31:54,171:INFO:Physical Core: 4
2023-04-29 17:31:54,171:INFO:Logical Core: 8
2023-04-29 17:31:54,171:INFO:Checking libraries
2023-04-29 17:31:54,171:INFO:System:
2023-04-29 17:31:54,171:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:31:54,171:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:31:54,171:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:31:54,171:INFO:PyCaret required dependencies:
2023-04-29 17:31:54,172:INFO:                 pip: 22.2.2
2023-04-29 17:31:54,172:INFO:          setuptools: 63.4.1
2023-04-29 17:31:54,172:INFO:             pycaret: 3.0.0
2023-04-29 17:31:54,172:INFO:             IPython: 7.31.1
2023-04-29 17:31:54,172:INFO:          ipywidgets: 7.6.5
2023-04-29 17:31:54,172:INFO:                tqdm: 4.64.1
2023-04-29 17:31:54,172:INFO:               numpy: 1.21.5
2023-04-29 17:31:54,172:INFO:              pandas: 1.4.4
2023-04-29 17:31:54,172:INFO:              jinja2: 2.11.3
2023-04-29 17:31:54,172:INFO:               scipy: 1.9.1
2023-04-29 17:31:54,172:INFO:              joblib: 1.2.0
2023-04-29 17:31:54,172:INFO:             sklearn: 1.0.2
2023-04-29 17:31:54,172:INFO:                pyod: 1.0.9
2023-04-29 17:31:54,172:INFO:            imblearn: 0.10.1
2023-04-29 17:31:54,172:INFO:   category_encoders: 2.6.0
2023-04-29 17:31:54,172:INFO:            lightgbm: 3.3.5
2023-04-29 17:31:54,172:INFO:               numba: 0.55.1
2023-04-29 17:31:54,172:INFO:            requests: 2.28.1
2023-04-29 17:31:54,172:INFO:          matplotlib: 3.5.2
2023-04-29 17:31:54,172:INFO:          scikitplot: 0.3.7
2023-04-29 17:31:54,172:INFO:         yellowbrick: 1.5
2023-04-29 17:31:54,172:INFO:              plotly: 5.9.0
2023-04-29 17:31:54,172:INFO:             kaleido: 0.2.1
2023-04-29 17:31:54,172:INFO:         statsmodels: 0.13.2
2023-04-29 17:31:54,172:INFO:              sktime: 0.17.1
2023-04-29 17:31:54,172:INFO:               tbats: 1.1.2
2023-04-29 17:31:54,172:INFO:            pmdarima: 2.0.3
2023-04-29 17:31:54,173:INFO:              psutil: 5.9.0
2023-04-29 17:31:54,173:INFO:PyCaret optional dependencies:
2023-04-29 17:31:54,173:INFO:                shap: 0.41.0
2023-04-29 17:31:54,173:INFO:           interpret: Not installed
2023-04-29 17:31:54,173:INFO:                umap: Not installed
2023-04-29 17:31:54,173:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:31:54,173:INFO:  explainerdashboard: Not installed
2023-04-29 17:31:54,173:INFO:             autoviz: Not installed
2023-04-29 17:31:54,173:INFO:           fairlearn: Not installed
2023-04-29 17:31:54,174:INFO:             xgboost: Not installed
2023-04-29 17:31:54,174:INFO:            catboost: Not installed
2023-04-29 17:31:54,174:INFO:              kmodes: Not installed
2023-04-29 17:31:54,174:INFO:             mlxtend: Not installed
2023-04-29 17:31:54,174:INFO:       statsforecast: Not installed
2023-04-29 17:31:54,174:INFO:        tune_sklearn: Not installed
2023-04-29 17:31:54,174:INFO:                 ray: Not installed
2023-04-29 17:31:54,174:INFO:            hyperopt: Not installed
2023-04-29 17:31:54,174:INFO:              optuna: Not installed
2023-04-29 17:31:54,174:INFO:               skopt: Not installed
2023-04-29 17:31:54,174:INFO:              mlflow: 2.2.1
2023-04-29 17:31:54,174:INFO:              gradio: Not installed
2023-04-29 17:31:54,174:INFO:             fastapi: Not installed
2023-04-29 17:31:54,174:INFO:             uvicorn: Not installed
2023-04-29 17:31:54,174:INFO:              m2cgen: Not installed
2023-04-29 17:31:54,174:INFO:           evidently: Not installed
2023-04-29 17:31:54,174:INFO:               fugue: Not installed
2023-04-29 17:31:54,174:INFO:           streamlit: 1.21.0
2023-04-29 17:31:54,174:INFO:             prophet: Not installed
2023-04-29 17:31:54,174:INFO:None
2023-04-29 17:31:54,174:INFO:Set up data.
2023-04-29 17:31:54,178:INFO:Set up train/test split.
2023-04-29 17:31:54,180:INFO:Set up index.
2023-04-29 17:31:54,181:INFO:Set up folding strategy.
2023-04-29 17:31:54,181:INFO:Assigning column types.
2023-04-29 17:31:54,183:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:31:54,183:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,307:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,372:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,419:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,420:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:31:54,425:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,543:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,667:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:31:54,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,808:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:54,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:54,926:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:31:55,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:55,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:55,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:55,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:31:55,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,187:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:31:55,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:55,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,379:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:31:55,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,429:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:31:55,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,700:INFO:Preparing preprocessing pipeline...
2023-04-29 17:31:55,700:INFO:Set up simple imputation.
2023-04-29 17:31:55,701:INFO:Set up column name cleaning.
2023-04-29 17:31:55,724:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:31:55,728:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:31:55,728:INFO:Creating final display dataframe.
2023-04-29 17:31:55,805:INFO:Setup _display_container:                     Description             Value
0                    Session id              6722
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              36a4
2023-04-29 17:31:55,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:55,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:56,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:56,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:31:56,062:INFO:setup() successfully completed in 2.32s...............
2023-04-29 17:31:56,069:INFO:Initializing compare_models()
2023-04-29 17:31:56,070:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:31:56,070:INFO:Checking exceptions
2023-04-29 17:31:56,071:INFO:Preparing display monitor
2023-04-29 17:31:56,074:INFO:Initializing Linear Regression
2023-04-29 17:31:56,074:INFO:Total runtime is 0.0 minutes
2023-04-29 17:31:56,074:INFO:SubProcess create_model() called ==================================
2023-04-29 17:31:56,075:INFO:Initializing create_model()
2023-04-29 17:31:56,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:31:56,075:INFO:Checking exceptions
2023-04-29 17:31:56,075:INFO:Importing libraries
2023-04-29 17:31:56,075:INFO:Copying training dataset
2023-04-29 17:31:56,079:INFO:Defining folds
2023-04-29 17:31:56,079:INFO:Declaring metric variables
2023-04-29 17:31:56,080:INFO:Importing untrained model
2023-04-29 17:31:56,080:INFO:Linear Regression Imported successfully
2023-04-29 17:31:56,080:INFO:Starting cross validation
2023-04-29 17:31:56,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:00,577:INFO:Calculating mean and std
2023-04-29 17:32:00,578:INFO:Creating metrics dataframe
2023-04-29 17:32:01,159:INFO:Uploading results into container
2023-04-29 17:32:01,160:INFO:Uploading model into container now
2023-04-29 17:32:01,161:INFO:_master_model_container: 1
2023-04-29 17:32:01,161:INFO:_display_container: 2
2023-04-29 17:32:01,161:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:32:01,161:INFO:create_model() successfully completed......................................
2023-04-29 17:32:01,272:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:01,272:INFO:Creating metrics dataframe
2023-04-29 17:32:01,275:INFO:Initializing Lasso Regression
2023-04-29 17:32:01,275:INFO:Total runtime is 0.08668065865834554 minutes
2023-04-29 17:32:01,275:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:01,275:INFO:Initializing create_model()
2023-04-29 17:32:01,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:01,275:INFO:Checking exceptions
2023-04-29 17:32:01,275:INFO:Importing libraries
2023-04-29 17:32:01,275:INFO:Copying training dataset
2023-04-29 17:32:01,278:INFO:Defining folds
2023-04-29 17:32:01,278:INFO:Declaring metric variables
2023-04-29 17:32:01,278:INFO:Importing untrained model
2023-04-29 17:32:01,279:INFO:Lasso Regression Imported successfully
2023-04-29 17:32:01,279:INFO:Starting cross validation
2023-04-29 17:32:01,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:06,690:INFO:Calculating mean and std
2023-04-29 17:32:06,692:INFO:Creating metrics dataframe
2023-04-29 17:32:07,312:INFO:Uploading results into container
2023-04-29 17:32:07,313:INFO:Uploading model into container now
2023-04-29 17:32:07,313:INFO:_master_model_container: 2
2023-04-29 17:32:07,314:INFO:_display_container: 2
2023-04-29 17:32:07,314:INFO:Lasso(random_state=6722)
2023-04-29 17:32:07,314:INFO:create_model() successfully completed......................................
2023-04-29 17:32:07,434:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:07,434:INFO:Creating metrics dataframe
2023-04-29 17:32:07,440:INFO:Initializing Ridge Regression
2023-04-29 17:32:07,440:INFO:Total runtime is 0.1894304315249125 minutes
2023-04-29 17:32:07,440:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:07,440:INFO:Initializing create_model()
2023-04-29 17:32:07,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:07,440:INFO:Checking exceptions
2023-04-29 17:32:07,441:INFO:Importing libraries
2023-04-29 17:32:07,441:INFO:Copying training dataset
2023-04-29 17:32:07,444:INFO:Defining folds
2023-04-29 17:32:07,444:INFO:Declaring metric variables
2023-04-29 17:32:07,444:INFO:Importing untrained model
2023-04-29 17:32:07,444:INFO:Ridge Regression Imported successfully
2023-04-29 17:32:07,445:INFO:Starting cross validation
2023-04-29 17:32:07,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:13,141:INFO:Calculating mean and std
2023-04-29 17:32:13,142:INFO:Creating metrics dataframe
2023-04-29 17:32:13,777:INFO:Uploading results into container
2023-04-29 17:32:13,778:INFO:Uploading model into container now
2023-04-29 17:32:13,779:INFO:_master_model_container: 3
2023-04-29 17:32:13,779:INFO:_display_container: 2
2023-04-29 17:32:13,780:INFO:Ridge(random_state=6722)
2023-04-29 17:32:13,780:INFO:create_model() successfully completed......................................
2023-04-29 17:32:13,899:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:13,900:INFO:Creating metrics dataframe
2023-04-29 17:32:13,904:INFO:Initializing Elastic Net
2023-04-29 17:32:13,904:INFO:Total runtime is 0.29716418584187826 minutes
2023-04-29 17:32:13,904:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:13,904:INFO:Initializing create_model()
2023-04-29 17:32:13,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:13,904:INFO:Checking exceptions
2023-04-29 17:32:13,904:INFO:Importing libraries
2023-04-29 17:32:13,904:INFO:Copying training dataset
2023-04-29 17:32:13,907:INFO:Defining folds
2023-04-29 17:32:13,908:INFO:Declaring metric variables
2023-04-29 17:32:13,908:INFO:Importing untrained model
2023-04-29 17:32:13,909:INFO:Elastic Net Imported successfully
2023-04-29 17:32:13,910:INFO:Starting cross validation
2023-04-29 17:32:13,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:19,712:INFO:Calculating mean and std
2023-04-29 17:32:19,713:INFO:Creating metrics dataframe
2023-04-29 17:32:20,396:INFO:Uploading results into container
2023-04-29 17:32:20,397:INFO:Uploading model into container now
2023-04-29 17:32:20,398:INFO:_master_model_container: 4
2023-04-29 17:32:20,398:INFO:_display_container: 2
2023-04-29 17:32:20,398:INFO:ElasticNet(random_state=6722)
2023-04-29 17:32:20,399:INFO:create_model() successfully completed......................................
2023-04-29 17:32:20,555:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:20,555:INFO:Creating metrics dataframe
2023-04-29 17:32:20,567:INFO:Initializing Least Angle Regression
2023-04-29 17:32:20,568:INFO:Total runtime is 0.408239738146464 minutes
2023-04-29 17:32:20,569:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:20,569:INFO:Initializing create_model()
2023-04-29 17:32:20,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:20,569:INFO:Checking exceptions
2023-04-29 17:32:20,569:INFO:Importing libraries
2023-04-29 17:32:20,569:INFO:Copying training dataset
2023-04-29 17:32:20,577:INFO:Defining folds
2023-04-29 17:32:20,577:INFO:Declaring metric variables
2023-04-29 17:32:20,578:INFO:Importing untrained model
2023-04-29 17:32:20,578:INFO:Least Angle Regression Imported successfully
2023-04-29 17:32:20,579:INFO:Starting cross validation
2023-04-29 17:32:20,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:20,673:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,689:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,691:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,692:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,717:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,729:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,748:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:20,755:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:21,715:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:21,744:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:26,278:INFO:Calculating mean and std
2023-04-29 17:32:26,279:INFO:Creating metrics dataframe
2023-04-29 17:32:26,995:INFO:Uploading results into container
2023-04-29 17:32:26,996:INFO:Uploading model into container now
2023-04-29 17:32:26,997:INFO:_master_model_container: 5
2023-04-29 17:32:26,997:INFO:_display_container: 2
2023-04-29 17:32:26,998:INFO:Lars(random_state=6722)
2023-04-29 17:32:26,998:INFO:create_model() successfully completed......................................
2023-04-29 17:32:27,124:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:27,124:INFO:Creating metrics dataframe
2023-04-29 17:32:27,132:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:32:27,132:INFO:Total runtime is 0.5176430384318034 minutes
2023-04-29 17:32:27,132:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:27,133:INFO:Initializing create_model()
2023-04-29 17:32:27,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:27,133:INFO:Checking exceptions
2023-04-29 17:32:27,133:INFO:Importing libraries
2023-04-29 17:32:27,133:INFO:Copying training dataset
2023-04-29 17:32:27,141:INFO:Defining folds
2023-04-29 17:32:27,141:INFO:Declaring metric variables
2023-04-29 17:32:27,141:INFO:Importing untrained model
2023-04-29 17:32:27,142:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:32:27,142:INFO:Starting cross validation
2023-04-29 17:32:27,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:27,220:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,233:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,249:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,264:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,279:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,301:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,307:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:27,324:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:28,296:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:28,314:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:32:33,109:INFO:Calculating mean and std
2023-04-29 17:32:33,110:INFO:Creating metrics dataframe
2023-04-29 17:32:33,671:INFO:Uploading results into container
2023-04-29 17:32:33,672:INFO:Uploading model into container now
2023-04-29 17:32:33,672:INFO:_master_model_container: 6
2023-04-29 17:32:33,672:INFO:_display_container: 2
2023-04-29 17:32:33,673:INFO:LassoLars(random_state=6722)
2023-04-29 17:32:33,673:INFO:create_model() successfully completed......................................
2023-04-29 17:32:33,798:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:33,798:INFO:Creating metrics dataframe
2023-04-29 17:32:33,807:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:32:33,807:INFO:Total runtime is 0.6288808027903239 minutes
2023-04-29 17:32:33,807:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:33,808:INFO:Initializing create_model()
2023-04-29 17:32:33,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:33,808:INFO:Checking exceptions
2023-04-29 17:32:33,808:INFO:Importing libraries
2023-04-29 17:32:33,808:INFO:Copying training dataset
2023-04-29 17:32:33,812:INFO:Defining folds
2023-04-29 17:32:33,812:INFO:Declaring metric variables
2023-04-29 17:32:33,812:INFO:Importing untrained model
2023-04-29 17:32:33,813:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:32:33,813:INFO:Starting cross validation
2023-04-29 17:32:33,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:33,891:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,906:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,921:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,934:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,945:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,960:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,971:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:33,987:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:34,985:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:35,009:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:32:40,139:INFO:Calculating mean and std
2023-04-29 17:32:40,140:INFO:Creating metrics dataframe
2023-04-29 17:32:40,814:INFO:Uploading results into container
2023-04-29 17:32:40,814:INFO:Uploading model into container now
2023-04-29 17:32:40,814:INFO:_master_model_container: 7
2023-04-29 17:32:40,816:INFO:_display_container: 2
2023-04-29 17:32:40,816:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:32:40,816:INFO:create_model() successfully completed......................................
2023-04-29 17:32:40,945:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:40,946:INFO:Creating metrics dataframe
2023-04-29 17:32:40,950:INFO:Initializing Bayesian Ridge
2023-04-29 17:32:40,950:INFO:Total runtime is 0.7479297002156575 minutes
2023-04-29 17:32:40,951:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:40,951:INFO:Initializing create_model()
2023-04-29 17:32:40,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:40,951:INFO:Checking exceptions
2023-04-29 17:32:40,951:INFO:Importing libraries
2023-04-29 17:32:40,951:INFO:Copying training dataset
2023-04-29 17:32:40,954:INFO:Defining folds
2023-04-29 17:32:40,954:INFO:Declaring metric variables
2023-04-29 17:32:40,954:INFO:Importing untrained model
2023-04-29 17:32:40,955:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:32:40,955:INFO:Starting cross validation
2023-04-29 17:32:40,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:46,857:INFO:Calculating mean and std
2023-04-29 17:32:46,858:INFO:Creating metrics dataframe
2023-04-29 17:32:47,429:INFO:Uploading results into container
2023-04-29 17:32:47,429:INFO:Uploading model into container now
2023-04-29 17:32:47,430:INFO:_master_model_container: 8
2023-04-29 17:32:47,430:INFO:_display_container: 2
2023-04-29 17:32:47,430:INFO:BayesianRidge()
2023-04-29 17:32:47,431:INFO:create_model() successfully completed......................................
2023-04-29 17:32:47,557:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:47,557:INFO:Creating metrics dataframe
2023-04-29 17:32:47,561:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:32:47,561:INFO:Total runtime is 0.8581275900204977 minutes
2023-04-29 17:32:47,561:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:47,561:INFO:Initializing create_model()
2023-04-29 17:32:47,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:47,561:INFO:Checking exceptions
2023-04-29 17:32:47,562:INFO:Importing libraries
2023-04-29 17:32:47,562:INFO:Copying training dataset
2023-04-29 17:32:47,565:INFO:Defining folds
2023-04-29 17:32:47,565:INFO:Declaring metric variables
2023-04-29 17:32:47,565:INFO:Importing untrained model
2023-04-29 17:32:47,566:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:32:47,567:INFO:Starting cross validation
2023-04-29 17:32:47,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:52,866:INFO:Calculating mean and std
2023-04-29 17:32:52,867:INFO:Creating metrics dataframe
2023-04-29 17:32:53,421:INFO:Uploading results into container
2023-04-29 17:32:53,422:INFO:Uploading model into container now
2023-04-29 17:32:53,422:INFO:_master_model_container: 9
2023-04-29 17:32:53,422:INFO:_display_container: 2
2023-04-29 17:32:53,423:INFO:PassiveAggressiveRegressor(random_state=6722)
2023-04-29 17:32:53,423:INFO:create_model() successfully completed......................................
2023-04-29 17:32:53,550:INFO:SubProcess create_model() end ==================================
2023-04-29 17:32:53,550:INFO:Creating metrics dataframe
2023-04-29 17:32:53,554:INFO:Initializing Huber Regressor
2023-04-29 17:32:53,554:INFO:Total runtime is 0.9580096403757732 minutes
2023-04-29 17:32:53,554:INFO:SubProcess create_model() called ==================================
2023-04-29 17:32:53,555:INFO:Initializing create_model()
2023-04-29 17:32:53,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:32:53,555:INFO:Checking exceptions
2023-04-29 17:32:53,555:INFO:Importing libraries
2023-04-29 17:32:53,555:INFO:Copying training dataset
2023-04-29 17:32:53,558:INFO:Defining folds
2023-04-29 17:32:53,559:INFO:Declaring metric variables
2023-04-29 17:32:53,560:INFO:Importing untrained model
2023-04-29 17:32:53,560:INFO:Huber Regressor Imported successfully
2023-04-29 17:32:53,561:INFO:Starting cross validation
2023-04-29 17:32:53,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:32:59,467:INFO:Calculating mean and std
2023-04-29 17:32:59,468:INFO:Creating metrics dataframe
2023-04-29 17:33:00,207:INFO:Uploading results into container
2023-04-29 17:33:00,207:INFO:Uploading model into container now
2023-04-29 17:33:00,208:INFO:_master_model_container: 10
2023-04-29 17:33:00,209:INFO:_display_container: 2
2023-04-29 17:33:00,209:INFO:HuberRegressor()
2023-04-29 17:33:00,209:INFO:create_model() successfully completed......................................
2023-04-29 17:33:00,381:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:00,382:INFO:Creating metrics dataframe
2023-04-29 17:33:00,394:INFO:Initializing K Neighbors Regressor
2023-04-29 17:33:00,394:INFO:Total runtime is 1.0720056454340618 minutes
2023-04-29 17:33:00,395:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:00,396:INFO:Initializing create_model()
2023-04-29 17:33:00,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:00,396:INFO:Checking exceptions
2023-04-29 17:33:00,396:INFO:Importing libraries
2023-04-29 17:33:00,396:INFO:Copying training dataset
2023-04-29 17:33:00,405:INFO:Defining folds
2023-04-29 17:33:00,405:INFO:Declaring metric variables
2023-04-29 17:33:00,405:INFO:Importing untrained model
2023-04-29 17:33:00,407:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:33:00,409:INFO:Starting cross validation
2023-04-29 17:33:00,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:06,179:INFO:Calculating mean and std
2023-04-29 17:33:06,180:INFO:Creating metrics dataframe
2023-04-29 17:33:06,905:INFO:Uploading results into container
2023-04-29 17:33:06,906:INFO:Uploading model into container now
2023-04-29 17:33:06,907:INFO:_master_model_container: 11
2023-04-29 17:33:06,907:INFO:_display_container: 2
2023-04-29 17:33:06,907:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:33:06,907:INFO:create_model() successfully completed......................................
2023-04-29 17:33:07,064:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:07,065:INFO:Creating metrics dataframe
2023-04-29 17:33:07,075:INFO:Initializing Decision Tree Regressor
2023-04-29 17:33:07,075:INFO:Total runtime is 1.183353638648987 minutes
2023-04-29 17:33:07,076:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:07,076:INFO:Initializing create_model()
2023-04-29 17:33:07,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:07,077:INFO:Checking exceptions
2023-04-29 17:33:07,077:INFO:Importing libraries
2023-04-29 17:33:07,078:INFO:Copying training dataset
2023-04-29 17:33:07,085:INFO:Defining folds
2023-04-29 17:33:07,085:INFO:Declaring metric variables
2023-04-29 17:33:07,085:INFO:Importing untrained model
2023-04-29 17:33:07,086:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:33:07,087:INFO:Starting cross validation
2023-04-29 17:33:07,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:12,925:INFO:Calculating mean and std
2023-04-29 17:33:12,927:INFO:Creating metrics dataframe
2023-04-29 17:33:13,498:INFO:Uploading results into container
2023-04-29 17:33:13,498:INFO:Uploading model into container now
2023-04-29 17:33:13,498:INFO:_master_model_container: 12
2023-04-29 17:33:13,498:INFO:_display_container: 2
2023-04-29 17:33:13,498:INFO:DecisionTreeRegressor(random_state=6722)
2023-04-29 17:33:13,498:INFO:create_model() successfully completed......................................
2023-04-29 17:33:13,640:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:13,640:INFO:Creating metrics dataframe
2023-04-29 17:33:13,647:INFO:Initializing Random Forest Regressor
2023-04-29 17:33:13,647:INFO:Total runtime is 1.2928802132606507 minutes
2023-04-29 17:33:13,647:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:13,648:INFO:Initializing create_model()
2023-04-29 17:33:13,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:13,648:INFO:Checking exceptions
2023-04-29 17:33:13,648:INFO:Importing libraries
2023-04-29 17:33:13,648:INFO:Copying training dataset
2023-04-29 17:33:13,653:INFO:Defining folds
2023-04-29 17:33:13,653:INFO:Declaring metric variables
2023-04-29 17:33:13,653:INFO:Importing untrained model
2023-04-29 17:33:13,654:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:33:13,655:INFO:Starting cross validation
2023-04-29 17:33:13,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:21,277:INFO:Calculating mean and std
2023-04-29 17:33:21,278:INFO:Creating metrics dataframe
2023-04-29 17:33:21,935:INFO:Uploading results into container
2023-04-29 17:33:21,936:INFO:Uploading model into container now
2023-04-29 17:33:21,937:INFO:_master_model_container: 13
2023-04-29 17:33:21,937:INFO:_display_container: 2
2023-04-29 17:33:21,938:INFO:RandomForestRegressor(n_jobs=-1, random_state=6722)
2023-04-29 17:33:21,938:INFO:create_model() successfully completed......................................
2023-04-29 17:33:22,098:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:22,098:INFO:Creating metrics dataframe
2023-04-29 17:33:22,102:INFO:Initializing Extra Trees Regressor
2023-04-29 17:33:22,102:INFO:Total runtime is 1.4338092724482219 minutes
2023-04-29 17:33:22,102:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:22,103:INFO:Initializing create_model()
2023-04-29 17:33:22,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:22,103:INFO:Checking exceptions
2023-04-29 17:33:22,103:INFO:Importing libraries
2023-04-29 17:33:22,103:INFO:Copying training dataset
2023-04-29 17:33:22,106:INFO:Defining folds
2023-04-29 17:33:22,106:INFO:Declaring metric variables
2023-04-29 17:33:22,107:INFO:Importing untrained model
2023-04-29 17:33:22,107:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:33:22,108:INFO:Starting cross validation
2023-04-29 17:33:22,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:28,564:INFO:Calculating mean and std
2023-04-29 17:33:28,566:INFO:Creating metrics dataframe
2023-04-29 17:33:29,135:INFO:Uploading results into container
2023-04-29 17:33:29,136:INFO:Uploading model into container now
2023-04-29 17:33:29,136:INFO:_master_model_container: 14
2023-04-29 17:33:29,136:INFO:_display_container: 2
2023-04-29 17:33:29,136:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6722)
2023-04-29 17:33:29,136:INFO:create_model() successfully completed......................................
2023-04-29 17:33:29,250:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:29,250:INFO:Creating metrics dataframe
2023-04-29 17:33:29,254:INFO:Initializing AdaBoost Regressor
2023-04-29 17:33:29,254:INFO:Total runtime is 1.5529975056648255 minutes
2023-04-29 17:33:29,254:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:29,254:INFO:Initializing create_model()
2023-04-29 17:33:29,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:29,255:INFO:Checking exceptions
2023-04-29 17:33:29,255:INFO:Importing libraries
2023-04-29 17:33:29,255:INFO:Copying training dataset
2023-04-29 17:33:29,257:INFO:Defining folds
2023-04-29 17:33:29,257:INFO:Declaring metric variables
2023-04-29 17:33:29,257:INFO:Importing untrained model
2023-04-29 17:33:29,259:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:33:29,259:INFO:Starting cross validation
2023-04-29 17:33:29,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:34,741:INFO:Calculating mean and std
2023-04-29 17:33:34,741:INFO:Creating metrics dataframe
2023-04-29 17:33:35,737:INFO:Uploading results into container
2023-04-29 17:33:35,739:INFO:Uploading model into container now
2023-04-29 17:33:35,740:INFO:_master_model_container: 15
2023-04-29 17:33:35,740:INFO:_display_container: 2
2023-04-29 17:33:35,740:INFO:AdaBoostRegressor(random_state=6722)
2023-04-29 17:33:35,740:INFO:create_model() successfully completed......................................
2023-04-29 17:33:35,870:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:35,870:INFO:Creating metrics dataframe
2023-04-29 17:33:35,882:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:33:35,882:INFO:Total runtime is 1.6634741147359213 minutes
2023-04-29 17:33:35,883:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:35,883:INFO:Initializing create_model()
2023-04-29 17:33:35,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:35,883:INFO:Checking exceptions
2023-04-29 17:33:35,884:INFO:Importing libraries
2023-04-29 17:33:35,884:INFO:Copying training dataset
2023-04-29 17:33:35,891:INFO:Defining folds
2023-04-29 17:33:35,891:INFO:Declaring metric variables
2023-04-29 17:33:35,892:INFO:Importing untrained model
2023-04-29 17:33:35,893:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:33:35,893:INFO:Starting cross validation
2023-04-29 17:33:35,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:41,654:INFO:Calculating mean and std
2023-04-29 17:33:41,656:INFO:Creating metrics dataframe
2023-04-29 17:33:42,341:INFO:Uploading results into container
2023-04-29 17:33:42,342:INFO:Uploading model into container now
2023-04-29 17:33:42,343:INFO:_master_model_container: 16
2023-04-29 17:33:42,343:INFO:_display_container: 2
2023-04-29 17:33:42,344:INFO:GradientBoostingRegressor(random_state=6722)
2023-04-29 17:33:42,344:INFO:create_model() successfully completed......................................
2023-04-29 17:33:42,470:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:42,470:INFO:Creating metrics dataframe
2023-04-29 17:33:42,476:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:33:42,476:INFO:Total runtime is 1.7733665227890016 minutes
2023-04-29 17:33:42,476:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:42,476:INFO:Initializing create_model()
2023-04-29 17:33:42,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:42,477:INFO:Checking exceptions
2023-04-29 17:33:42,477:INFO:Importing libraries
2023-04-29 17:33:42,477:INFO:Copying training dataset
2023-04-29 17:33:42,482:INFO:Defining folds
2023-04-29 17:33:42,482:INFO:Declaring metric variables
2023-04-29 17:33:42,483:INFO:Importing untrained model
2023-04-29 17:33:42,483:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:33:42,484:INFO:Starting cross validation
2023-04-29 17:33:42,484:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:48,311:INFO:Calculating mean and std
2023-04-29 17:33:48,312:INFO:Creating metrics dataframe
2023-04-29 17:33:48,889:INFO:Uploading results into container
2023-04-29 17:33:48,890:INFO:Uploading model into container now
2023-04-29 17:33:48,891:INFO:_master_model_container: 17
2023-04-29 17:33:48,891:INFO:_display_container: 2
2023-04-29 17:33:48,892:INFO:LGBMRegressor(random_state=6722)
2023-04-29 17:33:48,892:INFO:create_model() successfully completed......................................
2023-04-29 17:33:49,020:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:49,020:INFO:Creating metrics dataframe
2023-04-29 17:33:49,029:INFO:Initializing Dummy Regressor
2023-04-29 17:33:49,029:INFO:Total runtime is 1.8825782934824626 minutes
2023-04-29 17:33:49,030:INFO:SubProcess create_model() called ==================================
2023-04-29 17:33:49,030:INFO:Initializing create_model()
2023-04-29 17:33:49,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B68AFAC0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:49,030:INFO:Checking exceptions
2023-04-29 17:33:49,031:INFO:Importing libraries
2023-04-29 17:33:49,031:INFO:Copying training dataset
2023-04-29 17:33:49,036:INFO:Defining folds
2023-04-29 17:33:49,038:INFO:Declaring metric variables
2023-04-29 17:33:49,038:INFO:Importing untrained model
2023-04-29 17:33:49,038:INFO:Dummy Regressor Imported successfully
2023-04-29 17:33:49,038:INFO:Starting cross validation
2023-04-29 17:33:49,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:33:53,932:INFO:Calculating mean and std
2023-04-29 17:33:53,933:INFO:Creating metrics dataframe
2023-04-29 17:33:54,483:INFO:Uploading results into container
2023-04-29 17:33:54,483:INFO:Uploading model into container now
2023-04-29 17:33:54,484:INFO:_master_model_container: 18
2023-04-29 17:33:54,484:INFO:_display_container: 2
2023-04-29 17:33:54,484:INFO:DummyRegressor()
2023-04-29 17:33:54,484:INFO:create_model() successfully completed......................................
2023-04-29 17:33:54,593:INFO:SubProcess create_model() end ==================================
2023-04-29 17:33:54,594:INFO:Creating metrics dataframe
2023-04-29 17:33:54,604:INFO:Initializing create_model()
2023-04-29 17:33:54,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=6722), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:33:54,605:INFO:Checking exceptions
2023-04-29 17:33:54,607:INFO:Importing libraries
2023-04-29 17:33:54,608:INFO:Copying training dataset
2023-04-29 17:33:54,617:INFO:Defining folds
2023-04-29 17:33:54,617:INFO:Declaring metric variables
2023-04-29 17:33:54,617:INFO:Importing untrained model
2023-04-29 17:33:54,617:INFO:Declaring custom model
2023-04-29 17:33:54,619:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:33:54,620:INFO:Cross validation set to False
2023-04-29 17:33:54,621:INFO:Fitting Model
2023-04-29 17:33:55,630:INFO:RandomForestRegressor(n_jobs=-1, random_state=6722)
2023-04-29 17:33:55,631:INFO:create_model() successfully completed......................................
2023-04-29 17:33:55,761:INFO:_master_model_container: 18
2023-04-29 17:33:55,761:INFO:_display_container: 2
2023-04-29 17:33:55,762:INFO:RandomForestRegressor(n_jobs=-1, random_state=6722)
2023-04-29 17:33:55,762:INFO:compare_models() successfully completed......................................
2023-04-29 17:33:55,768:INFO:Initializing predict_model()
2023-04-29 17:33:55,769:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6FA0CA0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=6722), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B8C84C10>)
2023-04-29 17:33:55,769:INFO:Checking exceptions
2023-04-29 17:33:55,769:INFO:Preloading libraries
2023-04-29 17:33:55,769:INFO:Set up data.
2023-04-29 17:33:55,773:INFO:Set up index.
2023-04-29 17:35:04,449:INFO:PyCaret RegressionExperiment
2023-04-29 17:35:04,449:INFO:Logging name: reg-default-name
2023-04-29 17:35:04,450:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:35:04,450:INFO:version 3.0.0
2023-04-29 17:35:04,450:INFO:Initializing setup()
2023-04-29 17:35:04,450:INFO:self.USI: 93b0
2023-04-29 17:35:04,450:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:35:04,450:INFO:Checking environment
2023-04-29 17:35:04,450:INFO:python_version: 3.9.13
2023-04-29 17:35:04,450:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:35:04,450:INFO:machine: AMD64
2023-04-29 17:35:04,451:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:35:04,451:INFO:Memory: svmem(total=16935899136, available=5451571200, percent=67.8, used=11484327936, free=5451571200)
2023-04-29 17:35:04,451:INFO:Physical Core: 4
2023-04-29 17:35:04,451:INFO:Logical Core: 8
2023-04-29 17:35:04,451:INFO:Checking libraries
2023-04-29 17:35:04,451:INFO:System:
2023-04-29 17:35:04,451:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:35:04,451:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:35:04,451:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:35:04,452:INFO:PyCaret required dependencies:
2023-04-29 17:35:04,452:INFO:                 pip: 22.2.2
2023-04-29 17:35:04,452:INFO:          setuptools: 63.4.1
2023-04-29 17:35:04,453:INFO:             pycaret: 3.0.0
2023-04-29 17:35:04,453:INFO:             IPython: 7.31.1
2023-04-29 17:35:04,453:INFO:          ipywidgets: 7.6.5
2023-04-29 17:35:04,453:INFO:                tqdm: 4.64.1
2023-04-29 17:35:04,453:INFO:               numpy: 1.21.5
2023-04-29 17:35:04,453:INFO:              pandas: 1.4.4
2023-04-29 17:35:04,453:INFO:              jinja2: 2.11.3
2023-04-29 17:35:04,453:INFO:               scipy: 1.9.1
2023-04-29 17:35:04,453:INFO:              joblib: 1.2.0
2023-04-29 17:35:04,453:INFO:             sklearn: 1.0.2
2023-04-29 17:35:04,453:INFO:                pyod: 1.0.9
2023-04-29 17:35:04,453:INFO:            imblearn: 0.10.1
2023-04-29 17:35:04,453:INFO:   category_encoders: 2.6.0
2023-04-29 17:35:04,453:INFO:            lightgbm: 3.3.5
2023-04-29 17:35:04,453:INFO:               numba: 0.55.1
2023-04-29 17:35:04,453:INFO:            requests: 2.28.1
2023-04-29 17:35:04,453:INFO:          matplotlib: 3.5.2
2023-04-29 17:35:04,453:INFO:          scikitplot: 0.3.7
2023-04-29 17:35:04,453:INFO:         yellowbrick: 1.5
2023-04-29 17:35:04,453:INFO:              plotly: 5.9.0
2023-04-29 17:35:04,453:INFO:             kaleido: 0.2.1
2023-04-29 17:35:04,453:INFO:         statsmodels: 0.13.2
2023-04-29 17:35:04,453:INFO:              sktime: 0.17.1
2023-04-29 17:35:04,453:INFO:               tbats: 1.1.2
2023-04-29 17:35:04,453:INFO:            pmdarima: 2.0.3
2023-04-29 17:35:04,453:INFO:              psutil: 5.9.0
2023-04-29 17:35:04,453:INFO:PyCaret optional dependencies:
2023-04-29 17:35:04,453:INFO:                shap: 0.41.0
2023-04-29 17:35:04,453:INFO:           interpret: Not installed
2023-04-29 17:35:04,453:INFO:                umap: Not installed
2023-04-29 17:35:04,453:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:35:04,453:INFO:  explainerdashboard: Not installed
2023-04-29 17:35:04,453:INFO:             autoviz: Not installed
2023-04-29 17:35:04,453:INFO:           fairlearn: Not installed
2023-04-29 17:35:04,453:INFO:             xgboost: Not installed
2023-04-29 17:35:04,453:INFO:            catboost: Not installed
2023-04-29 17:35:04,453:INFO:              kmodes: Not installed
2023-04-29 17:35:04,454:INFO:             mlxtend: Not installed
2023-04-29 17:35:04,454:INFO:       statsforecast: Not installed
2023-04-29 17:35:04,454:INFO:        tune_sklearn: Not installed
2023-04-29 17:35:04,454:INFO:                 ray: Not installed
2023-04-29 17:35:04,454:INFO:            hyperopt: Not installed
2023-04-29 17:35:04,454:INFO:              optuna: Not installed
2023-04-29 17:35:04,454:INFO:               skopt: Not installed
2023-04-29 17:35:04,454:INFO:              mlflow: 2.2.1
2023-04-29 17:35:04,454:INFO:              gradio: Not installed
2023-04-29 17:35:04,454:INFO:             fastapi: Not installed
2023-04-29 17:35:04,454:INFO:             uvicorn: Not installed
2023-04-29 17:35:04,454:INFO:              m2cgen: Not installed
2023-04-29 17:35:04,454:INFO:           evidently: Not installed
2023-04-29 17:35:04,454:INFO:               fugue: Not installed
2023-04-29 17:35:04,454:INFO:           streamlit: 1.21.0
2023-04-29 17:35:04,454:INFO:             prophet: Not installed
2023-04-29 17:35:04,454:INFO:None
2023-04-29 17:35:04,454:INFO:Set up data.
2023-04-29 17:35:04,458:INFO:Set up train/test split.
2023-04-29 17:35:04,461:INFO:Set up index.
2023-04-29 17:35:04,462:INFO:Set up folding strategy.
2023-04-29 17:35:04,462:INFO:Assigning column types.
2023-04-29 17:35:04,465:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:35:04,465:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,470:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,474:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:04,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:04,623:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,628:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,700:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:04,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:04,793:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:35:04,808:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,815:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:35:04,952:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,028:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,142:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:35:05,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,229:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,532:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:35:05,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,831:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:35:05,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:05,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:05,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,037:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:35:06,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,101:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:35:06,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,357:INFO:Preparing preprocessing pipeline...
2023-04-29 17:35:06,357:INFO:Set up simple imputation.
2023-04-29 17:35:06,357:INFO:Set up column name cleaning.
2023-04-29 17:35:06,388:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:35:06,398:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:35:06,398:INFO:Creating final display dataframe.
2023-04-29 17:35:06,523:INFO:Setup _display_container:                     Description             Value
0                    Session id              6203
1                        Target               VEC
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              93b0
2023-04-29 17:35:06,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:35:06,988:INFO:setup() successfully completed in 3.01s...............
2023-04-29 17:35:06,995:INFO:Initializing compare_models()
2023-04-29 17:35:06,996:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:35:06,996:INFO:Checking exceptions
2023-04-29 17:35:06,999:INFO:Preparing display monitor
2023-04-29 17:35:07,003:INFO:Initializing Linear Regression
2023-04-29 17:35:07,003:INFO:Total runtime is 0.0 minutes
2023-04-29 17:35:07,003:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:07,004:INFO:Initializing create_model()
2023-04-29 17:35:07,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:07,004:INFO:Checking exceptions
2023-04-29 17:35:07,004:INFO:Importing libraries
2023-04-29 17:35:07,004:INFO:Copying training dataset
2023-04-29 17:35:07,011:INFO:Defining folds
2023-04-29 17:35:07,011:INFO:Declaring metric variables
2023-04-29 17:35:07,011:INFO:Importing untrained model
2023-04-29 17:35:07,012:INFO:Linear Regression Imported successfully
2023-04-29 17:35:07,012:INFO:Starting cross validation
2023-04-29 17:35:07,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:12,005:INFO:Calculating mean and std
2023-04-29 17:35:12,007:INFO:Creating metrics dataframe
2023-04-29 17:35:12,609:INFO:Uploading results into container
2023-04-29 17:35:12,611:INFO:Uploading model into container now
2023-04-29 17:35:12,612:INFO:_master_model_container: 1
2023-04-29 17:35:12,612:INFO:_display_container: 2
2023-04-29 17:35:12,612:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:35:12,613:INFO:create_model() successfully completed......................................
2023-04-29 17:35:12,757:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:12,757:INFO:Creating metrics dataframe
2023-04-29 17:35:12,763:INFO:Initializing Lasso Regression
2023-04-29 17:35:12,763:INFO:Total runtime is 0.09599742094675699 minutes
2023-04-29 17:35:12,764:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:12,764:INFO:Initializing create_model()
2023-04-29 17:35:12,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:12,764:INFO:Checking exceptions
2023-04-29 17:35:12,764:INFO:Importing libraries
2023-04-29 17:35:12,764:INFO:Copying training dataset
2023-04-29 17:35:12,768:INFO:Defining folds
2023-04-29 17:35:12,769:INFO:Declaring metric variables
2023-04-29 17:35:12,769:INFO:Importing untrained model
2023-04-29 17:35:12,769:INFO:Lasso Regression Imported successfully
2023-04-29 17:35:12,769:INFO:Starting cross validation
2023-04-29 17:35:12,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:18,268:INFO:Calculating mean and std
2023-04-29 17:35:18,270:INFO:Creating metrics dataframe
2023-04-29 17:35:18,779:INFO:Uploading results into container
2023-04-29 17:35:18,780:INFO:Uploading model into container now
2023-04-29 17:35:18,780:INFO:_master_model_container: 2
2023-04-29 17:35:18,780:INFO:_display_container: 2
2023-04-29 17:35:18,781:INFO:Lasso(random_state=6203)
2023-04-29 17:35:18,781:INFO:create_model() successfully completed......................................
2023-04-29 17:35:18,902:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:18,902:INFO:Creating metrics dataframe
2023-04-29 17:35:18,906:INFO:Initializing Ridge Regression
2023-04-29 17:35:18,907:INFO:Total runtime is 0.1984045187632243 minutes
2023-04-29 17:35:18,907:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:18,907:INFO:Initializing create_model()
2023-04-29 17:35:18,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:18,907:INFO:Checking exceptions
2023-04-29 17:35:18,907:INFO:Importing libraries
2023-04-29 17:35:18,907:INFO:Copying training dataset
2023-04-29 17:35:18,911:INFO:Defining folds
2023-04-29 17:35:18,911:INFO:Declaring metric variables
2023-04-29 17:35:18,912:INFO:Importing untrained model
2023-04-29 17:35:18,912:INFO:Ridge Regression Imported successfully
2023-04-29 17:35:18,913:INFO:Starting cross validation
2023-04-29 17:35:18,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:23,699:INFO:Calculating mean and std
2023-04-29 17:35:23,700:INFO:Creating metrics dataframe
2023-04-29 17:35:24,228:INFO:Uploading results into container
2023-04-29 17:35:24,228:INFO:Uploading model into container now
2023-04-29 17:35:24,229:INFO:_master_model_container: 3
2023-04-29 17:35:24,229:INFO:_display_container: 2
2023-04-29 17:35:24,229:INFO:Ridge(random_state=6203)
2023-04-29 17:35:24,229:INFO:create_model() successfully completed......................................
2023-04-29 17:35:24,337:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:24,337:INFO:Creating metrics dataframe
2023-04-29 17:35:24,347:INFO:Initializing Elastic Net
2023-04-29 17:35:24,350:INFO:Total runtime is 0.2891147255897522 minutes
2023-04-29 17:35:24,350:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:24,351:INFO:Initializing create_model()
2023-04-29 17:35:24,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:24,351:INFO:Checking exceptions
2023-04-29 17:35:24,351:INFO:Importing libraries
2023-04-29 17:35:24,351:INFO:Copying training dataset
2023-04-29 17:35:24,359:INFO:Defining folds
2023-04-29 17:35:24,359:INFO:Declaring metric variables
2023-04-29 17:35:24,359:INFO:Importing untrained model
2023-04-29 17:35:24,360:INFO:Elastic Net Imported successfully
2023-04-29 17:35:24,361:INFO:Starting cross validation
2023-04-29 17:35:24,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:32,733:INFO:Calculating mean and std
2023-04-29 17:35:32,734:INFO:Creating metrics dataframe
2023-04-29 17:35:33,253:INFO:Uploading results into container
2023-04-29 17:35:33,254:INFO:Uploading model into container now
2023-04-29 17:35:33,254:INFO:_master_model_container: 4
2023-04-29 17:35:33,254:INFO:_display_container: 2
2023-04-29 17:35:33,255:INFO:ElasticNet(random_state=6203)
2023-04-29 17:35:33,255:INFO:create_model() successfully completed......................................
2023-04-29 17:35:33,360:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:33,360:INFO:Creating metrics dataframe
2023-04-29 17:35:33,364:INFO:Initializing Least Angle Regression
2023-04-29 17:35:33,364:INFO:Total runtime is 0.43934974273045857 minutes
2023-04-29 17:35:33,364:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:33,365:INFO:Initializing create_model()
2023-04-29 17:35:33,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:33,365:INFO:Checking exceptions
2023-04-29 17:35:33,365:INFO:Importing libraries
2023-04-29 17:35:33,365:INFO:Copying training dataset
2023-04-29 17:35:33,368:INFO:Defining folds
2023-04-29 17:35:33,368:INFO:Declaring metric variables
2023-04-29 17:35:33,369:INFO:Importing untrained model
2023-04-29 17:35:33,370:INFO:Least Angle Regression Imported successfully
2023-04-29 17:35:33,370:INFO:Starting cross validation
2023-04-29 17:35:33,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:33,453:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,461:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,477:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,495:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,501:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,521:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,533:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:33,550:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:34,428:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:34,475:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:37,952:INFO:Calculating mean and std
2023-04-29 17:35:37,953:INFO:Creating metrics dataframe
2023-04-29 17:35:38,459:INFO:Uploading results into container
2023-04-29 17:35:38,460:INFO:Uploading model into container now
2023-04-29 17:35:38,460:INFO:_master_model_container: 5
2023-04-29 17:35:38,460:INFO:_display_container: 2
2023-04-29 17:35:38,461:INFO:Lars(random_state=6203)
2023-04-29 17:35:38,461:INFO:create_model() successfully completed......................................
2023-04-29 17:35:38,576:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:38,577:INFO:Creating metrics dataframe
2023-04-29 17:35:38,581:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:35:38,581:INFO:Total runtime is 0.5263025164604187 minutes
2023-04-29 17:35:38,581:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:38,581:INFO:Initializing create_model()
2023-04-29 17:35:38,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:38,581:INFO:Checking exceptions
2023-04-29 17:35:38,582:INFO:Importing libraries
2023-04-29 17:35:38,582:INFO:Copying training dataset
2023-04-29 17:35:38,586:INFO:Defining folds
2023-04-29 17:35:38,586:INFO:Declaring metric variables
2023-04-29 17:35:38,586:INFO:Importing untrained model
2023-04-29 17:35:38,587:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:35:38,588:INFO:Starting cross validation
2023-04-29 17:35:38,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:38,684:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,689:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,702:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,719:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,730:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,740:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,755:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:38,770:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:39,677:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:39,700:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:35:43,254:INFO:Calculating mean and std
2023-04-29 17:35:43,256:INFO:Creating metrics dataframe
2023-04-29 17:35:43,766:INFO:Uploading results into container
2023-04-29 17:35:43,766:INFO:Uploading model into container now
2023-04-29 17:35:43,767:INFO:_master_model_container: 6
2023-04-29 17:35:43,767:INFO:_display_container: 2
2023-04-29 17:35:43,767:INFO:LassoLars(random_state=6203)
2023-04-29 17:35:43,767:INFO:create_model() successfully completed......................................
2023-04-29 17:35:43,890:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:43,890:INFO:Creating metrics dataframe
2023-04-29 17:35:43,897:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:35:43,897:INFO:Total runtime is 0.6149022897084554 minutes
2023-04-29 17:35:43,897:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:43,898:INFO:Initializing create_model()
2023-04-29 17:35:43,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:43,898:INFO:Checking exceptions
2023-04-29 17:35:43,898:INFO:Importing libraries
2023-04-29 17:35:43,898:INFO:Copying training dataset
2023-04-29 17:35:43,903:INFO:Defining folds
2023-04-29 17:35:43,903:INFO:Declaring metric variables
2023-04-29 17:35:43,904:INFO:Importing untrained model
2023-04-29 17:35:43,904:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:35:43,904:INFO:Starting cross validation
2023-04-29 17:35:43,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:43,980:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:43,998:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:44,012:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:44,019:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:44,035:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:44,054:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:44,066:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:44,079:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:45,000:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:45,018:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:35:48,886:INFO:Calculating mean and std
2023-04-29 17:35:48,887:INFO:Creating metrics dataframe
2023-04-29 17:35:49,413:INFO:Uploading results into container
2023-04-29 17:35:49,414:INFO:Uploading model into container now
2023-04-29 17:35:49,415:INFO:_master_model_container: 7
2023-04-29 17:35:49,415:INFO:_display_container: 2
2023-04-29 17:35:49,416:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:35:49,416:INFO:create_model() successfully completed......................................
2023-04-29 17:35:49,529:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:49,529:INFO:Creating metrics dataframe
2023-04-29 17:35:49,533:INFO:Initializing Bayesian Ridge
2023-04-29 17:35:49,533:INFO:Total runtime is 0.708839476108551 minutes
2023-04-29 17:35:49,533:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:49,533:INFO:Initializing create_model()
2023-04-29 17:35:49,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:49,533:INFO:Checking exceptions
2023-04-29 17:35:49,533:INFO:Importing libraries
2023-04-29 17:35:49,534:INFO:Copying training dataset
2023-04-29 17:35:49,537:INFO:Defining folds
2023-04-29 17:35:49,537:INFO:Declaring metric variables
2023-04-29 17:35:49,537:INFO:Importing untrained model
2023-04-29 17:35:49,537:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:35:49,538:INFO:Starting cross validation
2023-04-29 17:35:49,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:35:54,257:INFO:Calculating mean and std
2023-04-29 17:35:54,259:INFO:Creating metrics dataframe
2023-04-29 17:35:55,562:INFO:Uploading results into container
2023-04-29 17:35:55,564:INFO:Uploading model into container now
2023-04-29 17:35:55,566:INFO:_master_model_container: 8
2023-04-29 17:35:55,566:INFO:_display_container: 2
2023-04-29 17:35:55,567:INFO:BayesianRidge()
2023-04-29 17:35:55,567:INFO:create_model() successfully completed......................................
2023-04-29 17:35:55,779:INFO:SubProcess create_model() end ==================================
2023-04-29 17:35:55,779:INFO:Creating metrics dataframe
2023-04-29 17:35:55,790:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:35:55,790:INFO:Total runtime is 0.8131261984507243 minutes
2023-04-29 17:35:55,791:INFO:SubProcess create_model() called ==================================
2023-04-29 17:35:55,792:INFO:Initializing create_model()
2023-04-29 17:35:55,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:35:55,792:INFO:Checking exceptions
2023-04-29 17:35:55,792:INFO:Importing libraries
2023-04-29 17:35:55,792:INFO:Copying training dataset
2023-04-29 17:35:55,800:INFO:Defining folds
2023-04-29 17:35:55,800:INFO:Declaring metric variables
2023-04-29 17:35:55,800:INFO:Importing untrained model
2023-04-29 17:35:55,802:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:35:55,802:INFO:Starting cross validation
2023-04-29 17:35:55,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:06,323:INFO:Calculating mean and std
2023-04-29 17:36:06,324:INFO:Creating metrics dataframe
2023-04-29 17:36:07,145:INFO:Uploading results into container
2023-04-29 17:36:07,145:INFO:Uploading model into container now
2023-04-29 17:36:07,146:INFO:_master_model_container: 9
2023-04-29 17:36:07,146:INFO:_display_container: 2
2023-04-29 17:36:07,147:INFO:PassiveAggressiveRegressor(random_state=6203)
2023-04-29 17:36:07,147:INFO:create_model() successfully completed......................................
2023-04-29 17:36:07,264:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:07,264:INFO:Creating metrics dataframe
2023-04-29 17:36:07,268:INFO:Initializing Huber Regressor
2023-04-29 17:36:07,268:INFO:Total runtime is 1.0044237891832988 minutes
2023-04-29 17:36:07,268:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:07,269:INFO:Initializing create_model()
2023-04-29 17:36:07,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:07,269:INFO:Checking exceptions
2023-04-29 17:36:07,269:INFO:Importing libraries
2023-04-29 17:36:07,269:INFO:Copying training dataset
2023-04-29 17:36:07,272:INFO:Defining folds
2023-04-29 17:36:07,272:INFO:Declaring metric variables
2023-04-29 17:36:07,272:INFO:Importing untrained model
2023-04-29 17:36:07,273:INFO:Huber Regressor Imported successfully
2023-04-29 17:36:07,273:INFO:Starting cross validation
2023-04-29 17:36:07,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:07,432:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:36:08,662:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:36:12,141:INFO:Calculating mean and std
2023-04-29 17:36:12,142:INFO:Creating metrics dataframe
2023-04-29 17:36:12,761:INFO:Uploading results into container
2023-04-29 17:36:12,762:INFO:Uploading model into container now
2023-04-29 17:36:12,763:INFO:_master_model_container: 10
2023-04-29 17:36:12,763:INFO:_display_container: 2
2023-04-29 17:36:12,763:INFO:HuberRegressor()
2023-04-29 17:36:12,763:INFO:create_model() successfully completed......................................
2023-04-29 17:36:12,935:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:12,935:INFO:Creating metrics dataframe
2023-04-29 17:36:12,950:INFO:Initializing K Neighbors Regressor
2023-04-29 17:36:12,950:INFO:Total runtime is 1.0991271654764811 minutes
2023-04-29 17:36:12,950:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:12,952:INFO:Initializing create_model()
2023-04-29 17:36:12,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:12,953:INFO:Checking exceptions
2023-04-29 17:36:12,953:INFO:Importing libraries
2023-04-29 17:36:12,953:INFO:Copying training dataset
2023-04-29 17:36:12,964:INFO:Defining folds
2023-04-29 17:36:12,964:INFO:Declaring metric variables
2023-04-29 17:36:12,964:INFO:Importing untrained model
2023-04-29 17:36:12,966:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:36:12,966:INFO:Starting cross validation
2023-04-29 17:36:12,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:20,614:INFO:Calculating mean and std
2023-04-29 17:36:20,616:INFO:Creating metrics dataframe
2023-04-29 17:36:21,478:INFO:Uploading results into container
2023-04-29 17:36:21,479:INFO:Uploading model into container now
2023-04-29 17:36:21,480:INFO:_master_model_container: 11
2023-04-29 17:36:21,480:INFO:_display_container: 2
2023-04-29 17:36:21,480:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:36:21,480:INFO:create_model() successfully completed......................................
2023-04-29 17:36:21,608:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:21,608:INFO:Creating metrics dataframe
2023-04-29 17:36:21,618:INFO:Initializing Decision Tree Regressor
2023-04-29 17:36:21,620:INFO:Total runtime is 1.2436122258504232 minutes
2023-04-29 17:36:21,620:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:21,620:INFO:Initializing create_model()
2023-04-29 17:36:21,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:21,620:INFO:Checking exceptions
2023-04-29 17:36:21,620:INFO:Importing libraries
2023-04-29 17:36:21,621:INFO:Copying training dataset
2023-04-29 17:36:21,628:INFO:Defining folds
2023-04-29 17:36:21,628:INFO:Declaring metric variables
2023-04-29 17:36:21,628:INFO:Importing untrained model
2023-04-29 17:36:21,628:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:36:21,630:INFO:Starting cross validation
2023-04-29 17:36:21,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:26,792:INFO:Calculating mean and std
2023-04-29 17:36:26,793:INFO:Creating metrics dataframe
2023-04-29 17:36:27,414:INFO:Uploading results into container
2023-04-29 17:36:27,416:INFO:Uploading model into container now
2023-04-29 17:36:27,416:INFO:_master_model_container: 12
2023-04-29 17:36:27,416:INFO:_display_container: 2
2023-04-29 17:36:27,417:INFO:DecisionTreeRegressor(random_state=6203)
2023-04-29 17:36:27,418:INFO:create_model() successfully completed......................................
2023-04-29 17:36:27,515:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:27,516:INFO:Creating metrics dataframe
2023-04-29 17:36:27,521:INFO:Initializing Random Forest Regressor
2023-04-29 17:36:27,521:INFO:Total runtime is 1.3419734160105388 minutes
2023-04-29 17:36:27,521:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:27,522:INFO:Initializing create_model()
2023-04-29 17:36:27,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:27,522:INFO:Checking exceptions
2023-04-29 17:36:27,522:INFO:Importing libraries
2023-04-29 17:36:27,522:INFO:Copying training dataset
2023-04-29 17:36:27,525:INFO:Defining folds
2023-04-29 17:36:27,525:INFO:Declaring metric variables
2023-04-29 17:36:27,525:INFO:Importing untrained model
2023-04-29 17:36:27,525:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:36:27,526:INFO:Starting cross validation
2023-04-29 17:36:27,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:33,459:INFO:Calculating mean and std
2023-04-29 17:36:33,460:INFO:Creating metrics dataframe
2023-04-29 17:36:34,014:INFO:Uploading results into container
2023-04-29 17:36:34,015:INFO:Uploading model into container now
2023-04-29 17:36:34,015:INFO:_master_model_container: 13
2023-04-29 17:36:34,015:INFO:_display_container: 2
2023-04-29 17:36:34,016:INFO:RandomForestRegressor(n_jobs=-1, random_state=6203)
2023-04-29 17:36:34,016:INFO:create_model() successfully completed......................................
2023-04-29 17:36:34,131:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:34,131:INFO:Creating metrics dataframe
2023-04-29 17:36:34,136:INFO:Initializing Extra Trees Regressor
2023-04-29 17:36:34,136:INFO:Total runtime is 1.452225935459137 minutes
2023-04-29 17:36:34,136:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:34,136:INFO:Initializing create_model()
2023-04-29 17:36:34,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:34,137:INFO:Checking exceptions
2023-04-29 17:36:34,137:INFO:Importing libraries
2023-04-29 17:36:34,137:INFO:Copying training dataset
2023-04-29 17:36:34,140:INFO:Defining folds
2023-04-29 17:36:34,141:INFO:Declaring metric variables
2023-04-29 17:36:34,141:INFO:Importing untrained model
2023-04-29 17:36:34,141:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:36:34,142:INFO:Starting cross validation
2023-04-29 17:36:34,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:41,413:INFO:Calculating mean and std
2023-04-29 17:36:41,416:INFO:Creating metrics dataframe
2023-04-29 17:36:42,055:INFO:Uploading results into container
2023-04-29 17:36:42,056:INFO:Uploading model into container now
2023-04-29 17:36:42,056:INFO:_master_model_container: 14
2023-04-29 17:36:42,057:INFO:_display_container: 2
2023-04-29 17:36:42,057:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6203)
2023-04-29 17:36:42,057:INFO:create_model() successfully completed......................................
2023-04-29 17:36:42,172:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:42,173:INFO:Creating metrics dataframe
2023-04-29 17:36:42,176:INFO:Initializing AdaBoost Regressor
2023-04-29 17:36:42,177:INFO:Total runtime is 1.5862413048744202 minutes
2023-04-29 17:36:42,177:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:42,178:INFO:Initializing create_model()
2023-04-29 17:36:42,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:42,178:INFO:Checking exceptions
2023-04-29 17:36:42,178:INFO:Importing libraries
2023-04-29 17:36:42,178:INFO:Copying training dataset
2023-04-29 17:36:42,182:INFO:Defining folds
2023-04-29 17:36:42,182:INFO:Declaring metric variables
2023-04-29 17:36:42,182:INFO:Importing untrained model
2023-04-29 17:36:42,183:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:36:42,183:INFO:Starting cross validation
2023-04-29 17:36:42,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:48,552:INFO:Calculating mean and std
2023-04-29 17:36:48,553:INFO:Creating metrics dataframe
2023-04-29 17:36:49,124:INFO:Uploading results into container
2023-04-29 17:36:49,124:INFO:Uploading model into container now
2023-04-29 17:36:49,125:INFO:_master_model_container: 15
2023-04-29 17:36:49,125:INFO:_display_container: 2
2023-04-29 17:36:49,125:INFO:AdaBoostRegressor(random_state=6203)
2023-04-29 17:36:49,125:INFO:create_model() successfully completed......................................
2023-04-29 17:36:49,262:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:49,262:INFO:Creating metrics dataframe
2023-04-29 17:36:49,268:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:36:49,268:INFO:Total runtime is 1.7044259587923685 minutes
2023-04-29 17:36:49,268:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:49,268:INFO:Initializing create_model()
2023-04-29 17:36:49,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:49,268:INFO:Checking exceptions
2023-04-29 17:36:49,268:INFO:Importing libraries
2023-04-29 17:36:49,269:INFO:Copying training dataset
2023-04-29 17:36:49,272:INFO:Defining folds
2023-04-29 17:36:49,273:INFO:Declaring metric variables
2023-04-29 17:36:49,273:INFO:Importing untrained model
2023-04-29 17:36:49,273:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:36:49,273:INFO:Starting cross validation
2023-04-29 17:36:49,273:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:36:55,811:INFO:Calculating mean and std
2023-04-29 17:36:55,814:INFO:Creating metrics dataframe
2023-04-29 17:36:56,495:INFO:Uploading results into container
2023-04-29 17:36:56,496:INFO:Uploading model into container now
2023-04-29 17:36:56,497:INFO:_master_model_container: 16
2023-04-29 17:36:56,497:INFO:_display_container: 2
2023-04-29 17:36:56,497:INFO:GradientBoostingRegressor(random_state=6203)
2023-04-29 17:36:56,497:INFO:create_model() successfully completed......................................
2023-04-29 17:36:56,621:INFO:SubProcess create_model() end ==================================
2023-04-29 17:36:56,621:INFO:Creating metrics dataframe
2023-04-29 17:36:56,634:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:36:56,635:INFO:Total runtime is 1.8272054314613342 minutes
2023-04-29 17:36:56,636:INFO:SubProcess create_model() called ==================================
2023-04-29 17:36:56,637:INFO:Initializing create_model()
2023-04-29 17:36:56,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:36:56,637:INFO:Checking exceptions
2023-04-29 17:36:56,638:INFO:Importing libraries
2023-04-29 17:36:56,638:INFO:Copying training dataset
2023-04-29 17:36:56,658:INFO:Defining folds
2023-04-29 17:36:56,658:INFO:Declaring metric variables
2023-04-29 17:36:56,659:INFO:Importing untrained model
2023-04-29 17:36:56,661:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:36:56,662:INFO:Starting cross validation
2023-04-29 17:36:56,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:37:03,162:INFO:Calculating mean and std
2023-04-29 17:37:03,164:INFO:Creating metrics dataframe
2023-04-29 17:37:03,725:INFO:Uploading results into container
2023-04-29 17:37:03,725:INFO:Uploading model into container now
2023-04-29 17:37:03,726:INFO:_master_model_container: 17
2023-04-29 17:37:03,726:INFO:_display_container: 2
2023-04-29 17:37:03,726:INFO:LGBMRegressor(random_state=6203)
2023-04-29 17:37:03,726:INFO:create_model() successfully completed......................................
2023-04-29 17:37:03,841:INFO:SubProcess create_model() end ==================================
2023-04-29 17:37:03,841:INFO:Creating metrics dataframe
2023-04-29 17:37:03,849:INFO:Initializing Dummy Regressor
2023-04-29 17:37:03,849:INFO:Total runtime is 1.9474347472190856 minutes
2023-04-29 17:37:03,849:INFO:SubProcess create_model() called ==================================
2023-04-29 17:37:03,849:INFO:Initializing create_model()
2023-04-29 17:37:03,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B65D63D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:37:03,850:INFO:Checking exceptions
2023-04-29 17:37:03,850:INFO:Importing libraries
2023-04-29 17:37:03,850:INFO:Copying training dataset
2023-04-29 17:37:03,853:INFO:Defining folds
2023-04-29 17:37:03,853:INFO:Declaring metric variables
2023-04-29 17:37:03,853:INFO:Importing untrained model
2023-04-29 17:37:03,853:INFO:Dummy Regressor Imported successfully
2023-04-29 17:37:03,855:INFO:Starting cross validation
2023-04-29 17:37:03,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:37:10,274:INFO:Calculating mean and std
2023-04-29 17:37:10,275:INFO:Creating metrics dataframe
2023-04-29 17:37:10,994:INFO:Uploading results into container
2023-04-29 17:37:10,995:INFO:Uploading model into container now
2023-04-29 17:37:10,995:INFO:_master_model_container: 18
2023-04-29 17:37:10,996:INFO:_display_container: 2
2023-04-29 17:37:10,996:INFO:DummyRegressor()
2023-04-29 17:37:10,996:INFO:create_model() successfully completed......................................
2023-04-29 17:37:11,143:INFO:SubProcess create_model() end ==================================
2023-04-29 17:37:11,143:INFO:Creating metrics dataframe
2023-04-29 17:37:11,151:INFO:Initializing create_model()
2023-04-29 17:37:11,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6203), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:37:11,151:INFO:Checking exceptions
2023-04-29 17:37:11,151:INFO:Importing libraries
2023-04-29 17:37:11,151:INFO:Copying training dataset
2023-04-29 17:37:11,154:INFO:Defining folds
2023-04-29 17:37:11,154:INFO:Declaring metric variables
2023-04-29 17:37:11,154:INFO:Importing untrained model
2023-04-29 17:37:11,154:INFO:Declaring custom model
2023-04-29 17:37:11,155:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:37:11,155:INFO:Cross validation set to False
2023-04-29 17:37:11,155:INFO:Fitting Model
2023-04-29 17:37:12,049:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6203)
2023-04-29 17:37:12,049:INFO:create_model() successfully completed......................................
2023-04-29 17:37:12,238:INFO:_master_model_container: 18
2023-04-29 17:37:12,239:INFO:_display_container: 2
2023-04-29 17:37:12,240:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6203)
2023-04-29 17:37:12,240:INFO:compare_models() successfully completed......................................
2023-04-29 17:37:12,247:INFO:Initializing predict_model()
2023-04-29 17:37:12,247:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6DCDEE0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6203), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B77590D0>)
2023-04-29 17:37:12,247:INFO:Checking exceptions
2023-04-29 17:37:12,248:INFO:Preloading libraries
2023-04-29 17:37:12,248:INFO:Set up data.
2023-04-29 17:37:12,253:INFO:Set up index.
2023-04-29 17:42:08,816:INFO:PyCaret RegressionExperiment
2023-04-29 17:42:08,816:INFO:Logging name: reg-default-name
2023-04-29 17:42:08,816:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:42:08,816:INFO:version 3.0.0
2023-04-29 17:42:08,816:INFO:Initializing setup()
2023-04-29 17:42:08,816:INFO:self.USI: 5c2c
2023-04-29 17:42:08,816:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:42:08,816:INFO:Checking environment
2023-04-29 17:42:08,816:INFO:python_version: 3.9.13
2023-04-29 17:42:08,816:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:42:08,816:INFO:machine: AMD64
2023-04-29 17:42:08,816:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:42:08,817:INFO:Memory: svmem(total=16935899136, available=6614134784, percent=60.9, used=10321764352, free=6614134784)
2023-04-29 17:42:08,817:INFO:Physical Core: 4
2023-04-29 17:42:08,817:INFO:Logical Core: 8
2023-04-29 17:42:08,817:INFO:Checking libraries
2023-04-29 17:42:08,817:INFO:System:
2023-04-29 17:42:08,817:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:42:08,817:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:42:08,817:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:42:08,817:INFO:PyCaret required dependencies:
2023-04-29 17:42:08,817:INFO:                 pip: 22.2.2
2023-04-29 17:42:08,817:INFO:          setuptools: 63.4.1
2023-04-29 17:42:08,817:INFO:             pycaret: 3.0.0
2023-04-29 17:42:08,817:INFO:             IPython: 7.31.1
2023-04-29 17:42:08,817:INFO:          ipywidgets: 7.6.5
2023-04-29 17:42:08,817:INFO:                tqdm: 4.64.1
2023-04-29 17:42:08,817:INFO:               numpy: 1.21.5
2023-04-29 17:42:08,817:INFO:              pandas: 1.4.4
2023-04-29 17:42:08,817:INFO:              jinja2: 2.11.3
2023-04-29 17:42:08,817:INFO:               scipy: 1.9.1
2023-04-29 17:42:08,817:INFO:              joblib: 1.2.0
2023-04-29 17:42:08,817:INFO:             sklearn: 1.0.2
2023-04-29 17:42:08,817:INFO:                pyod: 1.0.9
2023-04-29 17:42:08,817:INFO:            imblearn: 0.10.1
2023-04-29 17:42:08,817:INFO:   category_encoders: 2.6.0
2023-04-29 17:42:08,817:INFO:            lightgbm: 3.3.5
2023-04-29 17:42:08,817:INFO:               numba: 0.55.1
2023-04-29 17:42:08,817:INFO:            requests: 2.28.1
2023-04-29 17:42:08,817:INFO:          matplotlib: 3.5.2
2023-04-29 17:42:08,818:INFO:          scikitplot: 0.3.7
2023-04-29 17:42:08,818:INFO:         yellowbrick: 1.5
2023-04-29 17:42:08,818:INFO:              plotly: 5.9.0
2023-04-29 17:42:08,818:INFO:             kaleido: 0.2.1
2023-04-29 17:42:08,818:INFO:         statsmodels: 0.13.2
2023-04-29 17:42:08,818:INFO:              sktime: 0.17.1
2023-04-29 17:42:08,818:INFO:               tbats: 1.1.2
2023-04-29 17:42:08,818:INFO:            pmdarima: 2.0.3
2023-04-29 17:42:08,818:INFO:              psutil: 5.9.0
2023-04-29 17:42:08,818:INFO:PyCaret optional dependencies:
2023-04-29 17:42:08,818:INFO:                shap: 0.41.0
2023-04-29 17:42:08,818:INFO:           interpret: Not installed
2023-04-29 17:42:08,818:INFO:                umap: Not installed
2023-04-29 17:42:08,818:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:42:08,818:INFO:  explainerdashboard: Not installed
2023-04-29 17:42:08,818:INFO:             autoviz: Not installed
2023-04-29 17:42:08,818:INFO:           fairlearn: Not installed
2023-04-29 17:42:08,818:INFO:             xgboost: Not installed
2023-04-29 17:42:08,818:INFO:            catboost: Not installed
2023-04-29 17:42:08,818:INFO:              kmodes: Not installed
2023-04-29 17:42:08,818:INFO:             mlxtend: Not installed
2023-04-29 17:42:08,818:INFO:       statsforecast: Not installed
2023-04-29 17:42:08,818:INFO:        tune_sklearn: Not installed
2023-04-29 17:42:08,818:INFO:                 ray: Not installed
2023-04-29 17:42:08,818:INFO:            hyperopt: Not installed
2023-04-29 17:42:08,818:INFO:              optuna: Not installed
2023-04-29 17:42:08,818:INFO:               skopt: Not installed
2023-04-29 17:42:08,818:INFO:              mlflow: 2.2.1
2023-04-29 17:42:08,818:INFO:              gradio: Not installed
2023-04-29 17:42:08,818:INFO:             fastapi: Not installed
2023-04-29 17:42:08,818:INFO:             uvicorn: Not installed
2023-04-29 17:42:08,818:INFO:              m2cgen: Not installed
2023-04-29 17:42:08,819:INFO:           evidently: Not installed
2023-04-29 17:42:08,819:INFO:               fugue: Not installed
2023-04-29 17:42:08,819:INFO:           streamlit: 1.21.0
2023-04-29 17:42:08,819:INFO:             prophet: Not installed
2023-04-29 17:42:08,819:INFO:None
2023-04-29 17:42:08,819:INFO:Set up data.
2023-04-29 17:42:08,823:INFO:Set up train/test split.
2023-04-29 17:42:08,825:INFO:Set up index.
2023-04-29 17:42:08,825:INFO:Set up folding strategy.
2023-04-29 17:42:08,825:INFO:Assigning column types.
2023-04-29 17:42:08,827:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:42:08,829:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:42:08,836:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:42:08,843:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:42:08,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,002:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,010:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,016:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,132:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:42:09,135:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,263:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,384:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:42:09,394:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,456:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,518:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,643:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:42:09,712:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,832:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,883:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:42:09,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:09,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:09,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:42:10,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,117:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:42:10,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,403:INFO:Preparing preprocessing pipeline...
2023-04-29 17:42:10,404:INFO:Set up simple imputation.
2023-04-29 17:42:10,405:INFO:Set up column name cleaning.
2023-04-29 17:42:10,447:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:42:10,452:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:42:10,452:INFO:Creating final display dataframe.
2023-04-29 17:42:10,560:INFO:Setup _display_container:                     Description             Value
0                    Session id              5274
1                        Target               VEC
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5c2c
2023-04-29 17:42:10,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:42:10,834:INFO:setup() successfully completed in 2.43s...............
2023-04-29 17:42:10,840:INFO:Initializing compare_models()
2023-04-29 17:42:10,840:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:42:10,840:INFO:Checking exceptions
2023-04-29 17:42:10,843:INFO:Preparing display monitor
2023-04-29 17:42:10,851:INFO:Initializing Linear Regression
2023-04-29 17:42:10,853:INFO:Total runtime is 3.271102905273437e-05 minutes
2023-04-29 17:42:10,854:INFO:SubProcess create_model() called ==================================
2023-04-29 17:42:10,855:INFO:Initializing create_model()
2023-04-29 17:42:10,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:42:10,855:INFO:Checking exceptions
2023-04-29 17:42:10,856:INFO:Importing libraries
2023-04-29 17:42:10,856:INFO:Copying training dataset
2023-04-29 17:42:10,863:INFO:Defining folds
2023-04-29 17:42:10,863:INFO:Declaring metric variables
2023-04-29 17:42:10,864:INFO:Importing untrained model
2023-04-29 17:42:10,864:INFO:Linear Regression Imported successfully
2023-04-29 17:42:10,864:INFO:Starting cross validation
2023-04-29 17:42:10,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:42:24,558:INFO:Calculating mean and std
2023-04-29 17:42:24,559:INFO:Creating metrics dataframe
2023-04-29 17:42:25,331:INFO:Uploading results into container
2023-04-29 17:42:25,332:INFO:Uploading model into container now
2023-04-29 17:42:25,333:INFO:_master_model_container: 1
2023-04-29 17:42:25,333:INFO:_display_container: 2
2023-04-29 17:42:25,334:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:42:25,334:INFO:create_model() successfully completed......................................
2023-04-29 17:42:25,502:INFO:SubProcess create_model() end ==================================
2023-04-29 17:42:25,503:INFO:Creating metrics dataframe
2023-04-29 17:42:25,510:INFO:Initializing Lasso Regression
2023-04-29 17:42:25,510:INFO:Total runtime is 0.24431951840718585 minutes
2023-04-29 17:42:25,510:INFO:SubProcess create_model() called ==================================
2023-04-29 17:42:25,510:INFO:Initializing create_model()
2023-04-29 17:42:25,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:42:25,510:INFO:Checking exceptions
2023-04-29 17:42:25,511:INFO:Importing libraries
2023-04-29 17:42:25,511:INFO:Copying training dataset
2023-04-29 17:42:25,515:INFO:Defining folds
2023-04-29 17:42:25,515:INFO:Declaring metric variables
2023-04-29 17:42:25,515:INFO:Importing untrained model
2023-04-29 17:42:25,516:INFO:Lasso Regression Imported successfully
2023-04-29 17:42:25,517:INFO:Starting cross validation
2023-04-29 17:42:25,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:42:32,066:INFO:Calculating mean and std
2023-04-29 17:42:32,067:INFO:Creating metrics dataframe
2023-04-29 17:42:32,745:INFO:Uploading results into container
2023-04-29 17:42:32,745:INFO:Uploading model into container now
2023-04-29 17:42:32,746:INFO:_master_model_container: 2
2023-04-29 17:42:32,746:INFO:_display_container: 2
2023-04-29 17:42:32,746:INFO:Lasso(random_state=5274)
2023-04-29 17:42:32,746:INFO:create_model() successfully completed......................................
2023-04-29 17:42:32,868:INFO:SubProcess create_model() end ==================================
2023-04-29 17:42:32,868:INFO:Creating metrics dataframe
2023-04-29 17:42:32,875:INFO:Initializing Ridge Regression
2023-04-29 17:42:32,875:INFO:Total runtime is 0.36705547173817954 minutes
2023-04-29 17:42:32,875:INFO:SubProcess create_model() called ==================================
2023-04-29 17:42:32,875:INFO:Initializing create_model()
2023-04-29 17:42:32,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:42:32,875:INFO:Checking exceptions
2023-04-29 17:42:32,875:INFO:Importing libraries
2023-04-29 17:42:32,875:INFO:Copying training dataset
2023-04-29 17:42:32,879:INFO:Defining folds
2023-04-29 17:42:32,879:INFO:Declaring metric variables
2023-04-29 17:42:32,879:INFO:Importing untrained model
2023-04-29 17:42:32,879:INFO:Ridge Regression Imported successfully
2023-04-29 17:42:32,880:INFO:Starting cross validation
2023-04-29 17:42:32,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:42:39,166:INFO:Calculating mean and std
2023-04-29 17:42:39,167:INFO:Creating metrics dataframe
2023-04-29 17:42:39,889:INFO:Uploading results into container
2023-04-29 17:42:39,890:INFO:Uploading model into container now
2023-04-29 17:42:39,890:INFO:_master_model_container: 3
2023-04-29 17:42:39,890:INFO:_display_container: 2
2023-04-29 17:42:39,891:INFO:Ridge(random_state=5274)
2023-04-29 17:42:39,891:INFO:create_model() successfully completed......................................
2023-04-29 17:42:40,049:INFO:SubProcess create_model() end ==================================
2023-04-29 17:42:40,049:INFO:Creating metrics dataframe
2023-04-29 17:42:40,063:INFO:Initializing Elastic Net
2023-04-29 17:42:40,063:INFO:Total runtime is 0.48686304887135823 minutes
2023-04-29 17:42:40,064:INFO:SubProcess create_model() called ==================================
2023-04-29 17:42:40,064:INFO:Initializing create_model()
2023-04-29 17:42:40,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:42:40,064:INFO:Checking exceptions
2023-04-29 17:42:40,064:INFO:Importing libraries
2023-04-29 17:42:40,064:INFO:Copying training dataset
2023-04-29 17:42:40,074:INFO:Defining folds
2023-04-29 17:42:40,074:INFO:Declaring metric variables
2023-04-29 17:42:40,075:INFO:Importing untrained model
2023-04-29 17:42:40,075:INFO:Elastic Net Imported successfully
2023-04-29 17:42:40,076:INFO:Starting cross validation
2023-04-29 17:42:40,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:42:46,481:INFO:Calculating mean and std
2023-04-29 17:42:46,483:INFO:Creating metrics dataframe
2023-04-29 17:42:47,131:INFO:Uploading results into container
2023-04-29 17:42:47,131:INFO:Uploading model into container now
2023-04-29 17:42:47,132:INFO:_master_model_container: 4
2023-04-29 17:42:47,132:INFO:_display_container: 2
2023-04-29 17:42:47,132:INFO:ElasticNet(random_state=5274)
2023-04-29 17:42:47,132:INFO:create_model() successfully completed......................................
2023-04-29 17:42:47,264:INFO:SubProcess create_model() end ==================================
2023-04-29 17:42:47,264:INFO:Creating metrics dataframe
2023-04-29 17:42:47,273:INFO:Initializing Least Angle Regression
2023-04-29 17:42:47,273:INFO:Total runtime is 0.6070364793141683 minutes
2023-04-29 17:42:47,275:INFO:SubProcess create_model() called ==================================
2023-04-29 17:42:47,275:INFO:Initializing create_model()
2023-04-29 17:42:47,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:42:47,275:INFO:Checking exceptions
2023-04-29 17:42:47,275:INFO:Importing libraries
2023-04-29 17:42:47,275:INFO:Copying training dataset
2023-04-29 17:42:47,283:INFO:Defining folds
2023-04-29 17:42:47,283:INFO:Declaring metric variables
2023-04-29 17:42:47,284:INFO:Importing untrained model
2023-04-29 17:42:47,284:INFO:Least Angle Regression Imported successfully
2023-04-29 17:42:47,284:INFO:Starting cross validation
2023-04-29 17:42:47,286:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:42:47,387:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,394:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,415:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,434:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,455:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,468:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,483:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:47,499:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:48,710:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:48,726:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:42:53,401:INFO:Calculating mean and std
2023-04-29 17:42:53,402:INFO:Creating metrics dataframe
2023-04-29 17:42:53,974:INFO:Uploading results into container
2023-04-29 17:42:53,974:INFO:Uploading model into container now
2023-04-29 17:42:53,975:INFO:_master_model_container: 5
2023-04-29 17:42:53,975:INFO:_display_container: 2
2023-04-29 17:42:53,975:INFO:Lars(random_state=5274)
2023-04-29 17:42:53,975:INFO:create_model() successfully completed......................................
2023-04-29 17:42:54,110:INFO:SubProcess create_model() end ==================================
2023-04-29 17:42:54,111:INFO:Creating metrics dataframe
2023-04-29 17:42:54,119:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:42:54,119:INFO:Total runtime is 0.7211358308792114 minutes
2023-04-29 17:42:54,119:INFO:SubProcess create_model() called ==================================
2023-04-29 17:42:54,119:INFO:Initializing create_model()
2023-04-29 17:42:54,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:42:54,120:INFO:Checking exceptions
2023-04-29 17:42:54,120:INFO:Importing libraries
2023-04-29 17:42:54,120:INFO:Copying training dataset
2023-04-29 17:42:54,126:INFO:Defining folds
2023-04-29 17:42:54,126:INFO:Declaring metric variables
2023-04-29 17:42:54,127:INFO:Importing untrained model
2023-04-29 17:42:54,128:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:42:54,128:INFO:Starting cross validation
2023-04-29 17:42:54,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:42:54,231:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,244:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,262:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,280:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,296:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,312:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,321:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:54,354:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:55,463:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:42:55,481:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:43:00,396:INFO:Calculating mean and std
2023-04-29 17:43:00,397:INFO:Creating metrics dataframe
2023-04-29 17:43:01,138:INFO:Uploading results into container
2023-04-29 17:43:01,139:INFO:Uploading model into container now
2023-04-29 17:43:01,139:INFO:_master_model_container: 6
2023-04-29 17:43:01,140:INFO:_display_container: 2
2023-04-29 17:43:01,140:INFO:LassoLars(random_state=5274)
2023-04-29 17:43:01,140:INFO:create_model() successfully completed......................................
2023-04-29 17:43:01,269:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:01,269:INFO:Creating metrics dataframe
2023-04-29 17:43:01,274:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:43:01,275:INFO:Total runtime is 0.8403937141100566 minutes
2023-04-29 17:43:01,275:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:01,276:INFO:Initializing create_model()
2023-04-29 17:43:01,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:01,276:INFO:Checking exceptions
2023-04-29 17:43:01,277:INFO:Importing libraries
2023-04-29 17:43:01,277:INFO:Copying training dataset
2023-04-29 17:43:01,286:INFO:Defining folds
2023-04-29 17:43:01,287:INFO:Declaring metric variables
2023-04-29 17:43:01,287:INFO:Importing untrained model
2023-04-29 17:43:01,288:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:43:01,289:INFO:Starting cross validation
2023-04-29 17:43:01,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:01,409:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,429:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,433:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,449:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,463:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,476:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,487:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:01,503:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:02,689:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:02,697:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:43:07,811:INFO:Calculating mean and std
2023-04-29 17:43:07,812:INFO:Creating metrics dataframe
2023-04-29 17:43:08,635:INFO:Uploading results into container
2023-04-29 17:43:08,636:INFO:Uploading model into container now
2023-04-29 17:43:08,637:INFO:_master_model_container: 7
2023-04-29 17:43:08,637:INFO:_display_container: 2
2023-04-29 17:43:08,637:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:43:08,638:INFO:create_model() successfully completed......................................
2023-04-29 17:43:08,827:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:08,828:INFO:Creating metrics dataframe
2023-04-29 17:43:08,836:INFO:Initializing Bayesian Ridge
2023-04-29 17:43:08,836:INFO:Total runtime is 0.9664148886998495 minutes
2023-04-29 17:43:08,836:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:08,837:INFO:Initializing create_model()
2023-04-29 17:43:08,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:08,837:INFO:Checking exceptions
2023-04-29 17:43:08,837:INFO:Importing libraries
2023-04-29 17:43:08,837:INFO:Copying training dataset
2023-04-29 17:43:08,841:INFO:Defining folds
2023-04-29 17:43:08,841:INFO:Declaring metric variables
2023-04-29 17:43:08,842:INFO:Importing untrained model
2023-04-29 17:43:08,842:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:43:08,842:INFO:Starting cross validation
2023-04-29 17:43:08,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:15,335:INFO:Calculating mean and std
2023-04-29 17:43:15,336:INFO:Creating metrics dataframe
2023-04-29 17:43:16,066:INFO:Uploading results into container
2023-04-29 17:43:16,067:INFO:Uploading model into container now
2023-04-29 17:43:16,068:INFO:_master_model_container: 8
2023-04-29 17:43:16,068:INFO:_display_container: 2
2023-04-29 17:43:16,069:INFO:BayesianRidge()
2023-04-29 17:43:16,069:INFO:create_model() successfully completed......................................
2023-04-29 17:43:16,227:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:16,227:INFO:Creating metrics dataframe
2023-04-29 17:43:16,239:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:43:16,239:INFO:Total runtime is 1.0897943496704101 minutes
2023-04-29 17:43:16,239:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:16,239:INFO:Initializing create_model()
2023-04-29 17:43:16,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:16,240:INFO:Checking exceptions
2023-04-29 17:43:16,240:INFO:Importing libraries
2023-04-29 17:43:16,240:INFO:Copying training dataset
2023-04-29 17:43:16,247:INFO:Defining folds
2023-04-29 17:43:16,247:INFO:Declaring metric variables
2023-04-29 17:43:16,248:INFO:Importing untrained model
2023-04-29 17:43:16,248:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:43:16,250:INFO:Starting cross validation
2023-04-29 17:43:16,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:23,347:INFO:Calculating mean and std
2023-04-29 17:43:23,348:INFO:Creating metrics dataframe
2023-04-29 17:43:23,952:INFO:Uploading results into container
2023-04-29 17:43:23,953:INFO:Uploading model into container now
2023-04-29 17:43:23,954:INFO:_master_model_container: 9
2023-04-29 17:43:23,954:INFO:_display_container: 2
2023-04-29 17:43:23,955:INFO:PassiveAggressiveRegressor(random_state=5274)
2023-04-29 17:43:23,955:INFO:create_model() successfully completed......................................
2023-04-29 17:43:24,091:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:24,091:INFO:Creating metrics dataframe
2023-04-29 17:43:24,103:INFO:Initializing Huber Regressor
2023-04-29 17:43:24,104:INFO:Total runtime is 1.2208768407503763 minutes
2023-04-29 17:43:24,104:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:24,105:INFO:Initializing create_model()
2023-04-29 17:43:24,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:24,105:INFO:Checking exceptions
2023-04-29 17:43:24,105:INFO:Importing libraries
2023-04-29 17:43:24,105:INFO:Copying training dataset
2023-04-29 17:43:24,112:INFO:Defining folds
2023-04-29 17:43:24,113:INFO:Declaring metric variables
2023-04-29 17:43:24,113:INFO:Importing untrained model
2023-04-29 17:43:24,114:INFO:Huber Regressor Imported successfully
2023-04-29 17:43:24,114:INFO:Starting cross validation
2023-04-29 17:43:24,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:30,617:INFO:Calculating mean and std
2023-04-29 17:43:30,619:INFO:Creating metrics dataframe
2023-04-29 17:43:31,378:INFO:Uploading results into container
2023-04-29 17:43:31,379:INFO:Uploading model into container now
2023-04-29 17:43:31,380:INFO:_master_model_container: 10
2023-04-29 17:43:31,380:INFO:_display_container: 2
2023-04-29 17:43:31,380:INFO:HuberRegressor()
2023-04-29 17:43:31,380:INFO:create_model() successfully completed......................................
2023-04-29 17:43:31,525:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:31,526:INFO:Creating metrics dataframe
2023-04-29 17:43:31,534:INFO:Initializing K Neighbors Regressor
2023-04-29 17:43:31,534:INFO:Total runtime is 1.3447089433670043 minutes
2023-04-29 17:43:31,534:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:31,535:INFO:Initializing create_model()
2023-04-29 17:43:31,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:31,535:INFO:Checking exceptions
2023-04-29 17:43:31,535:INFO:Importing libraries
2023-04-29 17:43:31,535:INFO:Copying training dataset
2023-04-29 17:43:31,539:INFO:Defining folds
2023-04-29 17:43:31,539:INFO:Declaring metric variables
2023-04-29 17:43:31,539:INFO:Importing untrained model
2023-04-29 17:43:31,540:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:43:31,541:INFO:Starting cross validation
2023-04-29 17:43:31,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:37,440:INFO:Calculating mean and std
2023-04-29 17:43:37,441:INFO:Creating metrics dataframe
2023-04-29 17:43:38,033:INFO:Uploading results into container
2023-04-29 17:43:38,033:INFO:Uploading model into container now
2023-04-29 17:43:38,034:INFO:_master_model_container: 11
2023-04-29 17:43:38,034:INFO:_display_container: 2
2023-04-29 17:43:38,034:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:43:38,034:INFO:create_model() successfully completed......................................
2023-04-29 17:43:38,162:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:38,162:INFO:Creating metrics dataframe
2023-04-29 17:43:38,174:INFO:Initializing Decision Tree Regressor
2023-04-29 17:43:38,174:INFO:Total runtime is 1.4553780873616535 minutes
2023-04-29 17:43:38,175:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:38,176:INFO:Initializing create_model()
2023-04-29 17:43:38,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:38,176:INFO:Checking exceptions
2023-04-29 17:43:38,176:INFO:Importing libraries
2023-04-29 17:43:38,176:INFO:Copying training dataset
2023-04-29 17:43:38,184:INFO:Defining folds
2023-04-29 17:43:38,184:INFO:Declaring metric variables
2023-04-29 17:43:38,184:INFO:Importing untrained model
2023-04-29 17:43:38,185:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:43:38,185:INFO:Starting cross validation
2023-04-29 17:43:38,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:45,016:INFO:Calculating mean and std
2023-04-29 17:43:45,017:INFO:Creating metrics dataframe
2023-04-29 17:43:45,728:INFO:Uploading results into container
2023-04-29 17:43:45,729:INFO:Uploading model into container now
2023-04-29 17:43:45,729:INFO:_master_model_container: 12
2023-04-29 17:43:45,729:INFO:_display_container: 2
2023-04-29 17:43:45,729:INFO:DecisionTreeRegressor(random_state=5274)
2023-04-29 17:43:45,730:INFO:create_model() successfully completed......................................
2023-04-29 17:43:45,827:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:45,827:INFO:Creating metrics dataframe
2023-04-29 17:43:45,833:INFO:Initializing Random Forest Regressor
2023-04-29 17:43:45,833:INFO:Total runtime is 1.5830262660980223 minutes
2023-04-29 17:43:45,833:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:45,833:INFO:Initializing create_model()
2023-04-29 17:43:45,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:45,833:INFO:Checking exceptions
2023-04-29 17:43:45,833:INFO:Importing libraries
2023-04-29 17:43:45,833:INFO:Copying training dataset
2023-04-29 17:43:45,838:INFO:Defining folds
2023-04-29 17:43:45,838:INFO:Declaring metric variables
2023-04-29 17:43:45,838:INFO:Importing untrained model
2023-04-29 17:43:45,839:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:43:45,839:INFO:Starting cross validation
2023-04-29 17:43:45,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:43:51,898:INFO:Calculating mean and std
2023-04-29 17:43:51,899:INFO:Creating metrics dataframe
2023-04-29 17:43:52,468:INFO:Uploading results into container
2023-04-29 17:43:52,468:INFO:Uploading model into container now
2023-04-29 17:43:52,468:INFO:_master_model_container: 13
2023-04-29 17:43:52,469:INFO:_display_container: 2
2023-04-29 17:43:52,469:INFO:RandomForestRegressor(n_jobs=-1, random_state=5274)
2023-04-29 17:43:52,469:INFO:create_model() successfully completed......................................
2023-04-29 17:43:52,565:INFO:SubProcess create_model() end ==================================
2023-04-29 17:43:52,566:INFO:Creating metrics dataframe
2023-04-29 17:43:52,570:INFO:Initializing Extra Trees Regressor
2023-04-29 17:43:52,570:INFO:Total runtime is 1.695318015416463 minutes
2023-04-29 17:43:52,570:INFO:SubProcess create_model() called ==================================
2023-04-29 17:43:52,570:INFO:Initializing create_model()
2023-04-29 17:43:52,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:43:52,570:INFO:Checking exceptions
2023-04-29 17:43:52,570:INFO:Importing libraries
2023-04-29 17:43:52,570:INFO:Copying training dataset
2023-04-29 17:43:52,575:INFO:Defining folds
2023-04-29 17:43:52,576:INFO:Declaring metric variables
2023-04-29 17:43:52,576:INFO:Importing untrained model
2023-04-29 17:43:52,577:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:43:52,578:INFO:Starting cross validation
2023-04-29 17:43:52,579:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:44:00,146:INFO:Calculating mean and std
2023-04-29 17:44:00,147:INFO:Creating metrics dataframe
2023-04-29 17:44:00,802:INFO:Uploading results into container
2023-04-29 17:44:00,803:INFO:Uploading model into container now
2023-04-29 17:44:00,803:INFO:_master_model_container: 14
2023-04-29 17:44:00,803:INFO:_display_container: 2
2023-04-29 17:44:00,804:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5274)
2023-04-29 17:44:00,804:INFO:create_model() successfully completed......................................
2023-04-29 17:44:00,963:INFO:SubProcess create_model() end ==================================
2023-04-29 17:44:00,964:INFO:Creating metrics dataframe
2023-04-29 17:44:00,973:INFO:Initializing AdaBoost Regressor
2023-04-29 17:44:00,974:INFO:Total runtime is 1.8353832125663756 minutes
2023-04-29 17:44:00,975:INFO:SubProcess create_model() called ==================================
2023-04-29 17:44:00,975:INFO:Initializing create_model()
2023-04-29 17:44:00,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:44:00,977:INFO:Checking exceptions
2023-04-29 17:44:00,977:INFO:Importing libraries
2023-04-29 17:44:00,977:INFO:Copying training dataset
2023-04-29 17:44:00,982:INFO:Defining folds
2023-04-29 17:44:00,982:INFO:Declaring metric variables
2023-04-29 17:44:00,982:INFO:Importing untrained model
2023-04-29 17:44:00,983:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:44:00,983:INFO:Starting cross validation
2023-04-29 17:44:00,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:44:07,366:INFO:Calculating mean and std
2023-04-29 17:44:07,367:INFO:Creating metrics dataframe
2023-04-29 17:44:07,929:INFO:Uploading results into container
2023-04-29 17:44:07,929:INFO:Uploading model into container now
2023-04-29 17:44:07,930:INFO:_master_model_container: 15
2023-04-29 17:44:07,930:INFO:_display_container: 2
2023-04-29 17:44:07,930:INFO:AdaBoostRegressor(random_state=5274)
2023-04-29 17:44:07,930:INFO:create_model() successfully completed......................................
2023-04-29 17:44:08,056:INFO:SubProcess create_model() end ==================================
2023-04-29 17:44:08,056:INFO:Creating metrics dataframe
2023-04-29 17:44:08,066:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:44:08,066:INFO:Total runtime is 1.9535852750142415 minutes
2023-04-29 17:44:08,066:INFO:SubProcess create_model() called ==================================
2023-04-29 17:44:08,066:INFO:Initializing create_model()
2023-04-29 17:44:08,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:44:08,068:INFO:Checking exceptions
2023-04-29 17:44:08,068:INFO:Importing libraries
2023-04-29 17:44:08,068:INFO:Copying training dataset
2023-04-29 17:44:08,073:INFO:Defining folds
2023-04-29 17:44:08,073:INFO:Declaring metric variables
2023-04-29 17:44:08,073:INFO:Importing untrained model
2023-04-29 17:44:08,074:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:44:08,075:INFO:Starting cross validation
2023-04-29 17:44:08,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:44:15,087:INFO:Calculating mean and std
2023-04-29 17:44:15,088:INFO:Creating metrics dataframe
2023-04-29 17:44:15,797:INFO:Uploading results into container
2023-04-29 17:44:15,799:INFO:Uploading model into container now
2023-04-29 17:44:15,799:INFO:_master_model_container: 16
2023-04-29 17:44:15,800:INFO:_display_container: 2
2023-04-29 17:44:15,801:INFO:GradientBoostingRegressor(random_state=5274)
2023-04-29 17:44:15,801:INFO:create_model() successfully completed......................................
2023-04-29 17:44:15,939:INFO:SubProcess create_model() end ==================================
2023-04-29 17:44:15,940:INFO:Creating metrics dataframe
2023-04-29 17:44:15,949:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:44:15,949:INFO:Total runtime is 2.0849663734436037 minutes
2023-04-29 17:44:15,950:INFO:SubProcess create_model() called ==================================
2023-04-29 17:44:15,950:INFO:Initializing create_model()
2023-04-29 17:44:15,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:44:15,950:INFO:Checking exceptions
2023-04-29 17:44:15,950:INFO:Importing libraries
2023-04-29 17:44:15,950:INFO:Copying training dataset
2023-04-29 17:44:15,958:INFO:Defining folds
2023-04-29 17:44:15,958:INFO:Declaring metric variables
2023-04-29 17:44:15,959:INFO:Importing untrained model
2023-04-29 17:44:15,959:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:44:15,960:INFO:Starting cross validation
2023-04-29 17:44:15,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:44:24,992:INFO:Calculating mean and std
2023-04-29 17:44:24,993:INFO:Creating metrics dataframe
2023-04-29 17:44:25,674:INFO:Uploading results into container
2023-04-29 17:44:25,675:INFO:Uploading model into container now
2023-04-29 17:44:25,676:INFO:_master_model_container: 17
2023-04-29 17:44:25,676:INFO:_display_container: 2
2023-04-29 17:44:25,676:INFO:LGBMRegressor(random_state=5274)
2023-04-29 17:44:25,676:INFO:create_model() successfully completed......................................
2023-04-29 17:44:25,821:INFO:SubProcess create_model() end ==================================
2023-04-29 17:44:25,823:INFO:Creating metrics dataframe
2023-04-29 17:44:25,839:INFO:Initializing Dummy Regressor
2023-04-29 17:44:25,839:INFO:Total runtime is 2.2497948447863263 minutes
2023-04-29 17:44:25,840:INFO:SubProcess create_model() called ==================================
2023-04-29 17:44:25,840:INFO:Initializing create_model()
2023-04-29 17:44:25,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6E12C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:44:25,841:INFO:Checking exceptions
2023-04-29 17:44:25,841:INFO:Importing libraries
2023-04-29 17:44:25,841:INFO:Copying training dataset
2023-04-29 17:44:25,850:INFO:Defining folds
2023-04-29 17:44:25,851:INFO:Declaring metric variables
2023-04-29 17:44:25,851:INFO:Importing untrained model
2023-04-29 17:44:25,852:INFO:Dummy Regressor Imported successfully
2023-04-29 17:44:25,852:INFO:Starting cross validation
2023-04-29 17:44:25,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:44:32,084:INFO:Calculating mean and std
2023-04-29 17:44:32,085:INFO:Creating metrics dataframe
2023-04-29 17:44:32,888:INFO:Uploading results into container
2023-04-29 17:44:32,889:INFO:Uploading model into container now
2023-04-29 17:44:32,890:INFO:_master_model_container: 18
2023-04-29 17:44:32,890:INFO:_display_container: 2
2023-04-29 17:44:32,890:INFO:DummyRegressor()
2023-04-29 17:44:32,890:INFO:create_model() successfully completed......................................
2023-04-29 17:44:33,049:INFO:SubProcess create_model() end ==================================
2023-04-29 17:44:33,049:INFO:Creating metrics dataframe
2023-04-29 17:44:33,061:INFO:Initializing create_model()
2023-04-29 17:44:33,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5274), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:44:33,062:INFO:Checking exceptions
2023-04-29 17:44:33,062:INFO:Importing libraries
2023-04-29 17:44:33,062:INFO:Copying training dataset
2023-04-29 17:44:33,070:INFO:Defining folds
2023-04-29 17:44:33,070:INFO:Declaring metric variables
2023-04-29 17:44:33,071:INFO:Importing untrained model
2023-04-29 17:44:33,071:INFO:Declaring custom model
2023-04-29 17:44:33,073:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:44:33,074:INFO:Cross validation set to False
2023-04-29 17:44:33,074:INFO:Fitting Model
2023-04-29 17:44:33,939:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5274)
2023-04-29 17:44:33,939:INFO:create_model() successfully completed......................................
2023-04-29 17:44:34,132:INFO:_master_model_container: 18
2023-04-29 17:44:34,133:INFO:_display_container: 2
2023-04-29 17:44:34,134:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5274)
2023-04-29 17:44:34,134:INFO:compare_models() successfully completed......................................
2023-04-29 17:44:34,138:INFO:Initializing predict_model()
2023-04-29 17:44:34,138:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6785B50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5274), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B71A5430>)
2023-04-29 17:44:34,139:INFO:Checking exceptions
2023-04-29 17:44:34,140:INFO:Preloading libraries
2023-04-29 17:44:34,141:INFO:Set up data.
2023-04-29 17:44:34,150:INFO:Set up index.
2023-04-29 17:49:13,835:INFO:PyCaret RegressionExperiment
2023-04-29 17:49:13,835:INFO:Logging name: reg-default-name
2023-04-29 17:49:13,835:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:49:13,835:INFO:version 3.0.0
2023-04-29 17:49:13,835:INFO:Initializing setup()
2023-04-29 17:49:13,835:INFO:self.USI: b875
2023-04-29 17:49:13,835:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:49:13,835:INFO:Checking environment
2023-04-29 17:49:13,835:INFO:python_version: 3.9.13
2023-04-29 17:49:13,835:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:49:13,835:INFO:machine: AMD64
2023-04-29 17:49:13,835:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:49:13,835:INFO:Memory: svmem(total=16935899136, available=5567610880, percent=67.1, used=11368288256, free=5567610880)
2023-04-29 17:49:13,835:INFO:Physical Core: 4
2023-04-29 17:49:13,835:INFO:Logical Core: 8
2023-04-29 17:49:13,835:INFO:Checking libraries
2023-04-29 17:49:13,835:INFO:System:
2023-04-29 17:49:13,835:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:49:13,835:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:49:13,835:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:49:13,835:INFO:PyCaret required dependencies:
2023-04-29 17:49:13,835:INFO:                 pip: 22.2.2
2023-04-29 17:49:13,835:INFO:          setuptools: 63.4.1
2023-04-29 17:49:13,835:INFO:             pycaret: 3.0.0
2023-04-29 17:49:13,835:INFO:             IPython: 7.31.1
2023-04-29 17:49:13,835:INFO:          ipywidgets: 7.6.5
2023-04-29 17:49:13,835:INFO:                tqdm: 4.64.1
2023-04-29 17:49:13,835:INFO:               numpy: 1.21.5
2023-04-29 17:49:13,837:INFO:              pandas: 1.4.4
2023-04-29 17:49:13,837:INFO:              jinja2: 2.11.3
2023-04-29 17:49:13,837:INFO:               scipy: 1.9.1
2023-04-29 17:49:13,837:INFO:              joblib: 1.2.0
2023-04-29 17:49:13,837:INFO:             sklearn: 1.0.2
2023-04-29 17:49:13,837:INFO:                pyod: 1.0.9
2023-04-29 17:49:13,837:INFO:            imblearn: 0.10.1
2023-04-29 17:49:13,837:INFO:   category_encoders: 2.6.0
2023-04-29 17:49:13,837:INFO:            lightgbm: 3.3.5
2023-04-29 17:49:13,837:INFO:               numba: 0.55.1
2023-04-29 17:49:13,837:INFO:            requests: 2.28.1
2023-04-29 17:49:13,837:INFO:          matplotlib: 3.5.2
2023-04-29 17:49:13,837:INFO:          scikitplot: 0.3.7
2023-04-29 17:49:13,837:INFO:         yellowbrick: 1.5
2023-04-29 17:49:13,837:INFO:              plotly: 5.9.0
2023-04-29 17:49:13,837:INFO:             kaleido: 0.2.1
2023-04-29 17:49:13,837:INFO:         statsmodels: 0.13.2
2023-04-29 17:49:13,837:INFO:              sktime: 0.17.1
2023-04-29 17:49:13,837:INFO:               tbats: 1.1.2
2023-04-29 17:49:13,837:INFO:            pmdarima: 2.0.3
2023-04-29 17:49:13,837:INFO:              psutil: 5.9.0
2023-04-29 17:49:13,837:INFO:PyCaret optional dependencies:
2023-04-29 17:49:13,837:INFO:                shap: 0.41.0
2023-04-29 17:49:13,837:INFO:           interpret: Not installed
2023-04-29 17:49:13,837:INFO:                umap: Not installed
2023-04-29 17:49:13,837:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:49:13,837:INFO:  explainerdashboard: Not installed
2023-04-29 17:49:13,837:INFO:             autoviz: Not installed
2023-04-29 17:49:13,837:INFO:           fairlearn: Not installed
2023-04-29 17:49:13,837:INFO:             xgboost: Not installed
2023-04-29 17:49:13,837:INFO:            catboost: Not installed
2023-04-29 17:49:13,837:INFO:              kmodes: Not installed
2023-04-29 17:49:13,838:INFO:             mlxtend: Not installed
2023-04-29 17:49:13,838:INFO:       statsforecast: Not installed
2023-04-29 17:49:13,838:INFO:        tune_sklearn: Not installed
2023-04-29 17:49:13,838:INFO:                 ray: Not installed
2023-04-29 17:49:13,838:INFO:            hyperopt: Not installed
2023-04-29 17:49:13,838:INFO:              optuna: Not installed
2023-04-29 17:49:13,838:INFO:               skopt: Not installed
2023-04-29 17:49:13,838:INFO:              mlflow: 2.2.1
2023-04-29 17:49:13,838:INFO:              gradio: Not installed
2023-04-29 17:49:13,838:INFO:             fastapi: Not installed
2023-04-29 17:49:13,838:INFO:             uvicorn: Not installed
2023-04-29 17:49:13,838:INFO:              m2cgen: Not installed
2023-04-29 17:49:13,838:INFO:           evidently: Not installed
2023-04-29 17:49:13,838:INFO:               fugue: Not installed
2023-04-29 17:49:13,838:INFO:           streamlit: 1.21.0
2023-04-29 17:49:13,838:INFO:             prophet: Not installed
2023-04-29 17:49:13,838:INFO:None
2023-04-29 17:49:13,838:INFO:Set up data.
2023-04-29 17:49:13,841:INFO:Set up train/test split.
2023-04-29 17:49:13,843:INFO:Set up index.
2023-04-29 17:49:13,843:INFO:Set up folding strategy.
2023-04-29 17:49:13,844:INFO:Assigning column types.
2023-04-29 17:49:13,846:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:49:13,846:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,850:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:13,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:13,959:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,964:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:49:13,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,069:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,069:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:49:14,074:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,078:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,182:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,289:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:49:14,297:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,402:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,497:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:49:14,557:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,603:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,706:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:49:14,767:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,872:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:49:14,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:14,913:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:49:15,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,128:INFO:Preparing preprocessing pipeline...
2023-04-29 17:49:15,128:INFO:Set up simple imputation.
2023-04-29 17:49:15,129:INFO:Set up column name cleaning.
2023-04-29 17:49:15,147:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:49:15,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:49:15,150:INFO:Creating final display dataframe.
2023-04-29 17:49:15,219:INFO:Setup _display_container:                     Description             Value
0                    Session id              7807
1                        Target               VEC
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b875
2023-04-29 17:49:15,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:49:15,453:INFO:setup() successfully completed in 1.99s...............
2023-04-29 17:49:15,459:INFO:Initializing compare_models()
2023-04-29 17:49:15,459:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:49:15,459:INFO:Checking exceptions
2023-04-29 17:49:15,462:INFO:Preparing display monitor
2023-04-29 17:49:15,466:INFO:Initializing Linear Regression
2023-04-29 17:49:15,467:INFO:Total runtime is 0.0 minutes
2023-04-29 17:49:15,467:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:15,467:INFO:Initializing create_model()
2023-04-29 17:49:15,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:15,467:INFO:Checking exceptions
2023-04-29 17:49:15,467:INFO:Importing libraries
2023-04-29 17:49:15,467:INFO:Copying training dataset
2023-04-29 17:49:15,472:INFO:Defining folds
2023-04-29 17:49:15,472:INFO:Declaring metric variables
2023-04-29 17:49:15,472:INFO:Importing untrained model
2023-04-29 17:49:15,473:INFO:Linear Regression Imported successfully
2023-04-29 17:49:15,473:INFO:Starting cross validation
2023-04-29 17:49:15,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:20,761:INFO:Calculating mean and std
2023-04-29 17:49:20,761:INFO:Creating metrics dataframe
2023-04-29 17:49:21,955:INFO:Uploading results into container
2023-04-29 17:49:21,955:INFO:Uploading model into container now
2023-04-29 17:49:21,955:INFO:_master_model_container: 1
2023-04-29 17:49:21,957:INFO:_display_container: 2
2023-04-29 17:49:21,957:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:49:21,957:INFO:create_model() successfully completed......................................
2023-04-29 17:49:22,093:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:22,093:INFO:Creating metrics dataframe
2023-04-29 17:49:22,097:INFO:Initializing Lasso Regression
2023-04-29 17:49:22,097:INFO:Total runtime is 0.11050997575124105 minutes
2023-04-29 17:49:22,097:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:22,097:INFO:Initializing create_model()
2023-04-29 17:49:22,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:22,097:INFO:Checking exceptions
2023-04-29 17:49:22,097:INFO:Importing libraries
2023-04-29 17:49:22,097:INFO:Copying training dataset
2023-04-29 17:49:22,100:INFO:Defining folds
2023-04-29 17:49:22,100:INFO:Declaring metric variables
2023-04-29 17:49:22,101:INFO:Importing untrained model
2023-04-29 17:49:22,102:INFO:Lasso Regression Imported successfully
2023-04-29 17:49:22,102:INFO:Starting cross validation
2023-04-29 17:49:22,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:27,215:INFO:Calculating mean and std
2023-04-29 17:49:27,216:INFO:Creating metrics dataframe
2023-04-29 17:49:27,828:INFO:Uploading results into container
2023-04-29 17:49:27,829:INFO:Uploading model into container now
2023-04-29 17:49:27,829:INFO:_master_model_container: 2
2023-04-29 17:49:27,829:INFO:_display_container: 2
2023-04-29 17:49:27,830:INFO:Lasso(random_state=7807)
2023-04-29 17:49:27,830:INFO:create_model() successfully completed......................................
2023-04-29 17:49:27,940:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:27,940:INFO:Creating metrics dataframe
2023-04-29 17:49:27,944:INFO:Initializing Ridge Regression
2023-04-29 17:49:27,944:INFO:Total runtime is 0.20796894232432048 minutes
2023-04-29 17:49:27,945:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:27,945:INFO:Initializing create_model()
2023-04-29 17:49:27,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:27,945:INFO:Checking exceptions
2023-04-29 17:49:27,945:INFO:Importing libraries
2023-04-29 17:49:27,945:INFO:Copying training dataset
2023-04-29 17:49:27,948:INFO:Defining folds
2023-04-29 17:49:27,949:INFO:Declaring metric variables
2023-04-29 17:49:27,949:INFO:Importing untrained model
2023-04-29 17:49:27,949:INFO:Ridge Regression Imported successfully
2023-04-29 17:49:27,949:INFO:Starting cross validation
2023-04-29 17:49:27,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:33,253:INFO:Calculating mean and std
2023-04-29 17:49:33,255:INFO:Creating metrics dataframe
2023-04-29 17:49:33,862:INFO:Uploading results into container
2023-04-29 17:49:33,863:INFO:Uploading model into container now
2023-04-29 17:49:33,863:INFO:_master_model_container: 3
2023-04-29 17:49:33,863:INFO:_display_container: 2
2023-04-29 17:49:33,863:INFO:Ridge(random_state=7807)
2023-04-29 17:49:33,863:INFO:create_model() successfully completed......................................
2023-04-29 17:49:33,980:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:33,980:INFO:Creating metrics dataframe
2023-04-29 17:49:33,987:INFO:Initializing Elastic Net
2023-04-29 17:49:33,987:INFO:Total runtime is 0.30867776075998943 minutes
2023-04-29 17:49:33,987:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:33,988:INFO:Initializing create_model()
2023-04-29 17:49:33,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:33,988:INFO:Checking exceptions
2023-04-29 17:49:33,988:INFO:Importing libraries
2023-04-29 17:49:33,988:INFO:Copying training dataset
2023-04-29 17:49:33,991:INFO:Defining folds
2023-04-29 17:49:33,992:INFO:Declaring metric variables
2023-04-29 17:49:33,992:INFO:Importing untrained model
2023-04-29 17:49:33,992:INFO:Elastic Net Imported successfully
2023-04-29 17:49:33,992:INFO:Starting cross validation
2023-04-29 17:49:33,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:39,361:INFO:Calculating mean and std
2023-04-29 17:49:39,363:INFO:Creating metrics dataframe
2023-04-29 17:49:40,423:INFO:Uploading results into container
2023-04-29 17:49:40,424:INFO:Uploading model into container now
2023-04-29 17:49:40,425:INFO:_master_model_container: 4
2023-04-29 17:49:40,425:INFO:_display_container: 2
2023-04-29 17:49:40,426:INFO:ElasticNet(random_state=7807)
2023-04-29 17:49:40,426:INFO:create_model() successfully completed......................................
2023-04-29 17:49:40,547:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:40,547:INFO:Creating metrics dataframe
2023-04-29 17:49:40,551:INFO:Initializing Least Angle Regression
2023-04-29 17:49:40,551:INFO:Total runtime is 0.4180820385615031 minutes
2023-04-29 17:49:40,552:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:40,552:INFO:Initializing create_model()
2023-04-29 17:49:40,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:40,552:INFO:Checking exceptions
2023-04-29 17:49:40,552:INFO:Importing libraries
2023-04-29 17:49:40,552:INFO:Copying training dataset
2023-04-29 17:49:40,556:INFO:Defining folds
2023-04-29 17:49:40,556:INFO:Declaring metric variables
2023-04-29 17:49:40,556:INFO:Importing untrained model
2023-04-29 17:49:40,557:INFO:Least Angle Regression Imported successfully
2023-04-29 17:49:40,557:INFO:Starting cross validation
2023-04-29 17:49:40,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:40,677:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,689:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,692:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,700:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,719:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,741:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,750:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:40,760:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:41,697:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:41,734:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:45,696:INFO:Calculating mean and std
2023-04-29 17:49:45,697:INFO:Creating metrics dataframe
2023-04-29 17:49:46,942:INFO:Uploading results into container
2023-04-29 17:49:46,943:INFO:Uploading model into container now
2023-04-29 17:49:46,943:INFO:_master_model_container: 5
2023-04-29 17:49:46,944:INFO:_display_container: 2
2023-04-29 17:49:46,944:INFO:Lars(random_state=7807)
2023-04-29 17:49:46,944:INFO:create_model() successfully completed......................................
2023-04-29 17:49:47,067:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:47,068:INFO:Creating metrics dataframe
2023-04-29 17:49:47,074:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:49:47,074:INFO:Total runtime is 0.5267983516057333 minutes
2023-04-29 17:49:47,074:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:47,074:INFO:Initializing create_model()
2023-04-29 17:49:47,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:47,075:INFO:Checking exceptions
2023-04-29 17:49:47,075:INFO:Importing libraries
2023-04-29 17:49:47,075:INFO:Copying training dataset
2023-04-29 17:49:47,078:INFO:Defining folds
2023-04-29 17:49:47,078:INFO:Declaring metric variables
2023-04-29 17:49:47,078:INFO:Importing untrained model
2023-04-29 17:49:47,079:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:49:47,079:INFO:Starting cross validation
2023-04-29 17:49:47,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:47,161:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,168:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,183:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,194:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,211:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,226:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,234:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:47,247:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:48,206:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:48,244:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:49:52,490:INFO:Calculating mean and std
2023-04-29 17:49:52,491:INFO:Creating metrics dataframe
2023-04-29 17:49:53,124:INFO:Uploading results into container
2023-04-29 17:49:53,124:INFO:Uploading model into container now
2023-04-29 17:49:53,125:INFO:_master_model_container: 6
2023-04-29 17:49:53,125:INFO:_display_container: 2
2023-04-29 17:49:53,126:INFO:LassoLars(random_state=7807)
2023-04-29 17:49:53,126:INFO:create_model() successfully completed......................................
2023-04-29 17:49:53,263:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:53,263:INFO:Creating metrics dataframe
2023-04-29 17:49:53,267:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:49:53,267:INFO:Total runtime is 0.6300131996472678 minutes
2023-04-29 17:49:53,267:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:53,268:INFO:Initializing create_model()
2023-04-29 17:49:53,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:53,268:INFO:Checking exceptions
2023-04-29 17:49:53,268:INFO:Importing libraries
2023-04-29 17:49:53,268:INFO:Copying training dataset
2023-04-29 17:49:53,272:INFO:Defining folds
2023-04-29 17:49:53,272:INFO:Declaring metric variables
2023-04-29 17:49:53,272:INFO:Importing untrained model
2023-04-29 17:49:53,272:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:49:53,273:INFO:Starting cross validation
2023-04-29 17:49:53,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:49:53,352:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,360:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,373:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,388:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,412:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,415:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,419:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:53,432:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:54,423:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:54,434:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:49:58,707:INFO:Calculating mean and std
2023-04-29 17:49:58,709:INFO:Creating metrics dataframe
2023-04-29 17:49:59,303:INFO:Uploading results into container
2023-04-29 17:49:59,304:INFO:Uploading model into container now
2023-04-29 17:49:59,305:INFO:_master_model_container: 7
2023-04-29 17:49:59,305:INFO:_display_container: 2
2023-04-29 17:49:59,305:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:49:59,305:INFO:create_model() successfully completed......................................
2023-04-29 17:49:59,423:INFO:SubProcess create_model() end ==================================
2023-04-29 17:49:59,424:INFO:Creating metrics dataframe
2023-04-29 17:49:59,429:INFO:Initializing Bayesian Ridge
2023-04-29 17:49:59,429:INFO:Total runtime is 0.7327189485232036 minutes
2023-04-29 17:49:59,429:INFO:SubProcess create_model() called ==================================
2023-04-29 17:49:59,429:INFO:Initializing create_model()
2023-04-29 17:49:59,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:49:59,429:INFO:Checking exceptions
2023-04-29 17:49:59,429:INFO:Importing libraries
2023-04-29 17:49:59,429:INFO:Copying training dataset
2023-04-29 17:49:59,433:INFO:Defining folds
2023-04-29 17:49:59,433:INFO:Declaring metric variables
2023-04-29 17:49:59,433:INFO:Importing untrained model
2023-04-29 17:49:59,434:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:49:59,434:INFO:Starting cross validation
2023-04-29 17:49:59,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:04,716:INFO:Calculating mean and std
2023-04-29 17:50:04,717:INFO:Creating metrics dataframe
2023-04-29 17:50:05,946:INFO:Uploading results into container
2023-04-29 17:50:05,947:INFO:Uploading model into container now
2023-04-29 17:50:05,948:INFO:_master_model_container: 8
2023-04-29 17:50:05,948:INFO:_display_container: 2
2023-04-29 17:50:05,948:INFO:BayesianRidge()
2023-04-29 17:50:05,949:INFO:create_model() successfully completed......................................
2023-04-29 17:50:06,082:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:06,082:INFO:Creating metrics dataframe
2023-04-29 17:50:06,087:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:50:06,087:INFO:Total runtime is 0.8436844150225322 minutes
2023-04-29 17:50:06,087:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:06,087:INFO:Initializing create_model()
2023-04-29 17:50:06,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:06,087:INFO:Checking exceptions
2023-04-29 17:50:06,088:INFO:Importing libraries
2023-04-29 17:50:06,088:INFO:Copying training dataset
2023-04-29 17:50:06,091:INFO:Defining folds
2023-04-29 17:50:06,091:INFO:Declaring metric variables
2023-04-29 17:50:06,092:INFO:Importing untrained model
2023-04-29 17:50:06,092:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:50:06,093:INFO:Starting cross validation
2023-04-29 17:50:06,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:11,394:INFO:Calculating mean and std
2023-04-29 17:50:11,395:INFO:Creating metrics dataframe
2023-04-29 17:50:12,182:INFO:Uploading results into container
2023-04-29 17:50:12,182:INFO:Uploading model into container now
2023-04-29 17:50:12,183:INFO:_master_model_container: 9
2023-04-29 17:50:12,183:INFO:_display_container: 2
2023-04-29 17:50:12,183:INFO:PassiveAggressiveRegressor(random_state=7807)
2023-04-29 17:50:12,183:INFO:create_model() successfully completed......................................
2023-04-29 17:50:12,310:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:12,310:INFO:Creating metrics dataframe
2023-04-29 17:50:12,313:INFO:Initializing Huber Regressor
2023-04-29 17:50:12,313:INFO:Total runtime is 0.947456741333008 minutes
2023-04-29 17:50:12,313:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:12,313:INFO:Initializing create_model()
2023-04-29 17:50:12,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:12,313:INFO:Checking exceptions
2023-04-29 17:50:12,314:INFO:Importing libraries
2023-04-29 17:50:12,314:INFO:Copying training dataset
2023-04-29 17:50:12,318:INFO:Defining folds
2023-04-29 17:50:12,318:INFO:Declaring metric variables
2023-04-29 17:50:12,319:INFO:Importing untrained model
2023-04-29 17:50:12,319:INFO:Huber Regressor Imported successfully
2023-04-29 17:50:12,320:INFO:Starting cross validation
2023-04-29 17:50:12,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:12,512:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:50:12,537:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:50:12,579:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:50:17,686:INFO:Calculating mean and std
2023-04-29 17:50:17,688:INFO:Creating metrics dataframe
2023-04-29 17:50:18,350:INFO:Uploading results into container
2023-04-29 17:50:18,352:INFO:Uploading model into container now
2023-04-29 17:50:18,352:INFO:_master_model_container: 10
2023-04-29 17:50:18,352:INFO:_display_container: 2
2023-04-29 17:50:18,353:INFO:HuberRegressor()
2023-04-29 17:50:18,353:INFO:create_model() successfully completed......................................
2023-04-29 17:50:18,465:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:18,465:INFO:Creating metrics dataframe
2023-04-29 17:50:18,469:INFO:Initializing K Neighbors Regressor
2023-04-29 17:50:18,469:INFO:Total runtime is 1.0500457684199016 minutes
2023-04-29 17:50:18,470:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:18,470:INFO:Initializing create_model()
2023-04-29 17:50:18,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:18,470:INFO:Checking exceptions
2023-04-29 17:50:18,470:INFO:Importing libraries
2023-04-29 17:50:18,470:INFO:Copying training dataset
2023-04-29 17:50:18,474:INFO:Defining folds
2023-04-29 17:50:18,474:INFO:Declaring metric variables
2023-04-29 17:50:18,475:INFO:Importing untrained model
2023-04-29 17:50:18,475:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:50:18,476:INFO:Starting cross validation
2023-04-29 17:50:18,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:24,074:INFO:Calculating mean and std
2023-04-29 17:50:24,076:INFO:Creating metrics dataframe
2023-04-29 17:50:24,777:INFO:Uploading results into container
2023-04-29 17:50:24,779:INFO:Uploading model into container now
2023-04-29 17:50:24,779:INFO:_master_model_container: 11
2023-04-29 17:50:24,779:INFO:_display_container: 2
2023-04-29 17:50:24,780:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:50:24,780:INFO:create_model() successfully completed......................................
2023-04-29 17:50:24,937:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:24,937:INFO:Creating metrics dataframe
2023-04-29 17:50:24,949:INFO:Initializing Decision Tree Regressor
2023-04-29 17:50:24,950:INFO:Total runtime is 1.1580714027086894 minutes
2023-04-29 17:50:24,950:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:24,951:INFO:Initializing create_model()
2023-04-29 17:50:24,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:24,951:INFO:Checking exceptions
2023-04-29 17:50:24,951:INFO:Importing libraries
2023-04-29 17:50:24,951:INFO:Copying training dataset
2023-04-29 17:50:24,960:INFO:Defining folds
2023-04-29 17:50:24,960:INFO:Declaring metric variables
2023-04-29 17:50:24,961:INFO:Importing untrained model
2023-04-29 17:50:24,961:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:50:24,962:INFO:Starting cross validation
2023-04-29 17:50:24,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:31,856:INFO:Calculating mean and std
2023-04-29 17:50:31,858:INFO:Creating metrics dataframe
2023-04-29 17:50:33,493:INFO:Uploading results into container
2023-04-29 17:50:33,495:INFO:Uploading model into container now
2023-04-29 17:50:33,496:INFO:_master_model_container: 12
2023-04-29 17:50:33,496:INFO:_display_container: 2
2023-04-29 17:50:33,497:INFO:DecisionTreeRegressor(random_state=7807)
2023-04-29 17:50:33,497:INFO:create_model() successfully completed......................................
2023-04-29 17:50:33,710:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:33,711:INFO:Creating metrics dataframe
2023-04-29 17:50:33,729:INFO:Initializing Random Forest Regressor
2023-04-29 17:50:33,730:INFO:Total runtime is 1.3043794234593709 minutes
2023-04-29 17:50:33,730:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:33,731:INFO:Initializing create_model()
2023-04-29 17:50:33,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:33,732:INFO:Checking exceptions
2023-04-29 17:50:33,732:INFO:Importing libraries
2023-04-29 17:50:33,732:INFO:Copying training dataset
2023-04-29 17:50:33,746:INFO:Defining folds
2023-04-29 17:50:33,746:INFO:Declaring metric variables
2023-04-29 17:50:33,747:INFO:Importing untrained model
2023-04-29 17:50:33,748:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:50:33,749:INFO:Starting cross validation
2023-04-29 17:50:33,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:42,165:INFO:Calculating mean and std
2023-04-29 17:50:42,166:INFO:Creating metrics dataframe
2023-04-29 17:50:42,746:INFO:Uploading results into container
2023-04-29 17:50:42,747:INFO:Uploading model into container now
2023-04-29 17:50:42,747:INFO:_master_model_container: 13
2023-04-29 17:50:42,747:INFO:_display_container: 2
2023-04-29 17:50:42,747:INFO:RandomForestRegressor(n_jobs=-1, random_state=7807)
2023-04-29 17:50:42,748:INFO:create_model() successfully completed......................................
2023-04-29 17:50:42,848:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:42,849:INFO:Creating metrics dataframe
2023-04-29 17:50:42,853:INFO:Initializing Extra Trees Regressor
2023-04-29 17:50:42,853:INFO:Total runtime is 1.45644048055013 minutes
2023-04-29 17:50:42,853:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:42,854:INFO:Initializing create_model()
2023-04-29 17:50:42,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:42,854:INFO:Checking exceptions
2023-04-29 17:50:42,854:INFO:Importing libraries
2023-04-29 17:50:42,854:INFO:Copying training dataset
2023-04-29 17:50:42,858:INFO:Defining folds
2023-04-29 17:50:42,858:INFO:Declaring metric variables
2023-04-29 17:50:42,858:INFO:Importing untrained model
2023-04-29 17:50:42,859:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:50:42,859:INFO:Starting cross validation
2023-04-29 17:50:42,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:48,696:INFO:Calculating mean and std
2023-04-29 17:50:48,697:INFO:Creating metrics dataframe
2023-04-29 17:50:49,298:INFO:Uploading results into container
2023-04-29 17:50:49,299:INFO:Uploading model into container now
2023-04-29 17:50:49,299:INFO:_master_model_container: 14
2023-04-29 17:50:49,300:INFO:_display_container: 2
2023-04-29 17:50:49,300:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7807)
2023-04-29 17:50:49,300:INFO:create_model() successfully completed......................................
2023-04-29 17:50:49,396:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:49,396:INFO:Creating metrics dataframe
2023-04-29 17:50:49,399:INFO:Initializing AdaBoost Regressor
2023-04-29 17:50:49,400:INFO:Total runtime is 1.5655641078948974 minutes
2023-04-29 17:50:49,400:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:49,400:INFO:Initializing create_model()
2023-04-29 17:50:49,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:49,400:INFO:Checking exceptions
2023-04-29 17:50:49,400:INFO:Importing libraries
2023-04-29 17:50:49,400:INFO:Copying training dataset
2023-04-29 17:50:49,403:INFO:Defining folds
2023-04-29 17:50:49,404:INFO:Declaring metric variables
2023-04-29 17:50:49,404:INFO:Importing untrained model
2023-04-29 17:50:49,404:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:50:49,404:INFO:Starting cross validation
2023-04-29 17:50:49,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:50:54,864:INFO:Calculating mean and std
2023-04-29 17:50:54,866:INFO:Creating metrics dataframe
2023-04-29 17:50:55,599:INFO:Uploading results into container
2023-04-29 17:50:55,600:INFO:Uploading model into container now
2023-04-29 17:50:55,600:INFO:_master_model_container: 15
2023-04-29 17:50:55,600:INFO:_display_container: 2
2023-04-29 17:50:55,601:INFO:AdaBoostRegressor(random_state=7807)
2023-04-29 17:50:55,601:INFO:create_model() successfully completed......................................
2023-04-29 17:50:55,724:INFO:SubProcess create_model() end ==================================
2023-04-29 17:50:55,724:INFO:Creating metrics dataframe
2023-04-29 17:50:55,729:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:50:55,730:INFO:Total runtime is 1.6710512955983479 minutes
2023-04-29 17:50:55,730:INFO:SubProcess create_model() called ==================================
2023-04-29 17:50:55,730:INFO:Initializing create_model()
2023-04-29 17:50:55,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:50:55,730:INFO:Checking exceptions
2023-04-29 17:50:55,731:INFO:Importing libraries
2023-04-29 17:50:55,731:INFO:Copying training dataset
2023-04-29 17:50:55,735:INFO:Defining folds
2023-04-29 17:50:55,736:INFO:Declaring metric variables
2023-04-29 17:50:55,736:INFO:Importing untrained model
2023-04-29 17:50:55,737:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:50:55,737:INFO:Starting cross validation
2023-04-29 17:50:55,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:51:05,427:INFO:Calculating mean and std
2023-04-29 17:51:05,429:INFO:Creating metrics dataframe
2023-04-29 17:51:07,275:INFO:Uploading results into container
2023-04-29 17:51:07,277:INFO:Uploading model into container now
2023-04-29 17:51:07,278:INFO:_master_model_container: 16
2023-04-29 17:51:07,278:INFO:_display_container: 2
2023-04-29 17:51:07,278:INFO:GradientBoostingRegressor(random_state=7807)
2023-04-29 17:51:07,279:INFO:create_model() successfully completed......................................
2023-04-29 17:51:07,426:INFO:SubProcess create_model() end ==================================
2023-04-29 17:51:07,426:INFO:Creating metrics dataframe
2023-04-29 17:51:07,437:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:51:07,438:INFO:Total runtime is 1.8662045637766518 minutes
2023-04-29 17:51:07,438:INFO:SubProcess create_model() called ==================================
2023-04-29 17:51:07,439:INFO:Initializing create_model()
2023-04-29 17:51:07,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:51:07,439:INFO:Checking exceptions
2023-04-29 17:51:07,439:INFO:Importing libraries
2023-04-29 17:51:07,440:INFO:Copying training dataset
2023-04-29 17:51:07,446:INFO:Defining folds
2023-04-29 17:51:07,446:INFO:Declaring metric variables
2023-04-29 17:51:07,447:INFO:Importing untrained model
2023-04-29 17:51:07,447:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:51:07,448:INFO:Starting cross validation
2023-04-29 17:51:07,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:51:12,760:INFO:Calculating mean and std
2023-04-29 17:51:12,761:INFO:Creating metrics dataframe
2023-04-29 17:51:13,391:INFO:Uploading results into container
2023-04-29 17:51:13,391:INFO:Uploading model into container now
2023-04-29 17:51:13,392:INFO:_master_model_container: 17
2023-04-29 17:51:13,392:INFO:_display_container: 2
2023-04-29 17:51:13,392:INFO:LGBMRegressor(random_state=7807)
2023-04-29 17:51:13,392:INFO:create_model() successfully completed......................................
2023-04-29 17:51:13,487:INFO:SubProcess create_model() end ==================================
2023-04-29 17:51:13,487:INFO:Creating metrics dataframe
2023-04-29 17:51:13,492:INFO:Initializing Dummy Regressor
2023-04-29 17:51:13,492:INFO:Total runtime is 1.9670915961265563 minutes
2023-04-29 17:51:13,492:INFO:SubProcess create_model() called ==================================
2023-04-29 17:51:13,492:INFO:Initializing create_model()
2023-04-29 17:51:13,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B8DE3760>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:51:13,492:INFO:Checking exceptions
2023-04-29 17:51:13,492:INFO:Importing libraries
2023-04-29 17:51:13,492:INFO:Copying training dataset
2023-04-29 17:51:13,495:INFO:Defining folds
2023-04-29 17:51:13,496:INFO:Declaring metric variables
2023-04-29 17:51:13,496:INFO:Importing untrained model
2023-04-29 17:51:13,496:INFO:Dummy Regressor Imported successfully
2023-04-29 17:51:13,497:INFO:Starting cross validation
2023-04-29 17:51:13,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:51:18,436:INFO:Calculating mean and std
2023-04-29 17:51:18,437:INFO:Creating metrics dataframe
2023-04-29 17:51:19,076:INFO:Uploading results into container
2023-04-29 17:51:19,077:INFO:Uploading model into container now
2023-04-29 17:51:19,077:INFO:_master_model_container: 18
2023-04-29 17:51:19,078:INFO:_display_container: 2
2023-04-29 17:51:19,078:INFO:DummyRegressor()
2023-04-29 17:51:19,078:INFO:create_model() successfully completed......................................
2023-04-29 17:51:19,172:INFO:SubProcess create_model() end ==================================
2023-04-29 17:51:19,172:INFO:Creating metrics dataframe
2023-04-29 17:51:19,180:INFO:Initializing create_model()
2023-04-29 17:51:19,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=7807), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:51:19,180:INFO:Checking exceptions
2023-04-29 17:51:19,181:INFO:Importing libraries
2023-04-29 17:51:19,181:INFO:Copying training dataset
2023-04-29 17:51:19,185:INFO:Defining folds
2023-04-29 17:51:19,186:INFO:Declaring metric variables
2023-04-29 17:51:19,186:INFO:Importing untrained model
2023-04-29 17:51:19,186:INFO:Declaring custom model
2023-04-29 17:51:19,187:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:51:19,188:INFO:Cross validation set to False
2023-04-29 17:51:19,188:INFO:Fitting Model
2023-04-29 17:51:19,714:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7807)
2023-04-29 17:51:19,714:INFO:create_model() successfully completed......................................
2023-04-29 17:51:19,838:INFO:_master_model_container: 18
2023-04-29 17:51:19,838:INFO:_display_container: 2
2023-04-29 17:51:19,838:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7807)
2023-04-29 17:51:19,838:INFO:compare_models() successfully completed......................................
2023-04-29 17:51:19,842:INFO:Initializing predict_model()
2023-04-29 17:51:19,842:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B9000BB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=7807), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000243B8C9BDC0>)
2023-04-29 17:51:19,842:INFO:Checking exceptions
2023-04-29 17:51:19,843:INFO:Preloading libraries
2023-04-29 17:51:19,843:INFO:Set up data.
2023-04-29 17:51:19,848:INFO:Set up index.
2023-04-29 17:54:03,808:INFO:PyCaret RegressionExperiment
2023-04-29 17:54:03,808:INFO:Logging name: reg-default-name
2023-04-29 17:54:03,808:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:54:03,808:INFO:version 3.0.0
2023-04-29 17:54:03,808:INFO:Initializing setup()
2023-04-29 17:54:03,808:INFO:self.USI: a433
2023-04-29 17:54:03,808:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:54:03,808:INFO:Checking environment
2023-04-29 17:54:03,809:INFO:python_version: 3.9.13
2023-04-29 17:54:03,809:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:54:03,809:INFO:machine: AMD64
2023-04-29 17:54:03,809:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:54:03,809:INFO:Memory: svmem(total=16935899136, available=5587578880, percent=67.0, used=11348320256, free=5587578880)
2023-04-29 17:54:03,809:INFO:Physical Core: 4
2023-04-29 17:54:03,809:INFO:Logical Core: 8
2023-04-29 17:54:03,809:INFO:Checking libraries
2023-04-29 17:54:03,809:INFO:System:
2023-04-29 17:54:03,809:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:54:03,809:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:54:03,809:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:54:03,809:INFO:PyCaret required dependencies:
2023-04-29 17:54:03,810:INFO:                 pip: 22.2.2
2023-04-29 17:54:03,810:INFO:          setuptools: 63.4.1
2023-04-29 17:54:03,810:INFO:             pycaret: 3.0.0
2023-04-29 17:54:03,811:INFO:             IPython: 7.31.1
2023-04-29 17:54:03,811:INFO:          ipywidgets: 7.6.5
2023-04-29 17:54:03,811:INFO:                tqdm: 4.64.1
2023-04-29 17:54:03,811:INFO:               numpy: 1.21.5
2023-04-29 17:54:03,811:INFO:              pandas: 1.4.4
2023-04-29 17:54:03,811:INFO:              jinja2: 2.11.3
2023-04-29 17:54:03,811:INFO:               scipy: 1.9.1
2023-04-29 17:54:03,811:INFO:              joblib: 1.2.0
2023-04-29 17:54:03,811:INFO:             sklearn: 1.0.2
2023-04-29 17:54:03,811:INFO:                pyod: 1.0.9
2023-04-29 17:54:03,811:INFO:            imblearn: 0.10.1
2023-04-29 17:54:03,811:INFO:   category_encoders: 2.6.0
2023-04-29 17:54:03,811:INFO:            lightgbm: 3.3.5
2023-04-29 17:54:03,811:INFO:               numba: 0.55.1
2023-04-29 17:54:03,811:INFO:            requests: 2.28.1
2023-04-29 17:54:03,811:INFO:          matplotlib: 3.5.2
2023-04-29 17:54:03,811:INFO:          scikitplot: 0.3.7
2023-04-29 17:54:03,812:INFO:         yellowbrick: 1.5
2023-04-29 17:54:03,812:INFO:              plotly: 5.9.0
2023-04-29 17:54:03,812:INFO:             kaleido: 0.2.1
2023-04-29 17:54:03,812:INFO:         statsmodels: 0.13.2
2023-04-29 17:54:03,812:INFO:              sktime: 0.17.1
2023-04-29 17:54:03,812:INFO:               tbats: 1.1.2
2023-04-29 17:54:03,812:INFO:            pmdarima: 2.0.3
2023-04-29 17:54:03,812:INFO:              psutil: 5.9.0
2023-04-29 17:54:03,812:INFO:PyCaret optional dependencies:
2023-04-29 17:54:03,812:INFO:                shap: 0.41.0
2023-04-29 17:54:03,812:INFO:           interpret: Not installed
2023-04-29 17:54:03,812:INFO:                umap: Not installed
2023-04-29 17:54:03,812:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:54:03,812:INFO:  explainerdashboard: Not installed
2023-04-29 17:54:03,812:INFO:             autoviz: Not installed
2023-04-29 17:54:03,812:INFO:           fairlearn: Not installed
2023-04-29 17:54:03,812:INFO:             xgboost: Not installed
2023-04-29 17:54:03,812:INFO:            catboost: Not installed
2023-04-29 17:54:03,812:INFO:              kmodes: Not installed
2023-04-29 17:54:03,812:INFO:             mlxtend: Not installed
2023-04-29 17:54:03,812:INFO:       statsforecast: Not installed
2023-04-29 17:54:03,813:INFO:        tune_sklearn: Not installed
2023-04-29 17:54:03,813:INFO:                 ray: Not installed
2023-04-29 17:54:03,813:INFO:            hyperopt: Not installed
2023-04-29 17:54:03,813:INFO:              optuna: Not installed
2023-04-29 17:54:03,813:INFO:               skopt: Not installed
2023-04-29 17:54:03,813:INFO:              mlflow: 2.2.1
2023-04-29 17:54:03,813:INFO:              gradio: Not installed
2023-04-29 17:54:03,813:INFO:             fastapi: Not installed
2023-04-29 17:54:03,813:INFO:             uvicorn: Not installed
2023-04-29 17:54:03,813:INFO:              m2cgen: Not installed
2023-04-29 17:54:03,813:INFO:           evidently: Not installed
2023-04-29 17:54:03,813:INFO:               fugue: Not installed
2023-04-29 17:54:03,813:INFO:           streamlit: 1.21.0
2023-04-29 17:54:03,813:INFO:             prophet: Not installed
2023-04-29 17:54:03,813:INFO:None
2023-04-29 17:54:03,813:INFO:Set up data.
2023-04-29 17:54:03,817:INFO:Set up train/test split.
2023-04-29 17:54:03,820:INFO:Set up index.
2023-04-29 17:54:03,821:INFO:Set up folding strategy.
2023-04-29 17:54:03,821:INFO:Assigning column types.
2023-04-29 17:54:03,823:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:54:03,824:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,828:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:03,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:03,954:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:03,964:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,110:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:54:04,117:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,125:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,413:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:54:04,426:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,702:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:54:04,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:04,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:04,976:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:54:05,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:05,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:05,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,490:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:54:05,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:05,869:INFO:Preparing preprocessing pipeline...
2023-04-29 17:54:05,869:INFO:Set up simple imputation.
2023-04-29 17:54:05,872:INFO:Set up column name cleaning.
2023-04-29 17:54:05,970:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:54:05,994:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:54:05,996:INFO:Creating final display dataframe.
2023-04-29 17:54:06,423:INFO:Setup _display_container:                     Description             Value
0                    Session id              7864
1                        Target               VEC
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a433
2023-04-29 17:54:06,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:06,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:06,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:06,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:06,994:INFO:setup() successfully completed in 3.74s...............
2023-04-29 17:54:08,791:INFO:PyCaret RegressionExperiment
2023-04-29 17:54:08,791:INFO:Logging name: reg-default-name
2023-04-29 17:54:08,792:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:54:08,792:INFO:version 3.0.0
2023-04-29 17:54:08,792:INFO:Initializing setup()
2023-04-29 17:54:08,792:INFO:self.USI: d760
2023-04-29 17:54:08,792:INFO:self._variable_keys: {'X_test', 'X_train', 'exp_id', 'fold_shuffle_param', 'html_param', 'idx', 'gpu_param', 'y_train', 'memory', 'fold_generator', 'X', 'gpu_n_jobs_param', 'log_plots_param', 'seed', 'y', 'n_jobs_param', 'fold_groups_param', 'transform_target_param', 'pipeline', 'USI', 'exp_name_log', 'logging_param', '_available_plots', 'data', 'target_param', '_ml_usecase', 'y_test'}
2023-04-29 17:54:08,792:INFO:Checking environment
2023-04-29 17:54:08,792:INFO:python_version: 3.9.13
2023-04-29 17:54:08,793:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:54:08,793:INFO:machine: AMD64
2023-04-29 17:54:08,793:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:54:08,793:INFO:Memory: svmem(total=16935899136, available=5615669248, percent=66.8, used=11320229888, free=5615669248)
2023-04-29 17:54:08,793:INFO:Physical Core: 4
2023-04-29 17:54:08,793:INFO:Logical Core: 8
2023-04-29 17:54:08,793:INFO:Checking libraries
2023-04-29 17:54:08,793:INFO:System:
2023-04-29 17:54:08,793:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:54:08,794:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:54:08,794:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:54:08,794:INFO:PyCaret required dependencies:
2023-04-29 17:54:08,794:INFO:                 pip: 22.2.2
2023-04-29 17:54:08,794:INFO:          setuptools: 63.4.1
2023-04-29 17:54:08,794:INFO:             pycaret: 3.0.0
2023-04-29 17:54:08,794:INFO:             IPython: 7.31.1
2023-04-29 17:54:08,794:INFO:          ipywidgets: 7.6.5
2023-04-29 17:54:08,794:INFO:                tqdm: 4.64.1
2023-04-29 17:54:08,794:INFO:               numpy: 1.21.5
2023-04-29 17:54:08,795:INFO:              pandas: 1.4.4
2023-04-29 17:54:08,795:INFO:              jinja2: 2.11.3
2023-04-29 17:54:08,795:INFO:               scipy: 1.9.1
2023-04-29 17:54:08,795:INFO:              joblib: 1.2.0
2023-04-29 17:54:08,795:INFO:             sklearn: 1.0.2
2023-04-29 17:54:08,795:INFO:                pyod: 1.0.9
2023-04-29 17:54:08,795:INFO:            imblearn: 0.10.1
2023-04-29 17:54:08,795:INFO:   category_encoders: 2.6.0
2023-04-29 17:54:08,795:INFO:            lightgbm: 3.3.5
2023-04-29 17:54:08,795:INFO:               numba: 0.55.1
2023-04-29 17:54:08,795:INFO:            requests: 2.28.1
2023-04-29 17:54:08,795:INFO:          matplotlib: 3.5.2
2023-04-29 17:54:08,795:INFO:          scikitplot: 0.3.7
2023-04-29 17:54:08,795:INFO:         yellowbrick: 1.5
2023-04-29 17:54:08,795:INFO:              plotly: 5.9.0
2023-04-29 17:54:08,795:INFO:             kaleido: 0.2.1
2023-04-29 17:54:08,795:INFO:         statsmodels: 0.13.2
2023-04-29 17:54:08,795:INFO:              sktime: 0.17.1
2023-04-29 17:54:08,795:INFO:               tbats: 1.1.2
2023-04-29 17:54:08,795:INFO:            pmdarima: 2.0.3
2023-04-29 17:54:08,795:INFO:              psutil: 5.9.0
2023-04-29 17:54:08,795:INFO:PyCaret optional dependencies:
2023-04-29 17:54:08,796:INFO:                shap: 0.41.0
2023-04-29 17:54:08,796:INFO:           interpret: Not installed
2023-04-29 17:54:08,796:INFO:                umap: Not installed
2023-04-29 17:54:08,796:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:54:08,796:INFO:  explainerdashboard: Not installed
2023-04-29 17:54:08,796:INFO:             autoviz: Not installed
2023-04-29 17:54:08,796:INFO:           fairlearn: Not installed
2023-04-29 17:54:08,796:INFO:             xgboost: Not installed
2023-04-29 17:54:08,796:INFO:            catboost: Not installed
2023-04-29 17:54:08,796:INFO:              kmodes: Not installed
2023-04-29 17:54:08,796:INFO:             mlxtend: Not installed
2023-04-29 17:54:08,796:INFO:       statsforecast: Not installed
2023-04-29 17:54:08,796:INFO:        tune_sklearn: Not installed
2023-04-29 17:54:08,796:INFO:                 ray: Not installed
2023-04-29 17:54:08,796:INFO:            hyperopt: Not installed
2023-04-29 17:54:08,796:INFO:              optuna: Not installed
2023-04-29 17:54:08,796:INFO:               skopt: Not installed
2023-04-29 17:54:08,796:INFO:              mlflow: 2.2.1
2023-04-29 17:54:08,796:INFO:              gradio: Not installed
2023-04-29 17:54:08,796:INFO:             fastapi: Not installed
2023-04-29 17:54:08,796:INFO:             uvicorn: Not installed
2023-04-29 17:54:08,797:INFO:              m2cgen: Not installed
2023-04-29 17:54:08,797:INFO:           evidently: Not installed
2023-04-29 17:54:08,797:INFO:               fugue: Not installed
2023-04-29 17:54:08,797:INFO:           streamlit: 1.21.0
2023-04-29 17:54:08,797:INFO:             prophet: Not installed
2023-04-29 17:54:08,797:INFO:None
2023-04-29 17:54:08,797:INFO:Set up data.
2023-04-29 17:54:08,802:INFO:Set up train/test split.
2023-04-29 17:54:08,804:INFO:Set up index.
2023-04-29 17:54:08,804:INFO:Set up folding strategy.
2023-04-29 17:54:08,805:INFO:Assigning column types.
2023-04-29 17:54:08,807:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:54:08,807:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,812:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,816:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,885:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:08,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:08,950:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,955:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:08,959:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,120:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:54:09,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,129:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,303:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,520:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:54:09,529:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,617:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,801:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:09,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:09,885:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:54:10,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:10,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:10,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:10,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:54:10,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,376:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:54:10,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:10,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:54:10,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:10,962:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:54:11,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,422:INFO:Preparing preprocessing pipeline...
2023-04-29 17:54:11,422:INFO:Set up simple imputation.
2023-04-29 17:54:11,423:INFO:Set up column name cleaning.
2023-04-29 17:54:11,450:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:54:11,462:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:54:11,462:INFO:Creating final display dataframe.
2023-04-29 17:54:11,566:INFO:Setup _display_container:                     Description             Value
0                    Session id              2599
1                        Target               VEC
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d760
2023-04-29 17:54:11,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:54:11,843:INFO:setup() successfully completed in 3.73s...............
2023-04-29 17:54:11,849:INFO:Initializing compare_models()
2023-04-29 17:54:11,850:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EA2190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EA2190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:54:11,850:INFO:Checking exceptions
2023-04-29 17:54:11,852:INFO:Preparing display monitor
2023-04-29 17:54:11,855:INFO:Initializing Linear Regression
2023-04-29 17:54:11,856:INFO:Total runtime is 1.7289320627848307e-05 minutes
2023-04-29 17:54:11,856:INFO:SubProcess create_model() called ==================================
2023-04-29 17:54:11,857:INFO:Initializing create_model()
2023-04-29 17:54:11,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EA2190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6C97BE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:54:11,857:INFO:Checking exceptions
2023-04-29 17:54:11,857:INFO:Importing libraries
2023-04-29 17:54:11,857:INFO:Copying training dataset
2023-04-29 17:54:11,860:INFO:Defining folds
2023-04-29 17:54:11,860:INFO:Declaring metric variables
2023-04-29 17:54:11,861:INFO:Importing untrained model
2023-04-29 17:54:11,861:INFO:Linear Regression Imported successfully
2023-04-29 17:54:11,861:INFO:Starting cross validation
2023-04-29 17:54:11,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:54:16,383:INFO:Calculating mean and std
2023-04-29 17:54:16,383:INFO:Creating metrics dataframe
2023-04-29 17:54:16,928:INFO:Uploading results into container
2023-04-29 17:54:16,928:INFO:Uploading model into container now
2023-04-29 17:54:16,929:INFO:_master_model_container: 1
2023-04-29 17:54:16,929:INFO:_display_container: 2
2023-04-29 17:54:16,929:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:54:16,929:INFO:create_model() successfully completed......................................
2023-04-29 17:54:17,031:INFO:SubProcess create_model() end ==================================
2023-04-29 17:54:17,031:INFO:Creating metrics dataframe
2023-04-29 17:54:17,034:INFO:Initializing Lasso Regression
2023-04-29 17:54:17,035:INFO:Total runtime is 0.08633209864298502 minutes
2023-04-29 17:54:17,035:INFO:SubProcess create_model() called ==================================
2023-04-29 17:54:17,035:INFO:Initializing create_model()
2023-04-29 17:54:17,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EA2190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6C97BE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:54:17,035:INFO:Checking exceptions
2023-04-29 17:54:17,035:INFO:Importing libraries
2023-04-29 17:54:17,035:INFO:Copying training dataset
2023-04-29 17:54:17,038:INFO:Defining folds
2023-04-29 17:54:17,038:INFO:Declaring metric variables
2023-04-29 17:54:17,039:INFO:Importing untrained model
2023-04-29 17:54:17,039:INFO:Lasso Regression Imported successfully
2023-04-29 17:54:17,039:INFO:Starting cross validation
2023-04-29 17:54:17,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:54:21,639:INFO:Calculating mean and std
2023-04-29 17:54:21,640:INFO:Creating metrics dataframe
2023-04-29 17:54:22,199:INFO:Uploading results into container
2023-04-29 17:54:22,200:INFO:Uploading model into container now
2023-04-29 17:54:22,201:INFO:_master_model_container: 2
2023-04-29 17:54:22,201:INFO:_display_container: 2
2023-04-29 17:54:22,201:INFO:Lasso(random_state=2599)
2023-04-29 17:54:22,201:INFO:create_model() successfully completed......................................
2023-04-29 17:54:22,297:INFO:SubProcess create_model() end ==================================
2023-04-29 17:54:22,297:INFO:Creating metrics dataframe
2023-04-29 17:54:22,301:INFO:Initializing Ridge Regression
2023-04-29 17:54:22,302:INFO:Total runtime is 0.1741113821665446 minutes
2023-04-29 17:54:22,302:INFO:SubProcess create_model() called ==================================
2023-04-29 17:54:22,302:INFO:Initializing create_model()
2023-04-29 17:54:22,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000243B6EA2190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000243B6C97BE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:54:22,302:INFO:Checking exceptions
2023-04-29 17:54:22,302:INFO:Importing libraries
2023-04-29 17:54:22,302:INFO:Copying training dataset
2023-04-29 17:54:22,307:INFO:Defining folds
2023-04-29 17:54:22,307:INFO:Declaring metric variables
2023-04-29 17:54:22,307:INFO:Importing untrained model
2023-04-29 17:54:22,307:INFO:Ridge Regression Imported successfully
2023-04-29 17:54:22,307:INFO:Starting cross validation
2023-04-29 17:54:22,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:54:59,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 17:54:59,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 17:54:59,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 17:54:59,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 17:55:00,622:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-29 17:55:07,403:INFO:PyCaret RegressionExperiment
2023-04-29 17:55:07,404:INFO:Logging name: reg-default-name
2023-04-29 17:55:07,404:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:55:07,404:INFO:version 3.0.0
2023-04-29 17:55:07,404:INFO:Initializing setup()
2023-04-29 17:55:07,404:INFO:self.USI: e93c
2023-04-29 17:55:07,404:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 17:55:07,404:INFO:Checking environment
2023-04-29 17:55:07,404:INFO:python_version: 3.9.13
2023-04-29 17:55:07,404:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:55:07,404:INFO:machine: AMD64
2023-04-29 17:55:07,422:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:55:07,422:INFO:Memory: svmem(total=16935899136, available=6516047872, percent=61.5, used=10419851264, free=6516047872)
2023-04-29 17:55:07,422:INFO:Physical Core: 4
2023-04-29 17:55:07,422:INFO:Logical Core: 8
2023-04-29 17:55:07,424:INFO:Checking libraries
2023-04-29 17:55:07,424:INFO:System:
2023-04-29 17:55:07,424:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:55:07,424:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:55:07,424:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:55:07,424:INFO:PyCaret required dependencies:
2023-04-29 17:55:07,424:INFO:                 pip: 22.2.2
2023-04-29 17:55:07,424:INFO:          setuptools: 63.4.1
2023-04-29 17:55:07,424:INFO:             pycaret: 3.0.0
2023-04-29 17:55:07,424:INFO:             IPython: 7.31.1
2023-04-29 17:55:07,425:INFO:          ipywidgets: 7.6.5
2023-04-29 17:55:07,425:INFO:                tqdm: 4.64.1
2023-04-29 17:55:07,425:INFO:               numpy: 1.21.5
2023-04-29 17:55:07,425:INFO:              pandas: 1.4.4
2023-04-29 17:55:07,425:INFO:              jinja2: 2.11.3
2023-04-29 17:55:07,425:INFO:               scipy: 1.9.1
2023-04-29 17:55:07,425:INFO:              joblib: 1.2.0
2023-04-29 17:55:07,425:INFO:             sklearn: 1.0.2
2023-04-29 17:55:07,425:INFO:                pyod: 1.0.9
2023-04-29 17:55:07,425:INFO:            imblearn: 0.10.1
2023-04-29 17:55:07,425:INFO:   category_encoders: 2.6.0
2023-04-29 17:55:07,426:INFO:            lightgbm: 3.3.5
2023-04-29 17:55:07,426:INFO:               numba: 0.55.1
2023-04-29 17:55:07,426:INFO:            requests: 2.28.1
2023-04-29 17:55:07,426:INFO:          matplotlib: 3.5.2
2023-04-29 17:55:07,426:INFO:          scikitplot: 0.3.7
2023-04-29 17:55:07,426:INFO:         yellowbrick: 1.5
2023-04-29 17:55:07,426:INFO:              plotly: 5.9.0
2023-04-29 17:55:07,426:INFO:             kaleido: 0.2.1
2023-04-29 17:55:07,426:INFO:         statsmodels: 0.13.2
2023-04-29 17:55:07,426:INFO:              sktime: 0.17.1
2023-04-29 17:55:07,426:INFO:               tbats: 1.1.2
2023-04-29 17:55:07,426:INFO:            pmdarima: 2.0.3
2023-04-29 17:55:07,426:INFO:              psutil: 5.9.0
2023-04-29 17:55:07,426:INFO:PyCaret optional dependencies:
2023-04-29 17:55:07,443:INFO:                shap: 0.41.0
2023-04-29 17:55:07,443:INFO:           interpret: Not installed
2023-04-29 17:55:07,443:INFO:                umap: Not installed
2023-04-29 17:55:07,443:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:55:07,443:INFO:  explainerdashboard: Not installed
2023-04-29 17:55:07,443:INFO:             autoviz: Not installed
2023-04-29 17:55:07,443:INFO:           fairlearn: Not installed
2023-04-29 17:55:07,443:INFO:             xgboost: Not installed
2023-04-29 17:55:07,443:INFO:            catboost: Not installed
2023-04-29 17:55:07,443:INFO:              kmodes: Not installed
2023-04-29 17:55:07,443:INFO:             mlxtend: Not installed
2023-04-29 17:55:07,443:INFO:       statsforecast: Not installed
2023-04-29 17:55:07,443:INFO:        tune_sklearn: Not installed
2023-04-29 17:55:07,443:INFO:                 ray: Not installed
2023-04-29 17:55:07,443:INFO:            hyperopt: Not installed
2023-04-29 17:55:07,443:INFO:              optuna: Not installed
2023-04-29 17:55:07,443:INFO:               skopt: Not installed
2023-04-29 17:55:07,444:INFO:              mlflow: 2.2.1
2023-04-29 17:55:07,444:INFO:              gradio: Not installed
2023-04-29 17:55:07,444:INFO:             fastapi: Not installed
2023-04-29 17:55:07,444:INFO:             uvicorn: Not installed
2023-04-29 17:55:07,444:INFO:              m2cgen: Not installed
2023-04-29 17:55:07,444:INFO:           evidently: Not installed
2023-04-29 17:55:07,444:INFO:               fugue: Not installed
2023-04-29 17:55:07,444:INFO:           streamlit: 1.21.0
2023-04-29 17:55:07,444:INFO:             prophet: Not installed
2023-04-29 17:55:07,444:INFO:None
2023-04-29 17:55:07,444:INFO:Set up data.
2023-04-29 17:55:07,453:INFO:Set up train/test split.
2023-04-29 17:55:07,459:INFO:Set up index.
2023-04-29 17:55:07,459:INFO:Set up folding strategy.
2023-04-29 17:55:07,460:INFO:Assigning column types.
2023-04-29 17:55:07,462:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:55:07,463:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,468:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,473:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:07,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:07,671:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,678:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,694:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:07,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:07,910:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:55:07,917:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:55:07,923:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,015:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,086:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,097:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,241:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:55:08,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,463:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,562:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,668:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:55:08,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:08,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:08,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:09,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:55:09,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,005:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:55:09,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:09,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:55:09,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,361:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:55:09,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:09,673:INFO:Preparing preprocessing pipeline...
2023-04-29 17:55:09,673:INFO:Set up simple imputation.
2023-04-29 17:55:09,674:INFO:Set up column name cleaning.
2023-04-29 17:55:09,727:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:55:09,738:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:55:09,738:INFO:Creating final display dataframe.
2023-04-29 17:55:09,837:INFO:Setup _display_container:                     Description             Value
0                    Session id              7671
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e93c
2023-04-29 17:55:10,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:10,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:10,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:10,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:55:10,286:INFO:setup() successfully completed in 3.4s...............
2023-04-29 17:55:10,291:INFO:Initializing compare_models()
2023-04-29 17:55:10,291:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:55:10,291:INFO:Checking exceptions
2023-04-29 17:55:10,293:INFO:Preparing display monitor
2023-04-29 17:55:10,299:INFO:Initializing Linear Regression
2023-04-29 17:55:10,299:INFO:Total runtime is 8.340676625569662e-06 minutes
2023-04-29 17:55:10,299:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:10,300:INFO:Initializing create_model()
2023-04-29 17:55:10,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:10,300:INFO:Checking exceptions
2023-04-29 17:55:10,300:INFO:Importing libraries
2023-04-29 17:55:10,301:INFO:Copying training dataset
2023-04-29 17:55:10,311:INFO:Defining folds
2023-04-29 17:55:10,312:INFO:Declaring metric variables
2023-04-29 17:55:10,312:INFO:Importing untrained model
2023-04-29 17:55:10,312:INFO:Linear Regression Imported successfully
2023-04-29 17:55:10,313:INFO:Starting cross validation
2023-04-29 17:55:10,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:22,968:INFO:Calculating mean and std
2023-04-29 17:55:22,969:INFO:Creating metrics dataframe
2023-04-29 17:55:23,674:INFO:Uploading results into container
2023-04-29 17:55:23,675:INFO:Uploading model into container now
2023-04-29 17:55:23,675:INFO:_master_model_container: 1
2023-04-29 17:55:23,675:INFO:_display_container: 2
2023-04-29 17:55:23,675:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:55:23,675:INFO:create_model() successfully completed......................................
2023-04-29 17:55:23,767:INFO:SubProcess create_model() end ==================================
2023-04-29 17:55:23,767:INFO:Creating metrics dataframe
2023-04-29 17:55:23,770:INFO:Initializing Lasso Regression
2023-04-29 17:55:23,770:INFO:Total runtime is 0.22451493740081785 minutes
2023-04-29 17:55:23,770:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:23,770:INFO:Initializing create_model()
2023-04-29 17:55:23,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:23,770:INFO:Checking exceptions
2023-04-29 17:55:23,770:INFO:Importing libraries
2023-04-29 17:55:23,771:INFO:Copying training dataset
2023-04-29 17:55:23,775:INFO:Defining folds
2023-04-29 17:55:23,775:INFO:Declaring metric variables
2023-04-29 17:55:23,775:INFO:Importing untrained model
2023-04-29 17:55:23,776:INFO:Lasso Regression Imported successfully
2023-04-29 17:55:23,776:INFO:Starting cross validation
2023-04-29 17:55:23,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:30,842:INFO:Calculating mean and std
2023-04-29 17:55:30,843:INFO:Creating metrics dataframe
2023-04-29 17:55:31,729:INFO:Uploading results into container
2023-04-29 17:55:31,729:INFO:Uploading model into container now
2023-04-29 17:55:31,730:INFO:_master_model_container: 2
2023-04-29 17:55:31,730:INFO:_display_container: 2
2023-04-29 17:55:31,730:INFO:Lasso(random_state=7671)
2023-04-29 17:55:31,731:INFO:create_model() successfully completed......................................
2023-04-29 17:55:31,867:INFO:SubProcess create_model() end ==================================
2023-04-29 17:55:31,867:INFO:Creating metrics dataframe
2023-04-29 17:55:31,873:INFO:Initializing Ridge Regression
2023-04-29 17:55:31,873:INFO:Total runtime is 0.35956282615661617 minutes
2023-04-29 17:55:31,874:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:31,874:INFO:Initializing create_model()
2023-04-29 17:55:31,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:31,875:INFO:Checking exceptions
2023-04-29 17:55:31,875:INFO:Importing libraries
2023-04-29 17:55:31,875:INFO:Copying training dataset
2023-04-29 17:55:31,880:INFO:Defining folds
2023-04-29 17:55:31,880:INFO:Declaring metric variables
2023-04-29 17:55:31,880:INFO:Importing untrained model
2023-04-29 17:55:31,881:INFO:Ridge Regression Imported successfully
2023-04-29 17:55:31,882:INFO:Starting cross validation
2023-04-29 17:55:31,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:38,751:INFO:Calculating mean and std
2023-04-29 17:55:38,751:INFO:Creating metrics dataframe
2023-04-29 17:55:39,378:INFO:Uploading results into container
2023-04-29 17:55:39,379:INFO:Uploading model into container now
2023-04-29 17:55:39,379:INFO:_master_model_container: 3
2023-04-29 17:55:39,379:INFO:_display_container: 2
2023-04-29 17:55:39,380:INFO:Ridge(random_state=7671)
2023-04-29 17:55:39,380:INFO:create_model() successfully completed......................................
2023-04-29 17:55:39,472:INFO:SubProcess create_model() end ==================================
2023-04-29 17:55:39,473:INFO:Creating metrics dataframe
2023-04-29 17:55:39,476:INFO:Initializing Elastic Net
2023-04-29 17:55:39,476:INFO:Total runtime is 0.4862854242324829 minutes
2023-04-29 17:55:39,476:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:39,477:INFO:Initializing create_model()
2023-04-29 17:55:39,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:39,477:INFO:Checking exceptions
2023-04-29 17:55:39,477:INFO:Importing libraries
2023-04-29 17:55:39,477:INFO:Copying training dataset
2023-04-29 17:55:39,481:INFO:Defining folds
2023-04-29 17:55:39,481:INFO:Declaring metric variables
2023-04-29 17:55:39,481:INFO:Importing untrained model
2023-04-29 17:55:39,482:INFO:Elastic Net Imported successfully
2023-04-29 17:55:39,482:INFO:Starting cross validation
2023-04-29 17:55:39,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:44,497:INFO:Calculating mean and std
2023-04-29 17:55:44,498:INFO:Creating metrics dataframe
2023-04-29 17:55:45,137:INFO:Uploading results into container
2023-04-29 17:55:45,138:INFO:Uploading model into container now
2023-04-29 17:55:45,138:INFO:_master_model_container: 4
2023-04-29 17:55:45,138:INFO:_display_container: 2
2023-04-29 17:55:45,139:INFO:ElasticNet(random_state=7671)
2023-04-29 17:55:45,139:INFO:create_model() successfully completed......................................
2023-04-29 17:55:45,229:INFO:SubProcess create_model() end ==================================
2023-04-29 17:55:45,229:INFO:Creating metrics dataframe
2023-04-29 17:55:45,233:INFO:Initializing Least Angle Regression
2023-04-29 17:55:45,233:INFO:Total runtime is 0.5822287519772847 minutes
2023-04-29 17:55:45,234:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:45,234:INFO:Initializing create_model()
2023-04-29 17:55:45,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:45,234:INFO:Checking exceptions
2023-04-29 17:55:45,234:INFO:Importing libraries
2023-04-29 17:55:45,234:INFO:Copying training dataset
2023-04-29 17:55:45,239:INFO:Defining folds
2023-04-29 17:55:45,239:INFO:Declaring metric variables
2023-04-29 17:55:45,239:INFO:Importing untrained model
2023-04-29 17:55:45,240:INFO:Least Angle Regression Imported successfully
2023-04-29 17:55:45,241:INFO:Starting cross validation
2023-04-29 17:55:45,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:45,298:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,315:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,332:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,344:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,363:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,375:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,397:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:45,411:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:46,647:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:46,683:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:50,193:INFO:Calculating mean and std
2023-04-29 17:55:50,194:INFO:Creating metrics dataframe
2023-04-29 17:55:50,826:INFO:Uploading results into container
2023-04-29 17:55:50,827:INFO:Uploading model into container now
2023-04-29 17:55:50,827:INFO:_master_model_container: 5
2023-04-29 17:55:50,827:INFO:_display_container: 2
2023-04-29 17:55:50,828:INFO:Lars(random_state=7671)
2023-04-29 17:55:50,828:INFO:create_model() successfully completed......................................
2023-04-29 17:55:50,922:INFO:SubProcess create_model() end ==================================
2023-04-29 17:55:50,922:INFO:Creating metrics dataframe
2023-04-29 17:55:50,927:INFO:Initializing Lasso Least Angle Regression
2023-04-29 17:55:50,927:INFO:Total runtime is 0.6771396358807882 minutes
2023-04-29 17:55:50,927:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:50,927:INFO:Initializing create_model()
2023-04-29 17:55:50,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:50,927:INFO:Checking exceptions
2023-04-29 17:55:50,927:INFO:Importing libraries
2023-04-29 17:55:50,927:INFO:Copying training dataset
2023-04-29 17:55:50,931:INFO:Defining folds
2023-04-29 17:55:50,931:INFO:Declaring metric variables
2023-04-29 17:55:50,931:INFO:Importing untrained model
2023-04-29 17:55:50,931:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 17:55:50,932:INFO:Starting cross validation
2023-04-29 17:55:50,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:50,991:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:50,998:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:51,019:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:51,037:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:51,065:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:51,081:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:51,092:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:51,099:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:52,383:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:52,393:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 17:55:56,004:INFO:Calculating mean and std
2023-04-29 17:55:56,005:INFO:Creating metrics dataframe
2023-04-29 17:55:56,633:INFO:Uploading results into container
2023-04-29 17:55:56,634:INFO:Uploading model into container now
2023-04-29 17:55:56,635:INFO:_master_model_container: 6
2023-04-29 17:55:56,635:INFO:_display_container: 2
2023-04-29 17:55:56,635:INFO:LassoLars(random_state=7671)
2023-04-29 17:55:56,635:INFO:create_model() successfully completed......................................
2023-04-29 17:55:56,728:INFO:SubProcess create_model() end ==================================
2023-04-29 17:55:56,728:INFO:Creating metrics dataframe
2023-04-29 17:55:56,732:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 17:55:56,732:INFO:Total runtime is 0.773877207438151 minutes
2023-04-29 17:55:56,732:INFO:SubProcess create_model() called ==================================
2023-04-29 17:55:56,733:INFO:Initializing create_model()
2023-04-29 17:55:56,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:55:56,733:INFO:Checking exceptions
2023-04-29 17:55:56,733:INFO:Importing libraries
2023-04-29 17:55:56,733:INFO:Copying training dataset
2023-04-29 17:55:56,738:INFO:Defining folds
2023-04-29 17:55:56,738:INFO:Declaring metric variables
2023-04-29 17:55:56,738:INFO:Importing untrained model
2023-04-29 17:55:56,738:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 17:55:56,739:INFO:Starting cross validation
2023-04-29 17:55:56,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:55:56,795:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,810:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,817:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,838:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,850:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,870:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,887:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:56,901:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:58,222:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:55:58,233:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 17:56:01,920:INFO:Calculating mean and std
2023-04-29 17:56:01,921:INFO:Creating metrics dataframe
2023-04-29 17:56:02,576:INFO:Uploading results into container
2023-04-29 17:56:02,577:INFO:Uploading model into container now
2023-04-29 17:56:02,577:INFO:_master_model_container: 7
2023-04-29 17:56:02,577:INFO:_display_container: 2
2023-04-29 17:56:02,577:INFO:OrthogonalMatchingPursuit()
2023-04-29 17:56:02,577:INFO:create_model() successfully completed......................................
2023-04-29 17:56:02,669:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:02,669:INFO:Creating metrics dataframe
2023-04-29 17:56:02,674:INFO:Initializing Bayesian Ridge
2023-04-29 17:56:02,674:INFO:Total runtime is 0.8729170083999633 minutes
2023-04-29 17:56:02,674:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:02,674:INFO:Initializing create_model()
2023-04-29 17:56:02,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:02,674:INFO:Checking exceptions
2023-04-29 17:56:02,674:INFO:Importing libraries
2023-04-29 17:56:02,674:INFO:Copying training dataset
2023-04-29 17:56:02,677:INFO:Defining folds
2023-04-29 17:56:02,677:INFO:Declaring metric variables
2023-04-29 17:56:02,678:INFO:Importing untrained model
2023-04-29 17:56:02,679:INFO:Bayesian Ridge Imported successfully
2023-04-29 17:56:02,679:INFO:Starting cross validation
2023-04-29 17:56:02,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:07,684:INFO:Calculating mean and std
2023-04-29 17:56:07,685:INFO:Creating metrics dataframe
2023-04-29 17:56:08,350:INFO:Uploading results into container
2023-04-29 17:56:08,350:INFO:Uploading model into container now
2023-04-29 17:56:08,350:INFO:_master_model_container: 8
2023-04-29 17:56:08,350:INFO:_display_container: 2
2023-04-29 17:56:08,352:INFO:BayesianRidge()
2023-04-29 17:56:08,352:INFO:create_model() successfully completed......................................
2023-04-29 17:56:08,446:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:08,447:INFO:Creating metrics dataframe
2023-04-29 17:56:08,451:INFO:Initializing Passive Aggressive Regressor
2023-04-29 17:56:08,452:INFO:Total runtime is 0.9692233006159464 minutes
2023-04-29 17:56:08,452:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:08,452:INFO:Initializing create_model()
2023-04-29 17:56:08,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:08,452:INFO:Checking exceptions
2023-04-29 17:56:08,452:INFO:Importing libraries
2023-04-29 17:56:08,453:INFO:Copying training dataset
2023-04-29 17:56:08,456:INFO:Defining folds
2023-04-29 17:56:08,456:INFO:Declaring metric variables
2023-04-29 17:56:08,456:INFO:Importing untrained model
2023-04-29 17:56:08,457:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 17:56:08,457:INFO:Starting cross validation
2023-04-29 17:56:08,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:13,444:INFO:Calculating mean and std
2023-04-29 17:56:13,445:INFO:Creating metrics dataframe
2023-04-29 17:56:14,085:INFO:Uploading results into container
2023-04-29 17:56:14,086:INFO:Uploading model into container now
2023-04-29 17:56:14,086:INFO:_master_model_container: 9
2023-04-29 17:56:14,086:INFO:_display_container: 2
2023-04-29 17:56:14,086:INFO:PassiveAggressiveRegressor(random_state=7671)
2023-04-29 17:56:14,087:INFO:create_model() successfully completed......................................
2023-04-29 17:56:14,177:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:14,178:INFO:Creating metrics dataframe
2023-04-29 17:56:14,183:INFO:Initializing Huber Regressor
2023-04-29 17:56:14,184:INFO:Total runtime is 1.0647284348805746 minutes
2023-04-29 17:56:14,184:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:14,184:INFO:Initializing create_model()
2023-04-29 17:56:14,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:14,184:INFO:Checking exceptions
2023-04-29 17:56:14,184:INFO:Importing libraries
2023-04-29 17:56:14,184:INFO:Copying training dataset
2023-04-29 17:56:14,187:INFO:Defining folds
2023-04-29 17:56:14,187:INFO:Declaring metric variables
2023-04-29 17:56:14,187:INFO:Importing untrained model
2023-04-29 17:56:14,188:INFO:Huber Regressor Imported successfully
2023-04-29 17:56:14,188:INFO:Starting cross validation
2023-04-29 17:56:14,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:14,324:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:56:14,354:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 17:56:19,276:INFO:Calculating mean and std
2023-04-29 17:56:19,277:INFO:Creating metrics dataframe
2023-04-29 17:56:19,923:INFO:Uploading results into container
2023-04-29 17:56:19,924:INFO:Uploading model into container now
2023-04-29 17:56:19,924:INFO:_master_model_container: 10
2023-04-29 17:56:19,924:INFO:_display_container: 2
2023-04-29 17:56:19,924:INFO:HuberRegressor()
2023-04-29 17:56:19,924:INFO:create_model() successfully completed......................................
2023-04-29 17:56:20,017:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:20,017:INFO:Creating metrics dataframe
2023-04-29 17:56:20,021:INFO:Initializing K Neighbors Regressor
2023-04-29 17:56:20,022:INFO:Total runtime is 1.16205100218455 minutes
2023-04-29 17:56:20,022:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:20,022:INFO:Initializing create_model()
2023-04-29 17:56:20,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:20,022:INFO:Checking exceptions
2023-04-29 17:56:20,022:INFO:Importing libraries
2023-04-29 17:56:20,022:INFO:Copying training dataset
2023-04-29 17:56:20,025:INFO:Defining folds
2023-04-29 17:56:20,025:INFO:Declaring metric variables
2023-04-29 17:56:20,025:INFO:Importing untrained model
2023-04-29 17:56:20,026:INFO:K Neighbors Regressor Imported successfully
2023-04-29 17:56:20,026:INFO:Starting cross validation
2023-04-29 17:56:20,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:25,102:INFO:Calculating mean and std
2023-04-29 17:56:25,103:INFO:Creating metrics dataframe
2023-04-29 17:56:25,740:INFO:Uploading results into container
2023-04-29 17:56:25,740:INFO:Uploading model into container now
2023-04-29 17:56:25,741:INFO:_master_model_container: 11
2023-04-29 17:56:25,741:INFO:_display_container: 2
2023-04-29 17:56:25,741:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 17:56:25,741:INFO:create_model() successfully completed......................................
2023-04-29 17:56:25,830:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:25,831:INFO:Creating metrics dataframe
2023-04-29 17:56:25,835:INFO:Initializing Decision Tree Regressor
2023-04-29 17:56:25,836:INFO:Total runtime is 1.258954886595408 minutes
2023-04-29 17:56:25,836:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:25,836:INFO:Initializing create_model()
2023-04-29 17:56:25,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:25,836:INFO:Checking exceptions
2023-04-29 17:56:25,836:INFO:Importing libraries
2023-04-29 17:56:25,836:INFO:Copying training dataset
2023-04-29 17:56:25,839:INFO:Defining folds
2023-04-29 17:56:25,839:INFO:Declaring metric variables
2023-04-29 17:56:25,840:INFO:Importing untrained model
2023-04-29 17:56:25,840:INFO:Decision Tree Regressor Imported successfully
2023-04-29 17:56:25,841:INFO:Starting cross validation
2023-04-29 17:56:25,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:30,823:INFO:Calculating mean and std
2023-04-29 17:56:30,824:INFO:Creating metrics dataframe
2023-04-29 17:56:31,472:INFO:Uploading results into container
2023-04-29 17:56:31,473:INFO:Uploading model into container now
2023-04-29 17:56:31,474:INFO:_master_model_container: 12
2023-04-29 17:56:31,474:INFO:_display_container: 2
2023-04-29 17:56:31,474:INFO:DecisionTreeRegressor(random_state=7671)
2023-04-29 17:56:31,474:INFO:create_model() successfully completed......................................
2023-04-29 17:56:31,589:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:31,589:INFO:Creating metrics dataframe
2023-04-29 17:56:31,593:INFO:Initializing Random Forest Regressor
2023-04-29 17:56:31,594:INFO:Total runtime is 1.3549139142036437 minutes
2023-04-29 17:56:31,594:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:31,594:INFO:Initializing create_model()
2023-04-29 17:56:31,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:31,594:INFO:Checking exceptions
2023-04-29 17:56:31,594:INFO:Importing libraries
2023-04-29 17:56:31,594:INFO:Copying training dataset
2023-04-29 17:56:31,599:INFO:Defining folds
2023-04-29 17:56:31,599:INFO:Declaring metric variables
2023-04-29 17:56:31,599:INFO:Importing untrained model
2023-04-29 17:56:31,599:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:56:31,600:INFO:Starting cross validation
2023-04-29 17:56:31,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:37,827:INFO:Calculating mean and std
2023-04-29 17:56:37,828:INFO:Creating metrics dataframe
2023-04-29 17:56:38,507:INFO:Uploading results into container
2023-04-29 17:56:38,507:INFO:Uploading model into container now
2023-04-29 17:56:38,508:INFO:_master_model_container: 13
2023-04-29 17:56:38,508:INFO:_display_container: 2
2023-04-29 17:56:38,508:INFO:RandomForestRegressor(n_jobs=-1, random_state=7671)
2023-04-29 17:56:38,508:INFO:create_model() successfully completed......................................
2023-04-29 17:56:38,605:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:38,605:INFO:Creating metrics dataframe
2023-04-29 17:56:38,609:INFO:Initializing Extra Trees Regressor
2023-04-29 17:56:38,609:INFO:Total runtime is 1.4718262434005736 minutes
2023-04-29 17:56:38,610:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:38,610:INFO:Initializing create_model()
2023-04-29 17:56:38,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:38,610:INFO:Checking exceptions
2023-04-29 17:56:38,610:INFO:Importing libraries
2023-04-29 17:56:38,610:INFO:Copying training dataset
2023-04-29 17:56:38,613:INFO:Defining folds
2023-04-29 17:56:38,614:INFO:Declaring metric variables
2023-04-29 17:56:38,614:INFO:Importing untrained model
2023-04-29 17:56:38,615:INFO:Extra Trees Regressor Imported successfully
2023-04-29 17:56:38,615:INFO:Starting cross validation
2023-04-29 17:56:38,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:44,622:INFO:Calculating mean and std
2023-04-29 17:56:44,624:INFO:Creating metrics dataframe
2023-04-29 17:56:45,268:INFO:Uploading results into container
2023-04-29 17:56:45,270:INFO:Uploading model into container now
2023-04-29 17:56:45,270:INFO:_master_model_container: 14
2023-04-29 17:56:45,270:INFO:_display_container: 2
2023-04-29 17:56:45,270:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7671)
2023-04-29 17:56:45,270:INFO:create_model() successfully completed......................................
2023-04-29 17:56:45,364:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:45,364:INFO:Creating metrics dataframe
2023-04-29 17:56:45,368:INFO:Initializing AdaBoost Regressor
2023-04-29 17:56:45,368:INFO:Total runtime is 1.5844817439715067 minutes
2023-04-29 17:56:45,368:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:45,368:INFO:Initializing create_model()
2023-04-29 17:56:45,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:45,368:INFO:Checking exceptions
2023-04-29 17:56:45,368:INFO:Importing libraries
2023-04-29 17:56:45,368:INFO:Copying training dataset
2023-04-29 17:56:45,372:INFO:Defining folds
2023-04-29 17:56:45,372:INFO:Declaring metric variables
2023-04-29 17:56:45,372:INFO:Importing untrained model
2023-04-29 17:56:45,372:INFO:AdaBoost Regressor Imported successfully
2023-04-29 17:56:45,373:INFO:Starting cross validation
2023-04-29 17:56:45,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:51,009:INFO:Calculating mean and std
2023-04-29 17:56:51,011:INFO:Creating metrics dataframe
2023-04-29 17:56:51,674:INFO:Uploading results into container
2023-04-29 17:56:51,675:INFO:Uploading model into container now
2023-04-29 17:56:51,675:INFO:_master_model_container: 15
2023-04-29 17:56:51,676:INFO:_display_container: 2
2023-04-29 17:56:51,676:INFO:AdaBoostRegressor(random_state=7671)
2023-04-29 17:56:51,676:INFO:create_model() successfully completed......................................
2023-04-29 17:56:51,769:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:51,769:INFO:Creating metrics dataframe
2023-04-29 17:56:51,773:INFO:Initializing Gradient Boosting Regressor
2023-04-29 17:56:51,773:INFO:Total runtime is 1.691227678457896 minutes
2023-04-29 17:56:51,774:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:51,774:INFO:Initializing create_model()
2023-04-29 17:56:51,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:51,774:INFO:Checking exceptions
2023-04-29 17:56:51,774:INFO:Importing libraries
2023-04-29 17:56:51,774:INFO:Copying training dataset
2023-04-29 17:56:51,781:INFO:Defining folds
2023-04-29 17:56:51,781:INFO:Declaring metric variables
2023-04-29 17:56:51,781:INFO:Importing untrained model
2023-04-29 17:56:51,782:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 17:56:51,782:INFO:Starting cross validation
2023-04-29 17:56:51,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:56:57,614:INFO:Calculating mean and std
2023-04-29 17:56:57,615:INFO:Creating metrics dataframe
2023-04-29 17:56:58,279:INFO:Uploading results into container
2023-04-29 17:56:58,280:INFO:Uploading model into container now
2023-04-29 17:56:58,280:INFO:_master_model_container: 16
2023-04-29 17:56:58,280:INFO:_display_container: 2
2023-04-29 17:56:58,281:INFO:GradientBoostingRegressor(random_state=7671)
2023-04-29 17:56:58,281:INFO:create_model() successfully completed......................................
2023-04-29 17:56:58,374:INFO:SubProcess create_model() end ==================================
2023-04-29 17:56:58,374:INFO:Creating metrics dataframe
2023-04-29 17:56:58,379:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 17:56:58,379:INFO:Total runtime is 1.8013264735539753 minutes
2023-04-29 17:56:58,380:INFO:SubProcess create_model() called ==================================
2023-04-29 17:56:58,380:INFO:Initializing create_model()
2023-04-29 17:56:58,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:56:58,380:INFO:Checking exceptions
2023-04-29 17:56:58,380:INFO:Importing libraries
2023-04-29 17:56:58,380:INFO:Copying training dataset
2023-04-29 17:56:58,384:INFO:Defining folds
2023-04-29 17:56:58,384:INFO:Declaring metric variables
2023-04-29 17:56:58,384:INFO:Importing untrained model
2023-04-29 17:56:58,385:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 17:56:58,385:INFO:Starting cross validation
2023-04-29 17:56:58,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:57:06,243:INFO:Calculating mean and std
2023-04-29 17:57:06,244:INFO:Creating metrics dataframe
2023-04-29 17:57:06,908:INFO:Uploading results into container
2023-04-29 17:57:06,910:INFO:Uploading model into container now
2023-04-29 17:57:06,911:INFO:_master_model_container: 17
2023-04-29 17:57:06,911:INFO:_display_container: 2
2023-04-29 17:57:06,912:INFO:LGBMRegressor(random_state=7671)
2023-04-29 17:57:06,912:INFO:create_model() successfully completed......................................
2023-04-29 17:57:07,004:INFO:SubProcess create_model() end ==================================
2023-04-29 17:57:07,004:INFO:Creating metrics dataframe
2023-04-29 17:57:07,008:INFO:Initializing Dummy Regressor
2023-04-29 17:57:07,009:INFO:Total runtime is 1.9451667269070942 minutes
2023-04-29 17:57:07,009:INFO:SubProcess create_model() called ==================================
2023-04-29 17:57:07,009:INFO:Initializing create_model()
2023-04-29 17:57:07,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F585940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:57:07,010:INFO:Checking exceptions
2023-04-29 17:57:07,010:INFO:Importing libraries
2023-04-29 17:57:07,010:INFO:Copying training dataset
2023-04-29 17:57:07,013:INFO:Defining folds
2023-04-29 17:57:07,013:INFO:Declaring metric variables
2023-04-29 17:57:07,013:INFO:Importing untrained model
2023-04-29 17:57:07,014:INFO:Dummy Regressor Imported successfully
2023-04-29 17:57:07,014:INFO:Starting cross validation
2023-04-29 17:57:07,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:57:12,282:INFO:Calculating mean and std
2023-04-29 17:57:12,283:INFO:Creating metrics dataframe
2023-04-29 17:57:12,952:INFO:Uploading results into container
2023-04-29 17:57:12,953:INFO:Uploading model into container now
2023-04-29 17:57:12,953:INFO:_master_model_container: 18
2023-04-29 17:57:12,953:INFO:_display_container: 2
2023-04-29 17:57:12,953:INFO:DummyRegressor()
2023-04-29 17:57:12,953:INFO:create_model() successfully completed......................................
2023-04-29 17:57:13,046:INFO:SubProcess create_model() end ==================================
2023-04-29 17:57:13,046:INFO:Creating metrics dataframe
2023-04-29 17:57:13,052:INFO:Initializing create_model()
2023-04-29 17:57:13,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7671), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:57:13,052:INFO:Checking exceptions
2023-04-29 17:57:13,052:INFO:Importing libraries
2023-04-29 17:57:13,053:INFO:Copying training dataset
2023-04-29 17:57:13,055:INFO:Defining folds
2023-04-29 17:57:13,055:INFO:Declaring metric variables
2023-04-29 17:57:13,055:INFO:Importing untrained model
2023-04-29 17:57:13,055:INFO:Declaring custom model
2023-04-29 17:57:13,056:INFO:Random Forest Regressor Imported successfully
2023-04-29 17:57:13,056:INFO:Cross validation set to False
2023-04-29 17:57:13,057:INFO:Fitting Model
2023-04-29 17:57:13,732:INFO:RandomForestRegressor(n_jobs=-1, random_state=7671)
2023-04-29 17:57:13,732:INFO:create_model() successfully completed......................................
2023-04-29 17:57:13,849:INFO:_master_model_container: 18
2023-04-29 17:57:13,849:INFO:_display_container: 2
2023-04-29 17:57:13,850:INFO:RandomForestRegressor(n_jobs=-1, random_state=7671)
2023-04-29 17:57:13,850:INFO:compare_models() successfully completed......................................
2023-04-29 17:57:13,853:INFO:Initializing predict_model()
2023-04-29 17:57:13,854:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2DA5C8B0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=7671), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000017D2F10A310>)
2023-04-29 17:57:13,854:INFO:Checking exceptions
2023-04-29 17:57:13,854:INFO:Preloading libraries
2023-04-29 17:57:13,854:INFO:Set up data.
2023-04-29 17:57:13,861:INFO:Set up index.
2023-04-29 17:59:35,060:INFO:PyCaret RegressionExperiment
2023-04-29 17:59:35,061:INFO:Logging name: reg-default-name
2023-04-29 17:59:35,061:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 17:59:35,061:INFO:version 3.0.0
2023-04-29 17:59:35,061:INFO:Initializing setup()
2023-04-29 17:59:35,061:INFO:self.USI: 8747
2023-04-29 17:59:35,061:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 17:59:35,061:INFO:Checking environment
2023-04-29 17:59:35,061:INFO:python_version: 3.9.13
2023-04-29 17:59:35,061:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 17:59:35,061:INFO:machine: AMD64
2023-04-29 17:59:35,061:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 17:59:35,061:INFO:Memory: svmem(total=16935899136, available=5220810752, percent=69.2, used=11715088384, free=5220810752)
2023-04-29 17:59:35,062:INFO:Physical Core: 4
2023-04-29 17:59:35,062:INFO:Logical Core: 8
2023-04-29 17:59:35,062:INFO:Checking libraries
2023-04-29 17:59:35,062:INFO:System:
2023-04-29 17:59:35,062:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 17:59:35,062:INFO:executable: D:\Anaconda\python.exe
2023-04-29 17:59:35,062:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 17:59:35,062:INFO:PyCaret required dependencies:
2023-04-29 17:59:35,062:INFO:                 pip: 22.2.2
2023-04-29 17:59:35,062:INFO:          setuptools: 63.4.1
2023-04-29 17:59:35,062:INFO:             pycaret: 3.0.0
2023-04-29 17:59:35,062:INFO:             IPython: 7.31.1
2023-04-29 17:59:35,062:INFO:          ipywidgets: 7.6.5
2023-04-29 17:59:35,062:INFO:                tqdm: 4.64.1
2023-04-29 17:59:35,062:INFO:               numpy: 1.21.5
2023-04-29 17:59:35,062:INFO:              pandas: 1.4.4
2023-04-29 17:59:35,062:INFO:              jinja2: 2.11.3
2023-04-29 17:59:35,062:INFO:               scipy: 1.9.1
2023-04-29 17:59:35,062:INFO:              joblib: 1.2.0
2023-04-29 17:59:35,062:INFO:             sklearn: 1.0.2
2023-04-29 17:59:35,062:INFO:                pyod: 1.0.9
2023-04-29 17:59:35,062:INFO:            imblearn: 0.10.1
2023-04-29 17:59:35,062:INFO:   category_encoders: 2.6.0
2023-04-29 17:59:35,062:INFO:            lightgbm: 3.3.5
2023-04-29 17:59:35,062:INFO:               numba: 0.55.1
2023-04-29 17:59:35,062:INFO:            requests: 2.28.1
2023-04-29 17:59:35,062:INFO:          matplotlib: 3.5.2
2023-04-29 17:59:35,062:INFO:          scikitplot: 0.3.7
2023-04-29 17:59:35,062:INFO:         yellowbrick: 1.5
2023-04-29 17:59:35,063:INFO:              plotly: 5.9.0
2023-04-29 17:59:35,063:INFO:             kaleido: 0.2.1
2023-04-29 17:59:35,063:INFO:         statsmodels: 0.13.2
2023-04-29 17:59:35,063:INFO:              sktime: 0.17.1
2023-04-29 17:59:35,063:INFO:               tbats: 1.1.2
2023-04-29 17:59:35,063:INFO:            pmdarima: 2.0.3
2023-04-29 17:59:35,063:INFO:              psutil: 5.9.0
2023-04-29 17:59:35,063:INFO:PyCaret optional dependencies:
2023-04-29 17:59:35,063:INFO:                shap: 0.41.0
2023-04-29 17:59:35,063:INFO:           interpret: Not installed
2023-04-29 17:59:35,063:INFO:                umap: Not installed
2023-04-29 17:59:35,063:INFO:    pandas_profiling: 4.1.2
2023-04-29 17:59:35,063:INFO:  explainerdashboard: Not installed
2023-04-29 17:59:35,063:INFO:             autoviz: Not installed
2023-04-29 17:59:35,063:INFO:           fairlearn: Not installed
2023-04-29 17:59:35,063:INFO:             xgboost: Not installed
2023-04-29 17:59:35,063:INFO:            catboost: Not installed
2023-04-29 17:59:35,063:INFO:              kmodes: Not installed
2023-04-29 17:59:35,063:INFO:             mlxtend: Not installed
2023-04-29 17:59:35,063:INFO:       statsforecast: Not installed
2023-04-29 17:59:35,063:INFO:        tune_sklearn: Not installed
2023-04-29 17:59:35,063:INFO:                 ray: Not installed
2023-04-29 17:59:35,063:INFO:            hyperopt: Not installed
2023-04-29 17:59:35,063:INFO:              optuna: Not installed
2023-04-29 17:59:35,063:INFO:               skopt: Not installed
2023-04-29 17:59:35,063:INFO:              mlflow: 2.2.1
2023-04-29 17:59:35,063:INFO:              gradio: Not installed
2023-04-29 17:59:35,063:INFO:             fastapi: Not installed
2023-04-29 17:59:35,063:INFO:             uvicorn: Not installed
2023-04-29 17:59:35,063:INFO:              m2cgen: Not installed
2023-04-29 17:59:35,063:INFO:           evidently: Not installed
2023-04-29 17:59:35,063:INFO:               fugue: Not installed
2023-04-29 17:59:35,064:INFO:           streamlit: 1.21.0
2023-04-29 17:59:35,064:INFO:             prophet: Not installed
2023-04-29 17:59:35,064:INFO:None
2023-04-29 17:59:35,064:INFO:Set up data.
2023-04-29 17:59:35,068:INFO:Set up train/test split.
2023-04-29 17:59:35,071:INFO:Set up index.
2023-04-29 17:59:35,071:INFO:Set up folding strategy.
2023-04-29 17:59:35,071:INFO:Assigning column types.
2023-04-29 17:59:35,077:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 17:59:35,077:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,082:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,202:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,208:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,214:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,343:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 17:59:35,349:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,353:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,471:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,477:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,583:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 17:59:35,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,659:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,719:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,826:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 17:59:35,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:35,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:35,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:36,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 17:59:36,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,058:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 17:59:36,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:36,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 17:59:36,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,293:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 17:59:36,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,526:INFO:Preparing preprocessing pipeline...
2023-04-29 17:59:36,526:INFO:Set up simple imputation.
2023-04-29 17:59:36,527:INFO:Set up column name cleaning.
2023-04-29 17:59:36,547:INFO:Finished creating preprocessing pipeline.
2023-04-29 17:59:36,551:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 17:59:36,552:INFO:Creating final display dataframe.
2023-04-29 17:59:36,630:INFO:Setup _display_container:                     Description             Value
0                    Session id              6358
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8747
2023-04-29 17:59:36,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 17:59:36,882:INFO:setup() successfully completed in 2.33s...............
2023-04-29 17:59:36,887:INFO:Initializing compare_models()
2023-04-29 17:59:36,887:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 17:59:36,887:INFO:Checking exceptions
2023-04-29 17:59:36,890:INFO:Preparing display monitor
2023-04-29 17:59:36,894:INFO:Initializing Linear Regression
2023-04-29 17:59:36,894:INFO:Total runtime is 0.0 minutes
2023-04-29 17:59:36,895:INFO:SubProcess create_model() called ==================================
2023-04-29 17:59:36,895:INFO:Initializing create_model()
2023-04-29 17:59:36,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:59:36,895:INFO:Checking exceptions
2023-04-29 17:59:36,895:INFO:Importing libraries
2023-04-29 17:59:36,895:INFO:Copying training dataset
2023-04-29 17:59:36,898:INFO:Defining folds
2023-04-29 17:59:36,898:INFO:Declaring metric variables
2023-04-29 17:59:36,898:INFO:Importing untrained model
2023-04-29 17:59:36,899:INFO:Linear Regression Imported successfully
2023-04-29 17:59:36,899:INFO:Starting cross validation
2023-04-29 17:59:36,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:59:42,043:INFO:Calculating mean and std
2023-04-29 17:59:42,044:INFO:Creating metrics dataframe
2023-04-29 17:59:42,636:INFO:Uploading results into container
2023-04-29 17:59:42,637:INFO:Uploading model into container now
2023-04-29 17:59:42,638:INFO:_master_model_container: 1
2023-04-29 17:59:42,638:INFO:_display_container: 2
2023-04-29 17:59:42,638:INFO:LinearRegression(n_jobs=-1)
2023-04-29 17:59:42,638:INFO:create_model() successfully completed......................................
2023-04-29 17:59:42,739:INFO:SubProcess create_model() end ==================================
2023-04-29 17:59:42,740:INFO:Creating metrics dataframe
2023-04-29 17:59:42,743:INFO:Initializing Lasso Regression
2023-04-29 17:59:42,743:INFO:Total runtime is 0.09749211072921753 minutes
2023-04-29 17:59:42,743:INFO:SubProcess create_model() called ==================================
2023-04-29 17:59:42,743:INFO:Initializing create_model()
2023-04-29 17:59:42,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:59:42,743:INFO:Checking exceptions
2023-04-29 17:59:42,743:INFO:Importing libraries
2023-04-29 17:59:42,743:INFO:Copying training dataset
2023-04-29 17:59:42,746:INFO:Defining folds
2023-04-29 17:59:42,746:INFO:Declaring metric variables
2023-04-29 17:59:42,747:INFO:Importing untrained model
2023-04-29 17:59:42,747:INFO:Lasso Regression Imported successfully
2023-04-29 17:59:42,747:INFO:Starting cross validation
2023-04-29 17:59:42,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:59:48,211:INFO:Calculating mean and std
2023-04-29 17:59:48,212:INFO:Creating metrics dataframe
2023-04-29 17:59:48,866:INFO:Uploading results into container
2023-04-29 17:59:48,868:INFO:Uploading model into container now
2023-04-29 17:59:48,868:INFO:_master_model_container: 2
2023-04-29 17:59:48,868:INFO:_display_container: 2
2023-04-29 17:59:48,868:INFO:Lasso(random_state=6358)
2023-04-29 17:59:48,868:INFO:create_model() successfully completed......................................
2023-04-29 17:59:48,988:INFO:SubProcess create_model() end ==================================
2023-04-29 17:59:48,989:INFO:Creating metrics dataframe
2023-04-29 17:59:48,994:INFO:Initializing Ridge Regression
2023-04-29 17:59:48,994:INFO:Total runtime is 0.20166484912236532 minutes
2023-04-29 17:59:48,995:INFO:SubProcess create_model() called ==================================
2023-04-29 17:59:48,995:INFO:Initializing create_model()
2023-04-29 17:59:48,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:59:48,995:INFO:Checking exceptions
2023-04-29 17:59:48,995:INFO:Importing libraries
2023-04-29 17:59:48,995:INFO:Copying training dataset
2023-04-29 17:59:48,998:INFO:Defining folds
2023-04-29 17:59:48,999:INFO:Declaring metric variables
2023-04-29 17:59:48,999:INFO:Importing untrained model
2023-04-29 17:59:48,999:INFO:Ridge Regression Imported successfully
2023-04-29 17:59:49,000:INFO:Starting cross validation
2023-04-29 17:59:49,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:59:54,019:INFO:Calculating mean and std
2023-04-29 17:59:54,020:INFO:Creating metrics dataframe
2023-04-29 17:59:54,640:INFO:Uploading results into container
2023-04-29 17:59:54,641:INFO:Uploading model into container now
2023-04-29 17:59:54,641:INFO:_master_model_container: 3
2023-04-29 17:59:54,642:INFO:_display_container: 2
2023-04-29 17:59:54,642:INFO:Ridge(random_state=6358)
2023-04-29 17:59:54,642:INFO:create_model() successfully completed......................................
2023-04-29 17:59:54,728:INFO:SubProcess create_model() end ==================================
2023-04-29 17:59:54,728:INFO:Creating metrics dataframe
2023-04-29 17:59:54,732:INFO:Initializing Elastic Net
2023-04-29 17:59:54,732:INFO:Total runtime is 0.2973062435785929 minutes
2023-04-29 17:59:54,733:INFO:SubProcess create_model() called ==================================
2023-04-29 17:59:54,733:INFO:Initializing create_model()
2023-04-29 17:59:54,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 17:59:54,733:INFO:Checking exceptions
2023-04-29 17:59:54,733:INFO:Importing libraries
2023-04-29 17:59:54,733:INFO:Copying training dataset
2023-04-29 17:59:54,735:INFO:Defining folds
2023-04-29 17:59:54,736:INFO:Declaring metric variables
2023-04-29 17:59:54,736:INFO:Importing untrained model
2023-04-29 17:59:54,736:INFO:Elastic Net Imported successfully
2023-04-29 17:59:54,737:INFO:Starting cross validation
2023-04-29 17:59:54,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 17:59:59,968:INFO:Calculating mean and std
2023-04-29 17:59:59,969:INFO:Creating metrics dataframe
2023-04-29 18:00:00,662:INFO:Uploading results into container
2023-04-29 18:00:00,664:INFO:Uploading model into container now
2023-04-29 18:00:00,664:INFO:_master_model_container: 4
2023-04-29 18:00:00,664:INFO:_display_container: 2
2023-04-29 18:00:00,664:INFO:ElasticNet(random_state=6358)
2023-04-29 18:00:00,664:INFO:create_model() successfully completed......................................
2023-04-29 18:00:00,754:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:00,754:INFO:Creating metrics dataframe
2023-04-29 18:00:00,759:INFO:Initializing Least Angle Regression
2023-04-29 18:00:00,759:INFO:Total runtime is 0.3977572480837504 minutes
2023-04-29 18:00:00,759:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:00,759:INFO:Initializing create_model()
2023-04-29 18:00:00,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:00,759:INFO:Checking exceptions
2023-04-29 18:00:00,759:INFO:Importing libraries
2023-04-29 18:00:00,759:INFO:Copying training dataset
2023-04-29 18:00:00,762:INFO:Defining folds
2023-04-29 18:00:00,762:INFO:Declaring metric variables
2023-04-29 18:00:00,762:INFO:Importing untrained model
2023-04-29 18:00:00,762:INFO:Least Angle Regression Imported successfully
2023-04-29 18:00:00,763:INFO:Starting cross validation
2023-04-29 18:00:00,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:00,815:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,834:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,855:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,856:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,871:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,885:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,899:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:00,920:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:02,298:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:02,310:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:06,010:INFO:Calculating mean and std
2023-04-29 18:00:06,011:INFO:Creating metrics dataframe
2023-04-29 18:00:06,616:INFO:Uploading results into container
2023-04-29 18:00:06,617:INFO:Uploading model into container now
2023-04-29 18:00:06,617:INFO:_master_model_container: 5
2023-04-29 18:00:06,617:INFO:_display_container: 2
2023-04-29 18:00:06,618:INFO:Lars(random_state=6358)
2023-04-29 18:00:06,618:INFO:create_model() successfully completed......................................
2023-04-29 18:00:06,713:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:06,713:INFO:Creating metrics dataframe
2023-04-29 18:00:06,716:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:00:06,716:INFO:Total runtime is 0.4970311681429545 minutes
2023-04-29 18:00:06,716:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:06,717:INFO:Initializing create_model()
2023-04-29 18:00:06,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:06,717:INFO:Checking exceptions
2023-04-29 18:00:06,717:INFO:Importing libraries
2023-04-29 18:00:06,717:INFO:Copying training dataset
2023-04-29 18:00:06,721:INFO:Defining folds
2023-04-29 18:00:06,722:INFO:Declaring metric variables
2023-04-29 18:00:06,723:INFO:Importing untrained model
2023-04-29 18:00:06,723:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:00:06,724:INFO:Starting cross validation
2023-04-29 18:00:06,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:06,777:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,792:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,800:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,825:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,842:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,852:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,871:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:06,884:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:08,215:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:08,239:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:00:11,881:INFO:Calculating mean and std
2023-04-29 18:00:11,881:INFO:Creating metrics dataframe
2023-04-29 18:00:12,494:INFO:Uploading results into container
2023-04-29 18:00:12,495:INFO:Uploading model into container now
2023-04-29 18:00:12,495:INFO:_master_model_container: 6
2023-04-29 18:00:12,495:INFO:_display_container: 2
2023-04-29 18:00:12,496:INFO:LassoLars(random_state=6358)
2023-04-29 18:00:12,496:INFO:create_model() successfully completed......................................
2023-04-29 18:00:12,592:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:12,592:INFO:Creating metrics dataframe
2023-04-29 18:00:12,596:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:00:12,596:INFO:Total runtime is 0.5950262308120727 minutes
2023-04-29 18:00:12,596:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:12,596:INFO:Initializing create_model()
2023-04-29 18:00:12,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:12,596:INFO:Checking exceptions
2023-04-29 18:00:12,596:INFO:Importing libraries
2023-04-29 18:00:12,596:INFO:Copying training dataset
2023-04-29 18:00:12,599:INFO:Defining folds
2023-04-29 18:00:12,599:INFO:Declaring metric variables
2023-04-29 18:00:12,599:INFO:Importing untrained model
2023-04-29 18:00:12,599:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:00:12,599:INFO:Starting cross validation
2023-04-29 18:00:12,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:12,647:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,662:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,676:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,691:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,706:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,720:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,739:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:12,759:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:14,034:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:14,117:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:00:17,764:INFO:Calculating mean and std
2023-04-29 18:00:17,765:INFO:Creating metrics dataframe
2023-04-29 18:00:18,373:INFO:Uploading results into container
2023-04-29 18:00:18,374:INFO:Uploading model into container now
2023-04-29 18:00:18,374:INFO:_master_model_container: 7
2023-04-29 18:00:18,374:INFO:_display_container: 2
2023-04-29 18:00:18,374:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:00:18,374:INFO:create_model() successfully completed......................................
2023-04-29 18:00:18,465:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:18,465:INFO:Creating metrics dataframe
2023-04-29 18:00:18,471:INFO:Initializing Bayesian Ridge
2023-04-29 18:00:18,471:INFO:Total runtime is 0.6929502407709758 minutes
2023-04-29 18:00:18,471:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:18,472:INFO:Initializing create_model()
2023-04-29 18:00:18,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:18,472:INFO:Checking exceptions
2023-04-29 18:00:18,472:INFO:Importing libraries
2023-04-29 18:00:18,472:INFO:Copying training dataset
2023-04-29 18:00:18,475:INFO:Defining folds
2023-04-29 18:00:18,475:INFO:Declaring metric variables
2023-04-29 18:00:18,475:INFO:Importing untrained model
2023-04-29 18:00:18,476:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:00:18,476:INFO:Starting cross validation
2023-04-29 18:00:18,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:23,658:INFO:Calculating mean and std
2023-04-29 18:00:23,659:INFO:Creating metrics dataframe
2023-04-29 18:00:24,262:INFO:Uploading results into container
2023-04-29 18:00:24,263:INFO:Uploading model into container now
2023-04-29 18:00:24,263:INFO:_master_model_container: 8
2023-04-29 18:00:24,264:INFO:_display_container: 2
2023-04-29 18:00:24,264:INFO:BayesianRidge()
2023-04-29 18:00:24,264:INFO:create_model() successfully completed......................................
2023-04-29 18:00:24,357:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:24,358:INFO:Creating metrics dataframe
2023-04-29 18:00:24,362:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:00:24,362:INFO:Total runtime is 0.7911355654398601 minutes
2023-04-29 18:00:24,362:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:24,362:INFO:Initializing create_model()
2023-04-29 18:00:24,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:24,362:INFO:Checking exceptions
2023-04-29 18:00:24,362:INFO:Importing libraries
2023-04-29 18:00:24,362:INFO:Copying training dataset
2023-04-29 18:00:24,365:INFO:Defining folds
2023-04-29 18:00:24,365:INFO:Declaring metric variables
2023-04-29 18:00:24,366:INFO:Importing untrained model
2023-04-29 18:00:24,366:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:00:24,367:INFO:Starting cross validation
2023-04-29 18:00:24,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:29,663:INFO:Calculating mean and std
2023-04-29 18:00:29,663:INFO:Creating metrics dataframe
2023-04-29 18:00:30,446:INFO:Uploading results into container
2023-04-29 18:00:30,446:INFO:Uploading model into container now
2023-04-29 18:00:30,447:INFO:_master_model_container: 9
2023-04-29 18:00:30,447:INFO:_display_container: 2
2023-04-29 18:00:30,447:INFO:PassiveAggressiveRegressor(random_state=6358)
2023-04-29 18:00:30,447:INFO:create_model() successfully completed......................................
2023-04-29 18:00:30,542:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:30,542:INFO:Creating metrics dataframe
2023-04-29 18:00:30,546:INFO:Initializing Huber Regressor
2023-04-29 18:00:30,546:INFO:Total runtime is 0.894195036093394 minutes
2023-04-29 18:00:30,547:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:30,547:INFO:Initializing create_model()
2023-04-29 18:00:30,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:30,547:INFO:Checking exceptions
2023-04-29 18:00:30,547:INFO:Importing libraries
2023-04-29 18:00:30,547:INFO:Copying training dataset
2023-04-29 18:00:30,551:INFO:Defining folds
2023-04-29 18:00:30,551:INFO:Declaring metric variables
2023-04-29 18:00:30,552:INFO:Importing untrained model
2023-04-29 18:00:30,552:INFO:Huber Regressor Imported successfully
2023-04-29 18:00:30,553:INFO:Starting cross validation
2023-04-29 18:00:30,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:30,712:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:00:36,454:INFO:Calculating mean and std
2023-04-29 18:00:36,455:INFO:Creating metrics dataframe
2023-04-29 18:00:37,156:INFO:Uploading results into container
2023-04-29 18:00:37,157:INFO:Uploading model into container now
2023-04-29 18:00:37,158:INFO:_master_model_container: 10
2023-04-29 18:00:37,158:INFO:_display_container: 2
2023-04-29 18:00:37,158:INFO:HuberRegressor()
2023-04-29 18:00:37,158:INFO:create_model() successfully completed......................................
2023-04-29 18:00:37,264:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:37,264:INFO:Creating metrics dataframe
2023-04-29 18:00:37,274:INFO:Initializing K Neighbors Regressor
2023-04-29 18:00:37,274:INFO:Total runtime is 1.0063265879948935 minutes
2023-04-29 18:00:37,275:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:37,275:INFO:Initializing create_model()
2023-04-29 18:00:37,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:37,276:INFO:Checking exceptions
2023-04-29 18:00:37,276:INFO:Importing libraries
2023-04-29 18:00:37,276:INFO:Copying training dataset
2023-04-29 18:00:37,286:INFO:Defining folds
2023-04-29 18:00:37,287:INFO:Declaring metric variables
2023-04-29 18:00:37,288:INFO:Importing untrained model
2023-04-29 18:00:37,289:INFO:K Neighbors Regressor Imported successfully
2023-04-29 18:00:37,289:INFO:Starting cross validation
2023-04-29 18:00:37,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:42,992:INFO:Calculating mean and std
2023-04-29 18:00:42,993:INFO:Creating metrics dataframe
2023-04-29 18:00:43,604:INFO:Uploading results into container
2023-04-29 18:00:43,605:INFO:Uploading model into container now
2023-04-29 18:00:43,605:INFO:_master_model_container: 11
2023-04-29 18:00:43,605:INFO:_display_container: 2
2023-04-29 18:00:43,606:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 18:00:43,606:INFO:create_model() successfully completed......................................
2023-04-29 18:00:43,698:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:43,698:INFO:Creating metrics dataframe
2023-04-29 18:00:43,702:INFO:Initializing Decision Tree Regressor
2023-04-29 18:00:43,702:INFO:Total runtime is 1.113474182287852 minutes
2023-04-29 18:00:43,702:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:43,704:INFO:Initializing create_model()
2023-04-29 18:00:43,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:43,704:INFO:Checking exceptions
2023-04-29 18:00:43,704:INFO:Importing libraries
2023-04-29 18:00:43,704:INFO:Copying training dataset
2023-04-29 18:00:43,706:INFO:Defining folds
2023-04-29 18:00:43,706:INFO:Declaring metric variables
2023-04-29 18:00:43,707:INFO:Importing untrained model
2023-04-29 18:00:43,707:INFO:Decision Tree Regressor Imported successfully
2023-04-29 18:00:43,707:INFO:Starting cross validation
2023-04-29 18:00:43,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:49,316:INFO:Calculating mean and std
2023-04-29 18:00:49,317:INFO:Creating metrics dataframe
2023-04-29 18:00:50,038:INFO:Uploading results into container
2023-04-29 18:00:50,039:INFO:Uploading model into container now
2023-04-29 18:00:50,040:INFO:_master_model_container: 12
2023-04-29 18:00:50,040:INFO:_display_container: 2
2023-04-29 18:00:50,040:INFO:DecisionTreeRegressor(random_state=6358)
2023-04-29 18:00:50,040:INFO:create_model() successfully completed......................................
2023-04-29 18:00:50,170:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:50,170:INFO:Creating metrics dataframe
2023-04-29 18:00:50,175:INFO:Initializing Random Forest Regressor
2023-04-29 18:00:50,175:INFO:Total runtime is 1.2213435331980387 minutes
2023-04-29 18:00:50,175:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:50,176:INFO:Initializing create_model()
2023-04-29 18:00:50,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:50,176:INFO:Checking exceptions
2023-04-29 18:00:50,176:INFO:Importing libraries
2023-04-29 18:00:50,176:INFO:Copying training dataset
2023-04-29 18:00:50,180:INFO:Defining folds
2023-04-29 18:00:50,181:INFO:Declaring metric variables
2023-04-29 18:00:50,181:INFO:Importing untrained model
2023-04-29 18:00:50,182:INFO:Random Forest Regressor Imported successfully
2023-04-29 18:00:50,182:INFO:Starting cross validation
2023-04-29 18:00:50,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:00:57,887:INFO:Calculating mean and std
2023-04-29 18:00:57,888:INFO:Creating metrics dataframe
2023-04-29 18:00:58,567:INFO:Uploading results into container
2023-04-29 18:00:58,567:INFO:Uploading model into container now
2023-04-29 18:00:58,568:INFO:_master_model_container: 13
2023-04-29 18:00:58,568:INFO:_display_container: 2
2023-04-29 18:00:58,569:INFO:RandomForestRegressor(n_jobs=-1, random_state=6358)
2023-04-29 18:00:58,569:INFO:create_model() successfully completed......................................
2023-04-29 18:00:58,689:INFO:SubProcess create_model() end ==================================
2023-04-29 18:00:58,689:INFO:Creating metrics dataframe
2023-04-29 18:00:58,695:INFO:Initializing Extra Trees Regressor
2023-04-29 18:00:58,695:INFO:Total runtime is 1.3633461674054463 minutes
2023-04-29 18:00:58,695:INFO:SubProcess create_model() called ==================================
2023-04-29 18:00:58,696:INFO:Initializing create_model()
2023-04-29 18:00:58,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:00:58,696:INFO:Checking exceptions
2023-04-29 18:00:58,696:INFO:Importing libraries
2023-04-29 18:00:58,696:INFO:Copying training dataset
2023-04-29 18:00:58,701:INFO:Defining folds
2023-04-29 18:00:58,701:INFO:Declaring metric variables
2023-04-29 18:00:58,701:INFO:Importing untrained model
2023-04-29 18:00:58,701:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:00:58,701:INFO:Starting cross validation
2023-04-29 18:00:58,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:01:06,098:INFO:Calculating mean and std
2023-04-29 18:01:06,099:INFO:Creating metrics dataframe
2023-04-29 18:01:06,839:INFO:Uploading results into container
2023-04-29 18:01:06,840:INFO:Uploading model into container now
2023-04-29 18:01:06,841:INFO:_master_model_container: 14
2023-04-29 18:01:06,841:INFO:_display_container: 2
2023-04-29 18:01:06,841:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6358)
2023-04-29 18:01:06,841:INFO:create_model() successfully completed......................................
2023-04-29 18:01:06,948:INFO:SubProcess create_model() end ==================================
2023-04-29 18:01:06,948:INFO:Creating metrics dataframe
2023-04-29 18:01:06,953:INFO:Initializing AdaBoost Regressor
2023-04-29 18:01:06,953:INFO:Total runtime is 1.500982383886973 minutes
2023-04-29 18:01:06,954:INFO:SubProcess create_model() called ==================================
2023-04-29 18:01:06,954:INFO:Initializing create_model()
2023-04-29 18:01:06,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:01:06,954:INFO:Checking exceptions
2023-04-29 18:01:06,954:INFO:Importing libraries
2023-04-29 18:01:06,954:INFO:Copying training dataset
2023-04-29 18:01:06,960:INFO:Defining folds
2023-04-29 18:01:06,960:INFO:Declaring metric variables
2023-04-29 18:01:06,960:INFO:Importing untrained model
2023-04-29 18:01:06,961:INFO:AdaBoost Regressor Imported successfully
2023-04-29 18:01:06,961:INFO:Starting cross validation
2023-04-29 18:01:06,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:01:14,106:INFO:Calculating mean and std
2023-04-29 18:01:14,107:INFO:Creating metrics dataframe
2023-04-29 18:01:14,802:INFO:Uploading results into container
2023-04-29 18:01:14,803:INFO:Uploading model into container now
2023-04-29 18:01:14,803:INFO:_master_model_container: 15
2023-04-29 18:01:14,803:INFO:_display_container: 2
2023-04-29 18:01:14,803:INFO:AdaBoostRegressor(random_state=6358)
2023-04-29 18:01:14,803:INFO:create_model() successfully completed......................................
2023-04-29 18:01:14,934:INFO:SubProcess create_model() end ==================================
2023-04-29 18:01:14,935:INFO:Creating metrics dataframe
2023-04-29 18:01:14,941:INFO:Initializing Gradient Boosting Regressor
2023-04-29 18:01:14,941:INFO:Total runtime is 1.634119681517283 minutes
2023-04-29 18:01:14,941:INFO:SubProcess create_model() called ==================================
2023-04-29 18:01:14,942:INFO:Initializing create_model()
2023-04-29 18:01:14,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:01:14,942:INFO:Checking exceptions
2023-04-29 18:01:14,942:INFO:Importing libraries
2023-04-29 18:01:14,942:INFO:Copying training dataset
2023-04-29 18:01:14,947:INFO:Defining folds
2023-04-29 18:01:14,947:INFO:Declaring metric variables
2023-04-29 18:01:14,948:INFO:Importing untrained model
2023-04-29 18:01:14,949:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 18:01:14,949:INFO:Starting cross validation
2023-04-29 18:01:14,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:01:22,303:INFO:Calculating mean and std
2023-04-29 18:01:22,304:INFO:Creating metrics dataframe
2023-04-29 18:01:22,963:INFO:Uploading results into container
2023-04-29 18:01:22,963:INFO:Uploading model into container now
2023-04-29 18:01:22,964:INFO:_master_model_container: 16
2023-04-29 18:01:22,964:INFO:_display_container: 2
2023-04-29 18:01:22,964:INFO:GradientBoostingRegressor(random_state=6358)
2023-04-29 18:01:22,964:INFO:create_model() successfully completed......................................
2023-04-29 18:01:23,091:INFO:SubProcess create_model() end ==================================
2023-04-29 18:01:23,091:INFO:Creating metrics dataframe
2023-04-29 18:01:23,099:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 18:01:23,099:INFO:Total runtime is 1.7700866580009458 minutes
2023-04-29 18:01:23,099:INFO:SubProcess create_model() called ==================================
2023-04-29 18:01:23,100:INFO:Initializing create_model()
2023-04-29 18:01:23,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:01:23,100:INFO:Checking exceptions
2023-04-29 18:01:23,100:INFO:Importing libraries
2023-04-29 18:01:23,100:INFO:Copying training dataset
2023-04-29 18:01:23,105:INFO:Defining folds
2023-04-29 18:01:23,105:INFO:Declaring metric variables
2023-04-29 18:01:23,105:INFO:Importing untrained model
2023-04-29 18:01:23,106:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 18:01:23,106:INFO:Starting cross validation
2023-04-29 18:01:23,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:01:30,603:INFO:Calculating mean and std
2023-04-29 18:01:30,603:INFO:Creating metrics dataframe
2023-04-29 18:01:31,239:INFO:Uploading results into container
2023-04-29 18:01:31,240:INFO:Uploading model into container now
2023-04-29 18:01:31,240:INFO:_master_model_container: 17
2023-04-29 18:01:31,240:INFO:_display_container: 2
2023-04-29 18:01:31,241:INFO:LGBMRegressor(random_state=6358)
2023-04-29 18:01:31,241:INFO:create_model() successfully completed......................................
2023-04-29 18:01:31,331:INFO:SubProcess create_model() end ==================================
2023-04-29 18:01:31,331:INFO:Creating metrics dataframe
2023-04-29 18:01:31,335:INFO:Initializing Dummy Regressor
2023-04-29 18:01:31,335:INFO:Total runtime is 1.9073574980099992 minutes
2023-04-29 18:01:31,335:INFO:SubProcess create_model() called ==================================
2023-04-29 18:01:31,336:INFO:Initializing create_model()
2023-04-29 18:01:31,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E16BEB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:01:31,336:INFO:Checking exceptions
2023-04-29 18:01:31,336:INFO:Importing libraries
2023-04-29 18:01:31,336:INFO:Copying training dataset
2023-04-29 18:01:31,339:INFO:Defining folds
2023-04-29 18:01:31,339:INFO:Declaring metric variables
2023-04-29 18:01:31,339:INFO:Importing untrained model
2023-04-29 18:01:31,340:INFO:Dummy Regressor Imported successfully
2023-04-29 18:01:31,340:INFO:Starting cross validation
2023-04-29 18:01:31,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:01:37,031:INFO:Calculating mean and std
2023-04-29 18:01:37,031:INFO:Creating metrics dataframe
2023-04-29 18:01:37,717:INFO:Uploading results into container
2023-04-29 18:01:37,718:INFO:Uploading model into container now
2023-04-29 18:01:37,718:INFO:_master_model_container: 18
2023-04-29 18:01:37,718:INFO:_display_container: 2
2023-04-29 18:01:37,719:INFO:DummyRegressor()
2023-04-29 18:01:37,719:INFO:create_model() successfully completed......................................
2023-04-29 18:01:37,813:INFO:SubProcess create_model() end ==================================
2023-04-29 18:01:37,814:INFO:Creating metrics dataframe
2023-04-29 18:01:37,820:INFO:Initializing create_model()
2023-04-29 18:01:37,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=RandomForestRegressor(n_jobs=-1, random_state=6358), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:01:37,821:INFO:Checking exceptions
2023-04-29 18:01:37,821:INFO:Importing libraries
2023-04-29 18:01:37,821:INFO:Copying training dataset
2023-04-29 18:01:37,827:INFO:Defining folds
2023-04-29 18:01:37,827:INFO:Declaring metric variables
2023-04-29 18:01:37,827:INFO:Importing untrained model
2023-04-29 18:01:37,827:INFO:Declaring custom model
2023-04-29 18:01:37,828:INFO:Random Forest Regressor Imported successfully
2023-04-29 18:01:37,829:INFO:Cross validation set to False
2023-04-29 18:01:37,829:INFO:Fitting Model
2023-04-29 18:01:38,663:INFO:RandomForestRegressor(n_jobs=-1, random_state=6358)
2023-04-29 18:01:38,663:INFO:create_model() successfully completed......................................
2023-04-29 18:01:38,783:INFO:_master_model_container: 18
2023-04-29 18:01:38,783:INFO:_display_container: 2
2023-04-29 18:01:38,784:INFO:RandomForestRegressor(n_jobs=-1, random_state=6358)
2023-04-29 18:01:38,784:INFO:compare_models() successfully completed......................................
2023-04-29 18:01:38,788:INFO:Initializing predict_model()
2023-04-29 18:01:38,788:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D25067F40>, estimator=RandomForestRegressor(n_jobs=-1, random_state=6358), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000017D2F10A5E0>)
2023-04-29 18:01:38,788:INFO:Checking exceptions
2023-04-29 18:01:38,788:INFO:Preloading libraries
2023-04-29 18:01:38,788:INFO:Set up data.
2023-04-29 18:01:38,795:INFO:Set up index.
2023-04-29 18:02:06,010:INFO:PyCaret RegressionExperiment
2023-04-29 18:02:06,010:INFO:Logging name: reg-default-name
2023-04-29 18:02:06,010:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:02:06,010:INFO:version 3.0.0
2023-04-29 18:02:06,010:INFO:Initializing setup()
2023-04-29 18:02:06,010:INFO:self.USI: f169
2023-04-29 18:02:06,010:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:02:06,010:INFO:Checking environment
2023-04-29 18:02:06,010:INFO:python_version: 3.9.13
2023-04-29 18:02:06,010:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:02:06,010:INFO:machine: AMD64
2023-04-29 18:02:06,010:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:02:06,010:INFO:Memory: svmem(total=16935899136, available=5222932480, percent=69.2, used=11712966656, free=5222932480)
2023-04-29 18:02:06,010:INFO:Physical Core: 4
2023-04-29 18:02:06,010:INFO:Logical Core: 8
2023-04-29 18:02:06,010:INFO:Checking libraries
2023-04-29 18:02:06,010:INFO:System:
2023-04-29 18:02:06,010:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:02:06,010:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:02:06,010:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:02:06,010:INFO:PyCaret required dependencies:
2023-04-29 18:02:06,011:INFO:                 pip: 22.2.2
2023-04-29 18:02:06,011:INFO:          setuptools: 63.4.1
2023-04-29 18:02:06,011:INFO:             pycaret: 3.0.0
2023-04-29 18:02:06,011:INFO:             IPython: 7.31.1
2023-04-29 18:02:06,011:INFO:          ipywidgets: 7.6.5
2023-04-29 18:02:06,011:INFO:                tqdm: 4.64.1
2023-04-29 18:02:06,011:INFO:               numpy: 1.21.5
2023-04-29 18:02:06,011:INFO:              pandas: 1.4.4
2023-04-29 18:02:06,011:INFO:              jinja2: 2.11.3
2023-04-29 18:02:06,011:INFO:               scipy: 1.9.1
2023-04-29 18:02:06,011:INFO:              joblib: 1.2.0
2023-04-29 18:02:06,011:INFO:             sklearn: 1.0.2
2023-04-29 18:02:06,011:INFO:                pyod: 1.0.9
2023-04-29 18:02:06,011:INFO:            imblearn: 0.10.1
2023-04-29 18:02:06,011:INFO:   category_encoders: 2.6.0
2023-04-29 18:02:06,011:INFO:            lightgbm: 3.3.5
2023-04-29 18:02:06,011:INFO:               numba: 0.55.1
2023-04-29 18:02:06,011:INFO:            requests: 2.28.1
2023-04-29 18:02:06,011:INFO:          matplotlib: 3.5.2
2023-04-29 18:02:06,011:INFO:          scikitplot: 0.3.7
2023-04-29 18:02:06,011:INFO:         yellowbrick: 1.5
2023-04-29 18:02:06,011:INFO:              plotly: 5.9.0
2023-04-29 18:02:06,011:INFO:             kaleido: 0.2.1
2023-04-29 18:02:06,011:INFO:         statsmodels: 0.13.2
2023-04-29 18:02:06,011:INFO:              sktime: 0.17.1
2023-04-29 18:02:06,011:INFO:               tbats: 1.1.2
2023-04-29 18:02:06,011:INFO:            pmdarima: 2.0.3
2023-04-29 18:02:06,011:INFO:              psutil: 5.9.0
2023-04-29 18:02:06,011:INFO:PyCaret optional dependencies:
2023-04-29 18:02:06,012:INFO:                shap: 0.41.0
2023-04-29 18:02:06,012:INFO:           interpret: Not installed
2023-04-29 18:02:06,012:INFO:                umap: Not installed
2023-04-29 18:02:06,012:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:02:06,012:INFO:  explainerdashboard: Not installed
2023-04-29 18:02:06,012:INFO:             autoviz: Not installed
2023-04-29 18:02:06,012:INFO:           fairlearn: Not installed
2023-04-29 18:02:06,012:INFO:             xgboost: Not installed
2023-04-29 18:02:06,012:INFO:            catboost: Not installed
2023-04-29 18:02:06,012:INFO:              kmodes: Not installed
2023-04-29 18:02:06,012:INFO:             mlxtend: Not installed
2023-04-29 18:02:06,012:INFO:       statsforecast: Not installed
2023-04-29 18:02:06,012:INFO:        tune_sklearn: Not installed
2023-04-29 18:02:06,012:INFO:                 ray: Not installed
2023-04-29 18:02:06,012:INFO:            hyperopt: Not installed
2023-04-29 18:02:06,012:INFO:              optuna: Not installed
2023-04-29 18:02:06,012:INFO:               skopt: Not installed
2023-04-29 18:02:06,012:INFO:              mlflow: 2.2.1
2023-04-29 18:02:06,012:INFO:              gradio: Not installed
2023-04-29 18:02:06,012:INFO:             fastapi: Not installed
2023-04-29 18:02:06,012:INFO:             uvicorn: Not installed
2023-04-29 18:02:06,012:INFO:              m2cgen: Not installed
2023-04-29 18:02:06,012:INFO:           evidently: Not installed
2023-04-29 18:02:06,012:INFO:               fugue: Not installed
2023-04-29 18:02:06,012:INFO:           streamlit: 1.21.0
2023-04-29 18:02:06,012:INFO:             prophet: Not installed
2023-04-29 18:02:06,013:INFO:None
2023-04-29 18:02:06,013:INFO:Set up data.
2023-04-29 18:02:06,016:INFO:Set up train/test split.
2023-04-29 18:02:06,021:INFO:Set up index.
2023-04-29 18:02:06,021:INFO:Set up folding strategy.
2023-04-29 18:02:06,022:INFO:Assigning column types.
2023-04-29 18:02:06,029:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:02:06,030:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,043:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:06,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:06,284:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,294:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,306:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,534:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:06,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:06,536:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:02:06,544:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:06,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:06,823:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,834:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:02:06,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,078:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:02:07,096:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,220:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,300:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,321:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,506:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:02:07,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:02:07,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:07,979:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:02:08,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:08,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:02:08,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,535:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:02:08,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:08,999:INFO:Preparing preprocessing pipeline...
2023-04-29 18:02:08,999:INFO:Set up simple imputation.
2023-04-29 18:02:09,000:INFO:Set up column name cleaning.
2023-04-29 18:02:09,044:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:02:09,049:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:02:09,049:INFO:Creating final display dataframe.
2023-04-29 18:02:09,200:INFO:Setup _display_container:                     Description             Value
0                    Session id              8770
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              f169
2023-04-29 18:02:09,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:09,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:09,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:09,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:02:09,648:INFO:setup() successfully completed in 4.66s...............
2023-04-29 18:02:09,657:INFO:Initializing compare_models()
2023-04-29 18:02:09,657:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:02:09,658:INFO:Checking exceptions
2023-04-29 18:02:09,663:INFO:Preparing display monitor
2023-04-29 18:02:09,668:INFO:Initializing Linear Regression
2023-04-29 18:02:09,668:INFO:Total runtime is 0.0 minutes
2023-04-29 18:02:09,668:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:09,668:INFO:Initializing create_model()
2023-04-29 18:02:09,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:09,669:INFO:Checking exceptions
2023-04-29 18:02:09,669:INFO:Importing libraries
2023-04-29 18:02:09,669:INFO:Copying training dataset
2023-04-29 18:02:09,675:INFO:Defining folds
2023-04-29 18:02:09,675:INFO:Declaring metric variables
2023-04-29 18:02:09,676:INFO:Importing untrained model
2023-04-29 18:02:09,676:INFO:Linear Regression Imported successfully
2023-04-29 18:02:09,676:INFO:Starting cross validation
2023-04-29 18:02:09,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:15,245:INFO:Calculating mean and std
2023-04-29 18:02:15,246:INFO:Creating metrics dataframe
2023-04-29 18:02:15,889:INFO:Uploading results into container
2023-04-29 18:02:15,890:INFO:Uploading model into container now
2023-04-29 18:02:15,891:INFO:_master_model_container: 1
2023-04-29 18:02:15,891:INFO:_display_container: 2
2023-04-29 18:02:15,891:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:02:15,891:INFO:create_model() successfully completed......................................
2023-04-29 18:02:15,988:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:15,988:INFO:Creating metrics dataframe
2023-04-29 18:02:15,991:INFO:Initializing Lasso Regression
2023-04-29 18:02:15,992:INFO:Total runtime is 0.10540835062662761 minutes
2023-04-29 18:02:15,992:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:15,992:INFO:Initializing create_model()
2023-04-29 18:02:15,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:15,992:INFO:Checking exceptions
2023-04-29 18:02:15,992:INFO:Importing libraries
2023-04-29 18:02:15,992:INFO:Copying training dataset
2023-04-29 18:02:15,995:INFO:Defining folds
2023-04-29 18:02:15,995:INFO:Declaring metric variables
2023-04-29 18:02:15,995:INFO:Importing untrained model
2023-04-29 18:02:15,996:INFO:Lasso Regression Imported successfully
2023-04-29 18:02:15,996:INFO:Starting cross validation
2023-04-29 18:02:15,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:21,501:INFO:Calculating mean and std
2023-04-29 18:02:21,502:INFO:Creating metrics dataframe
2023-04-29 18:02:22,294:INFO:Uploading results into container
2023-04-29 18:02:22,295:INFO:Uploading model into container now
2023-04-29 18:02:22,296:INFO:_master_model_container: 2
2023-04-29 18:02:22,296:INFO:_display_container: 2
2023-04-29 18:02:22,296:INFO:Lasso(random_state=8770)
2023-04-29 18:02:22,296:INFO:create_model() successfully completed......................................
2023-04-29 18:02:22,395:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:22,395:INFO:Creating metrics dataframe
2023-04-29 18:02:22,399:INFO:Initializing Ridge Regression
2023-04-29 18:02:22,399:INFO:Total runtime is 0.21218270063400269 minutes
2023-04-29 18:02:22,399:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:22,400:INFO:Initializing create_model()
2023-04-29 18:02:22,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:22,400:INFO:Checking exceptions
2023-04-29 18:02:22,400:INFO:Importing libraries
2023-04-29 18:02:22,400:INFO:Copying training dataset
2023-04-29 18:02:22,405:INFO:Defining folds
2023-04-29 18:02:22,405:INFO:Declaring metric variables
2023-04-29 18:02:22,405:INFO:Importing untrained model
2023-04-29 18:02:22,405:INFO:Ridge Regression Imported successfully
2023-04-29 18:02:22,406:INFO:Starting cross validation
2023-04-29 18:02:22,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:28,191:INFO:Calculating mean and std
2023-04-29 18:02:28,192:INFO:Creating metrics dataframe
2023-04-29 18:02:28,862:INFO:Uploading results into container
2023-04-29 18:02:28,864:INFO:Uploading model into container now
2023-04-29 18:02:28,865:INFO:_master_model_container: 3
2023-04-29 18:02:28,865:INFO:_display_container: 2
2023-04-29 18:02:28,865:INFO:Ridge(random_state=8770)
2023-04-29 18:02:28,865:INFO:create_model() successfully completed......................................
2023-04-29 18:02:28,959:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:28,959:INFO:Creating metrics dataframe
2023-04-29 18:02:28,964:INFO:Initializing Elastic Net
2023-04-29 18:02:28,964:INFO:Total runtime is 0.32159594297409055 minutes
2023-04-29 18:02:28,965:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:28,965:INFO:Initializing create_model()
2023-04-29 18:02:28,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:28,965:INFO:Checking exceptions
2023-04-29 18:02:28,965:INFO:Importing libraries
2023-04-29 18:02:28,965:INFO:Copying training dataset
2023-04-29 18:02:28,970:INFO:Defining folds
2023-04-29 18:02:28,971:INFO:Declaring metric variables
2023-04-29 18:02:28,971:INFO:Importing untrained model
2023-04-29 18:02:28,972:INFO:Elastic Net Imported successfully
2023-04-29 18:02:28,972:INFO:Starting cross validation
2023-04-29 18:02:28,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:34,988:INFO:Calculating mean and std
2023-04-29 18:02:34,989:INFO:Creating metrics dataframe
2023-04-29 18:02:35,753:INFO:Uploading results into container
2023-04-29 18:02:35,754:INFO:Uploading model into container now
2023-04-29 18:02:35,755:INFO:_master_model_container: 4
2023-04-29 18:02:35,755:INFO:_display_container: 2
2023-04-29 18:02:35,755:INFO:ElasticNet(random_state=8770)
2023-04-29 18:02:35,755:INFO:create_model() successfully completed......................................
2023-04-29 18:02:35,893:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:35,893:INFO:Creating metrics dataframe
2023-04-29 18:02:35,898:INFO:Initializing Least Angle Regression
2023-04-29 18:02:35,898:INFO:Total runtime is 0.43716343641281125 minutes
2023-04-29 18:02:35,898:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:35,899:INFO:Initializing create_model()
2023-04-29 18:02:35,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:35,899:INFO:Checking exceptions
2023-04-29 18:02:35,899:INFO:Importing libraries
2023-04-29 18:02:35,899:INFO:Copying training dataset
2023-04-29 18:02:35,908:INFO:Defining folds
2023-04-29 18:02:35,908:INFO:Declaring metric variables
2023-04-29 18:02:35,908:INFO:Importing untrained model
2023-04-29 18:02:35,909:INFO:Least Angle Regression Imported successfully
2023-04-29 18:02:35,910:INFO:Starting cross validation
2023-04-29 18:02:35,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:36,014:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,018:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,044:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,050:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,067:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,087:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,102:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:36,117:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:37,456:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:37,480:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:42,548:INFO:Calculating mean and std
2023-04-29 18:02:42,549:INFO:Creating metrics dataframe
2023-04-29 18:02:43,230:INFO:Uploading results into container
2023-04-29 18:02:43,230:INFO:Uploading model into container now
2023-04-29 18:02:43,231:INFO:_master_model_container: 5
2023-04-29 18:02:43,231:INFO:_display_container: 2
2023-04-29 18:02:43,232:INFO:Lars(random_state=8770)
2023-04-29 18:02:43,232:INFO:create_model() successfully completed......................................
2023-04-29 18:02:43,353:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:43,353:INFO:Creating metrics dataframe
2023-04-29 18:02:43,357:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:02:43,357:INFO:Total runtime is 0.5614804665247599 minutes
2023-04-29 18:02:43,357:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:43,357:INFO:Initializing create_model()
2023-04-29 18:02:43,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:43,357:INFO:Checking exceptions
2023-04-29 18:02:43,358:INFO:Importing libraries
2023-04-29 18:02:43,358:INFO:Copying training dataset
2023-04-29 18:02:43,362:INFO:Defining folds
2023-04-29 18:02:43,362:INFO:Declaring metric variables
2023-04-29 18:02:43,363:INFO:Importing untrained model
2023-04-29 18:02:43,363:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:02:43,364:INFO:Starting cross validation
2023-04-29 18:02:43,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:43,457:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,467:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,484:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,504:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,518:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,537:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,550:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:43,566:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:44,892:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:44,913:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:02:50,086:INFO:Calculating mean and std
2023-04-29 18:02:50,087:INFO:Creating metrics dataframe
2023-04-29 18:02:50,873:INFO:Uploading results into container
2023-04-29 18:02:50,874:INFO:Uploading model into container now
2023-04-29 18:02:50,874:INFO:_master_model_container: 6
2023-04-29 18:02:50,874:INFO:_display_container: 2
2023-04-29 18:02:50,874:INFO:LassoLars(random_state=8770)
2023-04-29 18:02:50,874:INFO:create_model() successfully completed......................................
2023-04-29 18:02:51,010:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:51,011:INFO:Creating metrics dataframe
2023-04-29 18:02:51,024:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:02:51,025:INFO:Total runtime is 0.6892801721890767 minutes
2023-04-29 18:02:51,025:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:51,025:INFO:Initializing create_model()
2023-04-29 18:02:51,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:51,025:INFO:Checking exceptions
2023-04-29 18:02:51,025:INFO:Importing libraries
2023-04-29 18:02:51,025:INFO:Copying training dataset
2023-04-29 18:02:51,033:INFO:Defining folds
2023-04-29 18:02:51,033:INFO:Declaring metric variables
2023-04-29 18:02:51,033:INFO:Importing untrained model
2023-04-29 18:02:51,034:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:02:51,034:INFO:Starting cross validation
2023-04-29 18:02:51,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:02:51,147:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,150:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,174:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,194:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,208:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,227:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,242:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:51,256:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:52,568:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:52,643:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:02:57,398:INFO:Calculating mean and std
2023-04-29 18:02:57,399:INFO:Creating metrics dataframe
2023-04-29 18:02:58,074:INFO:Uploading results into container
2023-04-29 18:02:58,075:INFO:Uploading model into container now
2023-04-29 18:02:58,075:INFO:_master_model_container: 7
2023-04-29 18:02:58,075:INFO:_display_container: 2
2023-04-29 18:02:58,075:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:02:58,075:INFO:create_model() successfully completed......................................
2023-04-29 18:02:58,216:INFO:SubProcess create_model() end ==================================
2023-04-29 18:02:58,216:INFO:Creating metrics dataframe
2023-04-29 18:02:58,229:INFO:Initializing Bayesian Ridge
2023-04-29 18:02:58,229:INFO:Total runtime is 0.8093435645103454 minutes
2023-04-29 18:02:58,230:INFO:SubProcess create_model() called ==================================
2023-04-29 18:02:58,230:INFO:Initializing create_model()
2023-04-29 18:02:58,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:02:58,230:INFO:Checking exceptions
2023-04-29 18:02:58,230:INFO:Importing libraries
2023-04-29 18:02:58,231:INFO:Copying training dataset
2023-04-29 18:02:58,239:INFO:Defining folds
2023-04-29 18:02:58,239:INFO:Declaring metric variables
2023-04-29 18:02:58,240:INFO:Importing untrained model
2023-04-29 18:02:58,240:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:02:58,241:INFO:Starting cross validation
2023-04-29 18:02:58,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:05,147:INFO:Calculating mean and std
2023-04-29 18:03:05,149:INFO:Creating metrics dataframe
2023-04-29 18:03:05,926:INFO:Uploading results into container
2023-04-29 18:03:05,927:INFO:Uploading model into container now
2023-04-29 18:03:05,928:INFO:_master_model_container: 8
2023-04-29 18:03:05,928:INFO:_display_container: 2
2023-04-29 18:03:05,929:INFO:BayesianRidge()
2023-04-29 18:03:05,929:INFO:create_model() successfully completed......................................
2023-04-29 18:03:06,083:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:06,083:INFO:Creating metrics dataframe
2023-04-29 18:03:06,092:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:03:06,092:INFO:Total runtime is 0.9403949141502379 minutes
2023-04-29 18:03:06,093:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:06,094:INFO:Initializing create_model()
2023-04-29 18:03:06,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:06,095:INFO:Checking exceptions
2023-04-29 18:03:06,095:INFO:Importing libraries
2023-04-29 18:03:06,095:INFO:Copying training dataset
2023-04-29 18:03:06,104:INFO:Defining folds
2023-04-29 18:03:06,104:INFO:Declaring metric variables
2023-04-29 18:03:06,105:INFO:Importing untrained model
2023-04-29 18:03:06,105:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:03:06,106:INFO:Starting cross validation
2023-04-29 18:03:06,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:12,782:INFO:Calculating mean and std
2023-04-29 18:03:12,783:INFO:Creating metrics dataframe
2023-04-29 18:03:13,434:INFO:Uploading results into container
2023-04-29 18:03:13,435:INFO:Uploading model into container now
2023-04-29 18:03:13,435:INFO:_master_model_container: 9
2023-04-29 18:03:13,435:INFO:_display_container: 2
2023-04-29 18:03:13,436:INFO:PassiveAggressiveRegressor(random_state=8770)
2023-04-29 18:03:13,436:INFO:create_model() successfully completed......................................
2023-04-29 18:03:13,555:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:13,555:INFO:Creating metrics dataframe
2023-04-29 18:03:13,566:INFO:Initializing Huber Regressor
2023-04-29 18:03:13,566:INFO:Total runtime is 1.0649613380432128 minutes
2023-04-29 18:03:13,567:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:13,567:INFO:Initializing create_model()
2023-04-29 18:03:13,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:13,567:INFO:Checking exceptions
2023-04-29 18:03:13,567:INFO:Importing libraries
2023-04-29 18:03:13,568:INFO:Copying training dataset
2023-04-29 18:03:13,574:INFO:Defining folds
2023-04-29 18:03:13,574:INFO:Declaring metric variables
2023-04-29 18:03:13,574:INFO:Importing untrained model
2023-04-29 18:03:13,575:INFO:Huber Regressor Imported successfully
2023-04-29 18:03:13,576:INFO:Starting cross validation
2023-04-29 18:03:13,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:13,742:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:03:13,787:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:03:13,822:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:03:15,224:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:03:15,230:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:03:20,176:INFO:Calculating mean and std
2023-04-29 18:03:20,177:INFO:Creating metrics dataframe
2023-04-29 18:03:20,957:INFO:Uploading results into container
2023-04-29 18:03:20,958:INFO:Uploading model into container now
2023-04-29 18:03:20,958:INFO:_master_model_container: 10
2023-04-29 18:03:20,958:INFO:_display_container: 2
2023-04-29 18:03:20,958:INFO:HuberRegressor()
2023-04-29 18:03:20,958:INFO:create_model() successfully completed......................................
2023-04-29 18:03:21,103:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:21,103:INFO:Creating metrics dataframe
2023-04-29 18:03:21,108:INFO:Initializing K Neighbors Regressor
2023-04-29 18:03:21,108:INFO:Total runtime is 1.1906617442766825 minutes
2023-04-29 18:03:21,108:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:21,108:INFO:Initializing create_model()
2023-04-29 18:03:21,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:21,108:INFO:Checking exceptions
2023-04-29 18:03:21,108:INFO:Importing libraries
2023-04-29 18:03:21,109:INFO:Copying training dataset
2023-04-29 18:03:21,116:INFO:Defining folds
2023-04-29 18:03:21,116:INFO:Declaring metric variables
2023-04-29 18:03:21,116:INFO:Importing untrained model
2023-04-29 18:03:21,117:INFO:K Neighbors Regressor Imported successfully
2023-04-29 18:03:21,118:INFO:Starting cross validation
2023-04-29 18:03:21,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:27,806:INFO:Calculating mean and std
2023-04-29 18:03:27,807:INFO:Creating metrics dataframe
2023-04-29 18:03:28,502:INFO:Uploading results into container
2023-04-29 18:03:28,502:INFO:Uploading model into container now
2023-04-29 18:03:28,503:INFO:_master_model_container: 11
2023-04-29 18:03:28,504:INFO:_display_container: 2
2023-04-29 18:03:28,504:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 18:03:28,504:INFO:create_model() successfully completed......................................
2023-04-29 18:03:28,725:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:28,725:INFO:Creating metrics dataframe
2023-04-29 18:03:28,734:INFO:Initializing Decision Tree Regressor
2023-04-29 18:03:28,734:INFO:Total runtime is 1.3177664001782734 minutes
2023-04-29 18:03:28,734:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:28,734:INFO:Initializing create_model()
2023-04-29 18:03:28,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:28,735:INFO:Checking exceptions
2023-04-29 18:03:28,735:INFO:Importing libraries
2023-04-29 18:03:28,735:INFO:Copying training dataset
2023-04-29 18:03:28,740:INFO:Defining folds
2023-04-29 18:03:28,740:INFO:Declaring metric variables
2023-04-29 18:03:28,740:INFO:Importing untrained model
2023-04-29 18:03:28,740:INFO:Decision Tree Regressor Imported successfully
2023-04-29 18:03:28,741:INFO:Starting cross validation
2023-04-29 18:03:28,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:36,590:INFO:Calculating mean and std
2023-04-29 18:03:36,591:INFO:Creating metrics dataframe
2023-04-29 18:03:37,419:INFO:Uploading results into container
2023-04-29 18:03:37,420:INFO:Uploading model into container now
2023-04-29 18:03:37,420:INFO:_master_model_container: 12
2023-04-29 18:03:37,420:INFO:_display_container: 2
2023-04-29 18:03:37,421:INFO:DecisionTreeRegressor(random_state=8770)
2023-04-29 18:03:37,421:INFO:create_model() successfully completed......................................
2023-04-29 18:03:37,527:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:37,528:INFO:Creating metrics dataframe
2023-04-29 18:03:37,533:INFO:Initializing Random Forest Regressor
2023-04-29 18:03:37,533:INFO:Total runtime is 1.464412490526835 minutes
2023-04-29 18:03:37,533:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:37,533:INFO:Initializing create_model()
2023-04-29 18:03:37,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:37,533:INFO:Checking exceptions
2023-04-29 18:03:37,533:INFO:Importing libraries
2023-04-29 18:03:37,534:INFO:Copying training dataset
2023-04-29 18:03:37,538:INFO:Defining folds
2023-04-29 18:03:37,538:INFO:Declaring metric variables
2023-04-29 18:03:37,539:INFO:Importing untrained model
2023-04-29 18:03:37,539:INFO:Random Forest Regressor Imported successfully
2023-04-29 18:03:37,539:INFO:Starting cross validation
2023-04-29 18:03:37,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:45,601:INFO:Calculating mean and std
2023-04-29 18:03:45,602:INFO:Creating metrics dataframe
2023-04-29 18:03:46,435:INFO:Uploading results into container
2023-04-29 18:03:46,436:INFO:Uploading model into container now
2023-04-29 18:03:46,437:INFO:_master_model_container: 13
2023-04-29 18:03:46,437:INFO:_display_container: 2
2023-04-29 18:03:46,437:INFO:RandomForestRegressor(n_jobs=-1, random_state=8770)
2023-04-29 18:03:46,437:INFO:create_model() successfully completed......................................
2023-04-29 18:03:46,562:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:46,562:INFO:Creating metrics dataframe
2023-04-29 18:03:46,572:INFO:Initializing Extra Trees Regressor
2023-04-29 18:03:46,573:INFO:Total runtime is 1.615062920252482 minutes
2023-04-29 18:03:46,573:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:46,574:INFO:Initializing create_model()
2023-04-29 18:03:46,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:46,575:INFO:Checking exceptions
2023-04-29 18:03:46,575:INFO:Importing libraries
2023-04-29 18:03:46,575:INFO:Copying training dataset
2023-04-29 18:03:46,583:INFO:Defining folds
2023-04-29 18:03:46,583:INFO:Declaring metric variables
2023-04-29 18:03:46,584:INFO:Importing untrained model
2023-04-29 18:03:46,585:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:03:46,585:INFO:Starting cross validation
2023-04-29 18:03:46,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:03:55,863:INFO:Calculating mean and std
2023-04-29 18:03:55,864:INFO:Creating metrics dataframe
2023-04-29 18:03:56,835:INFO:Uploading results into container
2023-04-29 18:03:56,836:INFO:Uploading model into container now
2023-04-29 18:03:56,836:INFO:_master_model_container: 14
2023-04-29 18:03:56,836:INFO:_display_container: 2
2023-04-29 18:03:56,836:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8770)
2023-04-29 18:03:56,837:INFO:create_model() successfully completed......................................
2023-04-29 18:03:56,945:INFO:SubProcess create_model() end ==================================
2023-04-29 18:03:56,945:INFO:Creating metrics dataframe
2023-04-29 18:03:56,951:INFO:Initializing AdaBoost Regressor
2023-04-29 18:03:56,951:INFO:Total runtime is 1.7880519866943358 minutes
2023-04-29 18:03:56,952:INFO:SubProcess create_model() called ==================================
2023-04-29 18:03:56,952:INFO:Initializing create_model()
2023-04-29 18:03:56,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:03:56,952:INFO:Checking exceptions
2023-04-29 18:03:56,952:INFO:Importing libraries
2023-04-29 18:03:56,952:INFO:Copying training dataset
2023-04-29 18:03:56,958:INFO:Defining folds
2023-04-29 18:03:56,958:INFO:Declaring metric variables
2023-04-29 18:03:56,958:INFO:Importing untrained model
2023-04-29 18:03:56,959:INFO:AdaBoost Regressor Imported successfully
2023-04-29 18:03:56,959:INFO:Starting cross validation
2023-04-29 18:03:56,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:04:03,501:INFO:Calculating mean and std
2023-04-29 18:04:03,501:INFO:Creating metrics dataframe
2023-04-29 18:04:04,209:INFO:Uploading results into container
2023-04-29 18:04:04,210:INFO:Uploading model into container now
2023-04-29 18:04:04,211:INFO:_master_model_container: 15
2023-04-29 18:04:04,211:INFO:_display_container: 2
2023-04-29 18:04:04,211:INFO:AdaBoostRegressor(random_state=8770)
2023-04-29 18:04:04,211:INFO:create_model() successfully completed......................................
2023-04-29 18:04:04,299:INFO:SubProcess create_model() end ==================================
2023-04-29 18:04:04,300:INFO:Creating metrics dataframe
2023-04-29 18:04:04,305:INFO:Initializing Gradient Boosting Regressor
2023-04-29 18:04:04,305:INFO:Total runtime is 1.9106240312258402 minutes
2023-04-29 18:04:04,305:INFO:SubProcess create_model() called ==================================
2023-04-29 18:04:04,306:INFO:Initializing create_model()
2023-04-29 18:04:04,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:04:04,306:INFO:Checking exceptions
2023-04-29 18:04:04,306:INFO:Importing libraries
2023-04-29 18:04:04,306:INFO:Copying training dataset
2023-04-29 18:04:04,310:INFO:Defining folds
2023-04-29 18:04:04,310:INFO:Declaring metric variables
2023-04-29 18:04:04,311:INFO:Importing untrained model
2023-04-29 18:04:04,311:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 18:04:04,312:INFO:Starting cross validation
2023-04-29 18:04:04,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:04:11,458:INFO:Calculating mean and std
2023-04-29 18:04:11,460:INFO:Creating metrics dataframe
2023-04-29 18:04:12,450:INFO:Uploading results into container
2023-04-29 18:04:12,451:INFO:Uploading model into container now
2023-04-29 18:04:12,452:INFO:_master_model_container: 16
2023-04-29 18:04:12,452:INFO:_display_container: 2
2023-04-29 18:04:12,453:INFO:GradientBoostingRegressor(random_state=8770)
2023-04-29 18:04:12,453:INFO:create_model() successfully completed......................................
2023-04-29 18:04:12,609:INFO:SubProcess create_model() end ==================================
2023-04-29 18:04:12,609:INFO:Creating metrics dataframe
2023-04-29 18:04:12,618:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 18:04:12,618:INFO:Total runtime is 2.049170219898224 minutes
2023-04-29 18:04:12,618:INFO:SubProcess create_model() called ==================================
2023-04-29 18:04:12,619:INFO:Initializing create_model()
2023-04-29 18:04:12,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:04:12,619:INFO:Checking exceptions
2023-04-29 18:04:12,619:INFO:Importing libraries
2023-04-29 18:04:12,619:INFO:Copying training dataset
2023-04-29 18:04:12,631:INFO:Defining folds
2023-04-29 18:04:12,632:INFO:Declaring metric variables
2023-04-29 18:04:12,632:INFO:Importing untrained model
2023-04-29 18:04:12,633:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 18:04:12,634:INFO:Starting cross validation
2023-04-29 18:04:12,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:04:21,720:INFO:Calculating mean and std
2023-04-29 18:04:21,722:INFO:Creating metrics dataframe
2023-04-29 18:04:22,565:INFO:Uploading results into container
2023-04-29 18:04:22,565:INFO:Uploading model into container now
2023-04-29 18:04:22,566:INFO:_master_model_container: 17
2023-04-29 18:04:22,566:INFO:_display_container: 2
2023-04-29 18:04:22,566:INFO:LGBMRegressor(random_state=8770)
2023-04-29 18:04:22,566:INFO:create_model() successfully completed......................................
2023-04-29 18:04:22,684:INFO:SubProcess create_model() end ==================================
2023-04-29 18:04:22,684:INFO:Creating metrics dataframe
2023-04-29 18:04:22,695:INFO:Initializing Dummy Regressor
2023-04-29 18:04:22,695:INFO:Total runtime is 2.2171217163403827 minutes
2023-04-29 18:04:22,695:INFO:SubProcess create_model() called ==================================
2023-04-29 18:04:22,695:INFO:Initializing create_model()
2023-04-29 18:04:22,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F13B490>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:04:22,695:INFO:Checking exceptions
2023-04-29 18:04:22,695:INFO:Importing libraries
2023-04-29 18:04:22,695:INFO:Copying training dataset
2023-04-29 18:04:22,704:INFO:Defining folds
2023-04-29 18:04:22,705:INFO:Declaring metric variables
2023-04-29 18:04:22,705:INFO:Importing untrained model
2023-04-29 18:04:22,705:INFO:Dummy Regressor Imported successfully
2023-04-29 18:04:22,706:INFO:Starting cross validation
2023-04-29 18:04:22,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:04:29,461:INFO:Calculating mean and std
2023-04-29 18:04:29,462:INFO:Creating metrics dataframe
2023-04-29 18:04:30,189:INFO:Uploading results into container
2023-04-29 18:04:30,190:INFO:Uploading model into container now
2023-04-29 18:04:30,190:INFO:_master_model_container: 18
2023-04-29 18:04:30,190:INFO:_display_container: 2
2023-04-29 18:04:30,190:INFO:DummyRegressor()
2023-04-29 18:04:30,190:INFO:create_model() successfully completed......................................
2023-04-29 18:04:30,309:INFO:SubProcess create_model() end ==================================
2023-04-29 18:04:30,310:INFO:Creating metrics dataframe
2023-04-29 18:04:30,326:INFO:Initializing create_model()
2023-04-29 18:04:30,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8770), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:04:30,327:INFO:Checking exceptions
2023-04-29 18:04:30,329:INFO:Importing libraries
2023-04-29 18:04:30,329:INFO:Copying training dataset
2023-04-29 18:04:30,336:INFO:Defining folds
2023-04-29 18:04:30,336:INFO:Declaring metric variables
2023-04-29 18:04:30,336:INFO:Importing untrained model
2023-04-29 18:04:30,337:INFO:Declaring custom model
2023-04-29 18:04:30,338:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:04:30,339:INFO:Cross validation set to False
2023-04-29 18:04:30,340:INFO:Fitting Model
2023-04-29 18:04:31,314:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8770)
2023-04-29 18:04:31,314:INFO:create_model() successfully completed......................................
2023-04-29 18:04:31,496:INFO:_master_model_container: 18
2023-04-29 18:04:31,497:INFO:_display_container: 2
2023-04-29 18:04:31,497:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8770)
2023-04-29 18:04:31,497:INFO:compare_models() successfully completed......................................
2023-04-29 18:04:31,501:INFO:Initializing predict_model()
2023-04-29 18:04:31,502:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250BE310>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8770), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000017D2EE699D0>)
2023-04-29 18:04:31,502:INFO:Checking exceptions
2023-04-29 18:04:31,502:INFO:Preloading libraries
2023-04-29 18:04:31,502:INFO:Set up data.
2023-04-29 18:04:31,514:INFO:Set up index.
2023-04-29 18:10:20,520:INFO:PyCaret RegressionExperiment
2023-04-29 18:10:20,520:INFO:Logging name: reg-default-name
2023-04-29 18:10:20,520:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:10:20,520:INFO:version 3.0.0
2023-04-29 18:10:20,520:INFO:Initializing setup()
2023-04-29 18:10:20,521:INFO:self.USI: f24f
2023-04-29 18:10:20,521:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:10:20,521:INFO:Checking environment
2023-04-29 18:10:20,521:INFO:python_version: 3.9.13
2023-04-29 18:10:20,521:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:10:20,521:INFO:machine: AMD64
2023-04-29 18:10:20,521:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:10:20,521:INFO:Memory: svmem(total=16935899136, available=6247825408, percent=63.1, used=10688073728, free=6247825408)
2023-04-29 18:10:20,521:INFO:Physical Core: 4
2023-04-29 18:10:20,522:INFO:Logical Core: 8
2023-04-29 18:10:20,522:INFO:Checking libraries
2023-04-29 18:10:20,522:INFO:System:
2023-04-29 18:10:20,522:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:10:20,522:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:10:20,522:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:10:20,522:INFO:PyCaret required dependencies:
2023-04-29 18:10:20,522:INFO:                 pip: 22.2.2
2023-04-29 18:10:20,522:INFO:          setuptools: 63.4.1
2023-04-29 18:10:20,522:INFO:             pycaret: 3.0.0
2023-04-29 18:10:20,523:INFO:             IPython: 7.31.1
2023-04-29 18:10:20,523:INFO:          ipywidgets: 7.6.5
2023-04-29 18:10:20,523:INFO:                tqdm: 4.64.1
2023-04-29 18:10:20,523:INFO:               numpy: 1.21.5
2023-04-29 18:10:20,523:INFO:              pandas: 1.4.4
2023-04-29 18:10:20,523:INFO:              jinja2: 2.11.3
2023-04-29 18:10:20,523:INFO:               scipy: 1.9.1
2023-04-29 18:10:20,523:INFO:              joblib: 1.2.0
2023-04-29 18:10:20,523:INFO:             sklearn: 1.0.2
2023-04-29 18:10:20,523:INFO:                pyod: 1.0.9
2023-04-29 18:10:20,523:INFO:            imblearn: 0.10.1
2023-04-29 18:10:20,523:INFO:   category_encoders: 2.6.0
2023-04-29 18:10:20,524:INFO:            lightgbm: 3.3.5
2023-04-29 18:10:20,524:INFO:               numba: 0.55.1
2023-04-29 18:10:20,524:INFO:            requests: 2.28.1
2023-04-29 18:10:20,524:INFO:          matplotlib: 3.5.2
2023-04-29 18:10:20,524:INFO:          scikitplot: 0.3.7
2023-04-29 18:10:20,524:INFO:         yellowbrick: 1.5
2023-04-29 18:10:20,524:INFO:              plotly: 5.9.0
2023-04-29 18:10:20,524:INFO:             kaleido: 0.2.1
2023-04-29 18:10:20,524:INFO:         statsmodels: 0.13.2
2023-04-29 18:10:20,524:INFO:              sktime: 0.17.1
2023-04-29 18:10:20,524:INFO:               tbats: 1.1.2
2023-04-29 18:10:20,524:INFO:            pmdarima: 2.0.3
2023-04-29 18:10:20,525:INFO:              psutil: 5.9.0
2023-04-29 18:10:20,525:INFO:PyCaret optional dependencies:
2023-04-29 18:10:20,525:INFO:                shap: 0.41.0
2023-04-29 18:10:20,525:INFO:           interpret: Not installed
2023-04-29 18:10:20,525:INFO:                umap: Not installed
2023-04-29 18:10:20,525:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:10:20,525:INFO:  explainerdashboard: Not installed
2023-04-29 18:10:20,525:INFO:             autoviz: Not installed
2023-04-29 18:10:20,525:INFO:           fairlearn: Not installed
2023-04-29 18:10:20,525:INFO:             xgboost: Not installed
2023-04-29 18:10:20,525:INFO:            catboost: Not installed
2023-04-29 18:10:20,525:INFO:              kmodes: Not installed
2023-04-29 18:10:20,525:INFO:             mlxtend: Not installed
2023-04-29 18:10:20,525:INFO:       statsforecast: Not installed
2023-04-29 18:10:20,525:INFO:        tune_sklearn: Not installed
2023-04-29 18:10:20,525:INFO:                 ray: Not installed
2023-04-29 18:10:20,525:INFO:            hyperopt: Not installed
2023-04-29 18:10:20,525:INFO:              optuna: Not installed
2023-04-29 18:10:20,525:INFO:               skopt: Not installed
2023-04-29 18:10:20,525:INFO:              mlflow: 2.2.1
2023-04-29 18:10:20,525:INFO:              gradio: Not installed
2023-04-29 18:10:20,525:INFO:             fastapi: Not installed
2023-04-29 18:10:20,525:INFO:             uvicorn: Not installed
2023-04-29 18:10:20,525:INFO:              m2cgen: Not installed
2023-04-29 18:10:20,525:INFO:           evidently: Not installed
2023-04-29 18:10:20,525:INFO:               fugue: Not installed
2023-04-29 18:10:20,525:INFO:           streamlit: 1.21.0
2023-04-29 18:10:20,526:INFO:             prophet: Not installed
2023-04-29 18:10:20,526:INFO:None
2023-04-29 18:10:20,526:INFO:Set up data.
2023-04-29 18:10:20,534:INFO:Set up train/test split.
2023-04-29 18:10:20,540:INFO:Set up index.
2023-04-29 18:10:20,541:INFO:Set up folding strategy.
2023-04-29 18:10:20,541:INFO:Assigning column types.
2023-04-29 18:10:20,547:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:10:20,548:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,559:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:20,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:20,691:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,696:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,701:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:20,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:20,912:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:10:20,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:10:20,940:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,136:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,295:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:10:21,306:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,400:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,754:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:10:21,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:21,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:21,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:22,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:10:22,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,162:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:10:22,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:22,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:10:22,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,542:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:10:22,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:22,830:INFO:Preparing preprocessing pipeline...
2023-04-29 18:10:22,830:INFO:Set up simple imputation.
2023-04-29 18:10:22,831:INFO:Set up column name cleaning.
2023-04-29 18:10:22,861:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:10:22,869:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:10:22,869:INFO:Creating final display dataframe.
2023-04-29 18:10:23,003:INFO:Setup _display_container:                     Description             Value
0                    Session id              1308
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              f24f
2023-04-29 18:10:23,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:23,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:23,333:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:23,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:10:23,334:INFO:setup() successfully completed in 3.41s...............
2023-04-29 18:10:23,342:INFO:Initializing compare_models()
2023-04-29 18:10:23,342:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:10:23,342:INFO:Checking exceptions
2023-04-29 18:10:23,344:INFO:Preparing display monitor
2023-04-29 18:10:23,350:INFO:Initializing Linear Regression
2023-04-29 18:10:23,350:INFO:Total runtime is 8.229414621988932e-06 minutes
2023-04-29 18:10:23,351:INFO:SubProcess create_model() called ==================================
2023-04-29 18:10:23,352:INFO:Initializing create_model()
2023-04-29 18:10:23,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:10:23,352:INFO:Checking exceptions
2023-04-29 18:10:23,352:INFO:Importing libraries
2023-04-29 18:10:23,352:INFO:Copying training dataset
2023-04-29 18:10:23,362:INFO:Defining folds
2023-04-29 18:10:23,362:INFO:Declaring metric variables
2023-04-29 18:10:23,362:INFO:Importing untrained model
2023-04-29 18:10:23,363:INFO:Linear Regression Imported successfully
2023-04-29 18:10:23,363:INFO:Starting cross validation
2023-04-29 18:10:23,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:10:34,644:INFO:Calculating mean and std
2023-04-29 18:10:34,645:INFO:Creating metrics dataframe
2023-04-29 18:10:35,303:INFO:Uploading results into container
2023-04-29 18:10:35,303:INFO:Uploading model into container now
2023-04-29 18:10:35,304:INFO:_master_model_container: 1
2023-04-29 18:10:35,304:INFO:_display_container: 2
2023-04-29 18:10:35,304:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:10:35,304:INFO:create_model() successfully completed......................................
2023-04-29 18:10:35,397:INFO:SubProcess create_model() end ==================================
2023-04-29 18:10:35,397:INFO:Creating metrics dataframe
2023-04-29 18:10:35,401:INFO:Initializing Lasso Regression
2023-04-29 18:10:35,401:INFO:Total runtime is 0.2008460521697998 minutes
2023-04-29 18:10:35,401:INFO:SubProcess create_model() called ==================================
2023-04-29 18:10:35,401:INFO:Initializing create_model()
2023-04-29 18:10:35,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:10:35,401:INFO:Checking exceptions
2023-04-29 18:10:35,401:INFO:Importing libraries
2023-04-29 18:10:35,401:INFO:Copying training dataset
2023-04-29 18:10:35,404:INFO:Defining folds
2023-04-29 18:10:35,404:INFO:Declaring metric variables
2023-04-29 18:10:35,405:INFO:Importing untrained model
2023-04-29 18:10:35,405:INFO:Lasso Regression Imported successfully
2023-04-29 18:10:35,405:INFO:Starting cross validation
2023-04-29 18:10:35,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:10:40,499:INFO:Calculating mean and std
2023-04-29 18:10:40,500:INFO:Creating metrics dataframe
2023-04-29 18:10:41,174:INFO:Uploading results into container
2023-04-29 18:10:41,175:INFO:Uploading model into container now
2023-04-29 18:10:41,175:INFO:_master_model_container: 2
2023-04-29 18:10:41,175:INFO:_display_container: 2
2023-04-29 18:10:41,176:INFO:Lasso(random_state=1308)
2023-04-29 18:10:41,176:INFO:create_model() successfully completed......................................
2023-04-29 18:10:41,271:INFO:SubProcess create_model() end ==================================
2023-04-29 18:10:41,271:INFO:Creating metrics dataframe
2023-04-29 18:10:41,275:INFO:Initializing Ridge Regression
2023-04-29 18:10:41,275:INFO:Total runtime is 0.2987622221310934 minutes
2023-04-29 18:10:41,275:INFO:SubProcess create_model() called ==================================
2023-04-29 18:10:41,277:INFO:Initializing create_model()
2023-04-29 18:10:41,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:10:41,277:INFO:Checking exceptions
2023-04-29 18:10:41,277:INFO:Importing libraries
2023-04-29 18:10:41,277:INFO:Copying training dataset
2023-04-29 18:10:41,281:INFO:Defining folds
2023-04-29 18:10:41,281:INFO:Declaring metric variables
2023-04-29 18:10:41,281:INFO:Importing untrained model
2023-04-29 18:10:41,282:INFO:Ridge Regression Imported successfully
2023-04-29 18:10:41,282:INFO:Starting cross validation
2023-04-29 18:10:41,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:10:46,482:INFO:Calculating mean and std
2023-04-29 18:10:46,483:INFO:Creating metrics dataframe
2023-04-29 18:10:47,151:INFO:Uploading results into container
2023-04-29 18:10:47,152:INFO:Uploading model into container now
2023-04-29 18:10:47,152:INFO:_master_model_container: 3
2023-04-29 18:10:47,152:INFO:_display_container: 2
2023-04-29 18:10:47,152:INFO:Ridge(random_state=1308)
2023-04-29 18:10:47,152:INFO:create_model() successfully completed......................................
2023-04-29 18:10:47,243:INFO:SubProcess create_model() end ==================================
2023-04-29 18:10:47,243:INFO:Creating metrics dataframe
2023-04-29 18:10:47,248:INFO:Initializing Elastic Net
2023-04-29 18:10:47,248:INFO:Total runtime is 0.3983096520105998 minutes
2023-04-29 18:10:47,248:INFO:SubProcess create_model() called ==================================
2023-04-29 18:10:47,249:INFO:Initializing create_model()
2023-04-29 18:10:47,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:10:47,249:INFO:Checking exceptions
2023-04-29 18:10:47,249:INFO:Importing libraries
2023-04-29 18:10:47,249:INFO:Copying training dataset
2023-04-29 18:10:47,252:INFO:Defining folds
2023-04-29 18:10:47,252:INFO:Declaring metric variables
2023-04-29 18:10:47,252:INFO:Importing untrained model
2023-04-29 18:10:47,253:INFO:Elastic Net Imported successfully
2023-04-29 18:10:47,253:INFO:Starting cross validation
2023-04-29 18:10:47,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:10:52,392:INFO:Calculating mean and std
2023-04-29 18:10:52,393:INFO:Creating metrics dataframe
2023-04-29 18:10:53,025:INFO:Uploading results into container
2023-04-29 18:10:53,026:INFO:Uploading model into container now
2023-04-29 18:10:53,026:INFO:_master_model_container: 4
2023-04-29 18:10:53,027:INFO:_display_container: 2
2023-04-29 18:10:53,027:INFO:ElasticNet(random_state=1308)
2023-04-29 18:10:53,027:INFO:create_model() successfully completed......................................
2023-04-29 18:10:53,123:INFO:SubProcess create_model() end ==================================
2023-04-29 18:10:53,123:INFO:Creating metrics dataframe
2023-04-29 18:10:53,128:INFO:Initializing Least Angle Regression
2023-04-29 18:10:53,128:INFO:Total runtime is 0.4962961037953695 minutes
2023-04-29 18:10:53,129:INFO:SubProcess create_model() called ==================================
2023-04-29 18:10:53,129:INFO:Initializing create_model()
2023-04-29 18:10:53,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:10:53,129:INFO:Checking exceptions
2023-04-29 18:10:53,129:INFO:Importing libraries
2023-04-29 18:10:53,130:INFO:Copying training dataset
2023-04-29 18:10:53,133:INFO:Defining folds
2023-04-29 18:10:53,133:INFO:Declaring metric variables
2023-04-29 18:10:53,133:INFO:Importing untrained model
2023-04-29 18:10:53,133:INFO:Least Angle Regression Imported successfully
2023-04-29 18:10:53,133:INFO:Starting cross validation
2023-04-29 18:10:53,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:10:53,186:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,202:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,210:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,227:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,253:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,266:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,289:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:53,308:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:54,488:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:54,506:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:10:58,442:INFO:Calculating mean and std
2023-04-29 18:10:58,443:INFO:Creating metrics dataframe
2023-04-29 18:10:59,120:INFO:Uploading results into container
2023-04-29 18:10:59,122:INFO:Uploading model into container now
2023-04-29 18:10:59,122:INFO:_master_model_container: 5
2023-04-29 18:10:59,122:INFO:_display_container: 2
2023-04-29 18:10:59,123:INFO:Lars(random_state=1308)
2023-04-29 18:10:59,123:INFO:create_model() successfully completed......................................
2023-04-29 18:10:59,217:INFO:SubProcess create_model() end ==================================
2023-04-29 18:10:59,217:INFO:Creating metrics dataframe
2023-04-29 18:10:59,224:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:10:59,225:INFO:Total runtime is 0.5979172428448996 minutes
2023-04-29 18:10:59,225:INFO:SubProcess create_model() called ==================================
2023-04-29 18:10:59,225:INFO:Initializing create_model()
2023-04-29 18:10:59,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:10:59,225:INFO:Checking exceptions
2023-04-29 18:10:59,225:INFO:Importing libraries
2023-04-29 18:10:59,226:INFO:Copying training dataset
2023-04-29 18:10:59,230:INFO:Defining folds
2023-04-29 18:10:59,230:INFO:Declaring metric variables
2023-04-29 18:10:59,230:INFO:Importing untrained model
2023-04-29 18:10:59,230:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:10:59,231:INFO:Starting cross validation
2023-04-29 18:10:59,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:10:59,291:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,298:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,309:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,334:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,345:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,361:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,377:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:10:59,393:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:11:00,703:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:11:00,739:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:11:04,685:INFO:Calculating mean and std
2023-04-29 18:11:04,686:INFO:Creating metrics dataframe
2023-04-29 18:11:05,349:INFO:Uploading results into container
2023-04-29 18:11:05,349:INFO:Uploading model into container now
2023-04-29 18:11:05,350:INFO:_master_model_container: 6
2023-04-29 18:11:05,350:INFO:_display_container: 2
2023-04-29 18:11:05,350:INFO:LassoLars(random_state=1308)
2023-04-29 18:11:05,350:INFO:create_model() successfully completed......................................
2023-04-29 18:11:05,441:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:05,442:INFO:Creating metrics dataframe
2023-04-29 18:11:05,445:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:11:05,445:INFO:Total runtime is 0.7015827695528667 minutes
2023-04-29 18:11:05,445:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:05,445:INFO:Initializing create_model()
2023-04-29 18:11:05,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:05,446:INFO:Checking exceptions
2023-04-29 18:11:05,446:INFO:Importing libraries
2023-04-29 18:11:05,446:INFO:Copying training dataset
2023-04-29 18:11:05,448:INFO:Defining folds
2023-04-29 18:11:05,448:INFO:Declaring metric variables
2023-04-29 18:11:05,448:INFO:Importing untrained model
2023-04-29 18:11:05,448:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:11:05,449:INFO:Starting cross validation
2023-04-29 18:11:05,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:05,504:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,518:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,532:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,544:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,582:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,592:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,613:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:05,625:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:06,977:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:06,995:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:11:11,010:INFO:Calculating mean and std
2023-04-29 18:11:11,011:INFO:Creating metrics dataframe
2023-04-29 18:11:11,639:INFO:Uploading results into container
2023-04-29 18:11:11,639:INFO:Uploading model into container now
2023-04-29 18:11:11,640:INFO:_master_model_container: 7
2023-04-29 18:11:11,640:INFO:_display_container: 2
2023-04-29 18:11:11,640:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:11:11,640:INFO:create_model() successfully completed......................................
2023-04-29 18:11:11,730:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:11,730:INFO:Creating metrics dataframe
2023-04-29 18:11:11,737:INFO:Initializing Bayesian Ridge
2023-04-29 18:11:11,737:INFO:Total runtime is 0.8064595540364584 minutes
2023-04-29 18:11:11,737:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:11,738:INFO:Initializing create_model()
2023-04-29 18:11:11,738:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:11,738:INFO:Checking exceptions
2023-04-29 18:11:11,738:INFO:Importing libraries
2023-04-29 18:11:11,738:INFO:Copying training dataset
2023-04-29 18:11:11,743:INFO:Defining folds
2023-04-29 18:11:11,743:INFO:Declaring metric variables
2023-04-29 18:11:11,744:INFO:Importing untrained model
2023-04-29 18:11:11,744:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:11:11,744:INFO:Starting cross validation
2023-04-29 18:11:11,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:17,057:INFO:Calculating mean and std
2023-04-29 18:11:17,058:INFO:Creating metrics dataframe
2023-04-29 18:11:17,730:INFO:Uploading results into container
2023-04-29 18:11:17,731:INFO:Uploading model into container now
2023-04-29 18:11:17,731:INFO:_master_model_container: 8
2023-04-29 18:11:17,731:INFO:_display_container: 2
2023-04-29 18:11:17,732:INFO:BayesianRidge()
2023-04-29 18:11:17,732:INFO:create_model() successfully completed......................................
2023-04-29 18:11:17,834:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:17,835:INFO:Creating metrics dataframe
2023-04-29 18:11:17,840:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:11:17,841:INFO:Total runtime is 0.9081822355588278 minutes
2023-04-29 18:11:17,841:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:17,841:INFO:Initializing create_model()
2023-04-29 18:11:17,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:17,841:INFO:Checking exceptions
2023-04-29 18:11:17,841:INFO:Importing libraries
2023-04-29 18:11:17,841:INFO:Copying training dataset
2023-04-29 18:11:17,845:INFO:Defining folds
2023-04-29 18:11:17,845:INFO:Declaring metric variables
2023-04-29 18:11:17,846:INFO:Importing untrained model
2023-04-29 18:11:17,846:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:11:17,846:INFO:Starting cross validation
2023-04-29 18:11:17,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:23,287:INFO:Calculating mean and std
2023-04-29 18:11:23,288:INFO:Creating metrics dataframe
2023-04-29 18:11:23,902:INFO:Uploading results into container
2023-04-29 18:11:23,903:INFO:Uploading model into container now
2023-04-29 18:11:23,903:INFO:_master_model_container: 9
2023-04-29 18:11:23,903:INFO:_display_container: 2
2023-04-29 18:11:23,903:INFO:PassiveAggressiveRegressor(random_state=1308)
2023-04-29 18:11:23,903:INFO:create_model() successfully completed......................................
2023-04-29 18:11:23,990:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:23,990:INFO:Creating metrics dataframe
2023-04-29 18:11:23,994:INFO:Initializing Huber Regressor
2023-04-29 18:11:23,994:INFO:Total runtime is 1.0107291698455811 minutes
2023-04-29 18:11:23,994:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:23,994:INFO:Initializing create_model()
2023-04-29 18:11:23,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:23,995:INFO:Checking exceptions
2023-04-29 18:11:23,995:INFO:Importing libraries
2023-04-29 18:11:23,995:INFO:Copying training dataset
2023-04-29 18:11:23,996:INFO:Defining folds
2023-04-29 18:11:23,996:INFO:Declaring metric variables
2023-04-29 18:11:23,996:INFO:Importing untrained model
2023-04-29 18:11:23,996:INFO:Huber Regressor Imported successfully
2023-04-29 18:11:23,997:INFO:Starting cross validation
2023-04-29 18:11:23,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:24,128:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:11:24,215:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:11:25,624:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:11:29,441:INFO:Calculating mean and std
2023-04-29 18:11:29,442:INFO:Creating metrics dataframe
2023-04-29 18:11:30,091:INFO:Uploading results into container
2023-04-29 18:11:30,092:INFO:Uploading model into container now
2023-04-29 18:11:30,092:INFO:_master_model_container: 10
2023-04-29 18:11:30,092:INFO:_display_container: 2
2023-04-29 18:11:30,093:INFO:HuberRegressor()
2023-04-29 18:11:30,093:INFO:create_model() successfully completed......................................
2023-04-29 18:11:30,193:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:30,193:INFO:Creating metrics dataframe
2023-04-29 18:11:30,196:INFO:Initializing K Neighbors Regressor
2023-04-29 18:11:30,196:INFO:Total runtime is 1.114105224609375 minutes
2023-04-29 18:11:30,197:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:30,197:INFO:Initializing create_model()
2023-04-29 18:11:30,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:30,197:INFO:Checking exceptions
2023-04-29 18:11:30,197:INFO:Importing libraries
2023-04-29 18:11:30,197:INFO:Copying training dataset
2023-04-29 18:11:30,203:INFO:Defining folds
2023-04-29 18:11:30,203:INFO:Declaring metric variables
2023-04-29 18:11:30,203:INFO:Importing untrained model
2023-04-29 18:11:30,204:INFO:K Neighbors Regressor Imported successfully
2023-04-29 18:11:30,204:INFO:Starting cross validation
2023-04-29 18:11:30,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:35,581:INFO:Calculating mean and std
2023-04-29 18:11:35,582:INFO:Creating metrics dataframe
2023-04-29 18:11:36,206:INFO:Uploading results into container
2023-04-29 18:11:36,206:INFO:Uploading model into container now
2023-04-29 18:11:36,206:INFO:_master_model_container: 11
2023-04-29 18:11:36,206:INFO:_display_container: 2
2023-04-29 18:11:36,206:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 18:11:36,206:INFO:create_model() successfully completed......................................
2023-04-29 18:11:36,293:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:36,293:INFO:Creating metrics dataframe
2023-04-29 18:11:36,297:INFO:Initializing Decision Tree Regressor
2023-04-29 18:11:36,297:INFO:Total runtime is 1.2157925367355347 minutes
2023-04-29 18:11:36,297:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:36,298:INFO:Initializing create_model()
2023-04-29 18:11:36,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:36,298:INFO:Checking exceptions
2023-04-29 18:11:36,298:INFO:Importing libraries
2023-04-29 18:11:36,298:INFO:Copying training dataset
2023-04-29 18:11:36,301:INFO:Defining folds
2023-04-29 18:11:36,301:INFO:Declaring metric variables
2023-04-29 18:11:36,301:INFO:Importing untrained model
2023-04-29 18:11:36,301:INFO:Decision Tree Regressor Imported successfully
2023-04-29 18:11:36,302:INFO:Starting cross validation
2023-04-29 18:11:36,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:41,616:INFO:Calculating mean and std
2023-04-29 18:11:41,617:INFO:Creating metrics dataframe
2023-04-29 18:11:42,302:INFO:Uploading results into container
2023-04-29 18:11:42,303:INFO:Uploading model into container now
2023-04-29 18:11:42,303:INFO:_master_model_container: 12
2023-04-29 18:11:42,303:INFO:_display_container: 2
2023-04-29 18:11:42,303:INFO:DecisionTreeRegressor(random_state=1308)
2023-04-29 18:11:42,303:INFO:create_model() successfully completed......................................
2023-04-29 18:11:42,399:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:42,399:INFO:Creating metrics dataframe
2023-04-29 18:11:42,404:INFO:Initializing Random Forest Regressor
2023-04-29 18:11:42,404:INFO:Total runtime is 1.31756485303243 minutes
2023-04-29 18:11:42,404:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:42,404:INFO:Initializing create_model()
2023-04-29 18:11:42,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:42,404:INFO:Checking exceptions
2023-04-29 18:11:42,404:INFO:Importing libraries
2023-04-29 18:11:42,404:INFO:Copying training dataset
2023-04-29 18:11:42,408:INFO:Defining folds
2023-04-29 18:11:42,408:INFO:Declaring metric variables
2023-04-29 18:11:42,409:INFO:Importing untrained model
2023-04-29 18:11:42,409:INFO:Random Forest Regressor Imported successfully
2023-04-29 18:11:42,409:INFO:Starting cross validation
2023-04-29 18:11:42,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:49,131:INFO:Calculating mean and std
2023-04-29 18:11:49,131:INFO:Creating metrics dataframe
2023-04-29 18:11:49,759:INFO:Uploading results into container
2023-04-29 18:11:49,760:INFO:Uploading model into container now
2023-04-29 18:11:49,760:INFO:_master_model_container: 13
2023-04-29 18:11:49,760:INFO:_display_container: 2
2023-04-29 18:11:49,761:INFO:RandomForestRegressor(n_jobs=-1, random_state=1308)
2023-04-29 18:11:49,761:INFO:create_model() successfully completed......................................
2023-04-29 18:11:49,846:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:49,846:INFO:Creating metrics dataframe
2023-04-29 18:11:49,850:INFO:Initializing Extra Trees Regressor
2023-04-29 18:11:49,850:INFO:Total runtime is 1.4416670322418212 minutes
2023-04-29 18:11:49,850:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:49,850:INFO:Initializing create_model()
2023-04-29 18:11:49,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:49,851:INFO:Checking exceptions
2023-04-29 18:11:49,851:INFO:Importing libraries
2023-04-29 18:11:49,851:INFO:Copying training dataset
2023-04-29 18:11:49,854:INFO:Defining folds
2023-04-29 18:11:49,854:INFO:Declaring metric variables
2023-04-29 18:11:49,854:INFO:Importing untrained model
2023-04-29 18:11:49,854:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:11:49,854:INFO:Starting cross validation
2023-04-29 18:11:49,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:11:56,193:INFO:Calculating mean and std
2023-04-29 18:11:56,194:INFO:Creating metrics dataframe
2023-04-29 18:11:56,814:INFO:Uploading results into container
2023-04-29 18:11:56,814:INFO:Uploading model into container now
2023-04-29 18:11:56,815:INFO:_master_model_container: 14
2023-04-29 18:11:56,815:INFO:_display_container: 2
2023-04-29 18:11:56,815:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1308)
2023-04-29 18:11:56,815:INFO:create_model() successfully completed......................................
2023-04-29 18:11:56,900:INFO:SubProcess create_model() end ==================================
2023-04-29 18:11:56,900:INFO:Creating metrics dataframe
2023-04-29 18:11:56,904:INFO:Initializing AdaBoost Regressor
2023-04-29 18:11:56,904:INFO:Total runtime is 1.559244374434153 minutes
2023-04-29 18:11:56,904:INFO:SubProcess create_model() called ==================================
2023-04-29 18:11:56,904:INFO:Initializing create_model()
2023-04-29 18:11:56,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:11:56,905:INFO:Checking exceptions
2023-04-29 18:11:56,905:INFO:Importing libraries
2023-04-29 18:11:56,905:INFO:Copying training dataset
2023-04-29 18:11:56,907:INFO:Defining folds
2023-04-29 18:11:56,907:INFO:Declaring metric variables
2023-04-29 18:11:56,908:INFO:Importing untrained model
2023-04-29 18:11:56,908:INFO:AdaBoost Regressor Imported successfully
2023-04-29 18:11:56,908:INFO:Starting cross validation
2023-04-29 18:11:56,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:02,687:INFO:Calculating mean and std
2023-04-29 18:12:02,688:INFO:Creating metrics dataframe
2023-04-29 18:12:03,362:INFO:Uploading results into container
2023-04-29 18:12:03,363:INFO:Uploading model into container now
2023-04-29 18:12:03,364:INFO:_master_model_container: 15
2023-04-29 18:12:03,364:INFO:_display_container: 2
2023-04-29 18:12:03,365:INFO:AdaBoostRegressor(random_state=1308)
2023-04-29 18:12:03,365:INFO:create_model() successfully completed......................................
2023-04-29 18:12:03,458:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:03,458:INFO:Creating metrics dataframe
2023-04-29 18:12:03,463:INFO:Initializing Gradient Boosting Regressor
2023-04-29 18:12:03,464:INFO:Total runtime is 1.6685694813728331 minutes
2023-04-29 18:12:03,464:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:03,464:INFO:Initializing create_model()
2023-04-29 18:12:03,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:03,464:INFO:Checking exceptions
2023-04-29 18:12:03,464:INFO:Importing libraries
2023-04-29 18:12:03,464:INFO:Copying training dataset
2023-04-29 18:12:03,467:INFO:Defining folds
2023-04-29 18:12:03,468:INFO:Declaring metric variables
2023-04-29 18:12:03,468:INFO:Importing untrained model
2023-04-29 18:12:03,468:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 18:12:03,469:INFO:Starting cross validation
2023-04-29 18:12:03,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:09,425:INFO:Calculating mean and std
2023-04-29 18:12:09,426:INFO:Creating metrics dataframe
2023-04-29 18:12:10,062:INFO:Uploading results into container
2023-04-29 18:12:10,062:INFO:Uploading model into container now
2023-04-29 18:12:10,063:INFO:_master_model_container: 16
2023-04-29 18:12:10,063:INFO:_display_container: 2
2023-04-29 18:12:10,063:INFO:GradientBoostingRegressor(random_state=1308)
2023-04-29 18:12:10,064:INFO:create_model() successfully completed......................................
2023-04-29 18:12:10,155:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:10,156:INFO:Creating metrics dataframe
2023-04-29 18:12:10,161:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 18:12:10,161:INFO:Total runtime is 1.7801936268806455 minutes
2023-04-29 18:12:10,161:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:10,161:INFO:Initializing create_model()
2023-04-29 18:12:10,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:10,161:INFO:Checking exceptions
2023-04-29 18:12:10,161:INFO:Importing libraries
2023-04-29 18:12:10,162:INFO:Copying training dataset
2023-04-29 18:12:10,165:INFO:Defining folds
2023-04-29 18:12:10,165:INFO:Declaring metric variables
2023-04-29 18:12:10,166:INFO:Importing untrained model
2023-04-29 18:12:10,166:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 18:12:10,167:INFO:Starting cross validation
2023-04-29 18:12:10,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:11,589:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:12:11,589:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:12:11,589:INFO:Data columns (total 8 columns):
2023-04-29 18:12:11,589:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:12:11,589:INFO:---  ------          --------------  -----  
2023-04-29 18:12:11,589:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:12:11,589:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:12:11,589:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:12:11,591:INFO:memory usage: 79.8 KB
2023-04-29 18:12:13,075:INFO:PyCaret RegressionExperiment
2023-04-29 18:12:13,075:INFO:Logging name: reg-default-name
2023-04-29 18:12:13,075:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:12:13,075:INFO:version 3.0.0
2023-04-29 18:12:13,076:INFO:Initializing setup()
2023-04-29 18:12:13,076:INFO:self.USI: d9ed
2023-04-29 18:12:13,076:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:12:13,076:INFO:Checking environment
2023-04-29 18:12:13,076:INFO:python_version: 3.9.13
2023-04-29 18:12:13,076:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:12:13,076:INFO:machine: AMD64
2023-04-29 18:12:13,076:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:12:13,077:INFO:Memory: svmem(total=16935899136, available=5316055040, percent=68.6, used=11619844096, free=5316055040)
2023-04-29 18:12:13,077:INFO:Physical Core: 4
2023-04-29 18:12:13,077:INFO:Logical Core: 8
2023-04-29 18:12:13,077:INFO:Checking libraries
2023-04-29 18:12:13,077:INFO:System:
2023-04-29 18:12:13,077:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:12:13,077:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:12:13,077:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:12:13,077:INFO:PyCaret required dependencies:
2023-04-29 18:12:13,077:INFO:                 pip: 22.2.2
2023-04-29 18:12:13,078:INFO:          setuptools: 63.4.1
2023-04-29 18:12:13,078:INFO:             pycaret: 3.0.0
2023-04-29 18:12:13,078:INFO:             IPython: 7.31.1
2023-04-29 18:12:13,078:INFO:          ipywidgets: 7.6.5
2023-04-29 18:12:13,078:INFO:                tqdm: 4.64.1
2023-04-29 18:12:13,078:INFO:               numpy: 1.21.5
2023-04-29 18:12:13,078:INFO:              pandas: 1.4.4
2023-04-29 18:12:13,078:INFO:              jinja2: 2.11.3
2023-04-29 18:12:13,078:INFO:               scipy: 1.9.1
2023-04-29 18:12:13,078:INFO:              joblib: 1.2.0
2023-04-29 18:12:13,078:INFO:             sklearn: 1.0.2
2023-04-29 18:12:13,079:INFO:                pyod: 1.0.9
2023-04-29 18:12:13,079:INFO:            imblearn: 0.10.1
2023-04-29 18:12:13,079:INFO:   category_encoders: 2.6.0
2023-04-29 18:12:13,079:INFO:            lightgbm: 3.3.5
2023-04-29 18:12:13,079:INFO:               numba: 0.55.1
2023-04-29 18:12:13,079:INFO:            requests: 2.28.1
2023-04-29 18:12:13,079:INFO:          matplotlib: 3.5.2
2023-04-29 18:12:13,079:INFO:          scikitplot: 0.3.7
2023-04-29 18:12:13,079:INFO:         yellowbrick: 1.5
2023-04-29 18:12:13,080:INFO:              plotly: 5.9.0
2023-04-29 18:12:13,080:INFO:             kaleido: 0.2.1
2023-04-29 18:12:13,080:INFO:         statsmodels: 0.13.2
2023-04-29 18:12:13,080:INFO:              sktime: 0.17.1
2023-04-29 18:12:13,080:INFO:               tbats: 1.1.2
2023-04-29 18:12:13,080:INFO:            pmdarima: 2.0.3
2023-04-29 18:12:13,080:INFO:              psutil: 5.9.0
2023-04-29 18:12:13,080:INFO:PyCaret optional dependencies:
2023-04-29 18:12:13,080:INFO:                shap: 0.41.0
2023-04-29 18:12:13,080:INFO:           interpret: Not installed
2023-04-29 18:12:13,080:INFO:                umap: Not installed
2023-04-29 18:12:13,080:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:12:13,080:INFO:  explainerdashboard: Not installed
2023-04-29 18:12:13,080:INFO:             autoviz: Not installed
2023-04-29 18:12:13,081:INFO:           fairlearn: Not installed
2023-04-29 18:12:13,081:INFO:             xgboost: Not installed
2023-04-29 18:12:13,081:INFO:            catboost: Not installed
2023-04-29 18:12:13,081:INFO:              kmodes: Not installed
2023-04-29 18:12:13,081:INFO:             mlxtend: Not installed
2023-04-29 18:12:13,081:INFO:       statsforecast: Not installed
2023-04-29 18:12:13,081:INFO:        tune_sklearn: Not installed
2023-04-29 18:12:13,081:INFO:                 ray: Not installed
2023-04-29 18:12:13,081:INFO:            hyperopt: Not installed
2023-04-29 18:12:13,081:INFO:              optuna: Not installed
2023-04-29 18:12:13,081:INFO:               skopt: Not installed
2023-04-29 18:12:13,100:INFO:              mlflow: 2.2.1
2023-04-29 18:12:13,100:INFO:              gradio: Not installed
2023-04-29 18:12:13,100:INFO:             fastapi: Not installed
2023-04-29 18:12:13,100:INFO:             uvicorn: Not installed
2023-04-29 18:12:13,100:INFO:              m2cgen: Not installed
2023-04-29 18:12:13,100:INFO:           evidently: Not installed
2023-04-29 18:12:13,100:INFO:               fugue: Not installed
2023-04-29 18:12:13,101:INFO:           streamlit: 1.21.0
2023-04-29 18:12:13,101:INFO:             prophet: Not installed
2023-04-29 18:12:13,101:INFO:None
2023-04-29 18:12:13,101:INFO:Set up data.
2023-04-29 18:12:13,112:INFO:Set up train/test split.
2023-04-29 18:12:13,119:INFO:Set up index.
2023-04-29 18:12:13,119:INFO:Set up folding strategy.
2023-04-29 18:12:13,119:INFO:Assigning column types.
2023-04-29 18:12:13,128:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:12:13,128:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,157:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,353:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,490:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:13,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:13,493:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,534:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:13,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:13,891:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:12:13,912:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:13,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:14,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:14,275:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,287:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:14,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:14,609:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:12:14,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:14,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:14,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:14,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:15,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:15,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:12:15,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:15,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:15,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:15,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:15,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:15,924:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:12:16,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:16,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:16,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,251:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:12:16,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,564:INFO:Preparing preprocessing pipeline...
2023-04-29 18:12:16,564:INFO:Set up simple imputation.
2023-04-29 18:12:16,565:INFO:Set up column name cleaning.
2023-04-29 18:12:16,617:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:12:16,621:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:12:16,621:INFO:Creating final display dataframe.
2023-04-29 18:12:16,696:INFO:Setup _display_container:                     Description             Value
0                    Session id              3188
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d9ed
2023-04-29 18:12:16,698:INFO:                    Description             Value
2023-04-29 18:12:16,698:INFO:0                    Session id              3188
2023-04-29 18:12:16,698:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:12:16,698:INFO:2                   Target type        Regression
2023-04-29 18:12:16,698:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:12:16,698:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:12:16,698:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:12:16,698:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:12:16,698:INFO:7              Numeric features                 7
2023-04-29 18:12:16,698:INFO:8                    Preprocess              True
2023-04-29 18:12:16,698:INFO:9               Imputation type            simple
2023-04-29 18:12:16,698:INFO:10           Numeric imputation              mean
2023-04-29 18:12:16,698:INFO:11       Categorical imputation              mode
2023-04-29 18:12:16,699:INFO:12               Fold Generator             KFold
2023-04-29 18:12:16,699:INFO:13                  Fold Number                10
2023-04-29 18:12:16,699:INFO:14                     CPU Jobs                -1
2023-04-29 18:12:16,699:INFO:15                      Use GPU             False
2023-04-29 18:12:16,699:INFO:16               Log Experiment             False
2023-04-29 18:12:16,699:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:12:16,699:INFO:18                          USI              d9ed
2023-04-29 18:12:16,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:16,960:INFO:setup() successfully completed in 5.36s...............
2023-04-29 18:12:17,209:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:12:17,209:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:12:17,209:INFO:Data columns (total 8 columns):
2023-04-29 18:12:17,209:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:12:17,210:INFO:---  ------          --------------  -----  
2023-04-29 18:12:17,210:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:12:17,211:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:12:17,211:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:12:17,211:INFO:memory usage: 79.8 KB
2023-04-29 18:12:18,593:INFO:PyCaret RegressionExperiment
2023-04-29 18:12:18,593:INFO:Logging name: reg-default-name
2023-04-29 18:12:18,593:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:12:18,593:INFO:version 3.0.0
2023-04-29 18:12:18,593:INFO:Initializing setup()
2023-04-29 18:12:18,593:INFO:self.USI: f637
2023-04-29 18:12:18,593:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:12:18,593:INFO:Checking environment
2023-04-29 18:12:18,593:INFO:python_version: 3.9.13
2023-04-29 18:12:18,593:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:12:18,594:INFO:machine: AMD64
2023-04-29 18:12:18,594:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:12:18,594:INFO:Memory: svmem(total=16935899136, available=5303332864, percent=68.7, used=11632566272, free=5303332864)
2023-04-29 18:12:18,594:INFO:Physical Core: 4
2023-04-29 18:12:18,594:INFO:Logical Core: 8
2023-04-29 18:12:18,594:INFO:Checking libraries
2023-04-29 18:12:18,594:INFO:System:
2023-04-29 18:12:18,594:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:12:18,594:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:12:18,594:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:12:18,594:INFO:PyCaret required dependencies:
2023-04-29 18:12:18,594:INFO:                 pip: 22.2.2
2023-04-29 18:12:18,594:INFO:          setuptools: 63.4.1
2023-04-29 18:12:18,594:INFO:             pycaret: 3.0.0
2023-04-29 18:12:18,594:INFO:             IPython: 7.31.1
2023-04-29 18:12:18,594:INFO:          ipywidgets: 7.6.5
2023-04-29 18:12:18,595:INFO:                tqdm: 4.64.1
2023-04-29 18:12:18,595:INFO:               numpy: 1.21.5
2023-04-29 18:12:18,595:INFO:              pandas: 1.4.4
2023-04-29 18:12:18,595:INFO:              jinja2: 2.11.3
2023-04-29 18:12:18,595:INFO:               scipy: 1.9.1
2023-04-29 18:12:18,595:INFO:              joblib: 1.2.0
2023-04-29 18:12:18,595:INFO:             sklearn: 1.0.2
2023-04-29 18:12:18,595:INFO:                pyod: 1.0.9
2023-04-29 18:12:18,595:INFO:            imblearn: 0.10.1
2023-04-29 18:12:18,595:INFO:   category_encoders: 2.6.0
2023-04-29 18:12:18,595:INFO:            lightgbm: 3.3.5
2023-04-29 18:12:18,595:INFO:               numba: 0.55.1
2023-04-29 18:12:18,595:INFO:            requests: 2.28.1
2023-04-29 18:12:18,595:INFO:          matplotlib: 3.5.2
2023-04-29 18:12:18,595:INFO:          scikitplot: 0.3.7
2023-04-29 18:12:18,595:INFO:         yellowbrick: 1.5
2023-04-29 18:12:18,596:INFO:              plotly: 5.9.0
2023-04-29 18:12:18,596:INFO:             kaleido: 0.2.1
2023-04-29 18:12:18,596:INFO:         statsmodels: 0.13.2
2023-04-29 18:12:18,596:INFO:              sktime: 0.17.1
2023-04-29 18:12:18,596:INFO:               tbats: 1.1.2
2023-04-29 18:12:18,596:INFO:            pmdarima: 2.0.3
2023-04-29 18:12:18,596:INFO:              psutil: 5.9.0
2023-04-29 18:12:18,596:INFO:PyCaret optional dependencies:
2023-04-29 18:12:18,596:INFO:                shap: 0.41.0
2023-04-29 18:12:18,596:INFO:           interpret: Not installed
2023-04-29 18:12:18,596:INFO:                umap: Not installed
2023-04-29 18:12:18,597:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:12:18,597:INFO:  explainerdashboard: Not installed
2023-04-29 18:12:18,597:INFO:             autoviz: Not installed
2023-04-29 18:12:18,597:INFO:           fairlearn: Not installed
2023-04-29 18:12:18,597:INFO:             xgboost: Not installed
2023-04-29 18:12:18,597:INFO:            catboost: Not installed
2023-04-29 18:12:18,597:INFO:              kmodes: Not installed
2023-04-29 18:12:18,597:INFO:             mlxtend: Not installed
2023-04-29 18:12:18,597:INFO:       statsforecast: Not installed
2023-04-29 18:12:18,597:INFO:        tune_sklearn: Not installed
2023-04-29 18:12:18,597:INFO:                 ray: Not installed
2023-04-29 18:12:18,597:INFO:            hyperopt: Not installed
2023-04-29 18:12:18,597:INFO:              optuna: Not installed
2023-04-29 18:12:18,597:INFO:               skopt: Not installed
2023-04-29 18:12:18,597:INFO:              mlflow: 2.2.1
2023-04-29 18:12:18,597:INFO:              gradio: Not installed
2023-04-29 18:12:18,597:INFO:             fastapi: Not installed
2023-04-29 18:12:18,598:INFO:             uvicorn: Not installed
2023-04-29 18:12:18,598:INFO:              m2cgen: Not installed
2023-04-29 18:12:18,598:INFO:           evidently: Not installed
2023-04-29 18:12:18,598:INFO:               fugue: Not installed
2023-04-29 18:12:18,598:INFO:           streamlit: 1.21.0
2023-04-29 18:12:18,598:INFO:             prophet: Not installed
2023-04-29 18:12:18,598:INFO:None
2023-04-29 18:12:18,598:INFO:Set up data.
2023-04-29 18:12:18,603:INFO:Set up train/test split.
2023-04-29 18:12:18,605:INFO:Set up index.
2023-04-29 18:12:18,606:INFO:Set up folding strategy.
2023-04-29 18:12:18,606:INFO:Assigning column types.
2023-04-29 18:12:18,609:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:12:18,609:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,614:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:18,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:18,734:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,740:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,744:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:18,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:18,868:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:12:18,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,879:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:18,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:18,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,071:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,121:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:12:19,131:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,380:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:12:19,456:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,636:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:12:19,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,837:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:19,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:19,883:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:12:20,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,121:INFO:Preparing preprocessing pipeline...
2023-04-29 18:12:20,121:INFO:Set up simple imputation.
2023-04-29 18:12:20,122:INFO:Set up column name cleaning.
2023-04-29 18:12:20,144:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:12:20,149:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:12:20,149:INFO:Creating final display dataframe.
2023-04-29 18:12:20,224:INFO:Setup _display_container:                     Description             Value
0                    Session id              2360
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              f637
2023-04-29 18:12:20,226:INFO:                    Description             Value
2023-04-29 18:12:20,226:INFO:0                    Session id              2360
2023-04-29 18:12:20,226:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:12:20,226:INFO:2                   Target type        Regression
2023-04-29 18:12:20,226:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:12:20,227:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:12:20,227:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:12:20,227:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:12:20,227:INFO:7              Numeric features                 7
2023-04-29 18:12:20,227:INFO:8                    Preprocess              True
2023-04-29 18:12:20,227:INFO:9               Imputation type            simple
2023-04-29 18:12:20,227:INFO:10           Numeric imputation              mean
2023-04-29 18:12:20,227:INFO:11       Categorical imputation              mode
2023-04-29 18:12:20,227:INFO:12               Fold Generator             KFold
2023-04-29 18:12:20,227:INFO:13                  Fold Number                10
2023-04-29 18:12:20,227:INFO:14                     CPU Jobs                -1
2023-04-29 18:12:20,227:INFO:15                      Use GPU             False
2023-04-29 18:12:20,227:INFO:16               Log Experiment             False
2023-04-29 18:12:20,227:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:12:20,228:INFO:18                          USI              f637
2023-04-29 18:12:20,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:20,468:INFO:setup() successfully completed in 2.57s...............
2023-04-29 18:12:20,475:INFO:Initializing compare_models()
2023-04-29 18:12:20,476:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:12:20,476:INFO:Checking exceptions
2023-04-29 18:12:20,478:INFO:Preparing display monitor
2023-04-29 18:12:20,480:WARNING:
2023-04-29 18:12:20,481:WARNING:Processing:   0%| | 0/77 [00:00<?, ?i
2023-04-29 18:12:20,482:WARNING:[A
2023-04-29 18:12:20,482:INFO:Initializing Linear Regression
2023-04-29 18:12:20,482:INFO:Total runtime is 0.0 minutes
2023-04-29 18:12:20,482:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:20,484:INFO:Initializing create_model()
2023-04-29 18:12:20,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:20,484:INFO:Checking exceptions
2023-04-29 18:12:20,484:INFO:Importing libraries
2023-04-29 18:12:20,484:INFO:Copying training dataset
2023-04-29 18:12:20,488:INFO:Defining folds
2023-04-29 18:12:20,488:INFO:Declaring metric variables
2023-04-29 18:12:20,488:INFO:Importing untrained model
2023-04-29 18:12:20,488:INFO:Linear Regression Imported successfully
2023-04-29 18:12:20,488:INFO:Starting cross validation
2023-04-29 18:12:20,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:25,078:INFO:Calculating mean and std
2023-04-29 18:12:25,079:INFO:Creating metrics dataframe
2023-04-29 18:12:25,714:INFO:Uploading results into container
2023-04-29 18:12:25,714:INFO:Uploading model into container now
2023-04-29 18:12:25,715:INFO:_master_model_container: 17
2023-04-29 18:12:25,715:INFO:_display_container: 2
2023-04-29 18:12:25,715:INFO:LGBMRegressor(random_state=1308)
2023-04-29 18:12:25,715:INFO:create_model() successfully completed......................................
2023-04-29 18:12:25,808:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:25,809:INFO:Creating metrics dataframe
2023-04-29 18:12:25,815:INFO:Initializing Dummy Regressor
2023-04-29 18:12:25,815:INFO:Total runtime is 2.0410871505737305 minutes
2023-04-29 18:12:25,815:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:25,815:INFO:Initializing create_model()
2023-04-29 18:12:25,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2EF03A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:25,815:INFO:Checking exceptions
2023-04-29 18:12:25,815:INFO:Importing libraries
2023-04-29 18:12:25,816:INFO:Copying training dataset
2023-04-29 18:12:25,819:INFO:Defining folds
2023-04-29 18:12:25,819:INFO:Declaring metric variables
2023-04-29 18:12:25,819:INFO:Importing untrained model
2023-04-29 18:12:25,819:INFO:Dummy Regressor Imported successfully
2023-04-29 18:12:25,820:INFO:Starting cross validation
2023-04-29 18:12:25,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:31,578:INFO:Calculating mean and std
2023-04-29 18:12:31,578:WARNING:
2023-04-29 18:12:31,578:WARNING:Processing:   6%| | 5/77 [00:11<02:39
2023-04-29 18:12:31,579:WARNING:[A
2023-04-29 18:12:31,579:INFO:Creating metrics dataframe
2023-04-29 18:12:32,228:WARNING:
2023-04-29 18:12:32,228:WARNING:Processing:   8%| | 6/77 [00:11<02:12
2023-04-29 18:12:32,228:WARNING:[A
2023-04-29 18:12:32,228:INFO:Uploading results into container
2023-04-29 18:12:32,229:INFO:Uploading model into container now
2023-04-29 18:12:32,229:INFO:_master_model_container: 1
2023-04-29 18:12:32,229:INFO:_display_container: 2
2023-04-29 18:12:32,229:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:12:32,230:INFO:create_model() successfully completed......................................
2023-04-29 18:12:32,317:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:32,318:INFO:Creating metrics dataframe
2023-04-29 18:12:32,321:INFO:Initializing Lasso Regression
2023-04-29 18:12:32,321:INFO:Total runtime is 0.1973154346148173 minutes
2023-04-29 18:12:32,322:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:32,322:INFO:Initializing create_model()
2023-04-29 18:12:32,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:32,322:INFO:Checking exceptions
2023-04-29 18:12:32,322:INFO:Importing libraries
2023-04-29 18:12:32,322:INFO:Copying training dataset
2023-04-29 18:12:32,325:INFO:Defining folds
2023-04-29 18:12:32,325:INFO:Declaring metric variables
2023-04-29 18:12:32,325:INFO:Importing untrained model
2023-04-29 18:12:32,326:INFO:Lasso Regression Imported successfully
2023-04-29 18:12:32,326:INFO:Starting cross validation
2023-04-29 18:12:32,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:35,710:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:12:35,710:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:12:35,710:INFO:Data columns (total 8 columns):
2023-04-29 18:12:35,710:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:12:35,711:INFO:---  ------          --------------  -----  
2023-04-29 18:12:35,711:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:12:35,711:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:12:35,711:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:12:35,711:INFO:memory usage: 79.8 KB
2023-04-29 18:12:36,535:INFO:PyCaret RegressionExperiment
2023-04-29 18:12:36,535:INFO:Logging name: reg-default-name
2023-04-29 18:12:36,535:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:12:36,535:INFO:version 3.0.0
2023-04-29 18:12:36,535:INFO:Initializing setup()
2023-04-29 18:12:36,535:INFO:self.USI: b270
2023-04-29 18:12:36,535:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:12:36,535:INFO:Checking environment
2023-04-29 18:12:36,536:INFO:python_version: 3.9.13
2023-04-29 18:12:36,536:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:12:36,536:INFO:machine: AMD64
2023-04-29 18:12:36,536:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:12:36,536:INFO:Memory: svmem(total=16935899136, available=5302566912, percent=68.7, used=11633332224, free=5302566912)
2023-04-29 18:12:36,536:INFO:Physical Core: 4
2023-04-29 18:12:36,536:INFO:Logical Core: 8
2023-04-29 18:12:36,536:INFO:Checking libraries
2023-04-29 18:12:36,536:INFO:System:
2023-04-29 18:12:36,536:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:12:36,537:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:12:36,537:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:12:36,537:INFO:PyCaret required dependencies:
2023-04-29 18:12:36,537:INFO:                 pip: 22.2.2
2023-04-29 18:12:36,537:INFO:          setuptools: 63.4.1
2023-04-29 18:12:36,537:INFO:             pycaret: 3.0.0
2023-04-29 18:12:36,537:INFO:             IPython: 7.31.1
2023-04-29 18:12:36,537:INFO:          ipywidgets: 7.6.5
2023-04-29 18:12:36,537:INFO:                tqdm: 4.64.1
2023-04-29 18:12:36,537:INFO:               numpy: 1.21.5
2023-04-29 18:12:36,537:INFO:              pandas: 1.4.4
2023-04-29 18:12:36,537:INFO:              jinja2: 2.11.3
2023-04-29 18:12:36,537:INFO:               scipy: 1.9.1
2023-04-29 18:12:36,537:INFO:              joblib: 1.2.0
2023-04-29 18:12:36,537:INFO:             sklearn: 1.0.2
2023-04-29 18:12:36,537:INFO:                pyod: 1.0.9
2023-04-29 18:12:36,537:INFO:            imblearn: 0.10.1
2023-04-29 18:12:36,538:INFO:   category_encoders: 2.6.0
2023-04-29 18:12:36,538:INFO:            lightgbm: 3.3.5
2023-04-29 18:12:36,538:INFO:               numba: 0.55.1
2023-04-29 18:12:36,538:INFO:            requests: 2.28.1
2023-04-29 18:12:36,538:INFO:          matplotlib: 3.5.2
2023-04-29 18:12:36,538:INFO:          scikitplot: 0.3.7
2023-04-29 18:12:36,538:INFO:         yellowbrick: 1.5
2023-04-29 18:12:36,538:INFO:              plotly: 5.9.0
2023-04-29 18:12:36,538:INFO:             kaleido: 0.2.1
2023-04-29 18:12:36,538:INFO:         statsmodels: 0.13.2
2023-04-29 18:12:36,538:INFO:              sktime: 0.17.1
2023-04-29 18:12:36,538:INFO:               tbats: 1.1.2
2023-04-29 18:12:36,538:INFO:            pmdarima: 2.0.3
2023-04-29 18:12:36,538:INFO:              psutil: 5.9.0
2023-04-29 18:12:36,538:INFO:PyCaret optional dependencies:
2023-04-29 18:12:36,538:INFO:                shap: 0.41.0
2023-04-29 18:12:36,538:INFO:           interpret: Not installed
2023-04-29 18:12:36,539:INFO:                umap: Not installed
2023-04-29 18:12:36,539:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:12:36,539:INFO:  explainerdashboard: Not installed
2023-04-29 18:12:36,539:INFO:             autoviz: Not installed
2023-04-29 18:12:36,539:INFO:           fairlearn: Not installed
2023-04-29 18:12:36,539:INFO:             xgboost: Not installed
2023-04-29 18:12:36,539:INFO:            catboost: Not installed
2023-04-29 18:12:36,539:INFO:              kmodes: Not installed
2023-04-29 18:12:36,539:INFO:             mlxtend: Not installed
2023-04-29 18:12:36,539:INFO:       statsforecast: Not installed
2023-04-29 18:12:36,539:INFO:        tune_sklearn: Not installed
2023-04-29 18:12:36,539:INFO:                 ray: Not installed
2023-04-29 18:12:36,540:INFO:            hyperopt: Not installed
2023-04-29 18:12:36,540:INFO:              optuna: Not installed
2023-04-29 18:12:36,540:INFO:               skopt: Not installed
2023-04-29 18:12:36,540:INFO:              mlflow: 2.2.1
2023-04-29 18:12:36,540:INFO:              gradio: Not installed
2023-04-29 18:12:36,540:INFO:             fastapi: Not installed
2023-04-29 18:12:36,540:INFO:             uvicorn: Not installed
2023-04-29 18:12:36,540:INFO:              m2cgen: Not installed
2023-04-29 18:12:36,540:INFO:           evidently: Not installed
2023-04-29 18:12:36,540:INFO:               fugue: Not installed
2023-04-29 18:12:36,540:INFO:           streamlit: 1.21.0
2023-04-29 18:12:36,540:INFO:             prophet: Not installed
2023-04-29 18:12:36,540:INFO:None
2023-04-29 18:12:36,540:INFO:Set up data.
2023-04-29 18:12:36,545:INFO:Set up train/test split.
2023-04-29 18:12:36,548:INFO:Set up index.
2023-04-29 18:12:36,548:INFO:Set up folding strategy.
2023-04-29 18:12:36,548:INFO:Assigning column types.
2023-04-29 18:12:36,551:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:12:36,551:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,557:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,562:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,671:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:36,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:36,673:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:36,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:36,787:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:12:36,793:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,798:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:36,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:36,915:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,920:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:36,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,027:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:12:37,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,269:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:12:37,339:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,460:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,513:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:12:37,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:12:37,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,773:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:12:37,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:37,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,031:INFO:Preparing preprocessing pipeline...
2023-04-29 18:12:38,031:INFO:Set up simple imputation.
2023-04-29 18:12:38,032:INFO:Set up column name cleaning.
2023-04-29 18:12:38,053:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:12:38,057:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:12:38,058:INFO:Creating final display dataframe.
2023-04-29 18:12:38,156:INFO:Setup _display_container:                     Description             Value
0                    Session id              8496
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b270
2023-04-29 18:12:38,158:INFO:                    Description             Value
2023-04-29 18:12:38,158:INFO:0                    Session id              8496
2023-04-29 18:12:38,158:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:12:38,158:INFO:2                   Target type        Regression
2023-04-29 18:12:38,158:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:12:38,159:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:12:38,159:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:12:38,159:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:12:38,159:INFO:7              Numeric features                 7
2023-04-29 18:12:38,159:INFO:8                    Preprocess              True
2023-04-29 18:12:38,159:INFO:9               Imputation type            simple
2023-04-29 18:12:38,159:INFO:10           Numeric imputation              mean
2023-04-29 18:12:38,159:INFO:11       Categorical imputation              mode
2023-04-29 18:12:38,159:INFO:12               Fold Generator             KFold
2023-04-29 18:12:38,159:INFO:13                  Fold Number                10
2023-04-29 18:12:38,159:INFO:14                     CPU Jobs                -1
2023-04-29 18:12:38,159:INFO:15                      Use GPU             False
2023-04-29 18:12:38,159:INFO:16               Log Experiment             False
2023-04-29 18:12:38,159:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:12:38,159:INFO:18                          USI              b270
2023-04-29 18:12:38,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:12:38,421:INFO:setup() successfully completed in 2.7s...............
2023-04-29 18:12:38,428:INFO:Initializing compare_models()
2023-04-29 18:12:38,429:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:12:38,429:INFO:Checking exceptions
2023-04-29 18:12:38,433:INFO:Preparing display monitor
2023-04-29 18:12:38,436:WARNING:
2023-04-29 18:12:38,436:WARNING:
2023-04-29 18:12:38,436:WARNING:Processing:   0%| | 0/77 [00:00<?, ?i
2023-04-29 18:12:38,436:WARNING:[A[A
2023-04-29 18:12:38,437:INFO:Initializing Linear Regression
2023-04-29 18:12:38,437:INFO:Total runtime is 0.0 minutes
2023-04-29 18:12:38,437:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:38,438:INFO:Initializing create_model()
2023-04-29 18:12:38,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:38,438:INFO:Checking exceptions
2023-04-29 18:12:38,438:INFO:Importing libraries
2023-04-29 18:12:38,438:INFO:Copying training dataset
2023-04-29 18:12:38,446:INFO:Defining folds
2023-04-29 18:12:38,446:INFO:Declaring metric variables
2023-04-29 18:12:38,446:INFO:Importing untrained model
2023-04-29 18:12:38,446:INFO:Linear Regression Imported successfully
2023-04-29 18:12:38,447:INFO:Starting cross validation
2023-04-29 18:12:38,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:42,468:INFO:Calculating mean and std
2023-04-29 18:12:42,468:INFO:Creating metrics dataframe
2023-04-29 18:12:43,154:INFO:Uploading results into container
2023-04-29 18:12:43,154:INFO:Uploading model into container now
2023-04-29 18:12:43,156:INFO:_master_model_container: 18
2023-04-29 18:12:43,156:INFO:_display_container: 2
2023-04-29 18:12:43,156:INFO:DummyRegressor()
2023-04-29 18:12:43,156:INFO:create_model() successfully completed......................................
2023-04-29 18:12:43,256:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:43,256:INFO:Creating metrics dataframe
2023-04-29 18:12:43,263:INFO:Initializing create_model()
2023-04-29 18:12:43,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D250B7130>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1308), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:43,263:INFO:Checking exceptions
2023-04-29 18:12:43,264:INFO:Importing libraries
2023-04-29 18:12:43,264:INFO:Copying training dataset
2023-04-29 18:12:43,269:INFO:Defining folds
2023-04-29 18:12:43,270:INFO:Declaring metric variables
2023-04-29 18:12:43,270:INFO:Importing untrained model
2023-04-29 18:12:43,270:INFO:Declaring custom model
2023-04-29 18:12:43,271:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:12:43,271:INFO:Cross validation set to False
2023-04-29 18:12:43,271:INFO:Fitting Model
2023-04-29 18:12:44,096:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1308)
2023-04-29 18:12:44,096:INFO:create_model() successfully completed......................................
2023-04-29 18:12:44,218:INFO:_master_model_container: 18
2023-04-29 18:12:44,218:INFO:_display_container: 2
2023-04-29 18:12:44,218:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1308)
2023-04-29 18:12:44,218:INFO:compare_models() successfully completed......................................
2023-04-29 18:12:48,268:INFO:Calculating mean and std
2023-04-29 18:12:48,268:WARNING:
2023-04-29 18:12:48,268:WARNING:Processing:  12%|1| 9/77 [00:27<04:02
2023-04-29 18:12:48,268:WARNING:[A
2023-04-29 18:12:48,268:INFO:Creating metrics dataframe
2023-04-29 18:12:48,924:WARNING:
2023-04-29 18:12:48,924:WARNING:Processing:  13%|1| 10/77 [00:28<03:2
2023-04-29 18:12:48,924:WARNING:[A
2023-04-29 18:12:48,924:INFO:Uploading results into container
2023-04-29 18:12:48,925:INFO:Uploading model into container now
2023-04-29 18:12:48,925:INFO:_master_model_container: 2
2023-04-29 18:12:48,925:INFO:_display_container: 2
2023-04-29 18:12:48,926:INFO:Lasso(random_state=2360)
2023-04-29 18:12:48,926:INFO:create_model() successfully completed......................................
2023-04-29 18:12:49,021:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:49,021:INFO:Creating metrics dataframe
2023-04-29 18:12:49,025:INFO:Initializing Ridge Regression
2023-04-29 18:12:49,025:INFO:Total runtime is 0.47570721705754593 minutes
2023-04-29 18:12:49,025:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:49,025:INFO:Initializing create_model()
2023-04-29 18:12:49,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:49,025:INFO:Checking exceptions
2023-04-29 18:12:49,025:INFO:Importing libraries
2023-04-29 18:12:49,025:INFO:Copying training dataset
2023-04-29 18:12:49,028:WARNING:
2023-04-29 18:12:49,028:WARNING:Processing:  14%|1| 11/77 [00:28<02:3
2023-04-29 18:12:49,028:WARNING:[A
2023-04-29 18:12:49,028:INFO:Defining folds
2023-04-29 18:12:49,028:INFO:Declaring metric variables
2023-04-29 18:12:49,029:INFO:Importing untrained model
2023-04-29 18:12:49,029:INFO:Ridge Regression Imported successfully
2023-04-29 18:12:49,029:INFO:Starting cross validation
2023-04-29 18:12:49,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:12:54,949:INFO:Calculating mean and std
2023-04-29 18:12:54,949:WARNING:
2023-04-29 18:12:54,950:WARNING:
2023-04-29 18:12:54,950:WARNING:Processing:   6%| | 5/77 [00:16<03:57
2023-04-29 18:12:54,950:WARNING:[A[A
2023-04-29 18:12:54,950:INFO:Creating metrics dataframe
2023-04-29 18:12:55,660:WARNING:
2023-04-29 18:12:55,660:WARNING:
2023-04-29 18:12:55,660:WARNING:Processing:   8%| | 6/77 [00:17<03:13
2023-04-29 18:12:55,660:WARNING:[A[A
2023-04-29 18:12:55,660:INFO:Uploading results into container
2023-04-29 18:12:55,661:INFO:Uploading model into container now
2023-04-29 18:12:55,661:INFO:_master_model_container: 1
2023-04-29 18:12:55,661:INFO:_display_container: 2
2023-04-29 18:12:55,661:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:12:55,662:INFO:create_model() successfully completed......................................
2023-04-29 18:12:55,751:INFO:SubProcess create_model() end ==================================
2023-04-29 18:12:55,752:INFO:Creating metrics dataframe
2023-04-29 18:12:55,755:INFO:Initializing Lasso Regression
2023-04-29 18:12:55,755:INFO:Total runtime is 0.2886251171429952 minutes
2023-04-29 18:12:55,755:INFO:SubProcess create_model() called ==================================
2023-04-29 18:12:55,755:INFO:Initializing create_model()
2023-04-29 18:12:55,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:12:55,755:INFO:Checking exceptions
2023-04-29 18:12:55,755:INFO:Importing libraries
2023-04-29 18:12:55,755:INFO:Copying training dataset
2023-04-29 18:12:55,758:INFO:Defining folds
2023-04-29 18:12:55,758:INFO:Declaring metric variables
2023-04-29 18:12:55,758:INFO:Importing untrained model
2023-04-29 18:12:55,759:INFO:Lasso Regression Imported successfully
2023-04-29 18:12:55,759:INFO:Starting cross validation
2023-04-29 18:12:55,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:01,438:INFO:Calculating mean and std
2023-04-29 18:13:01,439:WARNING:
2023-04-29 18:13:01,439:WARNING:Processing:  17%|1| 13/77 [00:40<04:0
2023-04-29 18:13:01,439:WARNING:[A
2023-04-29 18:13:01,439:INFO:Creating metrics dataframe
2023-04-29 18:13:02,090:WARNING:
2023-04-29 18:13:02,090:WARNING:Processing:  18%|1| 14/77 [00:41<03:1
2023-04-29 18:13:02,090:WARNING:[A
2023-04-29 18:13:02,090:INFO:Uploading results into container
2023-04-29 18:13:02,091:INFO:Uploading model into container now
2023-04-29 18:13:02,091:INFO:_master_model_container: 3
2023-04-29 18:13:02,091:INFO:_display_container: 2
2023-04-29 18:13:02,092:INFO:Ridge(random_state=2360)
2023-04-29 18:13:02,092:INFO:create_model() successfully completed......................................
2023-04-29 18:13:02,184:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:02,184:INFO:Creating metrics dataframe
2023-04-29 18:13:02,189:INFO:Initializing Elastic Net
2023-04-29 18:13:02,189:INFO:Total runtime is 0.695112121105194 minutes
2023-04-29 18:13:02,189:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:02,189:INFO:Initializing create_model()
2023-04-29 18:13:02,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:02,189:INFO:Checking exceptions
2023-04-29 18:13:02,189:INFO:Importing libraries
2023-04-29 18:13:02,189:INFO:Copying training dataset
2023-04-29 18:13:02,192:WARNING:
2023-04-29 18:13:02,192:WARNING:Processing:  19%|1| 15/77 [00:41<02:3
2023-04-29 18:13:02,192:WARNING:[A
2023-04-29 18:13:02,193:INFO:Defining folds
2023-04-29 18:13:02,193:INFO:Declaring metric variables
2023-04-29 18:13:02,193:INFO:Importing untrained model
2023-04-29 18:13:02,193:INFO:Elastic Net Imported successfully
2023-04-29 18:13:02,193:INFO:Starting cross validation
2023-04-29 18:13:02,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:08,104:INFO:Calculating mean and std
2023-04-29 18:13:08,105:WARNING:
2023-04-29 18:13:08,105:WARNING:
2023-04-29 18:13:08,105:WARNING:Processing:  12%|1| 9/77 [00:29<03:52
2023-04-29 18:13:08,105:WARNING:[A[A
2023-04-29 18:13:08,105:INFO:Creating metrics dataframe
2023-04-29 18:13:08,854:WARNING:
2023-04-29 18:13:08,854:WARNING:
2023-04-29 18:13:08,855:WARNING:Processing:  13%|1| 10/77 [00:30<03:1
2023-04-29 18:13:08,855:WARNING:[A[A
2023-04-29 18:13:08,855:INFO:Uploading results into container
2023-04-29 18:13:08,855:INFO:Uploading model into container now
2023-04-29 18:13:08,856:INFO:_master_model_container: 2
2023-04-29 18:13:08,856:INFO:_display_container: 2
2023-04-29 18:13:08,856:INFO:Lasso(random_state=8496)
2023-04-29 18:13:08,856:INFO:create_model() successfully completed......................................
2023-04-29 18:13:08,984:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:08,985:INFO:Creating metrics dataframe
2023-04-29 18:13:08,991:INFO:Initializing Ridge Regression
2023-04-29 18:13:08,991:INFO:Total runtime is 0.5092221220334371 minutes
2023-04-29 18:13:08,991:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:08,991:INFO:Initializing create_model()
2023-04-29 18:13:08,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:08,991:INFO:Checking exceptions
2023-04-29 18:13:08,991:INFO:Importing libraries
2023-04-29 18:13:08,991:INFO:Copying training dataset
2023-04-29 18:13:08,997:WARNING:
2023-04-29 18:13:08,997:WARNING:
2023-04-29 18:13:08,997:WARNING:Processing:  14%|1| 11/77 [00:30<02:3
2023-04-29 18:13:08,997:WARNING:[A[A
2023-04-29 18:13:08,997:INFO:Defining folds
2023-04-29 18:13:08,997:INFO:Declaring metric variables
2023-04-29 18:13:08,997:INFO:Importing untrained model
2023-04-29 18:13:08,997:INFO:Ridge Regression Imported successfully
2023-04-29 18:13:08,999:INFO:Starting cross validation
2023-04-29 18:13:09,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:16,748:INFO:Calculating mean and std
2023-04-29 18:13:16,749:WARNING:
2023-04-29 18:13:16,749:WARNING:Processing:  22%|2| 17/77 [00:56<04:2
2023-04-29 18:13:16,750:WARNING:[A
2023-04-29 18:13:16,750:INFO:Creating metrics dataframe
2023-04-29 18:13:17,554:WARNING:
2023-04-29 18:13:17,554:WARNING:Processing:  23%|2| 18/77 [00:57<03:3
2023-04-29 18:13:17,554:WARNING:[A
2023-04-29 18:13:17,554:INFO:Uploading results into container
2023-04-29 18:13:17,555:INFO:Uploading model into container now
2023-04-29 18:13:17,556:INFO:_master_model_container: 4
2023-04-29 18:13:17,556:INFO:_display_container: 2
2023-04-29 18:13:17,556:INFO:ElasticNet(random_state=2360)
2023-04-29 18:13:17,556:INFO:create_model() successfully completed......................................
2023-04-29 18:13:17,654:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:17,655:INFO:Creating metrics dataframe
2023-04-29 18:13:17,659:INFO:Initializing Least Angle Regression
2023-04-29 18:13:17,659:INFO:Total runtime is 0.9529551744461059 minutes
2023-04-29 18:13:17,659:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:17,659:INFO:Initializing create_model()
2023-04-29 18:13:17,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:17,660:INFO:Checking exceptions
2023-04-29 18:13:17,660:INFO:Importing libraries
2023-04-29 18:13:17,660:INFO:Copying training dataset
2023-04-29 18:13:17,662:WARNING:
2023-04-29 18:13:17,662:WARNING:Processing:  25%|2| 19/77 [00:57<02:3
2023-04-29 18:13:17,662:WARNING:[A
2023-04-29 18:13:17,663:INFO:Defining folds
2023-04-29 18:13:17,663:INFO:Declaring metric variables
2023-04-29 18:13:17,663:INFO:Importing untrained model
2023-04-29 18:13:17,663:INFO:Least Angle Regression Imported successfully
2023-04-29 18:13:17,663:INFO:Starting cross validation
2023-04-29 18:13:17,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:17,725:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,734:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,754:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,781:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,792:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,810:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,829:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:17,841:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:19,219:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:19,245:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:23,284:INFO:Calculating mean and std
2023-04-29 18:13:23,284:WARNING:
2023-04-29 18:13:23,284:WARNING:
2023-04-29 18:13:23,285:WARNING:Processing:  17%|1| 13/77 [00:44<04:2
2023-04-29 18:13:23,285:WARNING:[A[A
2023-04-29 18:13:23,285:INFO:Creating metrics dataframe
2023-04-29 18:13:23,986:WARNING:
2023-04-29 18:13:23,986:WARNING:
2023-04-29 18:13:23,986:WARNING:Processing:  18%|1| 14/77 [00:45<03:3
2023-04-29 18:13:23,986:WARNING:[A[A
2023-04-29 18:13:23,986:INFO:Uploading results into container
2023-04-29 18:13:23,987:INFO:Uploading model into container now
2023-04-29 18:13:23,987:INFO:_master_model_container: 3
2023-04-29 18:13:23,987:INFO:_display_container: 2
2023-04-29 18:13:23,987:INFO:Ridge(random_state=8496)
2023-04-29 18:13:23,987:INFO:create_model() successfully completed......................................
2023-04-29 18:13:24,075:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:24,076:INFO:Creating metrics dataframe
2023-04-29 18:13:24,080:INFO:Initializing Elastic Net
2023-04-29 18:13:24,081:INFO:Total runtime is 0.760721468925476 minutes
2023-04-29 18:13:24,081:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:24,081:INFO:Initializing create_model()
2023-04-29 18:13:24,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:24,081:INFO:Checking exceptions
2023-04-29 18:13:24,081:INFO:Importing libraries
2023-04-29 18:13:24,081:INFO:Copying training dataset
2023-04-29 18:13:24,084:INFO:Defining folds
2023-04-29 18:13:24,085:INFO:Declaring metric variables
2023-04-29 18:13:24,085:INFO:Importing untrained model
2023-04-29 18:13:24,085:INFO:Elastic Net Imported successfully
2023-04-29 18:13:24,086:INFO:Starting cross validation
2023-04-29 18:13:24,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:30,106:INFO:Calculating mean and std
2023-04-29 18:13:30,106:WARNING:
2023-04-29 18:13:30,107:WARNING:Processing:  27%|2| 21/77 [01:09<03:5
2023-04-29 18:13:30,107:WARNING:[A
2023-04-29 18:13:30,107:INFO:Creating metrics dataframe
2023-04-29 18:13:30,819:WARNING:
2023-04-29 18:13:30,820:WARNING:Processing:  29%|2| 22/77 [01:10<03:0
2023-04-29 18:13:30,820:WARNING:[A
2023-04-29 18:13:30,820:INFO:Uploading results into container
2023-04-29 18:13:30,821:INFO:Uploading model into container now
2023-04-29 18:13:30,822:INFO:_master_model_container: 5
2023-04-29 18:13:30,822:INFO:_display_container: 2
2023-04-29 18:13:30,823:INFO:Lars(random_state=2360)
2023-04-29 18:13:30,823:INFO:create_model() successfully completed......................................
2023-04-29 18:13:30,948:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:30,948:INFO:Creating metrics dataframe
2023-04-29 18:13:30,961:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:13:30,961:INFO:Total runtime is 1.1746458967526754 minutes
2023-04-29 18:13:30,962:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:30,962:INFO:Initializing create_model()
2023-04-29 18:13:30,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:30,962:INFO:Checking exceptions
2023-04-29 18:13:30,962:INFO:Importing libraries
2023-04-29 18:13:30,963:INFO:Copying training dataset
2023-04-29 18:13:30,969:WARNING:
2023-04-29 18:13:30,969:WARNING:Processing:  30%|2| 23/77 [01:10<02:2
2023-04-29 18:13:30,970:WARNING:[A
2023-04-29 18:13:30,970:INFO:Defining folds
2023-04-29 18:13:30,970:INFO:Declaring metric variables
2023-04-29 18:13:30,970:INFO:Importing untrained model
2023-04-29 18:13:30,971:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:13:30,971:INFO:Starting cross validation
2023-04-29 18:13:30,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:31,081:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,100:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,118:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,133:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,163:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,167:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,186:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:31,209:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:33,203:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:33,281:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:13:34,638:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:13:34,639:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:13:34,639:INFO:Data columns (total 8 columns):
2023-04-29 18:13:34,639:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:13:34,639:INFO:---  ------          --------------  -----  
2023-04-29 18:13:34,639:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:13:34,639:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:13:34,639:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:13:34,639:INFO:memory usage: 79.8 KB
2023-04-29 18:13:35,399:INFO:PyCaret RegressionExperiment
2023-04-29 18:13:35,399:INFO:Logging name: reg-default-name
2023-04-29 18:13:35,400:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:13:35,400:INFO:version 3.0.0
2023-04-29 18:13:35,400:INFO:Initializing setup()
2023-04-29 18:13:35,400:INFO:self.USI: 8fef
2023-04-29 18:13:35,401:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:13:35,401:INFO:Checking environment
2023-04-29 18:13:35,401:INFO:python_version: 3.9.13
2023-04-29 18:13:35,401:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:13:35,401:INFO:machine: AMD64
2023-04-29 18:13:35,401:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:13:35,401:INFO:Memory: svmem(total=16935899136, available=5336236032, percent=68.5, used=11599663104, free=5336236032)
2023-04-29 18:13:35,401:INFO:Physical Core: 4
2023-04-29 18:13:35,401:INFO:Logical Core: 8
2023-04-29 18:13:35,401:INFO:Checking libraries
2023-04-29 18:13:35,401:INFO:System:
2023-04-29 18:13:35,401:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:13:35,402:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:13:35,402:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:13:35,402:INFO:PyCaret required dependencies:
2023-04-29 18:13:35,402:INFO:                 pip: 22.2.2
2023-04-29 18:13:35,402:INFO:          setuptools: 63.4.1
2023-04-29 18:13:35,402:INFO:             pycaret: 3.0.0
2023-04-29 18:13:35,402:INFO:             IPython: 7.31.1
2023-04-29 18:13:35,402:INFO:          ipywidgets: 7.6.5
2023-04-29 18:13:35,402:INFO:                tqdm: 4.64.1
2023-04-29 18:13:35,402:INFO:               numpy: 1.21.5
2023-04-29 18:13:35,402:INFO:              pandas: 1.4.4
2023-04-29 18:13:35,402:INFO:              jinja2: 2.11.3
2023-04-29 18:13:35,402:INFO:               scipy: 1.9.1
2023-04-29 18:13:35,402:INFO:              joblib: 1.2.0
2023-04-29 18:13:35,402:INFO:             sklearn: 1.0.2
2023-04-29 18:13:35,402:INFO:                pyod: 1.0.9
2023-04-29 18:13:35,402:INFO:            imblearn: 0.10.1
2023-04-29 18:13:35,402:INFO:   category_encoders: 2.6.0
2023-04-29 18:13:35,402:INFO:            lightgbm: 3.3.5
2023-04-29 18:13:35,403:INFO:               numba: 0.55.1
2023-04-29 18:13:35,403:INFO:            requests: 2.28.1
2023-04-29 18:13:35,403:INFO:          matplotlib: 3.5.2
2023-04-29 18:13:35,403:INFO:          scikitplot: 0.3.7
2023-04-29 18:13:35,403:INFO:         yellowbrick: 1.5
2023-04-29 18:13:35,403:INFO:              plotly: 5.9.0
2023-04-29 18:13:35,403:INFO:             kaleido: 0.2.1
2023-04-29 18:13:35,403:INFO:         statsmodels: 0.13.2
2023-04-29 18:13:35,403:INFO:              sktime: 0.17.1
2023-04-29 18:13:35,403:INFO:               tbats: 1.1.2
2023-04-29 18:13:35,403:INFO:            pmdarima: 2.0.3
2023-04-29 18:13:35,403:INFO:              psutil: 5.9.0
2023-04-29 18:13:35,403:INFO:PyCaret optional dependencies:
2023-04-29 18:13:35,403:INFO:                shap: 0.41.0
2023-04-29 18:13:35,403:INFO:           interpret: Not installed
2023-04-29 18:13:35,403:INFO:                umap: Not installed
2023-04-29 18:13:35,403:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:13:35,403:INFO:  explainerdashboard: Not installed
2023-04-29 18:13:35,403:INFO:             autoviz: Not installed
2023-04-29 18:13:35,404:INFO:           fairlearn: Not installed
2023-04-29 18:13:35,404:INFO:             xgboost: Not installed
2023-04-29 18:13:35,404:INFO:            catboost: Not installed
2023-04-29 18:13:35,404:INFO:              kmodes: Not installed
2023-04-29 18:13:35,404:INFO:             mlxtend: Not installed
2023-04-29 18:13:35,404:INFO:       statsforecast: Not installed
2023-04-29 18:13:35,404:INFO:        tune_sklearn: Not installed
2023-04-29 18:13:35,404:INFO:                 ray: Not installed
2023-04-29 18:13:35,404:INFO:            hyperopt: Not installed
2023-04-29 18:13:35,404:INFO:              optuna: Not installed
2023-04-29 18:13:35,404:INFO:               skopt: Not installed
2023-04-29 18:13:35,404:INFO:              mlflow: 2.2.1
2023-04-29 18:13:35,404:INFO:              gradio: Not installed
2023-04-29 18:13:35,404:INFO:             fastapi: Not installed
2023-04-29 18:13:35,404:INFO:             uvicorn: Not installed
2023-04-29 18:13:35,404:INFO:              m2cgen: Not installed
2023-04-29 18:13:35,404:INFO:           evidently: Not installed
2023-04-29 18:13:35,404:INFO:               fugue: Not installed
2023-04-29 18:13:35,404:INFO:           streamlit: 1.21.0
2023-04-29 18:13:35,404:INFO:             prophet: Not installed
2023-04-29 18:13:35,404:INFO:None
2023-04-29 18:13:35,405:INFO:Set up data.
2023-04-29 18:13:35,409:INFO:Set up train/test split.
2023-04-29 18:13:35,412:INFO:Set up index.
2023-04-29 18:13:35,412:INFO:Set up folding strategy.
2023-04-29 18:13:35,412:INFO:Assigning column types.
2023-04-29 18:13:35,415:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:13:35,415:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,422:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,427:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,550:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,555:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,671:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:13:35,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,861:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:35,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:35,987:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:13:35,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,121:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,228:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:13:36,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,489:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:13:36,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:13:36,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,741:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:13:36,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:36,985:INFO:Preparing preprocessing pipeline...
2023-04-29 18:13:36,985:INFO:Set up simple imputation.
2023-04-29 18:13:36,986:INFO:Set up column name cleaning.
2023-04-29 18:13:37,015:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:13:37,019:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:13:37,019:INFO:Creating final display dataframe.
2023-04-29 18:13:37,101:INFO:Setup _display_container:                     Description             Value
0                    Session id              6697
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8fef
2023-04-29 18:13:37,105:INFO:                    Description             Value
2023-04-29 18:13:37,105:INFO:0                    Session id              6697
2023-04-29 18:13:37,105:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:13:37,105:INFO:2                   Target type        Regression
2023-04-29 18:13:37,106:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:13:37,106:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:13:37,106:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:13:37,106:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:13:37,106:INFO:7              Numeric features                 7
2023-04-29 18:13:37,106:INFO:8                    Preprocess              True
2023-04-29 18:13:37,106:INFO:9               Imputation type            simple
2023-04-29 18:13:37,106:INFO:10           Numeric imputation              mean
2023-04-29 18:13:37,106:INFO:11       Categorical imputation              mode
2023-04-29 18:13:37,106:INFO:12               Fold Generator             KFold
2023-04-29 18:13:37,106:INFO:13                  Fold Number                10
2023-04-29 18:13:37,106:INFO:14                     CPU Jobs                -1
2023-04-29 18:13:37,107:INFO:15                      Use GPU             False
2023-04-29 18:13:37,107:INFO:16               Log Experiment             False
2023-04-29 18:13:37,107:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:13:37,107:INFO:18                          USI              8fef
2023-04-29 18:13:37,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:37,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:37,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:37,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:13:37,379:INFO:setup() successfully completed in 2.73s...............
2023-04-29 18:13:37,386:INFO:Initializing compare_models()
2023-04-29 18:13:37,386:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:13:37,386:INFO:Checking exceptions
2023-04-29 18:13:37,388:INFO:Preparing display monitor
2023-04-29 18:13:37,390:WARNING:Processing:   0%| | 0/77 [00:00<?, ?i
2023-04-29 18:13:37,390:INFO:Initializing Linear Regression
2023-04-29 18:13:37,391:INFO:Total runtime is 1.658201217651367e-05 minutes
2023-04-29 18:13:37,391:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:37,391:INFO:Initializing create_model()
2023-04-29 18:13:37,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FC53E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:37,391:INFO:Checking exceptions
2023-04-29 18:13:37,391:INFO:Importing libraries
2023-04-29 18:13:37,391:INFO:Copying training dataset
2023-04-29 18:13:37,396:INFO:Defining folds
2023-04-29 18:13:37,396:INFO:Declaring metric variables
2023-04-29 18:13:37,397:INFO:Importing untrained model
2023-04-29 18:13:37,397:INFO:Linear Regression Imported successfully
2023-04-29 18:13:37,397:INFO:Starting cross validation
2023-04-29 18:13:37,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:41,861:INFO:Calculating mean and std
2023-04-29 18:13:41,861:WARNING:
2023-04-29 18:13:41,861:WARNING:
2023-04-29 18:13:41,861:WARNING:Processing:  22%|2| 17/77 [01:03<04:3
2023-04-29 18:13:41,862:WARNING:[A[A
2023-04-29 18:13:41,862:INFO:Creating metrics dataframe
2023-04-29 18:13:42,626:WARNING:
2023-04-29 18:13:42,626:WARNING:
2023-04-29 18:13:42,627:WARNING:Processing:  23%|2| 18/77 [01:04<03:5
2023-04-29 18:13:42,627:WARNING:[A[A
2023-04-29 18:13:42,627:INFO:Uploading results into container
2023-04-29 18:13:42,628:INFO:Uploading model into container now
2023-04-29 18:13:42,628:INFO:_master_model_container: 4
2023-04-29 18:13:42,628:INFO:_display_container: 2
2023-04-29 18:13:42,629:INFO:ElasticNet(random_state=8496)
2023-04-29 18:13:42,629:INFO:create_model() successfully completed......................................
2023-04-29 18:13:42,729:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:42,729:INFO:Creating metrics dataframe
2023-04-29 18:13:42,733:INFO:Initializing Least Angle Regression
2023-04-29 18:13:42,734:INFO:Total runtime is 1.0716173330942789 minutes
2023-04-29 18:13:42,734:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:42,734:INFO:Initializing create_model()
2023-04-29 18:13:42,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:42,734:INFO:Checking exceptions
2023-04-29 18:13:42,734:INFO:Importing libraries
2023-04-29 18:13:42,734:INFO:Copying training dataset
2023-04-29 18:13:42,738:WARNING:
2023-04-29 18:13:42,738:WARNING:
2023-04-29 18:13:42,738:WARNING:Processing:  25%|2| 19/77 [01:04<03:0
2023-04-29 18:13:42,738:WARNING:[A[A
2023-04-29 18:13:42,738:INFO:Defining folds
2023-04-29 18:13:42,738:INFO:Declaring metric variables
2023-04-29 18:13:42,739:INFO:Importing untrained model
2023-04-29 18:13:42,740:INFO:Least Angle Regression Imported successfully
2023-04-29 18:13:42,740:INFO:Starting cross validation
2023-04-29 18:13:42,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:43,303:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,321:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,336:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,339:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,357:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,375:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,394:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:43,414:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:44,915:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:45,005:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:48,702:INFO:Calculating mean and std
2023-04-29 18:13:48,702:WARNING:
2023-04-29 18:13:48,703:WARNING:Processing:  32%|3| 25/77 [01:28<04:2
2023-04-29 18:13:48,703:WARNING:[A
2023-04-29 18:13:48,703:INFO:Creating metrics dataframe
2023-04-29 18:13:49,365:WARNING:
2023-04-29 18:13:49,365:WARNING:Processing:  34%|3| 26/77 [01:28<03:3
2023-04-29 18:13:49,365:WARNING:[A
2023-04-29 18:13:49,365:INFO:Uploading results into container
2023-04-29 18:13:49,366:INFO:Uploading model into container now
2023-04-29 18:13:49,366:INFO:_master_model_container: 6
2023-04-29 18:13:49,366:INFO:_display_container: 2
2023-04-29 18:13:49,366:INFO:LassoLars(random_state=2360)
2023-04-29 18:13:49,366:INFO:create_model() successfully completed......................................
2023-04-29 18:13:49,458:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:49,458:INFO:Creating metrics dataframe
2023-04-29 18:13:49,461:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:13:49,462:INFO:Total runtime is 1.4830007195472716 minutes
2023-04-29 18:13:49,462:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:49,462:INFO:Initializing create_model()
2023-04-29 18:13:49,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:49,462:INFO:Checking exceptions
2023-04-29 18:13:49,462:INFO:Importing libraries
2023-04-29 18:13:49,462:INFO:Copying training dataset
2023-04-29 18:13:49,466:WARNING:
2023-04-29 18:13:49,466:WARNING:Processing:  35%|3| 27/77 [01:28<02:3
2023-04-29 18:13:49,466:WARNING:[A
2023-04-29 18:13:49,466:INFO:Defining folds
2023-04-29 18:13:49,466:INFO:Declaring metric variables
2023-04-29 18:13:49,467:INFO:Importing untrained model
2023-04-29 18:13:49,467:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:13:49,467:INFO:Starting cross validation
2023-04-29 18:13:49,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:13:50,010:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,026:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,045:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,055:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,067:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,088:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,104:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:50,123:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:51,674:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:51,694:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:13:55,233:INFO:Calculating mean and std
2023-04-29 18:13:55,234:WARNING:Processing:   6%| | 5/77 [00:17<04:16
2023-04-29 18:13:55,234:INFO:Creating metrics dataframe
2023-04-29 18:13:55,909:WARNING:Processing:   8%| | 6/77 [00:18<03:27
2023-04-29 18:13:55,909:INFO:Uploading results into container
2023-04-29 18:13:55,910:INFO:Uploading model into container now
2023-04-29 18:13:55,910:INFO:_master_model_container: 1
2023-04-29 18:13:55,910:INFO:_display_container: 2
2023-04-29 18:13:55,910:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:13:55,910:INFO:create_model() successfully completed......................................
2023-04-29 18:13:56,004:INFO:SubProcess create_model() end ==================================
2023-04-29 18:13:56,005:INFO:Creating metrics dataframe
2023-04-29 18:13:56,008:INFO:Initializing Lasso Regression
2023-04-29 18:13:56,009:INFO:Total runtime is 0.3103176474571228 minutes
2023-04-29 18:13:56,009:INFO:SubProcess create_model() called ==================================
2023-04-29 18:13:56,009:INFO:Initializing create_model()
2023-04-29 18:13:56,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FC53E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:13:56,009:INFO:Checking exceptions
2023-04-29 18:13:56,009:INFO:Importing libraries
2023-04-29 18:13:56,009:INFO:Copying training dataset
2023-04-29 18:13:56,013:WARNING:Processing:   9%| | 7/77 [00:18<02:37
2023-04-29 18:13:56,013:INFO:Defining folds
2023-04-29 18:13:56,014:INFO:Declaring metric variables
2023-04-29 18:13:56,014:INFO:Importing untrained model
2023-04-29 18:13:56,014:INFO:Lasso Regression Imported successfully
2023-04-29 18:13:56,014:INFO:Starting cross validation
2023-04-29 18:13:56,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:01,676:INFO:Calculating mean and std
2023-04-29 18:14:01,676:WARNING:
2023-04-29 18:14:01,676:WARNING:
2023-04-29 18:14:01,676:WARNING:Processing:  27%|2| 21/77 [01:23<05:0
2023-04-29 18:14:01,676:WARNING:[A[A
2023-04-29 18:14:01,677:INFO:Creating metrics dataframe
2023-04-29 18:14:02,400:WARNING:
2023-04-29 18:14:02,400:WARNING:
2023-04-29 18:14:02,400:WARNING:Processing:  29%|2| 22/77 [01:23<04:0
2023-04-29 18:14:02,401:WARNING:[A[A
2023-04-29 18:14:02,401:INFO:Uploading results into container
2023-04-29 18:14:02,401:INFO:Uploading model into container now
2023-04-29 18:14:02,402:INFO:_master_model_container: 5
2023-04-29 18:14:02,402:INFO:_display_container: 2
2023-04-29 18:14:02,402:INFO:Lars(random_state=8496)
2023-04-29 18:14:02,402:INFO:create_model() successfully completed......................................
2023-04-29 18:14:02,495:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:02,496:INFO:Creating metrics dataframe
2023-04-29 18:14:02,499:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:14:02,499:INFO:Total runtime is 1.4010324199994404 minutes
2023-04-29 18:14:02,500:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:02,500:INFO:Initializing create_model()
2023-04-29 18:14:02,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:02,500:INFO:Checking exceptions
2023-04-29 18:14:02,500:INFO:Importing libraries
2023-04-29 18:14:02,500:INFO:Copying training dataset
2023-04-29 18:14:02,504:WARNING:
2023-04-29 18:14:02,504:WARNING:
2023-04-29 18:14:02,504:WARNING:Processing:  30%|2| 23/77 [01:24<03:0
2023-04-29 18:14:02,504:WARNING:[A[A
2023-04-29 18:14:02,504:INFO:Defining folds
2023-04-29 18:14:02,504:INFO:Declaring metric variables
2023-04-29 18:14:02,505:INFO:Importing untrained model
2023-04-29 18:14:02,505:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:14:02,505:INFO:Starting cross validation
2023-04-29 18:14:02,506:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:03,037:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,043:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,059:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,070:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,089:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,103:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,119:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:03,139:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:04,486:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:04,524:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:14:08,039:INFO:Calculating mean and std
2023-04-29 18:14:08,039:WARNING:
2023-04-29 18:14:08,039:WARNING:Processing:  38%|3| 29/77 [01:47<04:3
2023-04-29 18:14:08,039:WARNING:[A
2023-04-29 18:14:08,039:INFO:Creating metrics dataframe
2023-04-29 18:14:08,685:WARNING:
2023-04-29 18:14:08,685:WARNING:Processing:  39%|3| 30/77 [01:48<03:3
2023-04-29 18:14:08,685:WARNING:[A
2023-04-29 18:14:08,685:INFO:Uploading results into container
2023-04-29 18:14:08,686:INFO:Uploading model into container now
2023-04-29 18:14:08,686:INFO:_master_model_container: 7
2023-04-29 18:14:08,686:INFO:_display_container: 2
2023-04-29 18:14:08,687:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:14:08,687:INFO:create_model() successfully completed......................................
2023-04-29 18:14:08,780:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:08,781:INFO:Creating metrics dataframe
2023-04-29 18:14:08,784:INFO:Initializing Bayesian Ridge
2023-04-29 18:14:08,785:INFO:Total runtime is 1.8050458470980326 minutes
2023-04-29 18:14:08,785:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:08,785:INFO:Initializing create_model()
2023-04-29 18:14:08,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:08,785:INFO:Checking exceptions
2023-04-29 18:14:08,785:INFO:Importing libraries
2023-04-29 18:14:08,785:INFO:Copying training dataset
2023-04-29 18:14:08,788:WARNING:
2023-04-29 18:14:08,788:WARNING:Processing:  40%|4| 31/77 [01:48<02:3
2023-04-29 18:14:08,788:WARNING:[A
2023-04-29 18:14:08,788:INFO:Defining folds
2023-04-29 18:14:08,788:INFO:Declaring metric variables
2023-04-29 18:14:08,788:INFO:Importing untrained model
2023-04-29 18:14:08,789:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:14:08,789:INFO:Starting cross validation
2023-04-29 18:14:08,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:14,573:INFO:Calculating mean and std
2023-04-29 18:14:14,574:WARNING:Processing:  12%|1| 9/77 [00:37<05:47
2023-04-29 18:14:14,574:INFO:Creating metrics dataframe
2023-04-29 18:14:15,236:WARNING:Processing:  13%|1| 10/77 [00:37<04:3
2023-04-29 18:14:15,236:INFO:Uploading results into container
2023-04-29 18:14:15,237:INFO:Uploading model into container now
2023-04-29 18:14:15,237:INFO:_master_model_container: 2
2023-04-29 18:14:15,238:INFO:_display_container: 2
2023-04-29 18:14:15,238:INFO:Lasso(random_state=6697)
2023-04-29 18:14:15,238:INFO:create_model() successfully completed......................................
2023-04-29 18:14:15,327:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:15,327:INFO:Creating metrics dataframe
2023-04-29 18:14:15,333:INFO:Initializing Ridge Regression
2023-04-29 18:14:15,333:INFO:Total runtime is 0.6323892315228781 minutes
2023-04-29 18:14:15,333:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:15,333:INFO:Initializing create_model()
2023-04-29 18:14:15,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FC53E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:15,333:INFO:Checking exceptions
2023-04-29 18:14:15,334:INFO:Importing libraries
2023-04-29 18:14:15,334:INFO:Copying training dataset
2023-04-29 18:14:15,338:WARNING:Processing:  14%|1| 11/77 [00:37<03:2
2023-04-29 18:14:15,338:INFO:Defining folds
2023-04-29 18:14:15,339:INFO:Declaring metric variables
2023-04-29 18:14:15,339:INFO:Importing untrained model
2023-04-29 18:14:15,339:INFO:Ridge Regression Imported successfully
2023-04-29 18:14:15,340:INFO:Starting cross validation
2023-04-29 18:14:15,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:20,876:INFO:Calculating mean and std
2023-04-29 18:14:20,877:WARNING:
2023-04-29 18:14:20,877:WARNING:
2023-04-29 18:14:20,877:WARNING:Processing:  32%|3| 25/77 [01:42<04:5
2023-04-29 18:14:20,877:WARNING:[A[A
2023-04-29 18:14:20,877:INFO:Creating metrics dataframe
2023-04-29 18:14:21,564:WARNING:
2023-04-29 18:14:21,564:WARNING:
2023-04-29 18:14:21,564:WARNING:Processing:  34%|3| 26/77 [01:43<03:5
2023-04-29 18:14:21,564:WARNING:[A[A
2023-04-29 18:14:21,564:INFO:Uploading results into container
2023-04-29 18:14:21,565:INFO:Uploading model into container now
2023-04-29 18:14:21,565:INFO:_master_model_container: 6
2023-04-29 18:14:21,565:INFO:_display_container: 2
2023-04-29 18:14:21,566:INFO:LassoLars(random_state=8496)
2023-04-29 18:14:21,566:INFO:create_model() successfully completed......................................
2023-04-29 18:14:21,655:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:21,656:INFO:Creating metrics dataframe
2023-04-29 18:14:21,660:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:14:21,660:INFO:Total runtime is 1.7203816294670105 minutes
2023-04-29 18:14:21,660:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:21,661:INFO:Initializing create_model()
2023-04-29 18:14:21,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:21,661:INFO:Checking exceptions
2023-04-29 18:14:21,661:INFO:Importing libraries
2023-04-29 18:14:21,661:INFO:Copying training dataset
2023-04-29 18:14:21,665:WARNING:
2023-04-29 18:14:21,665:WARNING:
2023-04-29 18:14:21,665:WARNING:Processing:  35%|3| 27/77 [01:43<02:5
2023-04-29 18:14:21,665:WARNING:[A[A
2023-04-29 18:14:21,665:INFO:Defining folds
2023-04-29 18:14:21,665:INFO:Declaring metric variables
2023-04-29 18:14:21,666:INFO:Importing untrained model
2023-04-29 18:14:21,666:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:14:21,666:INFO:Starting cross validation
2023-04-29 18:14:21,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:22,178:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,195:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,201:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,218:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,234:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,254:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,269:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:22,282:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:23,635:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:23,722:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:14:27,653:INFO:Calculating mean and std
2023-04-29 18:14:27,653:WARNING:
2023-04-29 18:14:27,654:WARNING:Processing:  43%|4| 33/77 [02:07<04:2
2023-04-29 18:14:27,654:WARNING:[A
2023-04-29 18:14:27,654:INFO:Creating metrics dataframe
2023-04-29 18:14:28,322:WARNING:
2023-04-29 18:14:28,322:WARNING:Processing:  44%|4| 34/77 [02:07<03:2
2023-04-29 18:14:28,322:WARNING:[A
2023-04-29 18:14:28,322:INFO:Uploading results into container
2023-04-29 18:14:28,323:INFO:Uploading model into container now
2023-04-29 18:14:28,323:INFO:_master_model_container: 8
2023-04-29 18:14:28,323:INFO:_display_container: 2
2023-04-29 18:14:28,324:INFO:BayesianRidge()
2023-04-29 18:14:28,324:INFO:create_model() successfully completed......................................
2023-04-29 18:14:28,416:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:28,417:INFO:Creating metrics dataframe
2023-04-29 18:14:28,421:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:14:28,422:INFO:Total runtime is 2.1323251922925315 minutes
2023-04-29 18:14:28,422:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:28,422:INFO:Initializing create_model()
2023-04-29 18:14:28,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:28,422:INFO:Checking exceptions
2023-04-29 18:14:28,422:INFO:Importing libraries
2023-04-29 18:14:28,422:INFO:Copying training dataset
2023-04-29 18:14:28,425:WARNING:
2023-04-29 18:14:28,425:WARNING:Processing:  45%|4| 35/77 [02:07<02:3
2023-04-29 18:14:28,425:WARNING:[A
2023-04-29 18:14:28,425:INFO:Defining folds
2023-04-29 18:14:28,425:INFO:Declaring metric variables
2023-04-29 18:14:28,426:INFO:Importing untrained model
2023-04-29 18:14:28,426:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:14:28,426:INFO:Starting cross validation
2023-04-29 18:14:28,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:33,233:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:14:33,233:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:14:33,233:INFO:Data columns (total 8 columns):
2023-04-29 18:14:33,233:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:14:33,234:INFO:---  ------          --------------  -----  
2023-04-29 18:14:33,234:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:14:33,234:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:14:33,234:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:14:33,234:INFO:memory usage: 79.8 KB
2023-04-29 18:14:33,957:INFO:PyCaret RegressionExperiment
2023-04-29 18:14:33,958:INFO:Logging name: reg-default-name
2023-04-29 18:14:33,958:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:14:33,958:INFO:version 3.0.0
2023-04-29 18:14:33,958:INFO:Initializing setup()
2023-04-29 18:14:33,958:INFO:self.USI: b72f
2023-04-29 18:14:33,958:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:14:33,958:INFO:Checking environment
2023-04-29 18:14:33,958:INFO:python_version: 3.9.13
2023-04-29 18:14:33,958:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:14:33,958:INFO:machine: AMD64
2023-04-29 18:14:33,958:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:14:33,959:INFO:Memory: svmem(total=16935899136, available=5393739776, percent=68.2, used=11542159360, free=5393739776)
2023-04-29 18:14:33,959:INFO:Physical Core: 4
2023-04-29 18:14:33,959:INFO:Logical Core: 8
2023-04-29 18:14:33,959:INFO:Checking libraries
2023-04-29 18:14:33,959:INFO:System:
2023-04-29 18:14:33,959:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:14:33,959:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:14:33,959:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:14:33,960:INFO:PyCaret required dependencies:
2023-04-29 18:14:33,960:INFO:                 pip: 22.2.2
2023-04-29 18:14:33,960:INFO:          setuptools: 63.4.1
2023-04-29 18:14:33,960:INFO:             pycaret: 3.0.0
2023-04-29 18:14:33,960:INFO:             IPython: 7.31.1
2023-04-29 18:14:33,960:INFO:          ipywidgets: 7.6.5
2023-04-29 18:14:33,960:INFO:                tqdm: 4.64.1
2023-04-29 18:14:33,960:INFO:               numpy: 1.21.5
2023-04-29 18:14:33,960:INFO:              pandas: 1.4.4
2023-04-29 18:14:33,960:INFO:              jinja2: 2.11.3
2023-04-29 18:14:33,960:INFO:               scipy: 1.9.1
2023-04-29 18:14:33,961:INFO:              joblib: 1.2.0
2023-04-29 18:14:33,961:INFO:             sklearn: 1.0.2
2023-04-29 18:14:33,961:INFO:                pyod: 1.0.9
2023-04-29 18:14:33,961:INFO:            imblearn: 0.10.1
2023-04-29 18:14:33,961:INFO:   category_encoders: 2.6.0
2023-04-29 18:14:33,961:INFO:            lightgbm: 3.3.5
2023-04-29 18:14:33,961:INFO:               numba: 0.55.1
2023-04-29 18:14:33,962:INFO:            requests: 2.28.1
2023-04-29 18:14:33,962:INFO:          matplotlib: 3.5.2
2023-04-29 18:14:33,962:INFO:          scikitplot: 0.3.7
2023-04-29 18:14:33,962:INFO:         yellowbrick: 1.5
2023-04-29 18:14:33,962:INFO:              plotly: 5.9.0
2023-04-29 18:14:33,962:INFO:             kaleido: 0.2.1
2023-04-29 18:14:33,962:INFO:         statsmodels: 0.13.2
2023-04-29 18:14:33,962:INFO:              sktime: 0.17.1
2023-04-29 18:14:33,962:INFO:               tbats: 1.1.2
2023-04-29 18:14:33,962:INFO:            pmdarima: 2.0.3
2023-04-29 18:14:33,962:INFO:              psutil: 5.9.0
2023-04-29 18:14:33,962:INFO:PyCaret optional dependencies:
2023-04-29 18:14:33,962:INFO:                shap: 0.41.0
2023-04-29 18:14:33,962:INFO:           interpret: Not installed
2023-04-29 18:14:33,962:INFO:                umap: Not installed
2023-04-29 18:14:33,962:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:14:33,962:INFO:  explainerdashboard: Not installed
2023-04-29 18:14:33,962:INFO:             autoviz: Not installed
2023-04-29 18:14:33,963:INFO:           fairlearn: Not installed
2023-04-29 18:14:33,963:INFO:             xgboost: Not installed
2023-04-29 18:14:33,963:INFO:            catboost: Not installed
2023-04-29 18:14:33,963:INFO:              kmodes: Not installed
2023-04-29 18:14:33,963:INFO:             mlxtend: Not installed
2023-04-29 18:14:33,963:INFO:       statsforecast: Not installed
2023-04-29 18:14:33,963:INFO:        tune_sklearn: Not installed
2023-04-29 18:14:33,963:INFO:                 ray: Not installed
2023-04-29 18:14:33,963:INFO:            hyperopt: Not installed
2023-04-29 18:14:33,963:INFO:              optuna: Not installed
2023-04-29 18:14:33,963:INFO:               skopt: Not installed
2023-04-29 18:14:33,963:INFO:              mlflow: 2.2.1
2023-04-29 18:14:33,963:INFO:              gradio: Not installed
2023-04-29 18:14:33,963:INFO:             fastapi: Not installed
2023-04-29 18:14:33,963:INFO:             uvicorn: Not installed
2023-04-29 18:14:33,963:INFO:              m2cgen: Not installed
2023-04-29 18:14:33,963:INFO:           evidently: Not installed
2023-04-29 18:14:33,963:INFO:               fugue: Not installed
2023-04-29 18:14:33,963:INFO:           streamlit: 1.21.0
2023-04-29 18:14:33,963:INFO:             prophet: Not installed
2023-04-29 18:14:33,963:INFO:None
2023-04-29 18:14:33,964:INFO:Set up data.
2023-04-29 18:14:33,967:INFO:Set up train/test split.
2023-04-29 18:14:33,971:INFO:Set up index.
2023-04-29 18:14:33,971:INFO:Set up folding strategy.
2023-04-29 18:14:33,971:INFO:Assigning column types.
2023-04-29 18:14:33,974:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:14:33,974:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:33,980:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:33,985:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,115:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,120:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,126:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,250:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:14:34,256:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,262:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,388:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,395:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,514:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:14:34,524:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,764:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:14:34,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:34,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:34,964:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:35,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:35,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,024:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:14:35,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:35,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:35,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,273:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:14:35,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,520:INFO:Preparing preprocessing pipeline...
2023-04-29 18:14:35,520:INFO:Set up simple imputation.
2023-04-29 18:14:35,521:INFO:Set up column name cleaning.
2023-04-29 18:14:35,542:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:14:35,547:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:14:35,547:INFO:Creating final display dataframe.
2023-04-29 18:14:35,615:INFO:Setup _display_container:                     Description             Value
0                    Session id               862
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b72f
2023-04-29 18:14:35,616:INFO:                    Description             Value
2023-04-29 18:14:35,617:INFO:0                    Session id               862
2023-04-29 18:14:35,617:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:14:35,617:INFO:2                   Target type        Regression
2023-04-29 18:14:35,617:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:14:35,617:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:14:35,617:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:14:35,617:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:14:35,617:INFO:7              Numeric features                 7
2023-04-29 18:14:35,617:INFO:8                    Preprocess              True
2023-04-29 18:14:35,617:INFO:9               Imputation type            simple
2023-04-29 18:14:35,617:INFO:10           Numeric imputation              mean
2023-04-29 18:14:35,617:INFO:11       Categorical imputation              mode
2023-04-29 18:14:35,617:INFO:12               Fold Generator             KFold
2023-04-29 18:14:35,617:INFO:13                  Fold Number                10
2023-04-29 18:14:35,617:INFO:14                     CPU Jobs                -1
2023-04-29 18:14:35,617:INFO:15                      Use GPU             False
2023-04-29 18:14:35,617:INFO:16               Log Experiment             False
2023-04-29 18:14:35,617:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:14:35,617:INFO:18                          USI              b72f
2023-04-29 18:14:35,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:35,857:INFO:setup() successfully completed in 2.61s...............
2023-04-29 18:14:35,863:INFO:Initializing compare_models()
2023-04-29 18:14:35,864:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EE70A90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EE70A90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:14:35,864:INFO:Checking exceptions
2023-04-29 18:14:35,866:INFO:Preparing display monitor
2023-04-29 18:14:35,869:WARNING:
2023-04-29 18:14:35,869:WARNING:
2023-04-29 18:14:35,869:WARNING:
2023-04-29 18:14:35,869:WARNING:Processing:   0%| | 0/77 [00:00<?, ?i
2023-04-29 18:14:35,869:WARNING:[A[A[A
2023-04-29 18:14:35,870:INFO:Initializing Linear Regression
2023-04-29 18:14:35,870:INFO:Total runtime is 0.0 minutes
2023-04-29 18:14:35,870:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:35,870:INFO:Initializing create_model()
2023-04-29 18:14:35,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EE70A90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F091E80>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:35,870:INFO:Checking exceptions
2023-04-29 18:14:35,871:INFO:Importing libraries
2023-04-29 18:14:35,871:INFO:Copying training dataset
2023-04-29 18:14:35,874:INFO:Defining folds
2023-04-29 18:14:35,875:INFO:Declaring metric variables
2023-04-29 18:14:35,875:INFO:Importing untrained model
2023-04-29 18:14:35,876:INFO:Linear Regression Imported successfully
2023-04-29 18:14:35,877:INFO:Starting cross validation
2023-04-29 18:14:35,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:37,631:INFO:Calculating mean and std
2023-04-29 18:14:37,631:WARNING:Processing:  17%|1| 13/77 [01:00<06:5
2023-04-29 18:14:37,631:INFO:Creating metrics dataframe
2023-04-29 18:14:38,978:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:14:38,978:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:14:38,978:INFO:Data columns (total 8 columns):
2023-04-29 18:14:38,978:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:14:38,978:INFO:---  ------          --------------  -----  
2023-04-29 18:14:38,978:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:14:38,978:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:14:38,979:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:14:38,979:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:14:38,979:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:14:38,979:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:14:38,979:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:14:38,979:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:14:38,979:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:14:38,979:INFO:memory usage: 79.8 KB
2023-04-29 18:14:39,195:WARNING:Processing:  18%|1| 14/77 [01:01<05:3
2023-04-29 18:14:39,195:INFO:Uploading results into container
2023-04-29 18:14:39,196:INFO:Uploading model into container now
2023-04-29 18:14:39,197:INFO:_master_model_container: 3
2023-04-29 18:14:39,197:INFO:_display_container: 2
2023-04-29 18:14:39,197:INFO:Ridge(random_state=6697)
2023-04-29 18:14:39,198:INFO:create_model() successfully completed......................................
2023-04-29 18:14:39,316:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:39,316:INFO:Creating metrics dataframe
2023-04-29 18:14:39,321:INFO:Initializing Elastic Net
2023-04-29 18:14:39,321:INFO:Total runtime is 1.0321860551834108 minutes
2023-04-29 18:14:39,321:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:39,321:INFO:Initializing create_model()
2023-04-29 18:14:39,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FC53E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:39,321:INFO:Checking exceptions
2023-04-29 18:14:39,322:INFO:Importing libraries
2023-04-29 18:14:39,322:INFO:Copying training dataset
2023-04-29 18:14:39,327:WARNING:Processing:  19%|1| 15/77 [01:01<04:1
2023-04-29 18:14:39,327:INFO:Defining folds
2023-04-29 18:14:39,327:INFO:Declaring metric variables
2023-04-29 18:14:39,328:INFO:Importing untrained model
2023-04-29 18:14:39,328:INFO:Elastic Net Imported successfully
2023-04-29 18:14:39,328:INFO:Starting cross validation
2023-04-29 18:14:39,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:40,278:INFO:PyCaret RegressionExperiment
2023-04-29 18:14:40,279:INFO:Logging name: reg-default-name
2023-04-29 18:14:40,279:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:14:40,279:INFO:version 3.0.0
2023-04-29 18:14:40,279:INFO:Initializing setup()
2023-04-29 18:14:40,279:INFO:self.USI: 8fca
2023-04-29 18:14:40,279:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:14:40,279:INFO:Checking environment
2023-04-29 18:14:40,279:INFO:python_version: 3.9.13
2023-04-29 18:14:40,279:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:14:40,279:INFO:machine: AMD64
2023-04-29 18:14:40,279:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:14:40,279:INFO:Memory: svmem(total=16935899136, available=5342298112, percent=68.5, used=11593601024, free=5342298112)
2023-04-29 18:14:40,279:INFO:Physical Core: 4
2023-04-29 18:14:40,279:INFO:Logical Core: 8
2023-04-29 18:14:40,279:INFO:Checking libraries
2023-04-29 18:14:40,280:INFO:System:
2023-04-29 18:14:40,280:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:14:40,280:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:14:40,280:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:14:40,280:INFO:PyCaret required dependencies:
2023-04-29 18:14:40,280:INFO:                 pip: 22.2.2
2023-04-29 18:14:40,280:INFO:          setuptools: 63.4.1
2023-04-29 18:14:40,280:INFO:             pycaret: 3.0.0
2023-04-29 18:14:40,280:INFO:             IPython: 7.31.1
2023-04-29 18:14:40,280:INFO:          ipywidgets: 7.6.5
2023-04-29 18:14:40,280:INFO:                tqdm: 4.64.1
2023-04-29 18:14:40,280:INFO:               numpy: 1.21.5
2023-04-29 18:14:40,280:INFO:              pandas: 1.4.4
2023-04-29 18:14:40,280:INFO:              jinja2: 2.11.3
2023-04-29 18:14:40,280:INFO:               scipy: 1.9.1
2023-04-29 18:14:40,280:INFO:              joblib: 1.2.0
2023-04-29 18:14:40,280:INFO:             sklearn: 1.0.2
2023-04-29 18:14:40,280:INFO:                pyod: 1.0.9
2023-04-29 18:14:40,281:INFO:            imblearn: 0.10.1
2023-04-29 18:14:40,281:INFO:   category_encoders: 2.6.0
2023-04-29 18:14:40,281:INFO:            lightgbm: 3.3.5
2023-04-29 18:14:40,281:INFO:               numba: 0.55.1
2023-04-29 18:14:40,281:INFO:            requests: 2.28.1
2023-04-29 18:14:40,281:INFO:          matplotlib: 3.5.2
2023-04-29 18:14:40,281:INFO:          scikitplot: 0.3.7
2023-04-29 18:14:40,281:INFO:         yellowbrick: 1.5
2023-04-29 18:14:40,281:INFO:              plotly: 5.9.0
2023-04-29 18:14:40,281:INFO:             kaleido: 0.2.1
2023-04-29 18:14:40,281:INFO:         statsmodels: 0.13.2
2023-04-29 18:14:40,281:INFO:              sktime: 0.17.1
2023-04-29 18:14:40,281:INFO:               tbats: 1.1.2
2023-04-29 18:14:40,281:INFO:            pmdarima: 2.0.3
2023-04-29 18:14:40,281:INFO:              psutil: 5.9.0
2023-04-29 18:14:40,281:INFO:PyCaret optional dependencies:
2023-04-29 18:14:40,282:INFO:                shap: 0.41.0
2023-04-29 18:14:40,282:INFO:           interpret: Not installed
2023-04-29 18:14:40,282:INFO:                umap: Not installed
2023-04-29 18:14:40,282:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:14:40,282:INFO:  explainerdashboard: Not installed
2023-04-29 18:14:40,282:INFO:             autoviz: Not installed
2023-04-29 18:14:40,282:INFO:           fairlearn: Not installed
2023-04-29 18:14:40,282:INFO:             xgboost: Not installed
2023-04-29 18:14:40,282:INFO:            catboost: Not installed
2023-04-29 18:14:40,282:INFO:              kmodes: Not installed
2023-04-29 18:14:40,282:INFO:             mlxtend: Not installed
2023-04-29 18:14:40,282:INFO:       statsforecast: Not installed
2023-04-29 18:14:40,282:INFO:        tune_sklearn: Not installed
2023-04-29 18:14:40,282:INFO:                 ray: Not installed
2023-04-29 18:14:40,282:INFO:            hyperopt: Not installed
2023-04-29 18:14:40,282:INFO:              optuna: Not installed
2023-04-29 18:14:40,282:INFO:               skopt: Not installed
2023-04-29 18:14:40,282:INFO:              mlflow: 2.2.1
2023-04-29 18:14:40,282:INFO:              gradio: Not installed
2023-04-29 18:14:40,282:INFO:             fastapi: Not installed
2023-04-29 18:14:40,283:INFO:             uvicorn: Not installed
2023-04-29 18:14:40,283:INFO:              m2cgen: Not installed
2023-04-29 18:14:40,283:INFO:           evidently: Not installed
2023-04-29 18:14:40,283:INFO:               fugue: Not installed
2023-04-29 18:14:40,283:INFO:           streamlit: 1.21.0
2023-04-29 18:14:40,283:INFO:             prophet: Not installed
2023-04-29 18:14:40,283:INFO:None
2023-04-29 18:14:40,283:INFO:Set up data.
2023-04-29 18:14:40,287:INFO:Set up train/test split.
2023-04-29 18:14:40,290:INFO:Set up index.
2023-04-29 18:14:40,290:INFO:Set up folding strategy.
2023-04-29 18:14:40,290:INFO:Assigning column types.
2023-04-29 18:14:40,293:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:14:40,293:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,299:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,304:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,372:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,421:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,426:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,543:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:14:40,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:40,819:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:14:40,844:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:40,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,228:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:14:41,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,542:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:14:41,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:41,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,797:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:14:41,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:41,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,109:INFO:Preparing preprocessing pipeline...
2023-04-29 18:14:42,109:INFO:Set up simple imputation.
2023-04-29 18:14:42,110:INFO:Set up column name cleaning.
2023-04-29 18:14:42,161:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:14:42,167:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:14:42,167:INFO:Creating final display dataframe.
2023-04-29 18:14:42,307:INFO:Setup _display_container:                     Description             Value
0                    Session id              5868
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8fca
2023-04-29 18:14:42,309:INFO:                    Description             Value
2023-04-29 18:14:42,309:INFO:0                    Session id              5868
2023-04-29 18:14:42,309:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:14:42,309:INFO:2                   Target type        Regression
2023-04-29 18:14:42,309:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:14:42,310:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:14:42,310:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:14:42,310:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:14:42,311:INFO:7              Numeric features                 7
2023-04-29 18:14:42,311:INFO:8                    Preprocess              True
2023-04-29 18:14:42,311:INFO:9               Imputation type            simple
2023-04-29 18:14:42,311:INFO:10           Numeric imputation              mean
2023-04-29 18:14:42,311:INFO:11       Categorical imputation              mode
2023-04-29 18:14:42,311:INFO:12               Fold Generator             KFold
2023-04-29 18:14:42,311:INFO:13                  Fold Number                10
2023-04-29 18:14:42,311:INFO:14                     CPU Jobs                -1
2023-04-29 18:14:42,311:INFO:15                      Use GPU             False
2023-04-29 18:14:42,311:INFO:16               Log Experiment             False
2023-04-29 18:14:42,312:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:14:42,312:INFO:18                          USI              8fca
2023-04-29 18:14:42,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:42,567:INFO:setup() successfully completed in 3.58s...............
2023-04-29 18:14:42,816:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:14:42,817:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:14:42,817:INFO:Data columns (total 8 columns):
2023-04-29 18:14:42,817:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:14:42,817:INFO:---  ------          --------------  -----  
2023-04-29 18:14:42,817:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:14:42,817:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:14:42,817:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:14:42,817:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:14:42,817:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:14:42,817:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:14:42,818:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:14:42,818:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:14:42,818:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:14:42,818:INFO:memory usage: 79.8 KB
2023-04-29 18:14:44,529:INFO:PyCaret RegressionExperiment
2023-04-29 18:14:44,530:INFO:Logging name: reg-default-name
2023-04-29 18:14:44,530:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:14:44,530:INFO:version 3.0.0
2023-04-29 18:14:44,530:INFO:Initializing setup()
2023-04-29 18:14:44,530:INFO:self.USI: 1308
2023-04-29 18:14:44,530:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:14:44,530:INFO:Checking environment
2023-04-29 18:14:44,530:INFO:python_version: 3.9.13
2023-04-29 18:14:44,530:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:14:44,530:INFO:machine: AMD64
2023-04-29 18:14:44,530:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:14:44,531:INFO:Memory: svmem(total=16935899136, available=5315510272, percent=68.6, used=11620388864, free=5315510272)
2023-04-29 18:14:44,531:INFO:Physical Core: 4
2023-04-29 18:14:44,531:INFO:Logical Core: 8
2023-04-29 18:14:44,531:INFO:Checking libraries
2023-04-29 18:14:44,531:INFO:System:
2023-04-29 18:14:44,531:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:14:44,531:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:14:44,531:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:14:44,531:INFO:PyCaret required dependencies:
2023-04-29 18:14:44,531:INFO:                 pip: 22.2.2
2023-04-29 18:14:44,531:INFO:          setuptools: 63.4.1
2023-04-29 18:14:44,531:INFO:             pycaret: 3.0.0
2023-04-29 18:14:44,532:INFO:             IPython: 7.31.1
2023-04-29 18:14:44,532:INFO:          ipywidgets: 7.6.5
2023-04-29 18:14:44,532:INFO:                tqdm: 4.64.1
2023-04-29 18:14:44,532:INFO:               numpy: 1.21.5
2023-04-29 18:14:44,532:INFO:              pandas: 1.4.4
2023-04-29 18:14:44,532:INFO:              jinja2: 2.11.3
2023-04-29 18:14:44,532:INFO:               scipy: 1.9.1
2023-04-29 18:14:44,532:INFO:              joblib: 1.2.0
2023-04-29 18:14:44,532:INFO:             sklearn: 1.0.2
2023-04-29 18:14:44,532:INFO:                pyod: 1.0.9
2023-04-29 18:14:44,532:INFO:            imblearn: 0.10.1
2023-04-29 18:14:44,532:INFO:   category_encoders: 2.6.0
2023-04-29 18:14:44,532:INFO:            lightgbm: 3.3.5
2023-04-29 18:14:44,532:INFO:               numba: 0.55.1
2023-04-29 18:14:44,532:INFO:            requests: 2.28.1
2023-04-29 18:14:44,532:INFO:          matplotlib: 3.5.2
2023-04-29 18:14:44,532:INFO:          scikitplot: 0.3.7
2023-04-29 18:14:44,533:INFO:         yellowbrick: 1.5
2023-04-29 18:14:44,533:INFO:              plotly: 5.9.0
2023-04-29 18:14:44,533:INFO:             kaleido: 0.2.1
2023-04-29 18:14:44,533:INFO:         statsmodels: 0.13.2
2023-04-29 18:14:44,533:INFO:              sktime: 0.17.1
2023-04-29 18:14:44,533:INFO:               tbats: 1.1.2
2023-04-29 18:14:44,533:INFO:            pmdarima: 2.0.3
2023-04-29 18:14:44,533:INFO:              psutil: 5.9.0
2023-04-29 18:14:44,533:INFO:PyCaret optional dependencies:
2023-04-29 18:14:44,533:INFO:                shap: 0.41.0
2023-04-29 18:14:44,533:INFO:           interpret: Not installed
2023-04-29 18:14:44,533:INFO:                umap: Not installed
2023-04-29 18:14:44,533:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:14:44,533:INFO:  explainerdashboard: Not installed
2023-04-29 18:14:44,533:INFO:             autoviz: Not installed
2023-04-29 18:14:44,533:INFO:           fairlearn: Not installed
2023-04-29 18:14:44,533:INFO:             xgboost: Not installed
2023-04-29 18:14:44,534:INFO:            catboost: Not installed
2023-04-29 18:14:44,534:INFO:              kmodes: Not installed
2023-04-29 18:14:44,534:INFO:             mlxtend: Not installed
2023-04-29 18:14:44,534:INFO:       statsforecast: Not installed
2023-04-29 18:14:44,534:INFO:        tune_sklearn: Not installed
2023-04-29 18:14:44,534:INFO:                 ray: Not installed
2023-04-29 18:14:44,534:INFO:            hyperopt: Not installed
2023-04-29 18:14:44,534:INFO:              optuna: Not installed
2023-04-29 18:14:44,534:INFO:               skopt: Not installed
2023-04-29 18:14:44,534:INFO:              mlflow: 2.2.1
2023-04-29 18:14:44,534:INFO:              gradio: Not installed
2023-04-29 18:14:44,534:INFO:             fastapi: Not installed
2023-04-29 18:14:44,534:INFO:             uvicorn: Not installed
2023-04-29 18:14:44,534:INFO:              m2cgen: Not installed
2023-04-29 18:14:44,534:INFO:           evidently: Not installed
2023-04-29 18:14:44,534:INFO:               fugue: Not installed
2023-04-29 18:14:44,534:INFO:           streamlit: 1.21.0
2023-04-29 18:14:44,534:INFO:             prophet: Not installed
2023-04-29 18:14:44,535:INFO:None
2023-04-29 18:14:44,535:INFO:Set up data.
2023-04-29 18:14:44,540:INFO:Set up train/test split.
2023-04-29 18:14:44,543:INFO:Set up index.
2023-04-29 18:14:44,544:INFO:Set up folding strategy.
2023-04-29 18:14:44,544:INFO:Assigning column types.
2023-04-29 18:14:44,547:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:14:44,547:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,553:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,558:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:44,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:44,680:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,768:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:44,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:44,827:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:14:44,833:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,839:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:44,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:44,985:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:44,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,172:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:14:45,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,436:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:14:45,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,730:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,731:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:14:45,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:45,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:45,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:46,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,022:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:14:46,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,285:INFO:Preparing preprocessing pipeline...
2023-04-29 18:14:46,285:INFO:Set up simple imputation.
2023-04-29 18:14:46,286:INFO:Set up column name cleaning.
2023-04-29 18:14:46,320:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:14:46,330:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:14:46,330:INFO:Creating final display dataframe.
2023-04-29 18:14:46,521:INFO:Setup _display_container:                     Description             Value
0                    Session id              6020
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              1308
2023-04-29 18:14:46,524:INFO:                    Description             Value
2023-04-29 18:14:46,524:INFO:0                    Session id              6020
2023-04-29 18:14:46,524:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:14:46,524:INFO:2                   Target type        Regression
2023-04-29 18:14:46,524:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:14:46,524:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:14:46,525:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:14:46,525:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:14:46,525:INFO:7              Numeric features                 7
2023-04-29 18:14:46,525:INFO:8                    Preprocess              True
2023-04-29 18:14:46,525:INFO:9               Imputation type            simple
2023-04-29 18:14:46,525:INFO:10           Numeric imputation              mean
2023-04-29 18:14:46,526:INFO:11       Categorical imputation              mode
2023-04-29 18:14:46,526:INFO:12               Fold Generator             KFold
2023-04-29 18:14:46,526:INFO:13                  Fold Number                10
2023-04-29 18:14:46,526:INFO:14                     CPU Jobs                -1
2023-04-29 18:14:46,526:INFO:15                      Use GPU             False
2023-04-29 18:14:46,526:INFO:16               Log Experiment             False
2023-04-29 18:14:46,526:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:14:46,526:INFO:18                          USI              1308
2023-04-29 18:14:46,716:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:46,847:INFO:setup() successfully completed in 3.23s...............
2023-04-29 18:14:47,095:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:14:47,095:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:14:47,096:INFO:Data columns (total 8 columns):
2023-04-29 18:14:47,096:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:14:47,096:INFO:---  ------          --------------  -----  
2023-04-29 18:14:47,096:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:14:47,096:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:14:47,096:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:14:47,096:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:14:47,096:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:14:47,096:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:14:47,097:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:14:47,097:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:14:47,097:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:14:47,097:INFO:memory usage: 79.8 KB
2023-04-29 18:14:48,809:INFO:PyCaret RegressionExperiment
2023-04-29 18:14:48,809:INFO:Logging name: reg-default-name
2023-04-29 18:14:48,809:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:14:48,809:INFO:version 3.0.0
2023-04-29 18:14:48,809:INFO:Initializing setup()
2023-04-29 18:14:48,809:INFO:self.USI: f49d
2023-04-29 18:14:48,809:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:14:48,809:INFO:Checking environment
2023-04-29 18:14:48,809:INFO:python_version: 3.9.13
2023-04-29 18:14:48,809:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:14:48,809:INFO:machine: AMD64
2023-04-29 18:14:48,809:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:14:48,810:INFO:Memory: svmem(total=16935899136, available=5309091840, percent=68.7, used=11626807296, free=5309091840)
2023-04-29 18:14:48,810:INFO:Physical Core: 4
2023-04-29 18:14:48,811:INFO:Logical Core: 8
2023-04-29 18:14:48,811:INFO:Checking libraries
2023-04-29 18:14:48,811:INFO:System:
2023-04-29 18:14:48,811:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:14:48,811:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:14:48,811:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:14:48,811:INFO:PyCaret required dependencies:
2023-04-29 18:14:48,811:INFO:                 pip: 22.2.2
2023-04-29 18:14:48,811:INFO:          setuptools: 63.4.1
2023-04-29 18:14:48,811:INFO:             pycaret: 3.0.0
2023-04-29 18:14:48,811:INFO:             IPython: 7.31.1
2023-04-29 18:14:48,811:INFO:          ipywidgets: 7.6.5
2023-04-29 18:14:48,811:INFO:                tqdm: 4.64.1
2023-04-29 18:14:48,811:INFO:               numpy: 1.21.5
2023-04-29 18:14:48,811:INFO:              pandas: 1.4.4
2023-04-29 18:14:48,811:INFO:              jinja2: 2.11.3
2023-04-29 18:14:48,811:INFO:               scipy: 1.9.1
2023-04-29 18:14:48,811:INFO:              joblib: 1.2.0
2023-04-29 18:14:48,811:INFO:             sklearn: 1.0.2
2023-04-29 18:14:48,811:INFO:                pyod: 1.0.9
2023-04-29 18:14:48,811:INFO:            imblearn: 0.10.1
2023-04-29 18:14:48,811:INFO:   category_encoders: 2.6.0
2023-04-29 18:14:48,811:INFO:            lightgbm: 3.3.5
2023-04-29 18:14:48,811:INFO:               numba: 0.55.1
2023-04-29 18:14:48,811:INFO:            requests: 2.28.1
2023-04-29 18:14:48,811:INFO:          matplotlib: 3.5.2
2023-04-29 18:14:48,812:INFO:          scikitplot: 0.3.7
2023-04-29 18:14:48,812:INFO:         yellowbrick: 1.5
2023-04-29 18:14:48,812:INFO:              plotly: 5.9.0
2023-04-29 18:14:48,812:INFO:             kaleido: 0.2.1
2023-04-29 18:14:48,812:INFO:         statsmodels: 0.13.2
2023-04-29 18:14:48,812:INFO:              sktime: 0.17.1
2023-04-29 18:14:48,812:INFO:               tbats: 1.1.2
2023-04-29 18:14:48,812:INFO:            pmdarima: 2.0.3
2023-04-29 18:14:48,812:INFO:              psutil: 5.9.0
2023-04-29 18:14:48,812:INFO:PyCaret optional dependencies:
2023-04-29 18:14:48,812:INFO:                shap: 0.41.0
2023-04-29 18:14:48,812:INFO:           interpret: Not installed
2023-04-29 18:14:48,812:INFO:                umap: Not installed
2023-04-29 18:14:48,812:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:14:48,812:INFO:  explainerdashboard: Not installed
2023-04-29 18:14:48,812:INFO:             autoviz: Not installed
2023-04-29 18:14:48,812:INFO:           fairlearn: Not installed
2023-04-29 18:14:48,813:INFO:             xgboost: Not installed
2023-04-29 18:14:48,813:INFO:            catboost: Not installed
2023-04-29 18:14:48,813:INFO:              kmodes: Not installed
2023-04-29 18:14:48,813:INFO:             mlxtend: Not installed
2023-04-29 18:14:48,813:INFO:       statsforecast: Not installed
2023-04-29 18:14:48,813:INFO:        tune_sklearn: Not installed
2023-04-29 18:14:48,813:INFO:                 ray: Not installed
2023-04-29 18:14:48,813:INFO:            hyperopt: Not installed
2023-04-29 18:14:48,813:INFO:              optuna: Not installed
2023-04-29 18:14:48,813:INFO:               skopt: Not installed
2023-04-29 18:14:48,813:INFO:              mlflow: 2.2.1
2023-04-29 18:14:48,813:INFO:              gradio: Not installed
2023-04-29 18:14:48,813:INFO:             fastapi: Not installed
2023-04-29 18:14:48,813:INFO:             uvicorn: Not installed
2023-04-29 18:14:48,813:INFO:              m2cgen: Not installed
2023-04-29 18:14:48,813:INFO:           evidently: Not installed
2023-04-29 18:14:48,813:INFO:               fugue: Not installed
2023-04-29 18:14:48,814:INFO:           streamlit: 1.21.0
2023-04-29 18:14:48,814:INFO:             prophet: Not installed
2023-04-29 18:14:48,814:INFO:None
2023-04-29 18:14:48,814:INFO:Set up data.
2023-04-29 18:14:48,818:INFO:Set up train/test split.
2023-04-29 18:14:48,822:INFO:Set up index.
2023-04-29 18:14:48,822:INFO:Set up folding strategy.
2023-04-29 18:14:48,822:INFO:Assigning column types.
2023-04-29 18:14:48,828:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:14:48,829:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,834:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,840:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:48,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:48,987:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,992:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:48,998:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,135:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:14:49,142:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,395:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,403:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,502:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,563:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,564:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:14:49,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,716:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:49,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:49,874:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:14:49,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:50,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:50,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:50,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:50,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,178:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:14:50,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:50,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,412:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:50,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,472:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:14:50,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:50,732:INFO:Preparing preprocessing pipeline...
2023-04-29 18:14:50,732:INFO:Set up simple imputation.
2023-04-29 18:14:50,733:INFO:Set up column name cleaning.
2023-04-29 18:14:50,771:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:14:50,776:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:14:50,777:INFO:Creating final display dataframe.
2023-04-29 18:14:50,930:INFO:Setup _display_container:                     Description             Value
0                    Session id              2182
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              f49d
2023-04-29 18:14:50,933:INFO:                    Description             Value
2023-04-29 18:14:50,933:INFO:0                    Session id              2182
2023-04-29 18:14:50,933:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:14:50,933:INFO:2                   Target type        Regression
2023-04-29 18:14:50,933:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:14:50,933:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:14:50,934:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:14:50,934:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:14:50,934:INFO:7              Numeric features                 7
2023-04-29 18:14:50,934:INFO:8                    Preprocess              True
2023-04-29 18:14:50,934:INFO:9               Imputation type            simple
2023-04-29 18:14:50,934:INFO:10           Numeric imputation              mean
2023-04-29 18:14:50,934:INFO:11       Categorical imputation              mode
2023-04-29 18:14:50,934:INFO:12               Fold Generator             KFold
2023-04-29 18:14:50,934:INFO:13                  Fold Number                10
2023-04-29 18:14:50,934:INFO:14                     CPU Jobs                -1
2023-04-29 18:14:50,934:INFO:15                      Use GPU             False
2023-04-29 18:14:50,934:INFO:16               Log Experiment             False
2023-04-29 18:14:50,934:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:14:50,934:INFO:18                          USI              f49d
2023-04-29 18:14:51,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:51,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:51,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:51,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:51,212:INFO:setup() successfully completed in 3.29s...............
2023-04-29 18:14:51,495:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:14:51,495:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:14:51,495:INFO:Data columns (total 8 columns):
2023-04-29 18:14:51,495:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:14:51,495:INFO:---  ------          --------------  -----  
2023-04-29 18:14:51,495:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:14:51,495:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:14:51,495:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:14:51,495:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:14:51,495:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:14:51,496:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:14:51,496:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:14:51,496:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:14:51,496:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:14:51,496:INFO:memory usage: 79.8 KB
2023-04-29 18:14:52,994:INFO:PyCaret RegressionExperiment
2023-04-29 18:14:52,995:INFO:Logging name: reg-default-name
2023-04-29 18:14:52,995:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:14:52,995:INFO:version 3.0.0
2023-04-29 18:14:52,995:INFO:Initializing setup()
2023-04-29 18:14:52,995:INFO:self.USI: fb81
2023-04-29 18:14:52,995:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:14:52,995:INFO:Checking environment
2023-04-29 18:14:52,995:INFO:python_version: 3.9.13
2023-04-29 18:14:52,995:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:14:52,995:INFO:machine: AMD64
2023-04-29 18:14:52,995:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:14:52,996:INFO:Memory: svmem(total=16935899136, available=5278720000, percent=68.8, used=11657179136, free=5278720000)
2023-04-29 18:14:52,996:INFO:Physical Core: 4
2023-04-29 18:14:52,996:INFO:Logical Core: 8
2023-04-29 18:14:52,996:INFO:Checking libraries
2023-04-29 18:14:52,996:INFO:System:
2023-04-29 18:14:52,996:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:14:52,996:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:14:52,996:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:14:52,996:INFO:PyCaret required dependencies:
2023-04-29 18:14:52,996:INFO:                 pip: 22.2.2
2023-04-29 18:14:52,996:INFO:          setuptools: 63.4.1
2023-04-29 18:14:52,996:INFO:             pycaret: 3.0.0
2023-04-29 18:14:52,997:INFO:             IPython: 7.31.1
2023-04-29 18:14:52,997:INFO:          ipywidgets: 7.6.5
2023-04-29 18:14:52,997:INFO:                tqdm: 4.64.1
2023-04-29 18:14:52,997:INFO:               numpy: 1.21.5
2023-04-29 18:14:52,997:INFO:              pandas: 1.4.4
2023-04-29 18:14:52,997:INFO:              jinja2: 2.11.3
2023-04-29 18:14:52,997:INFO:               scipy: 1.9.1
2023-04-29 18:14:52,997:INFO:              joblib: 1.2.0
2023-04-29 18:14:52,997:INFO:             sklearn: 1.0.2
2023-04-29 18:14:52,997:INFO:                pyod: 1.0.9
2023-04-29 18:14:52,997:INFO:            imblearn: 0.10.1
2023-04-29 18:14:52,997:INFO:   category_encoders: 2.6.0
2023-04-29 18:14:52,997:INFO:            lightgbm: 3.3.5
2023-04-29 18:14:52,997:INFO:               numba: 0.55.1
2023-04-29 18:14:52,997:INFO:            requests: 2.28.1
2023-04-29 18:14:52,997:INFO:          matplotlib: 3.5.2
2023-04-29 18:14:52,997:INFO:          scikitplot: 0.3.7
2023-04-29 18:14:52,998:INFO:         yellowbrick: 1.5
2023-04-29 18:14:52,998:INFO:              plotly: 5.9.0
2023-04-29 18:14:52,998:INFO:             kaleido: 0.2.1
2023-04-29 18:14:52,998:INFO:         statsmodels: 0.13.2
2023-04-29 18:14:52,998:INFO:              sktime: 0.17.1
2023-04-29 18:14:52,998:INFO:               tbats: 1.1.2
2023-04-29 18:14:52,998:INFO:            pmdarima: 2.0.3
2023-04-29 18:14:52,998:INFO:              psutil: 5.9.0
2023-04-29 18:14:52,998:INFO:PyCaret optional dependencies:
2023-04-29 18:14:52,998:INFO:                shap: 0.41.0
2023-04-29 18:14:52,998:INFO:           interpret: Not installed
2023-04-29 18:14:52,998:INFO:                umap: Not installed
2023-04-29 18:14:52,998:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:14:52,998:INFO:  explainerdashboard: Not installed
2023-04-29 18:14:52,998:INFO:             autoviz: Not installed
2023-04-29 18:14:52,998:INFO:           fairlearn: Not installed
2023-04-29 18:14:52,998:INFO:             xgboost: Not installed
2023-04-29 18:14:52,998:INFO:            catboost: Not installed
2023-04-29 18:14:52,999:INFO:              kmodes: Not installed
2023-04-29 18:14:52,999:INFO:             mlxtend: Not installed
2023-04-29 18:14:52,999:INFO:       statsforecast: Not installed
2023-04-29 18:14:52,999:INFO:        tune_sklearn: Not installed
2023-04-29 18:14:52,999:INFO:                 ray: Not installed
2023-04-29 18:14:52,999:INFO:            hyperopt: Not installed
2023-04-29 18:14:52,999:INFO:              optuna: Not installed
2023-04-29 18:14:52,999:INFO:               skopt: Not installed
2023-04-29 18:14:52,999:INFO:              mlflow: 2.2.1
2023-04-29 18:14:52,999:INFO:              gradio: Not installed
2023-04-29 18:14:52,999:INFO:             fastapi: Not installed
2023-04-29 18:14:52,999:INFO:             uvicorn: Not installed
2023-04-29 18:14:52,999:INFO:              m2cgen: Not installed
2023-04-29 18:14:52,999:INFO:           evidently: Not installed
2023-04-29 18:14:52,999:INFO:               fugue: Not installed
2023-04-29 18:14:52,999:INFO:           streamlit: 1.21.0
2023-04-29 18:14:52,999:INFO:             prophet: Not installed
2023-04-29 18:14:52,999:INFO:None
2023-04-29 18:14:52,999:INFO:Set up data.
2023-04-29 18:14:53,005:INFO:Set up train/test split.
2023-04-29 18:14:53,008:INFO:Set up index.
2023-04-29 18:14:53,008:INFO:Set up folding strategy.
2023-04-29 18:14:53,009:INFO:Assigning column types.
2023-04-29 18:14:53,012:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:14:53,012:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,017:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,022:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,157:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,164:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,171:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,310:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:14:53,316:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,322:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,403:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,469:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,474:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,607:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:14:53,618:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,749:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,864:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:14:53,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:53,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:53,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:54,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:14:54,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,123:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:14:54,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:54,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:14:54,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,378:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:14:54,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,651:INFO:Preparing preprocessing pipeline...
2023-04-29 18:14:54,651:INFO:Set up simple imputation.
2023-04-29 18:14:54,652:INFO:Set up column name cleaning.
2023-04-29 18:14:54,677:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:14:54,681:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:14:54,681:INFO:Creating final display dataframe.
2023-04-29 18:14:54,756:INFO:Setup _display_container:                     Description             Value
0                    Session id              8745
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              fb81
2023-04-29 18:14:54,758:INFO:                    Description             Value
2023-04-29 18:14:54,758:INFO:0                    Session id              8745
2023-04-29 18:14:54,758:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:14:54,759:INFO:2                   Target type        Regression
2023-04-29 18:14:54,759:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:14:54,759:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:14:54,759:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:14:54,759:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:14:54,759:INFO:7              Numeric features                 7
2023-04-29 18:14:54,759:INFO:8                    Preprocess              True
2023-04-29 18:14:54,759:INFO:9               Imputation type            simple
2023-04-29 18:14:54,759:INFO:10           Numeric imputation              mean
2023-04-29 18:14:54,759:INFO:11       Categorical imputation              mode
2023-04-29 18:14:54,759:INFO:12               Fold Generator             KFold
2023-04-29 18:14:54,759:INFO:13                  Fold Number                10
2023-04-29 18:14:54,759:INFO:14                     CPU Jobs                -1
2023-04-29 18:14:54,759:INFO:15                      Use GPU             False
2023-04-29 18:14:54,759:INFO:16               Log Experiment             False
2023-04-29 18:14:54,759:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:14:54,759:INFO:18                          USI              fb81
2023-04-29 18:14:54,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:54,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:55,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:55,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:14:55,008:INFO:setup() successfully completed in 2.78s...............
2023-04-29 18:14:55,015:INFO:Initializing compare_models()
2023-04-29 18:14:55,015:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2FBD99A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2FBD99A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:14:55,015:INFO:Checking exceptions
2023-04-29 18:14:55,017:INFO:Preparing display monitor
2023-04-29 18:14:55,020:WARNING:
2023-04-29 18:14:55,020:WARNING:
2023-04-29 18:14:55,020:WARNING:
2023-04-29 18:14:55,020:WARNING:
2023-04-29 18:14:55,020:WARNING:Processing:   0%| | 0/77 [00:00<?, ?i
2023-04-29 18:14:55,020:WARNING:[A[A[A[A
2023-04-29 18:14:55,020:INFO:Initializing Linear Regression
2023-04-29 18:14:55,020:INFO:Total runtime is 0.0 minutes
2023-04-29 18:14:55,021:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:55,021:INFO:Initializing create_model()
2023-04-29 18:14:55,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2FBD99A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D30808D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:55,021:INFO:Checking exceptions
2023-04-29 18:14:55,021:INFO:Importing libraries
2023-04-29 18:14:55,021:INFO:Copying training dataset
2023-04-29 18:14:55,027:INFO:Defining folds
2023-04-29 18:14:55,028:INFO:Declaring metric variables
2023-04-29 18:14:55,028:INFO:Importing untrained model
2023-04-29 18:14:55,028:INFO:Linear Regression Imported successfully
2023-04-29 18:14:55,029:INFO:Starting cross validation
2023-04-29 18:14:55,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:14:56,133:INFO:Calculating mean and std
2023-04-29 18:14:56,133:WARNING:
2023-04-29 18:14:56,133:WARNING:
2023-04-29 18:14:56,134:WARNING:Processing:  38%|3| 29/77 [02:17<07:1
2023-04-29 18:14:56,134:WARNING:[A[A
2023-04-29 18:14:56,134:INFO:Creating metrics dataframe
2023-04-29 18:14:56,989:WARNING:
2023-04-29 18:14:56,990:WARNING:
2023-04-29 18:14:56,990:WARNING:Processing:  39%|3| 30/77 [02:18<05:4
2023-04-29 18:14:56,990:WARNING:[A[A
2023-04-29 18:14:56,990:INFO:Uploading results into container
2023-04-29 18:14:56,991:INFO:Uploading model into container now
2023-04-29 18:14:56,992:INFO:_master_model_container: 7
2023-04-29 18:14:56,992:INFO:_display_container: 2
2023-04-29 18:14:56,992:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:14:56,992:INFO:create_model() successfully completed......................................
2023-04-29 18:14:57,096:INFO:SubProcess create_model() end ==================================
2023-04-29 18:14:57,096:INFO:Creating metrics dataframe
2023-04-29 18:14:57,100:INFO:Initializing Bayesian Ridge
2023-04-29 18:14:57,100:INFO:Total runtime is 2.3110496918360393 minutes
2023-04-29 18:14:57,100:INFO:SubProcess create_model() called ==================================
2023-04-29 18:14:57,101:INFO:Initializing create_model()
2023-04-29 18:14:57,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:14:57,101:INFO:Checking exceptions
2023-04-29 18:14:57,101:INFO:Importing libraries
2023-04-29 18:14:57,101:INFO:Copying training dataset
2023-04-29 18:14:57,106:WARNING:
2023-04-29 18:14:57,107:WARNING:
2023-04-29 18:14:57,107:WARNING:Processing:  40%|4| 31/77 [02:18<04:1
2023-04-29 18:14:57,107:WARNING:[A[A
2023-04-29 18:14:57,107:INFO:Defining folds
2023-04-29 18:14:57,107:INFO:Declaring metric variables
2023-04-29 18:14:57,107:INFO:Importing untrained model
2023-04-29 18:14:57,108:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:14:57,108:INFO:Starting cross validation
2023-04-29 18:14:57,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:03,087:INFO:Calculating mean and std
2023-04-29 18:15:03,088:WARNING:
2023-04-29 18:15:03,090:WARNING:Processing:  48%|4| 37/77 [02:42<06:0
2023-04-29 18:15:03,090:WARNING:[A
2023-04-29 18:15:03,090:INFO:Creating metrics dataframe
2023-04-29 18:15:04,408:WARNING:
2023-04-29 18:15:04,408:WARNING:Processing:  49%|4| 38/77 [02:43<04:5
2023-04-29 18:15:04,408:WARNING:[A
2023-04-29 18:15:04,408:INFO:Uploading results into container
2023-04-29 18:15:04,409:INFO:Uploading model into container now
2023-04-29 18:15:04,410:INFO:_master_model_container: 9
2023-04-29 18:15:04,410:INFO:_display_container: 2
2023-04-29 18:15:04,410:INFO:PassiveAggressiveRegressor(random_state=2360)
2023-04-29 18:15:04,410:INFO:create_model() successfully completed......................................
2023-04-29 18:15:04,542:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:04,543:INFO:Creating metrics dataframe
2023-04-29 18:15:04,547:INFO:Initializing Huber Regressor
2023-04-29 18:15:04,547:INFO:Total runtime is 2.7344083388646445 minutes
2023-04-29 18:15:04,548:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:04,548:INFO:Initializing create_model()
2023-04-29 18:15:04,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:04,548:INFO:Checking exceptions
2023-04-29 18:15:04,548:INFO:Importing libraries
2023-04-29 18:15:04,548:INFO:Copying training dataset
2023-04-29 18:15:04,551:WARNING:
2023-04-29 18:15:04,551:WARNING:Processing:  51%|5| 39/77 [02:44<03:3
2023-04-29 18:15:04,552:WARNING:[A
2023-04-29 18:15:04,552:INFO:Defining folds
2023-04-29 18:15:04,552:INFO:Declaring metric variables
2023-04-29 18:15:04,552:INFO:Importing untrained model
2023-04-29 18:15:04,552:INFO:Huber Regressor Imported successfully
2023-04-29 18:15:04,552:INFO:Starting cross validation
2023-04-29 18:15:04,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:05,165:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:15:05,166:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:15:05,166:INFO:Data columns (total 8 columns):
2023-04-29 18:15:05,166:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:15:05,166:INFO:---  ------          --------------  -----  
2023-04-29 18:15:05,166:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:15:05,166:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:15:05,166:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:15:05,166:INFO:memory usage: 79.8 KB
2023-04-29 18:15:06,049:INFO:PyCaret RegressionExperiment
2023-04-29 18:15:06,049:INFO:Logging name: reg-default-name
2023-04-29 18:15:06,049:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:15:06,049:INFO:version 3.0.0
2023-04-29 18:15:06,050:INFO:Initializing setup()
2023-04-29 18:15:06,050:INFO:self.USI: fc0b
2023-04-29 18:15:06,050:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:15:06,050:INFO:Checking environment
2023-04-29 18:15:06,050:INFO:python_version: 3.9.13
2023-04-29 18:15:06,050:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:15:06,050:INFO:machine: AMD64
2023-04-29 18:15:06,050:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:15:06,050:INFO:Memory: svmem(total=16935899136, available=5236477952, percent=69.1, used=11699421184, free=5236477952)
2023-04-29 18:15:06,051:INFO:Physical Core: 4
2023-04-29 18:15:06,051:INFO:Logical Core: 8
2023-04-29 18:15:06,051:INFO:Checking libraries
2023-04-29 18:15:06,051:INFO:System:
2023-04-29 18:15:06,051:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:15:06,051:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:15:06,051:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:15:06,051:INFO:PyCaret required dependencies:
2023-04-29 18:15:06,051:INFO:                 pip: 22.2.2
2023-04-29 18:15:06,053:INFO:          setuptools: 63.4.1
2023-04-29 18:15:06,053:INFO:             pycaret: 3.0.0
2023-04-29 18:15:06,053:INFO:             IPython: 7.31.1
2023-04-29 18:15:06,053:INFO:          ipywidgets: 7.6.5
2023-04-29 18:15:06,053:INFO:                tqdm: 4.64.1
2023-04-29 18:15:06,053:INFO:               numpy: 1.21.5
2023-04-29 18:15:06,053:INFO:              pandas: 1.4.4
2023-04-29 18:15:06,053:INFO:              jinja2: 2.11.3
2023-04-29 18:15:06,053:INFO:               scipy: 1.9.1
2023-04-29 18:15:06,053:INFO:              joblib: 1.2.0
2023-04-29 18:15:06,053:INFO:             sklearn: 1.0.2
2023-04-29 18:15:06,053:INFO:                pyod: 1.0.9
2023-04-29 18:15:06,053:INFO:            imblearn: 0.10.1
2023-04-29 18:15:06,054:INFO:   category_encoders: 2.6.0
2023-04-29 18:15:06,054:INFO:            lightgbm: 3.3.5
2023-04-29 18:15:06,054:INFO:               numba: 0.55.1
2023-04-29 18:15:06,054:INFO:            requests: 2.28.1
2023-04-29 18:15:06,054:INFO:          matplotlib: 3.5.2
2023-04-29 18:15:06,054:INFO:          scikitplot: 0.3.7
2023-04-29 18:15:06,054:INFO:         yellowbrick: 1.5
2023-04-29 18:15:06,054:INFO:              plotly: 5.9.0
2023-04-29 18:15:06,055:INFO:             kaleido: 0.2.1
2023-04-29 18:15:06,055:INFO:         statsmodels: 0.13.2
2023-04-29 18:15:06,055:INFO:              sktime: 0.17.1
2023-04-29 18:15:06,055:INFO:               tbats: 1.1.2
2023-04-29 18:15:06,055:INFO:            pmdarima: 2.0.3
2023-04-29 18:15:06,055:INFO:              psutil: 5.9.0
2023-04-29 18:15:06,055:INFO:PyCaret optional dependencies:
2023-04-29 18:15:06,055:INFO:                shap: 0.41.0
2023-04-29 18:15:06,056:INFO:           interpret: Not installed
2023-04-29 18:15:06,056:INFO:                umap: Not installed
2023-04-29 18:15:06,056:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:15:06,056:INFO:  explainerdashboard: Not installed
2023-04-29 18:15:06,056:INFO:             autoviz: Not installed
2023-04-29 18:15:06,056:INFO:           fairlearn: Not installed
2023-04-29 18:15:06,057:INFO:             xgboost: Not installed
2023-04-29 18:15:06,057:INFO:            catboost: Not installed
2023-04-29 18:15:06,057:INFO:              kmodes: Not installed
2023-04-29 18:15:06,057:INFO:             mlxtend: Not installed
2023-04-29 18:15:06,057:INFO:       statsforecast: Not installed
2023-04-29 18:15:06,057:INFO:        tune_sklearn: Not installed
2023-04-29 18:15:06,057:INFO:                 ray: Not installed
2023-04-29 18:15:06,057:INFO:            hyperopt: Not installed
2023-04-29 18:15:06,058:INFO:              optuna: Not installed
2023-04-29 18:15:06,058:INFO:               skopt: Not installed
2023-04-29 18:15:06,058:INFO:              mlflow: 2.2.1
2023-04-29 18:15:06,058:INFO:              gradio: Not installed
2023-04-29 18:15:06,058:INFO:             fastapi: Not installed
2023-04-29 18:15:06,058:INFO:             uvicorn: Not installed
2023-04-29 18:15:06,058:INFO:              m2cgen: Not installed
2023-04-29 18:15:06,058:INFO:           evidently: Not installed
2023-04-29 18:15:06,058:INFO:               fugue: Not installed
2023-04-29 18:15:06,058:INFO:           streamlit: 1.21.0
2023-04-29 18:15:06,059:INFO:             prophet: Not installed
2023-04-29 18:15:06,059:INFO:None
2023-04-29 18:15:06,059:INFO:Set up data.
2023-04-29 18:15:06,064:INFO:Set up train/test split.
2023-04-29 18:15:06,070:INFO:Set up index.
2023-04-29 18:15:06,070:INFO:Set up folding strategy.
2023-04-29 18:15:06,070:INFO:Assigning column types.
2023-04-29 18:15:06,078:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:15:06,079:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,092:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,274:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,415:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:15:06,421:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,427:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,547:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,670:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:15:06,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,812:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:06,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:06,935:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:15:07,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:07,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:07,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:07,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:07,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,193:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:15:07,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:07,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:07,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,448:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:15:07,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,706:INFO:Preparing preprocessing pipeline...
2023-04-29 18:15:07,706:INFO:Set up simple imputation.
2023-04-29 18:15:07,707:INFO:Set up column name cleaning.
2023-04-29 18:15:07,728:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:15:07,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:15:07,732:INFO:Creating final display dataframe.
2023-04-29 18:15:07,804:INFO:Setup _display_container:                     Description             Value
0                    Session id              8436
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              fc0b
2023-04-29 18:15:07,806:INFO:                    Description             Value
2023-04-29 18:15:07,806:INFO:0                    Session id              8436
2023-04-29 18:15:07,806:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:15:07,806:INFO:2                   Target type        Regression
2023-04-29 18:15:07,806:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:15:07,806:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:15:07,806:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:15:07,806:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:15:07,806:INFO:7              Numeric features                 7
2023-04-29 18:15:07,807:INFO:8                    Preprocess              True
2023-04-29 18:15:07,807:INFO:9               Imputation type            simple
2023-04-29 18:15:07,807:INFO:10           Numeric imputation              mean
2023-04-29 18:15:07,807:INFO:11       Categorical imputation              mode
2023-04-29 18:15:07,807:INFO:12               Fold Generator             KFold
2023-04-29 18:15:07,807:INFO:13                  Fold Number                10
2023-04-29 18:15:07,807:INFO:14                     CPU Jobs                -1
2023-04-29 18:15:07,807:INFO:15                      Use GPU             False
2023-04-29 18:15:07,807:INFO:16               Log Experiment             False
2023-04-29 18:15:07,807:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:15:07,807:INFO:18                          USI              fc0b
2023-04-29 18:15:07,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:07,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:08,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:08,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:08,058:INFO:setup() successfully completed in 2.88s...............
2023-04-29 18:15:08,063:INFO:Initializing compare_models()
2023-04-29 18:15:08,063:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F2E78E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F2E78E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:15:08,063:INFO:Checking exceptions
2023-04-29 18:15:08,067:INFO:Preparing display monitor
2023-04-29 18:15:08,069:WARNING:
2023-04-29 18:15:08,069:WARNING:
2023-04-29 18:15:08,069:WARNING:
2023-04-29 18:15:08,069:WARNING:
2023-04-29 18:15:08,069:WARNING:
2023-04-29 18:15:08,069:WARNING:Processing:   0%|             | 0/77 [00:00<?, ?it/s]
2023-04-29 18:15:08,069:WARNING:[A[A[A[A[A
2023-04-29 18:15:08,070:INFO:Initializing Linear Regression
2023-04-29 18:15:08,070:INFO:Total runtime is 0.0 minutes
2023-04-29 18:15:08,070:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:08,070:INFO:Initializing create_model()
2023-04-29 18:15:08,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F2E78E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FF20C40>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:08,070:INFO:Checking exceptions
2023-04-29 18:15:08,070:INFO:Importing libraries
2023-04-29 18:15:08,071:INFO:Copying training dataset
2023-04-29 18:15:08,075:INFO:Defining folds
2023-04-29 18:15:08,075:INFO:Declaring metric variables
2023-04-29 18:15:08,076:INFO:Importing untrained model
2023-04-29 18:15:08,076:INFO:Linear Regression Imported successfully
2023-04-29 18:15:08,076:INFO:Starting cross validation
2023-04-29 18:15:08,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:10,550:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:11,112:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:11,702:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:12,205:INFO:Calculating mean and std
2023-04-29 18:15:12,205:WARNING:
2023-04-29 18:15:12,205:WARNING:
2023-04-29 18:15:12,205:WARNING:
2023-04-29 18:15:12,205:WARNING:Processing:   6%| | 5/77 [00:36<08:43
2023-04-29 18:15:12,206:WARNING:[A[A[A
2023-04-29 18:15:12,206:INFO:Creating metrics dataframe
2023-04-29 18:15:12,934:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:13,030:WARNING:
2023-04-29 18:15:13,030:WARNING:
2023-04-29 18:15:13,030:WARNING:
2023-04-29 18:15:13,030:WARNING:Processing:   8%| | 6/77 [00:37<06:54
2023-04-29 18:15:13,030:WARNING:[A[A[A
2023-04-29 18:15:13,030:INFO:Uploading results into container
2023-04-29 18:15:13,031:INFO:Uploading model into container now
2023-04-29 18:15:13,031:INFO:_master_model_container: 1
2023-04-29 18:15:13,032:INFO:_display_container: 2
2023-04-29 18:15:13,032:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:15:13,032:INFO:create_model() successfully completed......................................
2023-04-29 18:15:13,131:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:13,131:INFO:Creating metrics dataframe
2023-04-29 18:15:13,135:INFO:Initializing Lasso Regression
2023-04-29 18:15:13,135:INFO:Total runtime is 0.6210956970850626 minutes
2023-04-29 18:15:13,135:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:13,135:INFO:Initializing create_model()
2023-04-29 18:15:13,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EE70A90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F091E80>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:13,135:INFO:Checking exceptions
2023-04-29 18:15:13,135:INFO:Importing libraries
2023-04-29 18:15:13,135:INFO:Copying training dataset
2023-04-29 18:15:13,138:WARNING:
2023-04-29 18:15:13,138:WARNING:
2023-04-29 18:15:13,139:WARNING:
2023-04-29 18:15:13,139:WARNING:Processing:   9%| | 7/77 [00:37<05:11
2023-04-29 18:15:13,139:WARNING:[A[A[A
2023-04-29 18:15:13,139:INFO:Defining folds
2023-04-29 18:15:13,139:INFO:Declaring metric variables
2023-04-29 18:15:13,139:INFO:Importing untrained model
2023-04-29 18:15:13,141:INFO:Lasso Regression Imported successfully
2023-04-29 18:15:13,141:INFO:Starting cross validation
2023-04-29 18:15:13,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:13,621:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:14,329:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:14,867:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:15,437:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:15:18,237:INFO:Calculating mean and std
2023-04-29 18:15:18,238:WARNING:Processing:  22%|2| 17/77 [01:40<10:2
2023-04-29 18:15:18,238:INFO:Creating metrics dataframe
2023-04-29 18:15:19,029:WARNING:Processing:  23%|2| 18/77 [01:41<08:0
2023-04-29 18:15:19,029:INFO:Uploading results into container
2023-04-29 18:15:19,030:INFO:Uploading model into container now
2023-04-29 18:15:19,031:INFO:_master_model_container: 4
2023-04-29 18:15:19,031:INFO:_display_container: 2
2023-04-29 18:15:19,031:INFO:ElasticNet(random_state=6697)
2023-04-29 18:15:19,031:INFO:create_model() successfully completed......................................
2023-04-29 18:15:19,127:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:19,127:INFO:Creating metrics dataframe
2023-04-29 18:15:19,131:INFO:Initializing Least Angle Regression
2023-04-29 18:15:19,131:INFO:Total runtime is 1.6956883788108827 minutes
2023-04-29 18:15:19,131:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:19,131:INFO:Initializing create_model()
2023-04-29 18:15:19,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FC53E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:19,131:INFO:Checking exceptions
2023-04-29 18:15:19,131:INFO:Importing libraries
2023-04-29 18:15:19,131:INFO:Copying training dataset
2023-04-29 18:15:19,134:WARNING:Processing:  25%|2| 19/77 [01:41<06:0
2023-04-29 18:15:19,134:INFO:Defining folds
2023-04-29 18:15:19,134:INFO:Declaring metric variables
2023-04-29 18:15:19,135:INFO:Importing untrained model
2023-04-29 18:15:19,135:INFO:Least Angle Regression Imported successfully
2023-04-29 18:15:19,135:INFO:Starting cross validation
2023-04-29 18:15:19,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:24,332:INFO:Calculating mean and std
2023-04-29 18:15:24,333:WARNING:
2023-04-29 18:15:24,333:WARNING:
2023-04-29 18:15:24,333:WARNING:
2023-04-29 18:15:24,333:WARNING:
2023-04-29 18:15:24,333:WARNING:Processing:   6%| | 5/77 [00:29<07:02
2023-04-29 18:15:24,333:WARNING:[A[A[A[A
2023-04-29 18:15:24,333:INFO:Creating metrics dataframe
2023-04-29 18:15:25,095:WARNING:
2023-04-29 18:15:25,096:WARNING:
2023-04-29 18:15:25,096:WARNING:
2023-04-29 18:15:25,096:WARNING:
2023-04-29 18:15:25,096:WARNING:Processing:   8%| | 6/77 [00:30<05:35
2023-04-29 18:15:25,096:WARNING:[A[A[A[A
2023-04-29 18:15:25,096:INFO:Uploading results into container
2023-04-29 18:15:25,097:INFO:Uploading model into container now
2023-04-29 18:15:25,097:INFO:_master_model_container: 1
2023-04-29 18:15:25,097:INFO:_display_container: 2
2023-04-29 18:15:25,098:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:15:25,098:INFO:create_model() successfully completed......................................
2023-04-29 18:15:25,216:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:25,216:INFO:Creating metrics dataframe
2023-04-29 18:15:25,221:INFO:Initializing Lasso Regression
2023-04-29 18:15:25,221:INFO:Total runtime is 0.5033507386843363 minutes
2023-04-29 18:15:25,222:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:25,222:INFO:Initializing create_model()
2023-04-29 18:15:25,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2FBD99A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D30808D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:25,222:INFO:Checking exceptions
2023-04-29 18:15:25,222:INFO:Importing libraries
2023-04-29 18:15:25,222:INFO:Copying training dataset
2023-04-29 18:15:25,228:WARNING:
2023-04-29 18:15:25,228:WARNING:
2023-04-29 18:15:25,228:WARNING:
2023-04-29 18:15:25,228:WARNING:
2023-04-29 18:15:25,228:WARNING:Processing:   9%| | 7/77 [00:30<04:13
2023-04-29 18:15:25,228:WARNING:[A[A[A[A
2023-04-29 18:15:25,228:INFO:Defining folds
2023-04-29 18:15:25,229:INFO:Declaring metric variables
2023-04-29 18:15:25,229:INFO:Importing untrained model
2023-04-29 18:15:25,229:INFO:Lasso Regression Imported successfully
2023-04-29 18:15:25,230:INFO:Starting cross validation
2023-04-29 18:15:25,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:28,089:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:28,725:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:29,471:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:30,065:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:30,635:INFO:Calculating mean and std
2023-04-29 18:15:30,635:WARNING:
2023-04-29 18:15:30,635:WARNING:
2023-04-29 18:15:30,636:WARNING:Processing:  43%|4| 33/77 [02:52<07:2
2023-04-29 18:15:30,636:WARNING:[A[A
2023-04-29 18:15:30,637:INFO:Creating metrics dataframe
2023-04-29 18:15:30,664:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:31,299:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:31,444:WARNING:
2023-04-29 18:15:31,444:WARNING:
2023-04-29 18:15:31,444:WARNING:Processing:  44%|4| 34/77 [02:53<05:4
2023-04-29 18:15:31,444:WARNING:[A[A
2023-04-29 18:15:31,444:INFO:Uploading results into container
2023-04-29 18:15:31,445:INFO:Uploading model into container now
2023-04-29 18:15:31,445:INFO:_master_model_container: 8
2023-04-29 18:15:31,445:INFO:_display_container: 2
2023-04-29 18:15:31,446:INFO:BayesianRidge()
2023-04-29 18:15:31,446:INFO:create_model() successfully completed......................................
2023-04-29 18:15:31,544:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:31,545:INFO:Creating metrics dataframe
2023-04-29 18:15:31,549:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:15:31,549:INFO:Total runtime is 2.885196586449941 minutes
2023-04-29 18:15:31,549:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:31,550:INFO:Initializing create_model()
2023-04-29 18:15:31,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F5D7790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F3D91F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:31,550:INFO:Checking exceptions
2023-04-29 18:15:31,550:INFO:Importing libraries
2023-04-29 18:15:31,550:INFO:Copying training dataset
2023-04-29 18:15:31,553:WARNING:
2023-04-29 18:15:31,553:WARNING:
2023-04-29 18:15:31,554:WARNING:Processing:  45%|4| 35/77 [02:53<04:1
2023-04-29 18:15:31,554:WARNING:[A[A
2023-04-29 18:15:31,554:INFO:Defining folds
2023-04-29 18:15:31,554:INFO:Declaring metric variables
2023-04-29 18:15:31,554:INFO:Importing untrained model
2023-04-29 18:15:31,554:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:15:31,555:INFO:Starting cross validation
2023-04-29 18:15:31,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:32,073:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:32,923:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:32,992:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:15:32,993:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:15:32,993:INFO:Data columns (total 8 columns):
2023-04-29 18:15:32,993:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:15:32,993:INFO:---  ------          --------------  -----  
2023-04-29 18:15:32,993:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:15:32,993:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:15:32,993:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:15:32,993:INFO:memory usage: 79.8 KB
2023-04-29 18:15:33,849:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:33,927:INFO:PyCaret RegressionExperiment
2023-04-29 18:15:33,927:INFO:Logging name: reg-default-name
2023-04-29 18:15:33,927:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:15:33,927:INFO:version 3.0.0
2023-04-29 18:15:33,928:INFO:Initializing setup()
2023-04-29 18:15:33,928:INFO:self.USI: 0dc4
2023-04-29 18:15:33,928:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:15:33,928:INFO:Checking environment
2023-04-29 18:15:33,928:INFO:python_version: 3.9.13
2023-04-29 18:15:33,928:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:15:33,928:INFO:machine: AMD64
2023-04-29 18:15:33,929:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:15:33,929:INFO:Memory: svmem(total=16935899136, available=5323231232, percent=68.6, used=11612667904, free=5323231232)
2023-04-29 18:15:33,929:INFO:Physical Core: 4
2023-04-29 18:15:33,929:INFO:Logical Core: 8
2023-04-29 18:15:33,929:INFO:Checking libraries
2023-04-29 18:15:33,929:INFO:System:
2023-04-29 18:15:33,929:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:15:33,929:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:15:33,929:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:15:33,930:INFO:PyCaret required dependencies:
2023-04-29 18:15:33,930:INFO:                 pip: 22.2.2
2023-04-29 18:15:33,930:INFO:          setuptools: 63.4.1
2023-04-29 18:15:33,930:INFO:             pycaret: 3.0.0
2023-04-29 18:15:33,930:INFO:             IPython: 7.31.1
2023-04-29 18:15:33,930:INFO:          ipywidgets: 7.6.5
2023-04-29 18:15:33,930:INFO:                tqdm: 4.64.1
2023-04-29 18:15:33,930:INFO:               numpy: 1.21.5
2023-04-29 18:15:33,930:INFO:              pandas: 1.4.4
2023-04-29 18:15:33,930:INFO:              jinja2: 2.11.3
2023-04-29 18:15:33,930:INFO:               scipy: 1.9.1
2023-04-29 18:15:33,930:INFO:              joblib: 1.2.0
2023-04-29 18:15:33,931:INFO:             sklearn: 1.0.2
2023-04-29 18:15:33,931:INFO:                pyod: 1.0.9
2023-04-29 18:15:33,931:INFO:            imblearn: 0.10.1
2023-04-29 18:15:33,931:INFO:   category_encoders: 2.6.0
2023-04-29 18:15:33,931:INFO:            lightgbm: 3.3.5
2023-04-29 18:15:33,931:INFO:               numba: 0.55.1
2023-04-29 18:15:33,931:INFO:            requests: 2.28.1
2023-04-29 18:15:33,931:INFO:          matplotlib: 3.5.2
2023-04-29 18:15:33,931:INFO:          scikitplot: 0.3.7
2023-04-29 18:15:33,931:INFO:         yellowbrick: 1.5
2023-04-29 18:15:33,931:INFO:              plotly: 5.9.0
2023-04-29 18:15:33,931:INFO:             kaleido: 0.2.1
2023-04-29 18:15:33,931:INFO:         statsmodels: 0.13.2
2023-04-29 18:15:33,931:INFO:              sktime: 0.17.1
2023-04-29 18:15:33,931:INFO:               tbats: 1.1.2
2023-04-29 18:15:33,931:INFO:            pmdarima: 2.0.3
2023-04-29 18:15:33,931:INFO:              psutil: 5.9.0
2023-04-29 18:15:33,931:INFO:PyCaret optional dependencies:
2023-04-29 18:15:33,932:INFO:                shap: 0.41.0
2023-04-29 18:15:33,932:INFO:           interpret: Not installed
2023-04-29 18:15:33,932:INFO:                umap: Not installed
2023-04-29 18:15:33,932:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:15:33,932:INFO:  explainerdashboard: Not installed
2023-04-29 18:15:33,932:INFO:             autoviz: Not installed
2023-04-29 18:15:33,932:INFO:           fairlearn: Not installed
2023-04-29 18:15:33,932:INFO:             xgboost: Not installed
2023-04-29 18:15:33,932:INFO:            catboost: Not installed
2023-04-29 18:15:33,932:INFO:              kmodes: Not installed
2023-04-29 18:15:33,932:INFO:             mlxtend: Not installed
2023-04-29 18:15:33,932:INFO:       statsforecast: Not installed
2023-04-29 18:15:33,932:INFO:        tune_sklearn: Not installed
2023-04-29 18:15:33,932:INFO:                 ray: Not installed
2023-04-29 18:15:33,932:INFO:            hyperopt: Not installed
2023-04-29 18:15:33,932:INFO:              optuna: Not installed
2023-04-29 18:15:33,932:INFO:               skopt: Not installed
2023-04-29 18:15:33,933:INFO:              mlflow: 2.2.1
2023-04-29 18:15:33,933:INFO:              gradio: Not installed
2023-04-29 18:15:33,933:INFO:             fastapi: Not installed
2023-04-29 18:15:33,933:INFO:             uvicorn: Not installed
2023-04-29 18:15:33,933:INFO:              m2cgen: Not installed
2023-04-29 18:15:33,933:INFO:           evidently: Not installed
2023-04-29 18:15:33,933:INFO:               fugue: Not installed
2023-04-29 18:15:33,933:INFO:           streamlit: 1.21.0
2023-04-29 18:15:33,933:INFO:             prophet: Not installed
2023-04-29 18:15:33,933:INFO:None
2023-04-29 18:15:33,933:INFO:Set up data.
2023-04-29 18:15:33,941:INFO:Set up train/test split.
2023-04-29 18:15:33,944:INFO:Set up index.
2023-04-29 18:15:33,945:INFO:Set up folding strategy.
2023-04-29 18:15:33,945:INFO:Assigning column types.
2023-04-29 18:15:33,948:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:15:33,948:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:33,956:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:33,963:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,157:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,163:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,170:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,297:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:15:34,303:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,437:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,442:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,560:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:15:34,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,690:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,804:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:15:34,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:34,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:34,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:35,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:35,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,083:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:15:35,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:35,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:35,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,334:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:15:35,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,601:INFO:Preparing preprocessing pipeline...
2023-04-29 18:15:35,601:INFO:Set up simple imputation.
2023-04-29 18:15:35,602:INFO:Set up column name cleaning.
2023-04-29 18:15:35,632:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:15:35,638:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:15:35,638:INFO:Creating final display dataframe.
2023-04-29 18:15:35,740:INFO:Setup _display_container:                     Description             Value
0                    Session id              3594
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0dc4
2023-04-29 18:15:35,742:INFO:                    Description             Value
2023-04-29 18:15:35,742:INFO:0                    Session id              3594
2023-04-29 18:15:35,742:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:15:35,742:INFO:2                   Target type        Regression
2023-04-29 18:15:35,742:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:15:35,743:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:15:35,743:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:15:35,743:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:15:35,743:INFO:7              Numeric features                 7
2023-04-29 18:15:35,743:INFO:8                    Preprocess              True
2023-04-29 18:15:35,743:INFO:9               Imputation type            simple
2023-04-29 18:15:35,743:INFO:10           Numeric imputation              mean
2023-04-29 18:15:35,743:INFO:11       Categorical imputation              mode
2023-04-29 18:15:35,743:INFO:12               Fold Generator             KFold
2023-04-29 18:15:35,743:INFO:13                  Fold Number                10
2023-04-29 18:15:35,743:INFO:14                     CPU Jobs                -1
2023-04-29 18:15:35,743:INFO:15                      Use GPU             False
2023-04-29 18:15:35,744:INFO:16               Log Experiment             False
2023-04-29 18:15:35,744:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:15:35,744:INFO:18                          USI              0dc4
2023-04-29 18:15:35,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:35,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:36,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:36,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:36,049:INFO:setup() successfully completed in 3.05s...............
2023-04-29 18:15:36,054:INFO:Initializing compare_models()
2023-04-29 18:15:36,054:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D301D8190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D301D8190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:15:36,054:INFO:Checking exceptions
2023-04-29 18:15:36,055:INFO:Preparing display monitor
2023-04-29 18:15:36,059:WARNING:
2023-04-29 18:15:36,059:WARNING:
2023-04-29 18:15:36,059:WARNING:
2023-04-29 18:15:36,059:WARNING:
2023-04-29 18:15:36,060:WARNING:
2023-04-29 18:15:36,060:WARNING:
2023-04-29 18:15:36,060:WARNING:Processing:   0%|             | 0/77 [00:00<?, ?it/s]
2023-04-29 18:15:36,060:WARNING:[A[A[A[A[A[A
2023-04-29 18:15:36,061:INFO:Initializing Linear Regression
2023-04-29 18:15:36,061:INFO:Total runtime is 0.0 minutes
2023-04-29 18:15:36,061:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:36,061:INFO:Initializing create_model()
2023-04-29 18:15:36,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D301D8190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FE62730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:36,061:INFO:Checking exceptions
2023-04-29 18:15:36,061:INFO:Importing libraries
2023-04-29 18:15:36,061:INFO:Copying training dataset
2023-04-29 18:15:36,066:INFO:Defining folds
2023-04-29 18:15:36,066:INFO:Declaring metric variables
2023-04-29 18:15:36,066:INFO:Importing untrained model
2023-04-29 18:15:36,067:INFO:Linear Regression Imported successfully
2023-04-29 18:15:36,068:INFO:Starting cross validation
2023-04-29 18:15:36,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:36,538:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:15:36,538:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:15:36,539:INFO:Data columns (total 8 columns):
2023-04-29 18:15:36,539:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:15:36,539:INFO:---  ------          --------------  -----  
2023-04-29 18:15:36,539:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:15:36,539:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:15:36,539:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:15:36,539:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:15:36,540:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:15:36,540:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:15:36,540:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:15:36,540:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:15:36,540:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:15:36,540:INFO:memory usage: 79.8 KB
2023-04-29 18:15:36,888:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:15:37,423:INFO:PyCaret RegressionExperiment
2023-04-29 18:15:37,424:INFO:Logging name: reg-default-name
2023-04-29 18:15:37,424:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:15:37,424:INFO:version 3.0.0
2023-04-29 18:15:37,424:INFO:Initializing setup()
2023-04-29 18:15:37,424:INFO:self.USI: a4ee
2023-04-29 18:15:37,424:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:15:37,424:INFO:Checking environment
2023-04-29 18:15:37,424:INFO:python_version: 3.9.13
2023-04-29 18:15:37,424:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:15:37,425:INFO:machine: AMD64
2023-04-29 18:15:37,425:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:15:37,425:INFO:Memory: svmem(total=16935899136, available=5296177152, percent=68.7, used=11639721984, free=5296177152)
2023-04-29 18:15:37,425:INFO:Physical Core: 4
2023-04-29 18:15:37,425:INFO:Logical Core: 8
2023-04-29 18:15:37,425:INFO:Checking libraries
2023-04-29 18:15:37,425:INFO:System:
2023-04-29 18:15:37,425:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:15:37,425:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:15:37,425:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:15:37,425:INFO:PyCaret required dependencies:
2023-04-29 18:15:37,425:INFO:                 pip: 22.2.2
2023-04-29 18:15:37,425:INFO:          setuptools: 63.4.1
2023-04-29 18:15:37,425:INFO:             pycaret: 3.0.0
2023-04-29 18:15:37,425:INFO:             IPython: 7.31.1
2023-04-29 18:15:37,426:INFO:          ipywidgets: 7.6.5
2023-04-29 18:15:37,426:INFO:                tqdm: 4.64.1
2023-04-29 18:15:37,426:INFO:               numpy: 1.21.5
2023-04-29 18:15:37,426:INFO:              pandas: 1.4.4
2023-04-29 18:15:37,426:INFO:              jinja2: 2.11.3
2023-04-29 18:15:37,426:INFO:               scipy: 1.9.1
2023-04-29 18:15:37,426:INFO:              joblib: 1.2.0
2023-04-29 18:15:37,426:INFO:             sklearn: 1.0.2
2023-04-29 18:15:37,426:INFO:                pyod: 1.0.9
2023-04-29 18:15:37,426:INFO:            imblearn: 0.10.1
2023-04-29 18:15:37,426:INFO:   category_encoders: 2.6.0
2023-04-29 18:15:37,426:INFO:            lightgbm: 3.3.5
2023-04-29 18:15:37,426:INFO:               numba: 0.55.1
2023-04-29 18:15:37,426:INFO:            requests: 2.28.1
2023-04-29 18:15:37,426:INFO:          matplotlib: 3.5.2
2023-04-29 18:15:37,426:INFO:          scikitplot: 0.3.7
2023-04-29 18:15:37,426:INFO:         yellowbrick: 1.5
2023-04-29 18:15:37,426:INFO:              plotly: 5.9.0
2023-04-29 18:15:37,426:INFO:             kaleido: 0.2.1
2023-04-29 18:15:37,427:INFO:         statsmodels: 0.13.2
2023-04-29 18:15:37,427:INFO:              sktime: 0.17.1
2023-04-29 18:15:37,427:INFO:               tbats: 1.1.2
2023-04-29 18:15:37,427:INFO:            pmdarima: 2.0.3
2023-04-29 18:15:37,427:INFO:              psutil: 5.9.0
2023-04-29 18:15:37,427:INFO:PyCaret optional dependencies:
2023-04-29 18:15:37,427:INFO:                shap: 0.41.0
2023-04-29 18:15:37,427:INFO:           interpret: Not installed
2023-04-29 18:15:37,427:INFO:                umap: Not installed
2023-04-29 18:15:37,427:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:15:37,427:INFO:  explainerdashboard: Not installed
2023-04-29 18:15:37,427:INFO:             autoviz: Not installed
2023-04-29 18:15:37,427:INFO:           fairlearn: Not installed
2023-04-29 18:15:37,427:INFO:             xgboost: Not installed
2023-04-29 18:15:37,427:INFO:            catboost: Not installed
2023-04-29 18:15:37,427:INFO:              kmodes: Not installed
2023-04-29 18:15:37,427:INFO:             mlxtend: Not installed
2023-04-29 18:15:37,428:INFO:       statsforecast: Not installed
2023-04-29 18:15:37,428:INFO:        tune_sklearn: Not installed
2023-04-29 18:15:37,428:INFO:                 ray: Not installed
2023-04-29 18:15:37,428:INFO:            hyperopt: Not installed
2023-04-29 18:15:37,428:INFO:              optuna: Not installed
2023-04-29 18:15:37,428:INFO:               skopt: Not installed
2023-04-29 18:15:37,428:INFO:              mlflow: 2.2.1
2023-04-29 18:15:37,428:INFO:              gradio: Not installed
2023-04-29 18:15:37,428:INFO:             fastapi: Not installed
2023-04-29 18:15:37,428:INFO:             uvicorn: Not installed
2023-04-29 18:15:37,428:INFO:              m2cgen: Not installed
2023-04-29 18:15:37,428:INFO:           evidently: Not installed
2023-04-29 18:15:37,428:INFO:               fugue: Not installed
2023-04-29 18:15:37,428:INFO:           streamlit: 1.21.0
2023-04-29 18:15:37,428:INFO:             prophet: Not installed
2023-04-29 18:15:37,428:INFO:None
2023-04-29 18:15:37,428:INFO:Set up data.
2023-04-29 18:15:37,434:INFO:Set up train/test split.
2023-04-29 18:15:37,439:INFO:Set up index.
2023-04-29 18:15:37,439:INFO:Set up folding strategy.
2023-04-29 18:15:37,440:INFO:Assigning column types.
2023-04-29 18:15:37,443:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:15:37,443:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,449:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,455:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:37,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:37,586:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,592:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:37,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:37,742:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:15:37,747:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,755:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:37,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:37,958:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:37,964:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,088:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:15:38,098:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,238:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,306:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,362:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:15:38,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,618:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,619:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:15:38,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:38,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:38,871:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:15:39,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,128:INFO:Preparing preprocessing pipeline...
2023-04-29 18:15:39,128:INFO:Set up simple imputation.
2023-04-29 18:15:39,129:INFO:Set up column name cleaning.
2023-04-29 18:15:39,151:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:15:39,156:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:15:39,156:INFO:Creating final display dataframe.
2023-04-29 18:15:39,227:INFO:Setup _display_container:                     Description             Value
0                    Session id              5432
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a4ee
2023-04-29 18:15:39,229:INFO:                    Description             Value
2023-04-29 18:15:39,229:INFO:0                    Session id              5432
2023-04-29 18:15:39,229:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:15:39,229:INFO:2                   Target type        Regression
2023-04-29 18:15:39,229:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:15:39,230:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:15:39,230:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:15:39,230:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:15:39,230:INFO:7              Numeric features                 7
2023-04-29 18:15:39,230:INFO:8                    Preprocess              True
2023-04-29 18:15:39,230:INFO:9               Imputation type            simple
2023-04-29 18:15:39,230:INFO:10           Numeric imputation              mean
2023-04-29 18:15:39,230:INFO:11       Categorical imputation              mode
2023-04-29 18:15:39,230:INFO:12               Fold Generator             KFold
2023-04-29 18:15:39,230:INFO:13                  Fold Number                10
2023-04-29 18:15:39,230:INFO:14                     CPU Jobs                -1
2023-04-29 18:15:39,230:INFO:15                      Use GPU             False
2023-04-29 18:15:39,230:INFO:16               Log Experiment             False
2023-04-29 18:15:39,230:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:15:39,230:INFO:18                          USI              a4ee
2023-04-29 18:15:39,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:39,546:INFO:setup() successfully completed in 3.0s...............
2023-04-29 18:15:39,553:INFO:Initializing compare_models()
2023-04-29 18:15:39,553:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F56D250>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F56D250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:15:39,554:INFO:Checking exceptions
2023-04-29 18:15:39,558:INFO:Preparing display monitor
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:
2023-04-29 18:15:39,560:WARNING:Processing:   0%|             | 0/77 [00:00<?, ?it/s]
2023-04-29 18:15:39,560:WARNING:[A[A[A[A[A[A[A
2023-04-29 18:15:39,561:INFO:Initializing Linear Regression
2023-04-29 18:15:39,561:INFO:Total runtime is 0.0 minutes
2023-04-29 18:15:39,561:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:39,561:INFO:Initializing create_model()
2023-04-29 18:15:39,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F56D250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D25067880>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:39,561:INFO:Checking exceptions
2023-04-29 18:15:39,561:INFO:Importing libraries
2023-04-29 18:15:39,561:INFO:Copying training dataset
2023-04-29 18:15:39,564:INFO:Defining folds
2023-04-29 18:15:39,564:INFO:Declaring metric variables
2023-04-29 18:15:39,565:INFO:Importing untrained model
2023-04-29 18:15:39,565:INFO:Linear Regression Imported successfully
2023-04-29 18:15:39,565:INFO:Starting cross validation
2023-04-29 18:15:39,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:42,394:INFO:Calculating mean and std
2023-04-29 18:15:42,395:WARNING:
2023-04-29 18:15:42,395:WARNING:Processing:  53%|5| 41/77 [03:21<06:4
2023-04-29 18:15:42,395:WARNING:[A
2023-04-29 18:15:42,395:INFO:Creating metrics dataframe
2023-04-29 18:15:43,120:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 18:15:43,120:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 18:15:43,120:INFO:Data columns (total 8 columns):
2023-04-29 18:15:43,120:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 18:15:43,120:INFO:---  ------          --------------  -----  
2023-04-29 18:15:43,120:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 6   VEC             1360 non-null   float64
2023-04-29 18:15:43,121:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 18:15:43,121:INFO:dtypes: float64(7), int32(1)
2023-04-29 18:15:43,121:INFO:memory usage: 79.8 KB
2023-04-29 18:15:43,721:WARNING:
2023-04-29 18:15:43,721:WARNING:Processing:  55%|5| 42/77 [03:23<05:1
2023-04-29 18:15:43,722:WARNING:[A
2023-04-29 18:15:43,722:INFO:Uploading results into container
2023-04-29 18:15:43,722:INFO:Uploading model into container now
2023-04-29 18:15:43,723:INFO:_master_model_container: 10
2023-04-29 18:15:43,723:INFO:_display_container: 2
2023-04-29 18:15:43,723:INFO:HuberRegressor()
2023-04-29 18:15:43,723:INFO:create_model() successfully completed......................................
2023-04-29 18:15:43,847:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:43,847:INFO:Creating metrics dataframe
2023-04-29 18:15:43,855:INFO:Initializing K Neighbors Regressor
2023-04-29 18:15:43,855:INFO:Total runtime is 3.3895522554715476 minutes
2023-04-29 18:15:43,855:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:43,855:INFO:Initializing create_model()
2023-04-29 18:15:43,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EF89700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2E1267C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:43,855:INFO:Checking exceptions
2023-04-29 18:15:43,855:INFO:Importing libraries
2023-04-29 18:15:43,855:INFO:Copying training dataset
2023-04-29 18:15:43,858:WARNING:
2023-04-29 18:15:43,859:WARNING:Processing:  56%|5| 43/77 [03:23<03:4
2023-04-29 18:15:43,859:WARNING:[A
2023-04-29 18:15:43,859:INFO:Defining folds
2023-04-29 18:15:43,859:INFO:Declaring metric variables
2023-04-29 18:15:43,859:INFO:Importing untrained model
2023-04-29 18:15:43,859:INFO:K Neighbors Regressor Imported successfully
2023-04-29 18:15:43,860:INFO:Starting cross validation
2023-04-29 18:15:43,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:44,237:INFO:PyCaret RegressionExperiment
2023-04-29 18:15:44,237:INFO:Logging name: reg-default-name
2023-04-29 18:15:44,237:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:15:44,237:INFO:version 3.0.0
2023-04-29 18:15:44,237:INFO:Initializing setup()
2023-04-29 18:15:44,237:INFO:self.USI: 3c46
2023-04-29 18:15:44,237:INFO:self._variable_keys: {'seed', 'exp_id', 'X_test', 'fold_groups_param', 'memory', 'USI', 'idx', 'logging_param', 'data', 'fold_shuffle_param', 'fold_generator', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y_test', 'pipeline', 'log_plots_param', 'n_jobs_param', 'X_train', 'exp_name_log', 'transform_target_param', 'gpu_param', 'y_train', '_available_plots', 'y'}
2023-04-29 18:15:44,237:INFO:Checking environment
2023-04-29 18:15:44,239:INFO:python_version: 3.9.13
2023-04-29 18:15:44,239:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:15:44,239:INFO:machine: AMD64
2023-04-29 18:15:44,239:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:15:44,239:INFO:Memory: svmem(total=16935899136, available=5229142016, percent=69.1, used=11706757120, free=5229142016)
2023-04-29 18:15:44,239:INFO:Physical Core: 4
2023-04-29 18:15:44,239:INFO:Logical Core: 8
2023-04-29 18:15:44,239:INFO:Checking libraries
2023-04-29 18:15:44,239:INFO:System:
2023-04-29 18:15:44,239:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:15:44,239:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:15:44,239:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:15:44,239:INFO:PyCaret required dependencies:
2023-04-29 18:15:44,240:INFO:                 pip: 22.2.2
2023-04-29 18:15:44,240:INFO:          setuptools: 63.4.1
2023-04-29 18:15:44,240:INFO:             pycaret: 3.0.0
2023-04-29 18:15:44,240:INFO:             IPython: 7.31.1
2023-04-29 18:15:44,240:INFO:          ipywidgets: 7.6.5
2023-04-29 18:15:44,240:INFO:                tqdm: 4.64.1
2023-04-29 18:15:44,240:INFO:               numpy: 1.21.5
2023-04-29 18:15:44,240:INFO:              pandas: 1.4.4
2023-04-29 18:15:44,240:INFO:              jinja2: 2.11.3
2023-04-29 18:15:44,240:INFO:               scipy: 1.9.1
2023-04-29 18:15:44,240:INFO:              joblib: 1.2.0
2023-04-29 18:15:44,240:INFO:             sklearn: 1.0.2
2023-04-29 18:15:44,240:INFO:                pyod: 1.0.9
2023-04-29 18:15:44,240:INFO:            imblearn: 0.10.1
2023-04-29 18:15:44,240:INFO:   category_encoders: 2.6.0
2023-04-29 18:15:44,240:INFO:            lightgbm: 3.3.5
2023-04-29 18:15:44,240:INFO:               numba: 0.55.1
2023-04-29 18:15:44,240:INFO:            requests: 2.28.1
2023-04-29 18:15:44,240:INFO:          matplotlib: 3.5.2
2023-04-29 18:15:44,240:INFO:          scikitplot: 0.3.7
2023-04-29 18:15:44,240:INFO:         yellowbrick: 1.5
2023-04-29 18:15:44,240:INFO:              plotly: 5.9.0
2023-04-29 18:15:44,240:INFO:             kaleido: 0.2.1
2023-04-29 18:15:44,240:INFO:         statsmodels: 0.13.2
2023-04-29 18:15:44,240:INFO:              sktime: 0.17.1
2023-04-29 18:15:44,240:INFO:               tbats: 1.1.2
2023-04-29 18:15:44,240:INFO:            pmdarima: 2.0.3
2023-04-29 18:15:44,240:INFO:              psutil: 5.9.0
2023-04-29 18:15:44,240:INFO:PyCaret optional dependencies:
2023-04-29 18:15:44,240:INFO:                shap: 0.41.0
2023-04-29 18:15:44,240:INFO:           interpret: Not installed
2023-04-29 18:15:44,240:INFO:                umap: Not installed
2023-04-29 18:15:44,240:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:15:44,240:INFO:  explainerdashboard: Not installed
2023-04-29 18:15:44,240:INFO:             autoviz: Not installed
2023-04-29 18:15:44,240:INFO:           fairlearn: Not installed
2023-04-29 18:15:44,241:INFO:             xgboost: Not installed
2023-04-29 18:15:44,241:INFO:            catboost: Not installed
2023-04-29 18:15:44,241:INFO:              kmodes: Not installed
2023-04-29 18:15:44,241:INFO:             mlxtend: Not installed
2023-04-29 18:15:44,241:INFO:       statsforecast: Not installed
2023-04-29 18:15:44,241:INFO:        tune_sklearn: Not installed
2023-04-29 18:15:44,241:INFO:                 ray: Not installed
2023-04-29 18:15:44,241:INFO:            hyperopt: Not installed
2023-04-29 18:15:44,241:INFO:              optuna: Not installed
2023-04-29 18:15:44,241:INFO:               skopt: Not installed
2023-04-29 18:15:44,241:INFO:              mlflow: 2.2.1
2023-04-29 18:15:44,241:INFO:              gradio: Not installed
2023-04-29 18:15:44,241:INFO:             fastapi: Not installed
2023-04-29 18:15:44,241:INFO:             uvicorn: Not installed
2023-04-29 18:15:44,241:INFO:              m2cgen: Not installed
2023-04-29 18:15:44,241:INFO:           evidently: Not installed
2023-04-29 18:15:44,241:INFO:               fugue: Not installed
2023-04-29 18:15:44,242:INFO:           streamlit: 1.21.0
2023-04-29 18:15:44,242:INFO:             prophet: Not installed
2023-04-29 18:15:44,242:INFO:None
2023-04-29 18:15:44,242:INFO:Set up data.
2023-04-29 18:15:44,246:INFO:Set up train/test split.
2023-04-29 18:15:44,250:INFO:Set up index.
2023-04-29 18:15:44,250:INFO:Set up folding strategy.
2023-04-29 18:15:44,250:INFO:Assigning column types.
2023-04-29 18:15:44,254:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:15:44,254:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,260:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,265:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,389:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,393:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,463:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,510:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,512:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:15:44,517:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,522:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,769:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:15:44,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:44,897:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:15:44,963:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,011:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:15:45,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,269:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:15:45,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:15:45,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,529:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:15:45,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:45,790:INFO:Preparing preprocessing pipeline...
2023-04-29 18:15:45,790:INFO:Set up simple imputation.
2023-04-29 18:15:45,791:INFO:Set up column name cleaning.
2023-04-29 18:15:45,814:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:15:45,819:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:15:45,819:INFO:Creating final display dataframe.
2023-04-29 18:15:45,899:INFO:Setup _display_container:                     Description             Value
0                    Session id              2708
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3c46
2023-04-29 18:15:45,901:INFO:                    Description             Value
2023-04-29 18:15:45,901:INFO:0                    Session id              2708
2023-04-29 18:15:45,901:INFO:1                        Target    Atom.Size.Diff
2023-04-29 18:15:45,901:INFO:2                   Target type        Regression
2023-04-29 18:15:45,901:INFO:3           Original data shape         (1360, 8)
2023-04-29 18:15:45,902:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 18:15:45,902:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 18:15:45,902:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 18:15:45,902:INFO:7              Numeric features                 7
2023-04-29 18:15:45,902:INFO:8                    Preprocess              True
2023-04-29 18:15:45,902:INFO:9               Imputation type            simple
2023-04-29 18:15:45,902:INFO:10           Numeric imputation              mean
2023-04-29 18:15:45,902:INFO:11       Categorical imputation              mode
2023-04-29 18:15:45,902:INFO:12               Fold Generator             KFold
2023-04-29 18:15:45,902:INFO:13                  Fold Number                10
2023-04-29 18:15:45,902:INFO:14                     CPU Jobs                -1
2023-04-29 18:15:45,903:INFO:15                      Use GPU             False
2023-04-29 18:15:45,903:INFO:16               Log Experiment             False
2023-04-29 18:15:45,903:INFO:17              Experiment Name  reg-default-name
2023-04-29 18:15:45,903:INFO:18                          USI              3c46
2023-04-29 18:15:46,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:46,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:46,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:46,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:15:46,162:INFO:setup() successfully completed in 3.03s...............
2023-04-29 18:15:46,168:INFO:Initializing compare_models()
2023-04-29 18:15:46,168:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D30024250>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D30024250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:15:46,169:INFO:Checking exceptions
2023-04-29 18:15:46,171:INFO:Preparing display monitor
2023-04-29 18:15:46,174:WARNING:
2023-04-29 18:15:46,175:WARNING:
2023-04-29 18:15:46,175:WARNING:
2023-04-29 18:15:46,176:WARNING:
2023-04-29 18:15:46,176:WARNING:
2023-04-29 18:15:46,176:WARNING:
2023-04-29 18:15:46,176:WARNING:
2023-04-29 18:15:46,176:WARNING:
2023-04-29 18:15:46,176:WARNING: ... (more hidden) ...
2023-04-29 18:15:46,176:WARNING:[A[A[A[A[A[A[A[A
2023-04-29 18:15:46,177:INFO:Initializing Linear Regression
2023-04-29 18:15:46,177:INFO:Total runtime is 0.0 minutes
2023-04-29 18:15:46,177:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:46,177:INFO:Initializing create_model()
2023-04-29 18:15:46,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D30024250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F71FE20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:46,178:INFO:Checking exceptions
2023-04-29 18:15:46,178:INFO:Importing libraries
2023-04-29 18:15:46,178:INFO:Copying training dataset
2023-04-29 18:15:46,182:INFO:Defining folds
2023-04-29 18:15:46,182:INFO:Declaring metric variables
2023-04-29 18:15:46,183:INFO:Importing untrained model
2023-04-29 18:15:46,183:INFO:Linear Regression Imported successfully
2023-04-29 18:15:46,184:INFO:Starting cross validation
2023-04-29 18:15:46,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:51,268:INFO:Calculating mean and std
2023-04-29 18:15:51,269:WARNING:
2023-04-29 18:15:51,269:WARNING:
2023-04-29 18:15:51,269:WARNING:
2023-04-29 18:15:51,269:WARNING:
2023-04-29 18:15:51,269:WARNING:
2023-04-29 18:15:51,269:WARNING:Processing:   6%|3    | 5/77 [00:43<10:22,  8.64s/it]
2023-04-29 18:15:51,269:WARNING:[A[A[A[A[A
2023-04-29 18:15:51,269:INFO:Creating metrics dataframe
2023-04-29 18:15:52,272:WARNING:
2023-04-29 18:15:52,272:WARNING:
2023-04-29 18:15:52,272:WARNING:
2023-04-29 18:15:52,272:WARNING:
2023-04-29 18:15:52,272:WARNING:
2023-04-29 18:15:52,273:WARNING:Processing:   8%|3    | 6/77 [00:44<08:12,  6.94s/it]
2023-04-29 18:15:52,273:WARNING:[A[A[A[A[A
2023-04-29 18:15:52,273:INFO:Uploading results into container
2023-04-29 18:15:52,274:INFO:Uploading model into container now
2023-04-29 18:15:52,274:INFO:_master_model_container: 1
2023-04-29 18:15:52,274:INFO:_display_container: 2
2023-04-29 18:15:52,274:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:15:52,274:INFO:create_model() successfully completed......................................
2023-04-29 18:15:52,383:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:52,384:INFO:Creating metrics dataframe
2023-04-29 18:15:52,387:INFO:Initializing Lasso Regression
2023-04-29 18:15:52,387:INFO:Total runtime is 0.7386176625887553 minutes
2023-04-29 18:15:52,387:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:52,388:INFO:Initializing create_model()
2023-04-29 18:15:52,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F2E78E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FF20C40>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:52,388:INFO:Checking exceptions
2023-04-29 18:15:52,388:INFO:Importing libraries
2023-04-29 18:15:52,388:INFO:Copying training dataset
2023-04-29 18:15:52,392:WARNING:
2023-04-29 18:15:52,392:WARNING:
2023-04-29 18:15:52,392:WARNING:
2023-04-29 18:15:52,392:WARNING:
2023-04-29 18:15:52,392:WARNING:
2023-04-29 18:15:52,392:WARNING:Processing:   9%|4    | 7/77 [00:44<06:10,  5.30s/it]
2023-04-29 18:15:52,392:WARNING:[A[A[A[A[A
2023-04-29 18:15:52,393:INFO:Defining folds
2023-04-29 18:15:52,393:INFO:Declaring metric variables
2023-04-29 18:15:52,393:INFO:Importing untrained model
2023-04-29 18:15:52,393:INFO:Lasso Regression Imported successfully
2023-04-29 18:15:52,394:INFO:Starting cross validation
2023-04-29 18:15:52,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:15:57,858:INFO:Calculating mean and std
2023-04-29 18:15:57,858:WARNING:
2023-04-29 18:15:57,858:WARNING:
2023-04-29 18:15:57,858:WARNING:
2023-04-29 18:15:57,858:WARNING:Processing:  12%|1| 9/77 [01:21<13:19
2023-04-29 18:15:57,858:WARNING:[A[A[A
2023-04-29 18:15:57,859:INFO:Creating metrics dataframe
2023-04-29 18:15:58,644:WARNING:
2023-04-29 18:15:58,644:WARNING:
2023-04-29 18:15:58,644:WARNING:
2023-04-29 18:15:58,644:WARNING:Processing:  13%|1| 10/77 [01:22<10:2
2023-04-29 18:15:58,644:WARNING:[A[A[A
2023-04-29 18:15:58,644:INFO:Uploading results into container
2023-04-29 18:15:58,645:INFO:Uploading model into container now
2023-04-29 18:15:58,645:INFO:_master_model_container: 2
2023-04-29 18:15:58,645:INFO:_display_container: 2
2023-04-29 18:15:58,646:INFO:Lasso(random_state=862)
2023-04-29 18:15:58,646:INFO:create_model() successfully completed......................................
2023-04-29 18:15:58,765:INFO:SubProcess create_model() end ==================================
2023-04-29 18:15:58,765:INFO:Creating metrics dataframe
2023-04-29 18:15:58,770:INFO:Initializing Ridge Regression
2023-04-29 18:15:58,770:INFO:Total runtime is 1.3816667477289837 minutes
2023-04-29 18:15:58,770:INFO:SubProcess create_model() called ==================================
2023-04-29 18:15:58,770:INFO:Initializing create_model()
2023-04-29 18:15:58,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2EE70A90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2F091E80>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:15:58,770:INFO:Checking exceptions
2023-04-29 18:15:58,770:INFO:Importing libraries
2023-04-29 18:15:58,770:INFO:Copying training dataset
2023-04-29 18:15:58,774:WARNING:
2023-04-29 18:15:58,774:WARNING:
2023-04-29 18:15:58,774:WARNING:
2023-04-29 18:15:58,774:WARNING:Processing:  14%|1| 11/77 [01:22<07:4
2023-04-29 18:15:58,774:WARNING:[A[A[A
2023-04-29 18:15:58,774:INFO:Defining folds
2023-04-29 18:15:58,774:INFO:Declaring metric variables
2023-04-29 18:15:58,774:INFO:Importing untrained model
2023-04-29 18:15:58,775:INFO:Ridge Regression Imported successfully
2023-04-29 18:15:58,775:INFO:Starting cross validation
2023-04-29 18:15:58,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:16:04,178:INFO:Calculating mean and std
2023-04-29 18:16:04,179:WARNING:Processing:  27%|2| 21/77 [02:26<12:0
2023-04-29 18:16:04,179:INFO:Creating metrics dataframe
2023-04-29 18:16:04,978:WARNING:Processing:  29%|2| 22/77 [02:27<09:1
2023-04-29 18:16:04,978:INFO:Uploading results into container
2023-04-29 18:16:04,979:INFO:Uploading model into container now
2023-04-29 18:16:04,979:INFO:_master_model_container: 5
2023-04-29 18:16:04,979:INFO:_display_container: 2
2023-04-29 18:16:04,980:INFO:Lars(random_state=6697)
2023-04-29 18:16:04,980:INFO:create_model() successfully completed......................................
2023-04-29 18:16:05,086:INFO:SubProcess create_model() end ==================================
2023-04-29 18:16:05,086:INFO:Creating metrics dataframe
2023-04-29 18:16:05,090:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:16:05,090:INFO:Total runtime is 2.4616615970929465 minutes
2023-04-29 18:16:05,090:INFO:SubProcess create_model() called ==================================
2023-04-29 18:16:05,091:INFO:Initializing create_model()
2023-04-29 18:16:05,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D2F6AB4C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D2FC53E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:16:05,091:INFO:Checking exceptions
2023-04-29 18:16:05,091:INFO:Importing libraries
2023-04-29 18:16:05,091:INFO:Copying training dataset
2023-04-29 18:16:05,094:WARNING:Processing:  30%|2| 23/77 [02:27<06:5
2023-04-29 18:16:05,094:INFO:Defining folds
2023-04-29 18:16:05,094:INFO:Declaring metric variables
2023-04-29 18:16:05,095:INFO:Importing untrained model
2023-04-29 18:16:05,095:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:16:05,095:INFO:Starting cross validation
2023-04-29 18:16:05,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:16:22,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 18:16:22,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 18:16:22,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 18:16:22,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 18:16:23,382:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-29 18:16:32,536:INFO:PyCaret RegressionExperiment
2023-04-29 18:16:32,536:INFO:Logging name: reg-default-name
2023-04-29 18:16:32,536:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:16:32,536:INFO:version 3.0.0
2023-04-29 18:16:32,536:INFO:Initializing setup()
2023-04-29 18:16:32,536:INFO:self.USI: 60f4
2023-04-29 18:16:32,536:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 18:16:32,537:INFO:Checking environment
2023-04-29 18:16:32,537:INFO:python_version: 3.9.13
2023-04-29 18:16:32,537:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:16:32,537:INFO:machine: AMD64
2023-04-29 18:16:32,551:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:16:32,551:INFO:Memory: svmem(total=16935899136, available=6602760192, percent=61.0, used=10333138944, free=6602760192)
2023-04-29 18:16:32,551:INFO:Physical Core: 4
2023-04-29 18:16:32,551:INFO:Logical Core: 8
2023-04-29 18:16:32,551:INFO:Checking libraries
2023-04-29 18:16:32,551:INFO:System:
2023-04-29 18:16:32,551:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:16:32,552:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:16:32,552:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:16:32,552:INFO:PyCaret required dependencies:
2023-04-29 18:16:32,552:INFO:                 pip: 22.2.2
2023-04-29 18:16:32,552:INFO:          setuptools: 63.4.1
2023-04-29 18:16:32,552:INFO:             pycaret: 3.0.0
2023-04-29 18:16:32,552:INFO:             IPython: 7.31.1
2023-04-29 18:16:32,552:INFO:          ipywidgets: 7.6.5
2023-04-29 18:16:32,552:INFO:                tqdm: 4.64.1
2023-04-29 18:16:32,553:INFO:               numpy: 1.21.5
2023-04-29 18:16:32,553:INFO:              pandas: 1.4.4
2023-04-29 18:16:32,553:INFO:              jinja2: 2.11.3
2023-04-29 18:16:32,553:INFO:               scipy: 1.9.1
2023-04-29 18:16:32,553:INFO:              joblib: 1.2.0
2023-04-29 18:16:32,553:INFO:             sklearn: 1.0.2
2023-04-29 18:16:32,553:INFO:                pyod: 1.0.9
2023-04-29 18:16:32,553:INFO:            imblearn: 0.10.1
2023-04-29 18:16:32,553:INFO:   category_encoders: 2.6.0
2023-04-29 18:16:32,553:INFO:            lightgbm: 3.3.5
2023-04-29 18:16:32,553:INFO:               numba: 0.55.1
2023-04-29 18:16:32,553:INFO:            requests: 2.28.1
2023-04-29 18:16:32,554:INFO:          matplotlib: 3.5.2
2023-04-29 18:16:32,554:INFO:          scikitplot: 0.3.7
2023-04-29 18:16:32,554:INFO:         yellowbrick: 1.5
2023-04-29 18:16:32,554:INFO:              plotly: 5.9.0
2023-04-29 18:16:32,554:INFO:             kaleido: 0.2.1
2023-04-29 18:16:32,554:INFO:         statsmodels: 0.13.2
2023-04-29 18:16:32,554:INFO:              sktime: 0.17.1
2023-04-29 18:16:32,554:INFO:               tbats: 1.1.2
2023-04-29 18:16:32,554:INFO:            pmdarima: 2.0.3
2023-04-29 18:16:32,554:INFO:              psutil: 5.9.0
2023-04-29 18:16:32,554:INFO:PyCaret optional dependencies:
2023-04-29 18:16:32,566:INFO:                shap: 0.41.0
2023-04-29 18:16:32,566:INFO:           interpret: Not installed
2023-04-29 18:16:32,566:INFO:                umap: Not installed
2023-04-29 18:16:32,566:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:16:32,566:INFO:  explainerdashboard: Not installed
2023-04-29 18:16:32,566:INFO:             autoviz: Not installed
2023-04-29 18:16:32,566:INFO:           fairlearn: Not installed
2023-04-29 18:16:32,566:INFO:             xgboost: Not installed
2023-04-29 18:16:32,566:INFO:            catboost: Not installed
2023-04-29 18:16:32,566:INFO:              kmodes: Not installed
2023-04-29 18:16:32,566:INFO:             mlxtend: Not installed
2023-04-29 18:16:32,566:INFO:       statsforecast: Not installed
2023-04-29 18:16:32,567:INFO:        tune_sklearn: Not installed
2023-04-29 18:16:32,567:INFO:                 ray: Not installed
2023-04-29 18:16:32,567:INFO:            hyperopt: Not installed
2023-04-29 18:16:32,567:INFO:              optuna: Not installed
2023-04-29 18:16:32,567:INFO:               skopt: Not installed
2023-04-29 18:16:32,567:INFO:              mlflow: 2.2.1
2023-04-29 18:16:32,567:INFO:              gradio: Not installed
2023-04-29 18:16:32,567:INFO:             fastapi: Not installed
2023-04-29 18:16:32,567:INFO:             uvicorn: Not installed
2023-04-29 18:16:32,567:INFO:              m2cgen: Not installed
2023-04-29 18:16:32,567:INFO:           evidently: Not installed
2023-04-29 18:16:32,567:INFO:               fugue: Not installed
2023-04-29 18:16:32,567:INFO:           streamlit: 1.21.0
2023-04-29 18:16:32,567:INFO:             prophet: Not installed
2023-04-29 18:16:32,567:INFO:None
2023-04-29 18:16:32,567:INFO:Set up data.
2023-04-29 18:16:32,572:INFO:Set up train/test split.
2023-04-29 18:16:32,575:INFO:Set up index.
2023-04-29 18:16:32,575:INFO:Set up folding strategy.
2023-04-29 18:16:32,576:INFO:Assigning column types.
2023-04-29 18:16:32,579:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:16:32,579:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,584:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,589:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,653:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:32,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:32,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,777:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,785:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:32,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:32,909:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:16:32,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:16:32,922:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,101:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,105:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,168:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,217:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:16:33,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,387:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,498:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:16:33,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,724:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,783:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:16:33,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:33,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:33,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:16:34,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,073:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:16:34,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,343:INFO:Preparing preprocessing pipeline...
2023-04-29 18:16:34,343:INFO:Set up simple imputation.
2023-04-29 18:16:34,344:INFO:Set up column name cleaning.
2023-04-29 18:16:34,365:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:16:34,371:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:16:34,371:INFO:Creating final display dataframe.
2023-04-29 18:16:34,450:INFO:Setup _display_container:                     Description             Value
0                    Session id              5501
1                        Target               VEC
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              60f4
2023-04-29 18:16:34,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:16:34,985:INFO:setup() successfully completed in 3.08s...............
2023-04-29 18:16:34,993:INFO:Initializing compare_models()
2023-04-29 18:16:34,993:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:16:34,994:INFO:Checking exceptions
2023-04-29 18:16:34,999:INFO:Preparing display monitor
2023-04-29 18:16:35,009:INFO:Initializing Linear Regression
2023-04-29 18:16:35,010:INFO:Total runtime is 8.253256479899089e-06 minutes
2023-04-29 18:16:35,010:INFO:SubProcess create_model() called ==================================
2023-04-29 18:16:35,010:INFO:Initializing create_model()
2023-04-29 18:16:35,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:16:35,010:INFO:Checking exceptions
2023-04-29 18:16:35,010:INFO:Importing libraries
2023-04-29 18:16:35,010:INFO:Copying training dataset
2023-04-29 18:16:35,018:INFO:Defining folds
2023-04-29 18:16:35,018:INFO:Declaring metric variables
2023-04-29 18:16:35,018:INFO:Importing untrained model
2023-04-29 18:16:35,019:INFO:Linear Regression Imported successfully
2023-04-29 18:16:35,020:INFO:Starting cross validation
2023-04-29 18:16:35,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:16:50,618:INFO:Calculating mean and std
2023-04-29 18:16:50,620:INFO:Creating metrics dataframe
2023-04-29 18:16:52,053:INFO:Uploading results into container
2023-04-29 18:16:52,053:INFO:Uploading model into container now
2023-04-29 18:16:52,054:INFO:_master_model_container: 1
2023-04-29 18:16:52,054:INFO:_display_container: 2
2023-04-29 18:16:52,055:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:16:52,055:INFO:create_model() successfully completed......................................
2023-04-29 18:16:52,184:INFO:SubProcess create_model() end ==================================
2023-04-29 18:16:52,184:INFO:Creating metrics dataframe
2023-04-29 18:16:52,190:INFO:Initializing Lasso Regression
2023-04-29 18:16:52,190:INFO:Total runtime is 0.28634712696075443 minutes
2023-04-29 18:16:52,190:INFO:SubProcess create_model() called ==================================
2023-04-29 18:16:52,190:INFO:Initializing create_model()
2023-04-29 18:16:52,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:16:52,191:INFO:Checking exceptions
2023-04-29 18:16:52,191:INFO:Importing libraries
2023-04-29 18:16:52,191:INFO:Copying training dataset
2023-04-29 18:16:52,197:INFO:Defining folds
2023-04-29 18:16:52,198:INFO:Declaring metric variables
2023-04-29 18:16:52,198:INFO:Importing untrained model
2023-04-29 18:16:52,199:INFO:Lasso Regression Imported successfully
2023-04-29 18:16:52,199:INFO:Starting cross validation
2023-04-29 18:16:52,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:16:58,493:INFO:Calculating mean and std
2023-04-29 18:16:58,494:INFO:Creating metrics dataframe
2023-04-29 18:16:59,240:INFO:Uploading results into container
2023-04-29 18:16:59,241:INFO:Uploading model into container now
2023-04-29 18:16:59,241:INFO:_master_model_container: 2
2023-04-29 18:16:59,241:INFO:_display_container: 2
2023-04-29 18:16:59,241:INFO:Lasso(random_state=5501)
2023-04-29 18:16:59,241:INFO:create_model() successfully completed......................................
2023-04-29 18:16:59,346:INFO:SubProcess create_model() end ==================================
2023-04-29 18:16:59,346:INFO:Creating metrics dataframe
2023-04-29 18:16:59,351:INFO:Initializing Ridge Regression
2023-04-29 18:16:59,352:INFO:Total runtime is 0.4057167291641236 minutes
2023-04-29 18:16:59,352:INFO:SubProcess create_model() called ==================================
2023-04-29 18:16:59,352:INFO:Initializing create_model()
2023-04-29 18:16:59,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:16:59,352:INFO:Checking exceptions
2023-04-29 18:16:59,352:INFO:Importing libraries
2023-04-29 18:16:59,352:INFO:Copying training dataset
2023-04-29 18:16:59,356:INFO:Defining folds
2023-04-29 18:16:59,356:INFO:Declaring metric variables
2023-04-29 18:16:59,356:INFO:Importing untrained model
2023-04-29 18:16:59,358:INFO:Ridge Regression Imported successfully
2023-04-29 18:16:59,358:INFO:Starting cross validation
2023-04-29 18:16:59,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:06,157:INFO:Calculating mean and std
2023-04-29 18:17:06,159:INFO:Creating metrics dataframe
2023-04-29 18:17:07,201:INFO:Uploading results into container
2023-04-29 18:17:07,202:INFO:Uploading model into container now
2023-04-29 18:17:07,202:INFO:_master_model_container: 3
2023-04-29 18:17:07,202:INFO:_display_container: 2
2023-04-29 18:17:07,203:INFO:Ridge(random_state=5501)
2023-04-29 18:17:07,203:INFO:create_model() successfully completed......................................
2023-04-29 18:17:07,314:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:07,314:INFO:Creating metrics dataframe
2023-04-29 18:17:07,318:INFO:Initializing Elastic Net
2023-04-29 18:17:07,318:INFO:Total runtime is 0.5384814739227295 minutes
2023-04-29 18:17:07,319:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:07,319:INFO:Initializing create_model()
2023-04-29 18:17:07,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:07,319:INFO:Checking exceptions
2023-04-29 18:17:07,319:INFO:Importing libraries
2023-04-29 18:17:07,319:INFO:Copying training dataset
2023-04-29 18:17:07,323:INFO:Defining folds
2023-04-29 18:17:07,323:INFO:Declaring metric variables
2023-04-29 18:17:07,323:INFO:Importing untrained model
2023-04-29 18:17:07,324:INFO:Elastic Net Imported successfully
2023-04-29 18:17:07,324:INFO:Starting cross validation
2023-04-29 18:17:07,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:13,608:INFO:Calculating mean and std
2023-04-29 18:17:13,609:INFO:Creating metrics dataframe
2023-04-29 18:17:14,358:INFO:Uploading results into container
2023-04-29 18:17:14,359:INFO:Uploading model into container now
2023-04-29 18:17:14,359:INFO:_master_model_container: 4
2023-04-29 18:17:14,359:INFO:_display_container: 2
2023-04-29 18:17:14,360:INFO:ElasticNet(random_state=5501)
2023-04-29 18:17:14,360:INFO:create_model() successfully completed......................................
2023-04-29 18:17:14,448:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:14,448:INFO:Creating metrics dataframe
2023-04-29 18:17:14,452:INFO:Initializing Least Angle Regression
2023-04-29 18:17:14,452:INFO:Total runtime is 0.6573870261510213 minutes
2023-04-29 18:17:14,452:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:14,452:INFO:Initializing create_model()
2023-04-29 18:17:14,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:14,452:INFO:Checking exceptions
2023-04-29 18:17:14,452:INFO:Importing libraries
2023-04-29 18:17:14,452:INFO:Copying training dataset
2023-04-29 18:17:14,455:INFO:Defining folds
2023-04-29 18:17:14,455:INFO:Declaring metric variables
2023-04-29 18:17:14,455:INFO:Importing untrained model
2023-04-29 18:17:14,455:INFO:Least Angle Regression Imported successfully
2023-04-29 18:17:14,456:INFO:Starting cross validation
2023-04-29 18:17:14,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:14,502:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,509:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,527:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,539:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,555:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,577:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,594:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:14,613:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:15,919:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:15,928:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:19,789:INFO:Calculating mean and std
2023-04-29 18:17:19,789:INFO:Creating metrics dataframe
2023-04-29 18:17:20,472:INFO:Uploading results into container
2023-04-29 18:17:20,473:INFO:Uploading model into container now
2023-04-29 18:17:20,473:INFO:_master_model_container: 5
2023-04-29 18:17:20,473:INFO:_display_container: 2
2023-04-29 18:17:20,474:INFO:Lars(random_state=5501)
2023-04-29 18:17:20,474:INFO:create_model() successfully completed......................................
2023-04-29 18:17:20,560:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:20,560:INFO:Creating metrics dataframe
2023-04-29 18:17:20,564:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:17:20,564:INFO:Total runtime is 0.7592446247736613 minutes
2023-04-29 18:17:20,564:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:20,564:INFO:Initializing create_model()
2023-04-29 18:17:20,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:20,564:INFO:Checking exceptions
2023-04-29 18:17:20,564:INFO:Importing libraries
2023-04-29 18:17:20,564:INFO:Copying training dataset
2023-04-29 18:17:20,567:INFO:Defining folds
2023-04-29 18:17:20,567:INFO:Declaring metric variables
2023-04-29 18:17:20,567:INFO:Importing untrained model
2023-04-29 18:17:20,567:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:17:20,568:INFO:Starting cross validation
2023-04-29 18:17:20,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:20,620:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,629:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,644:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,661:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,672:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,685:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,690:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:20,706:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:22,114:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:22,145:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:17:25,920:INFO:Calculating mean and std
2023-04-29 18:17:25,921:INFO:Creating metrics dataframe
2023-04-29 18:17:26,608:INFO:Uploading results into container
2023-04-29 18:17:26,609:INFO:Uploading model into container now
2023-04-29 18:17:26,609:INFO:_master_model_container: 6
2023-04-29 18:17:26,609:INFO:_display_container: 2
2023-04-29 18:17:26,609:INFO:LassoLars(random_state=5501)
2023-04-29 18:17:26,609:INFO:create_model() successfully completed......................................
2023-04-29 18:17:26,695:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:26,695:INFO:Creating metrics dataframe
2023-04-29 18:17:26,698:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:17:26,698:INFO:Total runtime is 0.8614892403284709 minutes
2023-04-29 18:17:26,698:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:26,698:INFO:Initializing create_model()
2023-04-29 18:17:26,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:26,698:INFO:Checking exceptions
2023-04-29 18:17:26,698:INFO:Importing libraries
2023-04-29 18:17:26,698:INFO:Copying training dataset
2023-04-29 18:17:26,701:INFO:Defining folds
2023-04-29 18:17:26,701:INFO:Declaring metric variables
2023-04-29 18:17:26,701:INFO:Importing untrained model
2023-04-29 18:17:26,701:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:17:26,702:INFO:Starting cross validation
2023-04-29 18:17:26,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:26,749:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,760:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,774:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,779:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,797:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,814:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,829:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:26,845:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:28,218:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:28,227:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:17:32,003:INFO:Calculating mean and std
2023-04-29 18:17:32,004:INFO:Creating metrics dataframe
2023-04-29 18:17:32,697:INFO:Uploading results into container
2023-04-29 18:17:32,698:INFO:Uploading model into container now
2023-04-29 18:17:32,698:INFO:_master_model_container: 7
2023-04-29 18:17:32,698:INFO:_display_container: 2
2023-04-29 18:17:32,698:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:17:32,699:INFO:create_model() successfully completed......................................
2023-04-29 18:17:32,789:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:32,789:INFO:Creating metrics dataframe
2023-04-29 18:17:32,794:INFO:Initializing Bayesian Ridge
2023-04-29 18:17:32,794:INFO:Total runtime is 0.9630876302719116 minutes
2023-04-29 18:17:32,794:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:32,794:INFO:Initializing create_model()
2023-04-29 18:17:32,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:32,794:INFO:Checking exceptions
2023-04-29 18:17:32,794:INFO:Importing libraries
2023-04-29 18:17:32,794:INFO:Copying training dataset
2023-04-29 18:17:32,798:INFO:Defining folds
2023-04-29 18:17:32,798:INFO:Declaring metric variables
2023-04-29 18:17:32,798:INFO:Importing untrained model
2023-04-29 18:17:32,798:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:17:32,799:INFO:Starting cross validation
2023-04-29 18:17:32,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:38,130:INFO:Calculating mean and std
2023-04-29 18:17:38,131:INFO:Creating metrics dataframe
2023-04-29 18:17:38,830:INFO:Uploading results into container
2023-04-29 18:17:38,831:INFO:Uploading model into container now
2023-04-29 18:17:38,832:INFO:_master_model_container: 8
2023-04-29 18:17:38,832:INFO:_display_container: 2
2023-04-29 18:17:38,832:INFO:BayesianRidge()
2023-04-29 18:17:38,832:INFO:create_model() successfully completed......................................
2023-04-29 18:17:38,920:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:38,920:INFO:Creating metrics dataframe
2023-04-29 18:17:38,924:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:17:38,924:INFO:Total runtime is 1.0652554353078205 minutes
2023-04-29 18:17:38,924:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:38,925:INFO:Initializing create_model()
2023-04-29 18:17:38,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:38,925:INFO:Checking exceptions
2023-04-29 18:17:38,925:INFO:Importing libraries
2023-04-29 18:17:38,925:INFO:Copying training dataset
2023-04-29 18:17:38,927:INFO:Defining folds
2023-04-29 18:17:38,928:INFO:Declaring metric variables
2023-04-29 18:17:38,928:INFO:Importing untrained model
2023-04-29 18:17:38,928:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:17:38,928:INFO:Starting cross validation
2023-04-29 18:17:38,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:44,241:INFO:Calculating mean and std
2023-04-29 18:17:44,242:INFO:Creating metrics dataframe
2023-04-29 18:17:44,927:INFO:Uploading results into container
2023-04-29 18:17:44,927:INFO:Uploading model into container now
2023-04-29 18:17:44,928:INFO:_master_model_container: 9
2023-04-29 18:17:44,928:INFO:_display_container: 2
2023-04-29 18:17:44,928:INFO:PassiveAggressiveRegressor(random_state=5501)
2023-04-29 18:17:44,928:INFO:create_model() successfully completed......................................
2023-04-29 18:17:45,016:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:45,017:INFO:Creating metrics dataframe
2023-04-29 18:17:45,020:INFO:Initializing Huber Regressor
2023-04-29 18:17:45,020:INFO:Total runtime is 1.166842480500539 minutes
2023-04-29 18:17:45,020:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:45,021:INFO:Initializing create_model()
2023-04-29 18:17:45,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:45,021:INFO:Checking exceptions
2023-04-29 18:17:45,021:INFO:Importing libraries
2023-04-29 18:17:45,021:INFO:Copying training dataset
2023-04-29 18:17:45,023:INFO:Defining folds
2023-04-29 18:17:45,023:INFO:Declaring metric variables
2023-04-29 18:17:45,023:INFO:Importing untrained model
2023-04-29 18:17:45,024:INFO:Huber Regressor Imported successfully
2023-04-29 18:17:45,024:INFO:Starting cross validation
2023-04-29 18:17:45,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:45,142:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:17:45,210:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:17:45,213:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:17:46,591:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:17:46,616:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:17:50,424:INFO:Calculating mean and std
2023-04-29 18:17:50,425:INFO:Creating metrics dataframe
2023-04-29 18:17:51,114:INFO:Uploading results into container
2023-04-29 18:17:51,115:INFO:Uploading model into container now
2023-04-29 18:17:51,116:INFO:_master_model_container: 10
2023-04-29 18:17:51,116:INFO:_display_container: 2
2023-04-29 18:17:51,116:INFO:HuberRegressor()
2023-04-29 18:17:51,116:INFO:create_model() successfully completed......................................
2023-04-29 18:17:51,211:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:51,212:INFO:Creating metrics dataframe
2023-04-29 18:17:51,215:INFO:Initializing K Neighbors Regressor
2023-04-29 18:17:51,216:INFO:Total runtime is 1.2701111316680906 minutes
2023-04-29 18:17:51,216:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:51,216:INFO:Initializing create_model()
2023-04-29 18:17:51,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:51,216:INFO:Checking exceptions
2023-04-29 18:17:51,216:INFO:Importing libraries
2023-04-29 18:17:51,216:INFO:Copying training dataset
2023-04-29 18:17:51,219:INFO:Defining folds
2023-04-29 18:17:51,219:INFO:Declaring metric variables
2023-04-29 18:17:51,220:INFO:Importing untrained model
2023-04-29 18:17:51,220:INFO:K Neighbors Regressor Imported successfully
2023-04-29 18:17:51,220:INFO:Starting cross validation
2023-04-29 18:17:51,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:17:56,594:INFO:Calculating mean and std
2023-04-29 18:17:56,595:INFO:Creating metrics dataframe
2023-04-29 18:17:57,286:INFO:Uploading results into container
2023-04-29 18:17:57,287:INFO:Uploading model into container now
2023-04-29 18:17:57,287:INFO:_master_model_container: 11
2023-04-29 18:17:57,287:INFO:_display_container: 2
2023-04-29 18:17:57,287:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 18:17:57,287:INFO:create_model() successfully completed......................................
2023-04-29 18:17:57,376:INFO:SubProcess create_model() end ==================================
2023-04-29 18:17:57,376:INFO:Creating metrics dataframe
2023-04-29 18:17:57,380:INFO:Initializing Decision Tree Regressor
2023-04-29 18:17:57,381:INFO:Total runtime is 1.372869801521301 minutes
2023-04-29 18:17:57,382:INFO:SubProcess create_model() called ==================================
2023-04-29 18:17:57,382:INFO:Initializing create_model()
2023-04-29 18:17:57,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:17:57,382:INFO:Checking exceptions
2023-04-29 18:17:57,382:INFO:Importing libraries
2023-04-29 18:17:57,382:INFO:Copying training dataset
2023-04-29 18:17:57,387:INFO:Defining folds
2023-04-29 18:17:57,387:INFO:Declaring metric variables
2023-04-29 18:17:57,387:INFO:Importing untrained model
2023-04-29 18:17:57,388:INFO:Decision Tree Regressor Imported successfully
2023-04-29 18:17:57,388:INFO:Starting cross validation
2023-04-29 18:17:57,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:02,865:INFO:Calculating mean and std
2023-04-29 18:18:02,866:INFO:Creating metrics dataframe
2023-04-29 18:18:03,551:INFO:Uploading results into container
2023-04-29 18:18:03,552:INFO:Uploading model into container now
2023-04-29 18:18:03,552:INFO:_master_model_container: 12
2023-04-29 18:18:03,552:INFO:_display_container: 2
2023-04-29 18:18:03,552:INFO:DecisionTreeRegressor(random_state=5501)
2023-04-29 18:18:03,552:INFO:create_model() successfully completed......................................
2023-04-29 18:18:03,642:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:03,642:INFO:Creating metrics dataframe
2023-04-29 18:18:03,648:INFO:Initializing Random Forest Regressor
2023-04-29 18:18:03,648:INFO:Total runtime is 1.477307589848836 minutes
2023-04-29 18:18:03,649:INFO:SubProcess create_model() called ==================================
2023-04-29 18:18:03,649:INFO:Initializing create_model()
2023-04-29 18:18:03,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:03,649:INFO:Checking exceptions
2023-04-29 18:18:03,649:INFO:Importing libraries
2023-04-29 18:18:03,649:INFO:Copying training dataset
2023-04-29 18:18:03,653:INFO:Defining folds
2023-04-29 18:18:03,653:INFO:Declaring metric variables
2023-04-29 18:18:03,654:INFO:Importing untrained model
2023-04-29 18:18:03,654:INFO:Random Forest Regressor Imported successfully
2023-04-29 18:18:03,654:INFO:Starting cross validation
2023-04-29 18:18:03,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:10,238:INFO:Calculating mean and std
2023-04-29 18:18:10,238:INFO:Creating metrics dataframe
2023-04-29 18:18:10,928:INFO:Uploading results into container
2023-04-29 18:18:10,929:INFO:Uploading model into container now
2023-04-29 18:18:10,929:INFO:_master_model_container: 13
2023-04-29 18:18:10,929:INFO:_display_container: 2
2023-04-29 18:18:10,930:INFO:RandomForestRegressor(n_jobs=-1, random_state=5501)
2023-04-29 18:18:10,930:INFO:create_model() successfully completed......................................
2023-04-29 18:18:11,018:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:11,018:INFO:Creating metrics dataframe
2023-04-29 18:18:11,026:INFO:Initializing Extra Trees Regressor
2023-04-29 18:18:11,027:INFO:Total runtime is 1.6003019690513607 minutes
2023-04-29 18:18:11,027:INFO:SubProcess create_model() called ==================================
2023-04-29 18:18:11,027:INFO:Initializing create_model()
2023-04-29 18:18:11,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:11,027:INFO:Checking exceptions
2023-04-29 18:18:11,027:INFO:Importing libraries
2023-04-29 18:18:11,027:INFO:Copying training dataset
2023-04-29 18:18:11,030:INFO:Defining folds
2023-04-29 18:18:11,030:INFO:Declaring metric variables
2023-04-29 18:18:11,031:INFO:Importing untrained model
2023-04-29 18:18:11,032:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:18:11,032:INFO:Starting cross validation
2023-04-29 18:18:11,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:17,470:INFO:Calculating mean and std
2023-04-29 18:18:17,471:INFO:Creating metrics dataframe
2023-04-29 18:18:18,171:INFO:Uploading results into container
2023-04-29 18:18:18,172:INFO:Uploading model into container now
2023-04-29 18:18:18,172:INFO:_master_model_container: 14
2023-04-29 18:18:18,173:INFO:_display_container: 2
2023-04-29 18:18:18,173:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5501)
2023-04-29 18:18:18,173:INFO:create_model() successfully completed......................................
2023-04-29 18:18:18,261:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:18,261:INFO:Creating metrics dataframe
2023-04-29 18:18:18,265:INFO:Initializing AdaBoost Regressor
2023-04-29 18:18:18,265:INFO:Total runtime is 1.7209316213925676 minutes
2023-04-29 18:18:18,266:INFO:SubProcess create_model() called ==================================
2023-04-29 18:18:18,266:INFO:Initializing create_model()
2023-04-29 18:18:18,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:18,266:INFO:Checking exceptions
2023-04-29 18:18:18,266:INFO:Importing libraries
2023-04-29 18:18:18,266:INFO:Copying training dataset
2023-04-29 18:18:18,269:INFO:Defining folds
2023-04-29 18:18:18,269:INFO:Declaring metric variables
2023-04-29 18:18:18,269:INFO:Importing untrained model
2023-04-29 18:18:18,269:INFO:AdaBoost Regressor Imported successfully
2023-04-29 18:18:18,270:INFO:Starting cross validation
2023-04-29 18:18:18,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:24,105:INFO:Calculating mean and std
2023-04-29 18:18:24,105:INFO:Creating metrics dataframe
2023-04-29 18:18:24,812:INFO:Uploading results into container
2023-04-29 18:18:24,813:INFO:Uploading model into container now
2023-04-29 18:18:24,814:INFO:_master_model_container: 15
2023-04-29 18:18:24,814:INFO:_display_container: 2
2023-04-29 18:18:24,814:INFO:AdaBoostRegressor(random_state=5501)
2023-04-29 18:18:24,814:INFO:create_model() successfully completed......................................
2023-04-29 18:18:24,899:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:24,900:INFO:Creating metrics dataframe
2023-04-29 18:18:24,903:INFO:Initializing Gradient Boosting Regressor
2023-04-29 18:18:24,903:INFO:Total runtime is 1.8315690159797664 minutes
2023-04-29 18:18:24,903:INFO:SubProcess create_model() called ==================================
2023-04-29 18:18:24,904:INFO:Initializing create_model()
2023-04-29 18:18:24,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:24,904:INFO:Checking exceptions
2023-04-29 18:18:24,904:INFO:Importing libraries
2023-04-29 18:18:24,904:INFO:Copying training dataset
2023-04-29 18:18:24,906:INFO:Defining folds
2023-04-29 18:18:24,906:INFO:Declaring metric variables
2023-04-29 18:18:24,906:INFO:Importing untrained model
2023-04-29 18:18:24,907:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 18:18:24,907:INFO:Starting cross validation
2023-04-29 18:18:24,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:30,915:INFO:Calculating mean and std
2023-04-29 18:18:30,916:INFO:Creating metrics dataframe
2023-04-29 18:18:31,619:INFO:Uploading results into container
2023-04-29 18:18:31,620:INFO:Uploading model into container now
2023-04-29 18:18:31,620:INFO:_master_model_container: 16
2023-04-29 18:18:31,620:INFO:_display_container: 2
2023-04-29 18:18:31,620:INFO:GradientBoostingRegressor(random_state=5501)
2023-04-29 18:18:31,621:INFO:create_model() successfully completed......................................
2023-04-29 18:18:31,707:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:31,707:INFO:Creating metrics dataframe
2023-04-29 18:18:31,711:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 18:18:31,711:INFO:Total runtime is 1.945028173923492 minutes
2023-04-29 18:18:31,712:INFO:SubProcess create_model() called ==================================
2023-04-29 18:18:31,712:INFO:Initializing create_model()
2023-04-29 18:18:31,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:31,712:INFO:Checking exceptions
2023-04-29 18:18:31,712:INFO:Importing libraries
2023-04-29 18:18:31,712:INFO:Copying training dataset
2023-04-29 18:18:31,714:INFO:Defining folds
2023-04-29 18:18:31,714:INFO:Declaring metric variables
2023-04-29 18:18:31,714:INFO:Importing untrained model
2023-04-29 18:18:31,715:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 18:18:31,715:INFO:Starting cross validation
2023-04-29 18:18:31,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:39,656:INFO:Calculating mean and std
2023-04-29 18:18:39,657:INFO:Creating metrics dataframe
2023-04-29 18:18:40,358:INFO:Uploading results into container
2023-04-29 18:18:40,359:INFO:Uploading model into container now
2023-04-29 18:18:40,360:INFO:_master_model_container: 17
2023-04-29 18:18:40,360:INFO:_display_container: 2
2023-04-29 18:18:40,360:INFO:LGBMRegressor(random_state=5501)
2023-04-29 18:18:40,360:INFO:create_model() successfully completed......................................
2023-04-29 18:18:40,446:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:40,446:INFO:Creating metrics dataframe
2023-04-29 18:18:40,450:INFO:Initializing Dummy Regressor
2023-04-29 18:18:40,450:INFO:Total runtime is 2.090685331821441 minutes
2023-04-29 18:18:40,450:INFO:SubProcess create_model() called ==================================
2023-04-29 18:18:40,450:INFO:Initializing create_model()
2023-04-29 18:18:40,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB33430>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:40,450:INFO:Checking exceptions
2023-04-29 18:18:40,450:INFO:Importing libraries
2023-04-29 18:18:40,450:INFO:Copying training dataset
2023-04-29 18:18:40,453:INFO:Defining folds
2023-04-29 18:18:40,453:INFO:Declaring metric variables
2023-04-29 18:18:40,454:INFO:Importing untrained model
2023-04-29 18:18:40,454:INFO:Dummy Regressor Imported successfully
2023-04-29 18:18:40,454:INFO:Starting cross validation
2023-04-29 18:18:40,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:18:46,089:INFO:Calculating mean and std
2023-04-29 18:18:46,089:INFO:Creating metrics dataframe
2023-04-29 18:18:46,796:INFO:Uploading results into container
2023-04-29 18:18:46,796:INFO:Uploading model into container now
2023-04-29 18:18:46,797:INFO:_master_model_container: 18
2023-04-29 18:18:46,797:INFO:_display_container: 2
2023-04-29 18:18:46,797:INFO:DummyRegressor()
2023-04-29 18:18:46,797:INFO:create_model() successfully completed......................................
2023-04-29 18:18:46,884:INFO:SubProcess create_model() end ==================================
2023-04-29 18:18:46,884:INFO:Creating metrics dataframe
2023-04-29 18:18:46,889:INFO:Initializing create_model()
2023-04-29 18:18:46,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5501), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:18:46,890:INFO:Checking exceptions
2023-04-29 18:18:46,890:INFO:Importing libraries
2023-04-29 18:18:46,890:INFO:Copying training dataset
2023-04-29 18:18:46,896:INFO:Defining folds
2023-04-29 18:18:46,896:INFO:Declaring metric variables
2023-04-29 18:18:46,896:INFO:Importing untrained model
2023-04-29 18:18:46,896:INFO:Declaring custom model
2023-04-29 18:18:46,897:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:18:46,898:INFO:Cross validation set to False
2023-04-29 18:18:46,898:INFO:Fitting Model
2023-04-29 18:18:47,523:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5501)
2023-04-29 18:18:47,523:INFO:create_model() successfully completed......................................
2023-04-29 18:18:47,631:INFO:_master_model_container: 18
2023-04-29 18:18:47,631:INFO:_display_container: 2
2023-04-29 18:18:47,632:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5501)
2023-04-29 18:18:47,632:INFO:compare_models() successfully completed......................................
2023-04-29 18:18:47,634:INFO:Initializing predict_model()
2023-04-29 18:18:47,635:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B17EB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5501), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236EEBA1430>)
2023-04-29 18:18:47,635:INFO:Checking exceptions
2023-04-29 18:18:47,635:INFO:Preloading libraries
2023-04-29 18:18:47,635:INFO:Set up data.
2023-04-29 18:18:47,639:INFO:Set up index.
2023-04-29 18:37:58,888:INFO:PyCaret RegressionExperiment
2023-04-29 18:37:58,889:INFO:Logging name: reg-default-name
2023-04-29 18:37:58,889:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 18:37:58,889:INFO:version 3.0.0
2023-04-29 18:37:58,889:INFO:Initializing setup()
2023-04-29 18:37:58,889:INFO:self.USI: 593d
2023-04-29 18:37:58,889:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 18:37:58,889:INFO:Checking environment
2023-04-29 18:37:58,890:INFO:python_version: 3.9.13
2023-04-29 18:37:58,890:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:37:58,890:INFO:machine: AMD64
2023-04-29 18:37:58,890:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:37:58,890:INFO:Memory: svmem(total=16935899136, available=6379020288, percent=62.3, used=10556878848, free=6379020288)
2023-04-29 18:37:58,890:INFO:Physical Core: 4
2023-04-29 18:37:58,890:INFO:Logical Core: 8
2023-04-29 18:37:58,891:INFO:Checking libraries
2023-04-29 18:37:58,892:INFO:System:
2023-04-29 18:37:58,892:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:37:58,892:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:37:58,892:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:37:58,892:INFO:PyCaret required dependencies:
2023-04-29 18:37:58,892:INFO:                 pip: 22.2.2
2023-04-29 18:37:58,892:INFO:          setuptools: 63.4.1
2023-04-29 18:37:58,892:INFO:             pycaret: 3.0.0
2023-04-29 18:37:58,892:INFO:             IPython: 7.31.1
2023-04-29 18:37:58,892:INFO:          ipywidgets: 7.6.5
2023-04-29 18:37:58,892:INFO:                tqdm: 4.64.1
2023-04-29 18:37:58,892:INFO:               numpy: 1.21.5
2023-04-29 18:37:58,893:INFO:              pandas: 1.4.4
2023-04-29 18:37:58,893:INFO:              jinja2: 2.11.3
2023-04-29 18:37:58,893:INFO:               scipy: 1.9.1
2023-04-29 18:37:58,893:INFO:              joblib: 1.2.0
2023-04-29 18:37:58,893:INFO:             sklearn: 1.0.2
2023-04-29 18:37:58,893:INFO:                pyod: 1.0.9
2023-04-29 18:37:58,893:INFO:            imblearn: 0.10.1
2023-04-29 18:37:58,893:INFO:   category_encoders: 2.6.0
2023-04-29 18:37:58,893:INFO:            lightgbm: 3.3.5
2023-04-29 18:37:58,893:INFO:               numba: 0.55.1
2023-04-29 18:37:58,893:INFO:            requests: 2.28.1
2023-04-29 18:37:58,893:INFO:          matplotlib: 3.5.2
2023-04-29 18:37:58,893:INFO:          scikitplot: 0.3.7
2023-04-29 18:37:58,893:INFO:         yellowbrick: 1.5
2023-04-29 18:37:58,893:INFO:              plotly: 5.9.0
2023-04-29 18:37:58,893:INFO:             kaleido: 0.2.1
2023-04-29 18:37:58,893:INFO:         statsmodels: 0.13.2
2023-04-29 18:37:58,893:INFO:              sktime: 0.17.1
2023-04-29 18:37:58,893:INFO:               tbats: 1.1.2
2023-04-29 18:37:58,893:INFO:            pmdarima: 2.0.3
2023-04-29 18:37:58,893:INFO:              psutil: 5.9.0
2023-04-29 18:37:58,894:INFO:PyCaret optional dependencies:
2023-04-29 18:37:58,894:INFO:                shap: 0.41.0
2023-04-29 18:37:58,894:INFO:           interpret: Not installed
2023-04-29 18:37:58,894:INFO:                umap: Not installed
2023-04-29 18:37:58,894:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:37:58,894:INFO:  explainerdashboard: Not installed
2023-04-29 18:37:58,894:INFO:             autoviz: Not installed
2023-04-29 18:37:58,894:INFO:           fairlearn: Not installed
2023-04-29 18:37:58,895:INFO:             xgboost: Not installed
2023-04-29 18:37:58,895:INFO:            catboost: Not installed
2023-04-29 18:37:58,895:INFO:              kmodes: Not installed
2023-04-29 18:37:58,895:INFO:             mlxtend: Not installed
2023-04-29 18:37:58,895:INFO:       statsforecast: Not installed
2023-04-29 18:37:58,895:INFO:        tune_sklearn: Not installed
2023-04-29 18:37:58,895:INFO:                 ray: Not installed
2023-04-29 18:37:58,895:INFO:            hyperopt: Not installed
2023-04-29 18:37:58,895:INFO:              optuna: Not installed
2023-04-29 18:37:58,895:INFO:               skopt: Not installed
2023-04-29 18:37:58,896:INFO:              mlflow: 2.2.1
2023-04-29 18:37:58,896:INFO:              gradio: Not installed
2023-04-29 18:37:58,896:INFO:             fastapi: Not installed
2023-04-29 18:37:58,896:INFO:             uvicorn: Not installed
2023-04-29 18:37:58,896:INFO:              m2cgen: Not installed
2023-04-29 18:37:58,896:INFO:           evidently: Not installed
2023-04-29 18:37:58,896:INFO:               fugue: Not installed
2023-04-29 18:37:58,896:INFO:           streamlit: 1.21.0
2023-04-29 18:37:58,896:INFO:             prophet: Not installed
2023-04-29 18:37:58,896:INFO:None
2023-04-29 18:37:58,897:INFO:Set up data.
2023-04-29 18:37:58,906:INFO:Set up train/test split.
2023-04-29 18:37:58,912:INFO:Set up index.
2023-04-29 18:37:58,912:INFO:Set up folding strategy.
2023-04-29 18:37:58,912:INFO:Assigning column types.
2023-04-29 18:37:58,919:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 18:37:58,919:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:37:58,930:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:37:58,944:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,105:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,110:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,330:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 18:37:59,337:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,458:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,583:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 18:37:59,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,653:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,792:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:37:59,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:37:59,958:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 18:38:00,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:38:00,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:38:00,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:38:00,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 18:38:00,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,432:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 18:38:00,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:38:00,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 18:38:00,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:00,889:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 18:38:01,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,286:INFO:Preparing preprocessing pipeline...
2023-04-29 18:38:01,287:INFO:Set up simple imputation.
2023-04-29 18:38:01,288:INFO:Set up column name cleaning.
2023-04-29 18:38:01,319:INFO:Finished creating preprocessing pipeline.
2023-04-29 18:38:01,323:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 18:38:01,323:INFO:Creating final display dataframe.
2023-04-29 18:38:01,412:INFO:Setup _display_container:                     Description             Value
0                    Session id               152
1                        Target      Density_calc
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              593d
2023-04-29 18:38:01,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 18:38:01,831:INFO:setup() successfully completed in 3.47s...............
2023-04-29 18:38:01,837:INFO:Initializing compare_models()
2023-04-29 18:38:01,837:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 18:38:01,837:INFO:Checking exceptions
2023-04-29 18:38:01,841:INFO:Preparing display monitor
2023-04-29 18:38:01,847:INFO:Initializing Linear Regression
2023-04-29 18:38:01,847:INFO:Total runtime is 0.0 minutes
2023-04-29 18:38:01,849:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:01,849:INFO:Initializing create_model()
2023-04-29 18:38:01,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:01,850:INFO:Checking exceptions
2023-04-29 18:38:01,850:INFO:Importing libraries
2023-04-29 18:38:01,850:INFO:Copying training dataset
2023-04-29 18:38:01,858:INFO:Defining folds
2023-04-29 18:38:01,859:INFO:Declaring metric variables
2023-04-29 18:38:01,859:INFO:Importing untrained model
2023-04-29 18:38:01,860:INFO:Linear Regression Imported successfully
2023-04-29 18:38:01,860:INFO:Starting cross validation
2023-04-29 18:38:01,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:13,603:INFO:Calculating mean and std
2023-04-29 18:38:13,604:INFO:Creating metrics dataframe
2023-04-29 18:38:14,385:INFO:Uploading results into container
2023-04-29 18:38:14,386:INFO:Uploading model into container now
2023-04-29 18:38:14,386:INFO:_master_model_container: 1
2023-04-29 18:38:14,387:INFO:_display_container: 2
2023-04-29 18:38:14,387:INFO:LinearRegression(n_jobs=-1)
2023-04-29 18:38:14,387:INFO:create_model() successfully completed......................................
2023-04-29 18:38:14,488:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:14,488:INFO:Creating metrics dataframe
2023-04-29 18:38:14,491:INFO:Initializing Lasso Regression
2023-04-29 18:38:14,492:INFO:Total runtime is 0.2107495705286662 minutes
2023-04-29 18:38:14,492:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:14,492:INFO:Initializing create_model()
2023-04-29 18:38:14,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:14,492:INFO:Checking exceptions
2023-04-29 18:38:14,492:INFO:Importing libraries
2023-04-29 18:38:14,492:INFO:Copying training dataset
2023-04-29 18:38:14,495:INFO:Defining folds
2023-04-29 18:38:14,496:INFO:Declaring metric variables
2023-04-29 18:38:14,496:INFO:Importing untrained model
2023-04-29 18:38:14,496:INFO:Lasso Regression Imported successfully
2023-04-29 18:38:14,496:INFO:Starting cross validation
2023-04-29 18:38:14,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:19,821:INFO:Calculating mean and std
2023-04-29 18:38:19,822:INFO:Creating metrics dataframe
2023-04-29 18:38:20,468:INFO:Uploading results into container
2023-04-29 18:38:20,469:INFO:Uploading model into container now
2023-04-29 18:38:20,469:INFO:_master_model_container: 2
2023-04-29 18:38:20,469:INFO:_display_container: 2
2023-04-29 18:38:20,469:INFO:Lasso(random_state=152)
2023-04-29 18:38:20,469:INFO:create_model() successfully completed......................................
2023-04-29 18:38:20,555:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:20,555:INFO:Creating metrics dataframe
2023-04-29 18:38:20,559:INFO:Initializing Ridge Regression
2023-04-29 18:38:20,559:INFO:Total runtime is 0.3118593136469523 minutes
2023-04-29 18:38:20,559:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:20,559:INFO:Initializing create_model()
2023-04-29 18:38:20,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:20,559:INFO:Checking exceptions
2023-04-29 18:38:20,559:INFO:Importing libraries
2023-04-29 18:38:20,559:INFO:Copying training dataset
2023-04-29 18:38:20,561:INFO:Defining folds
2023-04-29 18:38:20,562:INFO:Declaring metric variables
2023-04-29 18:38:20,562:INFO:Importing untrained model
2023-04-29 18:38:20,562:INFO:Ridge Regression Imported successfully
2023-04-29 18:38:20,562:INFO:Starting cross validation
2023-04-29 18:38:20,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:25,702:INFO:Calculating mean and std
2023-04-29 18:38:25,703:INFO:Creating metrics dataframe
2023-04-29 18:38:26,374:INFO:Uploading results into container
2023-04-29 18:38:26,375:INFO:Uploading model into container now
2023-04-29 18:38:26,375:INFO:_master_model_container: 3
2023-04-29 18:38:26,375:INFO:_display_container: 2
2023-04-29 18:38:26,375:INFO:Ridge(random_state=152)
2023-04-29 18:38:26,375:INFO:create_model() successfully completed......................................
2023-04-29 18:38:26,461:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:26,461:INFO:Creating metrics dataframe
2023-04-29 18:38:26,465:INFO:Initializing Elastic Net
2023-04-29 18:38:26,465:INFO:Total runtime is 0.41030188798904416 minutes
2023-04-29 18:38:26,465:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:26,465:INFO:Initializing create_model()
2023-04-29 18:38:26,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:26,465:INFO:Checking exceptions
2023-04-29 18:38:26,465:INFO:Importing libraries
2023-04-29 18:38:26,465:INFO:Copying training dataset
2023-04-29 18:38:26,468:INFO:Defining folds
2023-04-29 18:38:26,468:INFO:Declaring metric variables
2023-04-29 18:38:26,468:INFO:Importing untrained model
2023-04-29 18:38:26,468:INFO:Elastic Net Imported successfully
2023-04-29 18:38:26,468:INFO:Starting cross validation
2023-04-29 18:38:26,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:31,622:INFO:Calculating mean and std
2023-04-29 18:38:31,622:INFO:Creating metrics dataframe
2023-04-29 18:38:32,296:INFO:Uploading results into container
2023-04-29 18:38:32,296:INFO:Uploading model into container now
2023-04-29 18:38:32,297:INFO:_master_model_container: 4
2023-04-29 18:38:32,297:INFO:_display_container: 2
2023-04-29 18:38:32,297:INFO:ElasticNet(random_state=152)
2023-04-29 18:38:32,297:INFO:create_model() successfully completed......................................
2023-04-29 18:38:32,387:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:32,387:INFO:Creating metrics dataframe
2023-04-29 18:38:32,393:INFO:Initializing Least Angle Regression
2023-04-29 18:38:32,393:INFO:Total runtime is 0.5090925097465515 minutes
2023-04-29 18:38:32,393:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:32,393:INFO:Initializing create_model()
2023-04-29 18:38:32,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:32,394:INFO:Checking exceptions
2023-04-29 18:38:32,394:INFO:Importing libraries
2023-04-29 18:38:32,394:INFO:Copying training dataset
2023-04-29 18:38:32,399:INFO:Defining folds
2023-04-29 18:38:32,399:INFO:Declaring metric variables
2023-04-29 18:38:32,399:INFO:Importing untrained model
2023-04-29 18:38:32,399:INFO:Least Angle Regression Imported successfully
2023-04-29 18:38:32,400:INFO:Starting cross validation
2023-04-29 18:38:32,400:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:32,469:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,472:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,479:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,505:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,520:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,536:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,544:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:32,558:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:33,853:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:33,864:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:37,597:INFO:Calculating mean and std
2023-04-29 18:38:37,598:INFO:Creating metrics dataframe
2023-04-29 18:38:38,274:INFO:Uploading results into container
2023-04-29 18:38:38,275:INFO:Uploading model into container now
2023-04-29 18:38:38,275:INFO:_master_model_container: 5
2023-04-29 18:38:38,275:INFO:_display_container: 2
2023-04-29 18:38:38,276:INFO:Lars(random_state=152)
2023-04-29 18:38:38,276:INFO:create_model() successfully completed......................................
2023-04-29 18:38:38,366:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:38,367:INFO:Creating metrics dataframe
2023-04-29 18:38:38,373:INFO:Initializing Lasso Least Angle Regression
2023-04-29 18:38:38,373:INFO:Total runtime is 0.608764934539795 minutes
2023-04-29 18:38:38,373:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:38,373:INFO:Initializing create_model()
2023-04-29 18:38:38,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:38,373:INFO:Checking exceptions
2023-04-29 18:38:38,373:INFO:Importing libraries
2023-04-29 18:38:38,374:INFO:Copying training dataset
2023-04-29 18:38:38,377:INFO:Defining folds
2023-04-29 18:38:38,377:INFO:Declaring metric variables
2023-04-29 18:38:38,377:INFO:Importing untrained model
2023-04-29 18:38:38,377:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 18:38:38,378:INFO:Starting cross validation
2023-04-29 18:38:38,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:38,432:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,444:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,452:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,462:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,486:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,499:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,515:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:38,542:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:39,837:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:39,840:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 18:38:43,631:INFO:Calculating mean and std
2023-04-29 18:38:43,632:INFO:Creating metrics dataframe
2023-04-29 18:38:44,316:INFO:Uploading results into container
2023-04-29 18:38:44,317:INFO:Uploading model into container now
2023-04-29 18:38:44,317:INFO:_master_model_container: 6
2023-04-29 18:38:44,318:INFO:_display_container: 2
2023-04-29 18:38:44,318:INFO:LassoLars(random_state=152)
2023-04-29 18:38:44,318:INFO:create_model() successfully completed......................................
2023-04-29 18:38:44,408:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:44,408:INFO:Creating metrics dataframe
2023-04-29 18:38:44,411:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 18:38:44,412:INFO:Total runtime is 0.7094067295392354 minutes
2023-04-29 18:38:44,412:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:44,412:INFO:Initializing create_model()
2023-04-29 18:38:44,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:44,412:INFO:Checking exceptions
2023-04-29 18:38:44,412:INFO:Importing libraries
2023-04-29 18:38:44,412:INFO:Copying training dataset
2023-04-29 18:38:44,415:INFO:Defining folds
2023-04-29 18:38:44,415:INFO:Declaring metric variables
2023-04-29 18:38:44,415:INFO:Importing untrained model
2023-04-29 18:38:44,415:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 18:38:44,416:INFO:Starting cross validation
2023-04-29 18:38:44,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:44,467:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,481:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,489:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,503:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,510:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,520:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,537:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:44,551:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:45,826:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:45,841:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 18:38:49,652:INFO:Calculating mean and std
2023-04-29 18:38:49,653:INFO:Creating metrics dataframe
2023-04-29 18:38:50,332:INFO:Uploading results into container
2023-04-29 18:38:50,333:INFO:Uploading model into container now
2023-04-29 18:38:50,334:INFO:_master_model_container: 7
2023-04-29 18:38:50,334:INFO:_display_container: 2
2023-04-29 18:38:50,334:INFO:OrthogonalMatchingPursuit()
2023-04-29 18:38:50,334:INFO:create_model() successfully completed......................................
2023-04-29 18:38:50,419:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:50,420:INFO:Creating metrics dataframe
2023-04-29 18:38:50,423:INFO:Initializing Bayesian Ridge
2023-04-29 18:38:50,423:INFO:Total runtime is 0.8095988432566326 minutes
2023-04-29 18:38:50,423:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:50,424:INFO:Initializing create_model()
2023-04-29 18:38:50,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:50,424:INFO:Checking exceptions
2023-04-29 18:38:50,424:INFO:Importing libraries
2023-04-29 18:38:50,424:INFO:Copying training dataset
2023-04-29 18:38:50,427:INFO:Defining folds
2023-04-29 18:38:50,427:INFO:Declaring metric variables
2023-04-29 18:38:50,427:INFO:Importing untrained model
2023-04-29 18:38:50,428:INFO:Bayesian Ridge Imported successfully
2023-04-29 18:38:50,428:INFO:Starting cross validation
2023-04-29 18:38:50,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:38:55,695:INFO:Calculating mean and std
2023-04-29 18:38:55,697:INFO:Creating metrics dataframe
2023-04-29 18:38:56,370:INFO:Uploading results into container
2023-04-29 18:38:56,371:INFO:Uploading model into container now
2023-04-29 18:38:56,371:INFO:_master_model_container: 8
2023-04-29 18:38:56,371:INFO:_display_container: 2
2023-04-29 18:38:56,371:INFO:BayesianRidge()
2023-04-29 18:38:56,372:INFO:create_model() successfully completed......................................
2023-04-29 18:38:56,459:INFO:SubProcess create_model() end ==================================
2023-04-29 18:38:56,459:INFO:Creating metrics dataframe
2023-04-29 18:38:56,464:INFO:Initializing Passive Aggressive Regressor
2023-04-29 18:38:56,464:INFO:Total runtime is 0.9102705717086793 minutes
2023-04-29 18:38:56,464:INFO:SubProcess create_model() called ==================================
2023-04-29 18:38:56,464:INFO:Initializing create_model()
2023-04-29 18:38:56,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:38:56,464:INFO:Checking exceptions
2023-04-29 18:38:56,464:INFO:Importing libraries
2023-04-29 18:38:56,464:INFO:Copying training dataset
2023-04-29 18:38:56,467:INFO:Defining folds
2023-04-29 18:38:56,467:INFO:Declaring metric variables
2023-04-29 18:38:56,468:INFO:Importing untrained model
2023-04-29 18:38:56,468:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 18:38:56,468:INFO:Starting cross validation
2023-04-29 18:38:56,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:01,758:INFO:Calculating mean and std
2023-04-29 18:39:01,759:INFO:Creating metrics dataframe
2023-04-29 18:39:02,437:INFO:Uploading results into container
2023-04-29 18:39:02,438:INFO:Uploading model into container now
2023-04-29 18:39:02,439:INFO:_master_model_container: 9
2023-04-29 18:39:02,439:INFO:_display_container: 2
2023-04-29 18:39:02,439:INFO:PassiveAggressiveRegressor(random_state=152)
2023-04-29 18:39:02,439:INFO:create_model() successfully completed......................................
2023-04-29 18:39:02,532:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:02,532:INFO:Creating metrics dataframe
2023-04-29 18:39:02,541:INFO:Initializing Huber Regressor
2023-04-29 18:39:02,542:INFO:Total runtime is 1.011584770679474 minutes
2023-04-29 18:39:02,542:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:02,542:INFO:Initializing create_model()
2023-04-29 18:39:02,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:02,543:INFO:Checking exceptions
2023-04-29 18:39:02,543:INFO:Importing libraries
2023-04-29 18:39:02,543:INFO:Copying training dataset
2023-04-29 18:39:02,548:INFO:Defining folds
2023-04-29 18:39:02,549:INFO:Declaring metric variables
2023-04-29 18:39:02,549:INFO:Importing untrained model
2023-04-29 18:39:02,549:INFO:Huber Regressor Imported successfully
2023-04-29 18:39:02,550:INFO:Starting cross validation
2023-04-29 18:39:02,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:02,740:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:39:04,134:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 18:39:07,868:INFO:Calculating mean and std
2023-04-29 18:39:07,869:INFO:Creating metrics dataframe
2023-04-29 18:39:08,550:INFO:Uploading results into container
2023-04-29 18:39:08,550:INFO:Uploading model into container now
2023-04-29 18:39:08,551:INFO:_master_model_container: 10
2023-04-29 18:39:08,551:INFO:_display_container: 2
2023-04-29 18:39:08,551:INFO:HuberRegressor()
2023-04-29 18:39:08,551:INFO:create_model() successfully completed......................................
2023-04-29 18:39:08,645:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:08,645:INFO:Creating metrics dataframe
2023-04-29 18:39:08,649:INFO:Initializing K Neighbors Regressor
2023-04-29 18:39:08,649:INFO:Total runtime is 1.1133577823638918 minutes
2023-04-29 18:39:08,649:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:08,650:INFO:Initializing create_model()
2023-04-29 18:39:08,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:08,650:INFO:Checking exceptions
2023-04-29 18:39:08,650:INFO:Importing libraries
2023-04-29 18:39:08,650:INFO:Copying training dataset
2023-04-29 18:39:08,653:INFO:Defining folds
2023-04-29 18:39:08,653:INFO:Declaring metric variables
2023-04-29 18:39:08,654:INFO:Importing untrained model
2023-04-29 18:39:08,654:INFO:K Neighbors Regressor Imported successfully
2023-04-29 18:39:08,654:INFO:Starting cross validation
2023-04-29 18:39:08,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:13,972:INFO:Calculating mean and std
2023-04-29 18:39:13,973:INFO:Creating metrics dataframe
2023-04-29 18:39:14,654:INFO:Uploading results into container
2023-04-29 18:39:14,655:INFO:Uploading model into container now
2023-04-29 18:39:14,655:INFO:_master_model_container: 11
2023-04-29 18:39:14,655:INFO:_display_container: 2
2023-04-29 18:39:14,656:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 18:39:14,656:INFO:create_model() successfully completed......................................
2023-04-29 18:39:14,745:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:14,745:INFO:Creating metrics dataframe
2023-04-29 18:39:14,750:INFO:Initializing Decision Tree Regressor
2023-04-29 18:39:14,750:INFO:Total runtime is 1.2150395989418032 minutes
2023-04-29 18:39:14,750:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:14,750:INFO:Initializing create_model()
2023-04-29 18:39:14,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:14,751:INFO:Checking exceptions
2023-04-29 18:39:14,751:INFO:Importing libraries
2023-04-29 18:39:14,751:INFO:Copying training dataset
2023-04-29 18:39:14,754:INFO:Defining folds
2023-04-29 18:39:14,754:INFO:Declaring metric variables
2023-04-29 18:39:14,755:INFO:Importing untrained model
2023-04-29 18:39:14,755:INFO:Decision Tree Regressor Imported successfully
2023-04-29 18:39:14,756:INFO:Starting cross validation
2023-04-29 18:39:14,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:20,045:INFO:Calculating mean and std
2023-04-29 18:39:20,046:INFO:Creating metrics dataframe
2023-04-29 18:39:20,728:INFO:Uploading results into container
2023-04-29 18:39:20,729:INFO:Uploading model into container now
2023-04-29 18:39:20,729:INFO:_master_model_container: 12
2023-04-29 18:39:20,729:INFO:_display_container: 2
2023-04-29 18:39:20,730:INFO:DecisionTreeRegressor(random_state=152)
2023-04-29 18:39:20,730:INFO:create_model() successfully completed......................................
2023-04-29 18:39:20,817:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:20,817:INFO:Creating metrics dataframe
2023-04-29 18:39:20,821:INFO:Initializing Random Forest Regressor
2023-04-29 18:39:20,821:INFO:Total runtime is 1.3162211934725445 minutes
2023-04-29 18:39:20,821:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:20,821:INFO:Initializing create_model()
2023-04-29 18:39:20,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:20,821:INFO:Checking exceptions
2023-04-29 18:39:20,821:INFO:Importing libraries
2023-04-29 18:39:20,821:INFO:Copying training dataset
2023-04-29 18:39:20,824:INFO:Defining folds
2023-04-29 18:39:20,824:INFO:Declaring metric variables
2023-04-29 18:39:20,825:INFO:Importing untrained model
2023-04-29 18:39:20,825:INFO:Random Forest Regressor Imported successfully
2023-04-29 18:39:20,825:INFO:Starting cross validation
2023-04-29 18:39:20,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:27,232:INFO:Calculating mean and std
2023-04-29 18:39:27,233:INFO:Creating metrics dataframe
2023-04-29 18:39:27,928:INFO:Uploading results into container
2023-04-29 18:39:27,929:INFO:Uploading model into container now
2023-04-29 18:39:27,929:INFO:_master_model_container: 13
2023-04-29 18:39:27,929:INFO:_display_container: 2
2023-04-29 18:39:27,929:INFO:RandomForestRegressor(n_jobs=-1, random_state=152)
2023-04-29 18:39:27,929:INFO:create_model() successfully completed......................................
2023-04-29 18:39:28,018:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:28,018:INFO:Creating metrics dataframe
2023-04-29 18:39:28,023:INFO:Initializing Extra Trees Regressor
2023-04-29 18:39:28,023:INFO:Total runtime is 1.4362540483474733 minutes
2023-04-29 18:39:28,023:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:28,024:INFO:Initializing create_model()
2023-04-29 18:39:28,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:28,024:INFO:Checking exceptions
2023-04-29 18:39:28,024:INFO:Importing libraries
2023-04-29 18:39:28,024:INFO:Copying training dataset
2023-04-29 18:39:28,027:INFO:Defining folds
2023-04-29 18:39:28,027:INFO:Declaring metric variables
2023-04-29 18:39:28,027:INFO:Importing untrained model
2023-04-29 18:39:28,027:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:39:28,027:INFO:Starting cross validation
2023-04-29 18:39:28,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:34,288:INFO:Calculating mean and std
2023-04-29 18:39:34,289:INFO:Creating metrics dataframe
2023-04-29 18:39:34,977:INFO:Uploading results into container
2023-04-29 18:39:34,978:INFO:Uploading model into container now
2023-04-29 18:39:34,978:INFO:_master_model_container: 14
2023-04-29 18:39:34,978:INFO:_display_container: 2
2023-04-29 18:39:34,979:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=152)
2023-04-29 18:39:34,979:INFO:create_model() successfully completed......................................
2023-04-29 18:39:35,065:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:35,066:INFO:Creating metrics dataframe
2023-04-29 18:39:35,073:INFO:Initializing AdaBoost Regressor
2023-04-29 18:39:35,073:INFO:Total runtime is 1.5537562688191733 minutes
2023-04-29 18:39:35,073:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:35,073:INFO:Initializing create_model()
2023-04-29 18:39:35,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:35,074:INFO:Checking exceptions
2023-04-29 18:39:35,074:INFO:Importing libraries
2023-04-29 18:39:35,074:INFO:Copying training dataset
2023-04-29 18:39:35,077:INFO:Defining folds
2023-04-29 18:39:35,077:INFO:Declaring metric variables
2023-04-29 18:39:35,077:INFO:Importing untrained model
2023-04-29 18:39:35,077:INFO:AdaBoost Regressor Imported successfully
2023-04-29 18:39:35,077:INFO:Starting cross validation
2023-04-29 18:39:35,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:40,927:INFO:Calculating mean and std
2023-04-29 18:39:40,928:INFO:Creating metrics dataframe
2023-04-29 18:39:41,631:INFO:Uploading results into container
2023-04-29 18:39:41,632:INFO:Uploading model into container now
2023-04-29 18:39:41,634:INFO:_master_model_container: 15
2023-04-29 18:39:41,634:INFO:_display_container: 2
2023-04-29 18:39:41,634:INFO:AdaBoostRegressor(random_state=152)
2023-04-29 18:39:41,634:INFO:create_model() successfully completed......................................
2023-04-29 18:39:41,723:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:41,723:INFO:Creating metrics dataframe
2023-04-29 18:39:41,727:INFO:Initializing Gradient Boosting Regressor
2023-04-29 18:39:41,727:INFO:Total runtime is 1.6646618366241457 minutes
2023-04-29 18:39:41,727:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:41,728:INFO:Initializing create_model()
2023-04-29 18:39:41,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:41,728:INFO:Checking exceptions
2023-04-29 18:39:41,728:INFO:Importing libraries
2023-04-29 18:39:41,728:INFO:Copying training dataset
2023-04-29 18:39:41,731:INFO:Defining folds
2023-04-29 18:39:41,731:INFO:Declaring metric variables
2023-04-29 18:39:41,731:INFO:Importing untrained model
2023-04-29 18:39:41,732:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 18:39:41,732:INFO:Starting cross validation
2023-04-29 18:39:41,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:47,658:INFO:Calculating mean and std
2023-04-29 18:39:47,659:INFO:Creating metrics dataframe
2023-04-29 18:39:48,367:INFO:Uploading results into container
2023-04-29 18:39:48,368:INFO:Uploading model into container now
2023-04-29 18:39:48,369:INFO:_master_model_container: 16
2023-04-29 18:39:48,369:INFO:_display_container: 2
2023-04-29 18:39:48,369:INFO:GradientBoostingRegressor(random_state=152)
2023-04-29 18:39:48,369:INFO:create_model() successfully completed......................................
2023-04-29 18:39:48,460:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:48,460:INFO:Creating metrics dataframe
2023-04-29 18:39:48,463:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 18:39:48,464:INFO:Total runtime is 1.7769257624944053 minutes
2023-04-29 18:39:48,464:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:48,464:INFO:Initializing create_model()
2023-04-29 18:39:48,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:48,464:INFO:Checking exceptions
2023-04-29 18:39:48,464:INFO:Importing libraries
2023-04-29 18:39:48,464:INFO:Copying training dataset
2023-04-29 18:39:48,468:INFO:Defining folds
2023-04-29 18:39:48,468:INFO:Declaring metric variables
2023-04-29 18:39:48,468:INFO:Importing untrained model
2023-04-29 18:39:48,469:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 18:39:48,469:INFO:Starting cross validation
2023-04-29 18:39:48,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:39:56,240:INFO:Calculating mean and std
2023-04-29 18:39:56,241:INFO:Creating metrics dataframe
2023-04-29 18:39:56,964:INFO:Uploading results into container
2023-04-29 18:39:56,965:INFO:Uploading model into container now
2023-04-29 18:39:56,966:INFO:_master_model_container: 17
2023-04-29 18:39:56,966:INFO:_display_container: 2
2023-04-29 18:39:56,966:INFO:LGBMRegressor(random_state=152)
2023-04-29 18:39:56,966:INFO:create_model() successfully completed......................................
2023-04-29 18:39:57,066:INFO:SubProcess create_model() end ==================================
2023-04-29 18:39:57,066:INFO:Creating metrics dataframe
2023-04-29 18:39:57,071:INFO:Initializing Dummy Regressor
2023-04-29 18:39:57,071:INFO:Total runtime is 1.9204024076461794 minutes
2023-04-29 18:39:57,071:INFO:SubProcess create_model() called ==================================
2023-04-29 18:39:57,071:INFO:Initializing create_model()
2023-04-29 18:39:57,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE21A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:39:57,071:INFO:Checking exceptions
2023-04-29 18:39:57,071:INFO:Importing libraries
2023-04-29 18:39:57,071:INFO:Copying training dataset
2023-04-29 18:39:57,075:INFO:Defining folds
2023-04-29 18:39:57,075:INFO:Declaring metric variables
2023-04-29 18:39:57,076:INFO:Importing untrained model
2023-04-29 18:39:57,076:INFO:Dummy Regressor Imported successfully
2023-04-29 18:39:57,076:INFO:Starting cross validation
2023-04-29 18:39:57,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 18:40:02,721:INFO:Calculating mean and std
2023-04-29 18:40:02,722:INFO:Creating metrics dataframe
2023-04-29 18:40:03,439:INFO:Uploading results into container
2023-04-29 18:40:03,440:INFO:Uploading model into container now
2023-04-29 18:40:03,440:INFO:_master_model_container: 18
2023-04-29 18:40:03,440:INFO:_display_container: 2
2023-04-29 18:40:03,440:INFO:DummyRegressor()
2023-04-29 18:40:03,440:INFO:create_model() successfully completed......................................
2023-04-29 18:40:03,529:INFO:SubProcess create_model() end ==================================
2023-04-29 18:40:03,529:INFO:Creating metrics dataframe
2023-04-29 18:40:03,535:INFO:Initializing create_model()
2023-04-29 18:40:03,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=152), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 18:40:03,535:INFO:Checking exceptions
2023-04-29 18:40:03,535:INFO:Importing libraries
2023-04-29 18:40:03,535:INFO:Copying training dataset
2023-04-29 18:40:03,538:INFO:Defining folds
2023-04-29 18:40:03,538:INFO:Declaring metric variables
2023-04-29 18:40:03,538:INFO:Importing untrained model
2023-04-29 18:40:03,538:INFO:Declaring custom model
2023-04-29 18:40:03,539:INFO:Extra Trees Regressor Imported successfully
2023-04-29 18:40:03,539:INFO:Cross validation set to False
2023-04-29 18:40:03,539:INFO:Fitting Model
2023-04-29 18:40:04,145:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=152)
2023-04-29 18:40:04,145:INFO:create_model() successfully completed......................................
2023-04-29 18:40:04,257:INFO:_master_model_container: 18
2023-04-29 18:40:04,257:INFO:_display_container: 2
2023-04-29 18:40:04,258:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=152)
2023-04-29 18:40:04,258:INFO:compare_models() successfully completed......................................
2023-04-29 18:40:04,263:INFO:Initializing predict_model()
2023-04-29 18:40:04,263:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEBAA340>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=152), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236EF9F0C10>)
2023-04-29 18:40:04,264:INFO:Checking exceptions
2023-04-29 18:40:04,264:INFO:Preloading libraries
2023-04-29 18:40:04,264:INFO:Set up data.
2023-04-29 18:40:04,270:INFO:Set up index.
2023-04-29 18:57:59,928:INFO:PyCaret ClassificationExperiment
2023-04-29 18:57:59,928:INFO:Logging name: clf-default-name
2023-04-29 18:57:59,928:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 18:57:59,928:INFO:version 3.0.0
2023-04-29 18:57:59,928:INFO:Initializing setup()
2023-04-29 18:57:59,928:INFO:self.USI: 9bf1
2023-04-29 18:57:59,929:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'X_test', 'y', 'is_multiclass', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 18:57:59,929:INFO:Checking environment
2023-04-29 18:57:59,929:INFO:python_version: 3.9.13
2023-04-29 18:57:59,929:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 18:57:59,929:INFO:machine: AMD64
2023-04-29 18:57:59,929:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 18:57:59,929:INFO:Memory: svmem(total=16935899136, available=6041448448, percent=64.3, used=10894450688, free=6041448448)
2023-04-29 18:57:59,929:INFO:Physical Core: 4
2023-04-29 18:57:59,929:INFO:Logical Core: 8
2023-04-29 18:57:59,930:INFO:Checking libraries
2023-04-29 18:57:59,930:INFO:System:
2023-04-29 18:57:59,930:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 18:57:59,930:INFO:executable: D:\Anaconda\python.exe
2023-04-29 18:57:59,930:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 18:57:59,930:INFO:PyCaret required dependencies:
2023-04-29 18:57:59,930:INFO:                 pip: 22.2.2
2023-04-29 18:57:59,930:INFO:          setuptools: 63.4.1
2023-04-29 18:57:59,930:INFO:             pycaret: 3.0.0
2023-04-29 18:57:59,931:INFO:             IPython: 7.31.1
2023-04-29 18:57:59,931:INFO:          ipywidgets: 7.6.5
2023-04-29 18:57:59,931:INFO:                tqdm: 4.64.1
2023-04-29 18:57:59,931:INFO:               numpy: 1.21.5
2023-04-29 18:57:59,931:INFO:              pandas: 1.4.4
2023-04-29 18:57:59,931:INFO:              jinja2: 2.11.3
2023-04-29 18:57:59,931:INFO:               scipy: 1.9.1
2023-04-29 18:57:59,931:INFO:              joblib: 1.2.0
2023-04-29 18:57:59,931:INFO:             sklearn: 1.0.2
2023-04-29 18:57:59,931:INFO:                pyod: 1.0.9
2023-04-29 18:57:59,931:INFO:            imblearn: 0.10.1
2023-04-29 18:57:59,931:INFO:   category_encoders: 2.6.0
2023-04-29 18:57:59,931:INFO:            lightgbm: 3.3.5
2023-04-29 18:57:59,931:INFO:               numba: 0.55.1
2023-04-29 18:57:59,931:INFO:            requests: 2.28.1
2023-04-29 18:57:59,931:INFO:          matplotlib: 3.5.2
2023-04-29 18:57:59,931:INFO:          scikitplot: 0.3.7
2023-04-29 18:57:59,931:INFO:         yellowbrick: 1.5
2023-04-29 18:57:59,931:INFO:              plotly: 5.9.0
2023-04-29 18:57:59,931:INFO:             kaleido: 0.2.1
2023-04-29 18:57:59,931:INFO:         statsmodels: 0.13.2
2023-04-29 18:57:59,931:INFO:              sktime: 0.17.1
2023-04-29 18:57:59,931:INFO:               tbats: 1.1.2
2023-04-29 18:57:59,931:INFO:            pmdarima: 2.0.3
2023-04-29 18:57:59,932:INFO:              psutil: 5.9.0
2023-04-29 18:57:59,932:INFO:PyCaret optional dependencies:
2023-04-29 18:57:59,932:INFO:                shap: 0.41.0
2023-04-29 18:57:59,932:INFO:           interpret: Not installed
2023-04-29 18:57:59,932:INFO:                umap: Not installed
2023-04-29 18:57:59,932:INFO:    pandas_profiling: 4.1.2
2023-04-29 18:57:59,932:INFO:  explainerdashboard: Not installed
2023-04-29 18:57:59,932:INFO:             autoviz: Not installed
2023-04-29 18:57:59,932:INFO:           fairlearn: Not installed
2023-04-29 18:57:59,932:INFO:             xgboost: Not installed
2023-04-29 18:57:59,932:INFO:            catboost: Not installed
2023-04-29 18:57:59,932:INFO:              kmodes: Not installed
2023-04-29 18:57:59,932:INFO:             mlxtend: Not installed
2023-04-29 18:57:59,932:INFO:       statsforecast: Not installed
2023-04-29 18:57:59,932:INFO:        tune_sklearn: Not installed
2023-04-29 18:57:59,932:INFO:                 ray: Not installed
2023-04-29 18:57:59,932:INFO:            hyperopt: Not installed
2023-04-29 18:57:59,932:INFO:              optuna: Not installed
2023-04-29 18:57:59,932:INFO:               skopt: Not installed
2023-04-29 18:57:59,932:INFO:              mlflow: 2.2.1
2023-04-29 18:57:59,932:INFO:              gradio: Not installed
2023-04-29 18:57:59,932:INFO:             fastapi: Not installed
2023-04-29 18:57:59,932:INFO:             uvicorn: Not installed
2023-04-29 18:57:59,932:INFO:              m2cgen: Not installed
2023-04-29 18:57:59,932:INFO:           evidently: Not installed
2023-04-29 18:57:59,933:INFO:               fugue: Not installed
2023-04-29 18:57:59,933:INFO:           streamlit: 1.21.0
2023-04-29 18:57:59,933:INFO:             prophet: Not installed
2023-04-29 18:57:59,933:INFO:None
2023-04-29 18:57:59,933:INFO:Set up data.
2023-04-29 18:57:59,938:INFO:Set up train/test split.
2023-04-29 19:01:54,169:INFO:PyCaret ClassificationExperiment
2023-04-29 19:01:54,170:INFO:Logging name: clf-default-name
2023-04-29 19:01:54,170:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 19:01:54,170:INFO:version 3.0.0
2023-04-29 19:01:54,170:INFO:Initializing setup()
2023-04-29 19:01:54,170:INFO:self.USI: 668f
2023-04-29 19:01:54,170:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'X_test', 'y', 'is_multiclass', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:01:54,170:INFO:Checking environment
2023-04-29 19:01:54,171:INFO:python_version: 3.9.13
2023-04-29 19:01:54,171:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:01:54,171:INFO:machine: AMD64
2023-04-29 19:01:54,171:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:01:54,171:INFO:Memory: svmem(total=16935899136, available=5716348928, percent=66.2, used=11219550208, free=5716348928)
2023-04-29 19:01:54,171:INFO:Physical Core: 4
2023-04-29 19:01:54,171:INFO:Logical Core: 8
2023-04-29 19:01:54,171:INFO:Checking libraries
2023-04-29 19:01:54,171:INFO:System:
2023-04-29 19:01:54,172:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:01:54,172:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:01:54,172:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:01:54,172:INFO:PyCaret required dependencies:
2023-04-29 19:01:54,173:INFO:                 pip: 22.2.2
2023-04-29 19:01:54,173:INFO:          setuptools: 63.4.1
2023-04-29 19:01:54,173:INFO:             pycaret: 3.0.0
2023-04-29 19:01:54,173:INFO:             IPython: 7.31.1
2023-04-29 19:01:54,173:INFO:          ipywidgets: 7.6.5
2023-04-29 19:01:54,173:INFO:                tqdm: 4.64.1
2023-04-29 19:01:54,173:INFO:               numpy: 1.21.5
2023-04-29 19:01:54,173:INFO:              pandas: 1.4.4
2023-04-29 19:01:54,173:INFO:              jinja2: 2.11.3
2023-04-29 19:01:54,173:INFO:               scipy: 1.9.1
2023-04-29 19:01:54,173:INFO:              joblib: 1.2.0
2023-04-29 19:01:54,173:INFO:             sklearn: 1.0.2
2023-04-29 19:01:54,173:INFO:                pyod: 1.0.9
2023-04-29 19:01:54,173:INFO:            imblearn: 0.10.1
2023-04-29 19:01:54,173:INFO:   category_encoders: 2.6.0
2023-04-29 19:01:54,173:INFO:            lightgbm: 3.3.5
2023-04-29 19:01:54,173:INFO:               numba: 0.55.1
2023-04-29 19:01:54,173:INFO:            requests: 2.28.1
2023-04-29 19:01:54,173:INFO:          matplotlib: 3.5.2
2023-04-29 19:01:54,173:INFO:          scikitplot: 0.3.7
2023-04-29 19:01:54,173:INFO:         yellowbrick: 1.5
2023-04-29 19:01:54,173:INFO:              plotly: 5.9.0
2023-04-29 19:01:54,173:INFO:             kaleido: 0.2.1
2023-04-29 19:01:54,173:INFO:         statsmodels: 0.13.2
2023-04-29 19:01:54,173:INFO:              sktime: 0.17.1
2023-04-29 19:01:54,173:INFO:               tbats: 1.1.2
2023-04-29 19:01:54,173:INFO:            pmdarima: 2.0.3
2023-04-29 19:01:54,173:INFO:              psutil: 5.9.0
2023-04-29 19:01:54,173:INFO:PyCaret optional dependencies:
2023-04-29 19:01:54,174:INFO:                shap: 0.41.0
2023-04-29 19:01:54,174:INFO:           interpret: Not installed
2023-04-29 19:01:54,174:INFO:                umap: Not installed
2023-04-29 19:01:54,174:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:01:54,174:INFO:  explainerdashboard: Not installed
2023-04-29 19:01:54,174:INFO:             autoviz: Not installed
2023-04-29 19:01:54,174:INFO:           fairlearn: Not installed
2023-04-29 19:01:54,174:INFO:             xgboost: Not installed
2023-04-29 19:01:54,174:INFO:            catboost: Not installed
2023-04-29 19:01:54,174:INFO:              kmodes: Not installed
2023-04-29 19:01:54,174:INFO:             mlxtend: Not installed
2023-04-29 19:01:54,174:INFO:       statsforecast: Not installed
2023-04-29 19:01:54,174:INFO:        tune_sklearn: Not installed
2023-04-29 19:01:54,174:INFO:                 ray: Not installed
2023-04-29 19:01:54,174:INFO:            hyperopt: Not installed
2023-04-29 19:01:54,174:INFO:              optuna: Not installed
2023-04-29 19:01:54,174:INFO:               skopt: Not installed
2023-04-29 19:01:54,174:INFO:              mlflow: 2.2.1
2023-04-29 19:01:54,174:INFO:              gradio: Not installed
2023-04-29 19:01:54,174:INFO:             fastapi: Not installed
2023-04-29 19:01:54,174:INFO:             uvicorn: Not installed
2023-04-29 19:01:54,174:INFO:              m2cgen: Not installed
2023-04-29 19:01:54,174:INFO:           evidently: Not installed
2023-04-29 19:01:54,174:INFO:               fugue: Not installed
2023-04-29 19:01:54,174:INFO:           streamlit: 1.21.0
2023-04-29 19:01:54,174:INFO:             prophet: Not installed
2023-04-29 19:01:54,174:INFO:None
2023-04-29 19:01:54,174:INFO:Set up data.
2023-04-29 19:01:54,178:INFO:Set up train/test split.
2023-04-29 19:16:23,153:INFO:PyCaret RegressionExperiment
2023-04-29 19:16:23,154:INFO:Logging name: reg-default-name
2023-04-29 19:16:23,154:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 19:16:23,154:INFO:version 3.0.0
2023-04-29 19:16:23,154:INFO:Initializing setup()
2023-04-29 19:16:23,155:INFO:self.USI: 6a46
2023-04-29 19:16:23,155:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:16:23,156:INFO:Checking environment
2023-04-29 19:16:23,156:INFO:python_version: 3.9.13
2023-04-29 19:16:23,157:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:16:23,157:INFO:machine: AMD64
2023-04-29 19:16:23,158:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:16:23,158:INFO:Memory: svmem(total=16935899136, available=5909061632, percent=65.1, used=11026837504, free=5909061632)
2023-04-29 19:16:23,158:INFO:Physical Core: 4
2023-04-29 19:16:23,159:INFO:Logical Core: 8
2023-04-29 19:16:23,159:INFO:Checking libraries
2023-04-29 19:16:23,162:INFO:System:
2023-04-29 19:16:23,163:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:16:23,163:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:16:23,163:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:16:23,164:INFO:PyCaret required dependencies:
2023-04-29 19:16:23,164:INFO:                 pip: 22.2.2
2023-04-29 19:16:23,164:INFO:          setuptools: 63.4.1
2023-04-29 19:16:23,165:INFO:             pycaret: 3.0.0
2023-04-29 19:16:23,165:INFO:             IPython: 7.31.1
2023-04-29 19:16:23,165:INFO:          ipywidgets: 7.6.5
2023-04-29 19:16:23,165:INFO:                tqdm: 4.64.1
2023-04-29 19:16:23,166:INFO:               numpy: 1.21.5
2023-04-29 19:16:23,166:INFO:              pandas: 1.4.4
2023-04-29 19:16:23,166:INFO:              jinja2: 2.11.3
2023-04-29 19:16:23,166:INFO:               scipy: 1.9.1
2023-04-29 19:16:23,167:INFO:              joblib: 1.2.0
2023-04-29 19:16:23,167:INFO:             sklearn: 1.0.2
2023-04-29 19:16:23,167:INFO:                pyod: 1.0.9
2023-04-29 19:16:23,168:INFO:            imblearn: 0.10.1
2023-04-29 19:16:23,168:INFO:   category_encoders: 2.6.0
2023-04-29 19:16:23,168:INFO:            lightgbm: 3.3.5
2023-04-29 19:16:23,168:INFO:               numba: 0.55.1
2023-04-29 19:16:23,168:INFO:            requests: 2.28.1
2023-04-29 19:16:23,168:INFO:          matplotlib: 3.5.2
2023-04-29 19:16:23,169:INFO:          scikitplot: 0.3.7
2023-04-29 19:16:23,169:INFO:         yellowbrick: 1.5
2023-04-29 19:16:23,169:INFO:              plotly: 5.9.0
2023-04-29 19:16:23,170:INFO:             kaleido: 0.2.1
2023-04-29 19:16:23,170:INFO:         statsmodels: 0.13.2
2023-04-29 19:16:23,170:INFO:              sktime: 0.17.1
2023-04-29 19:16:23,170:INFO:               tbats: 1.1.2
2023-04-29 19:16:23,170:INFO:            pmdarima: 2.0.3
2023-04-29 19:16:23,170:INFO:              psutil: 5.9.0
2023-04-29 19:16:23,170:INFO:PyCaret optional dependencies:
2023-04-29 19:16:23,171:INFO:                shap: 0.41.0
2023-04-29 19:16:23,171:INFO:           interpret: Not installed
2023-04-29 19:16:23,171:INFO:                umap: Not installed
2023-04-29 19:16:23,171:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:16:23,171:INFO:  explainerdashboard: Not installed
2023-04-29 19:16:23,171:INFO:             autoviz: Not installed
2023-04-29 19:16:23,172:INFO:           fairlearn: Not installed
2023-04-29 19:16:23,172:INFO:             xgboost: Not installed
2023-04-29 19:16:23,172:INFO:            catboost: Not installed
2023-04-29 19:16:23,172:INFO:              kmodes: Not installed
2023-04-29 19:16:23,172:INFO:             mlxtend: Not installed
2023-04-29 19:16:23,172:INFO:       statsforecast: Not installed
2023-04-29 19:16:23,173:INFO:        tune_sklearn: Not installed
2023-04-29 19:16:23,173:INFO:                 ray: Not installed
2023-04-29 19:16:23,173:INFO:            hyperopt: Not installed
2023-04-29 19:16:23,173:INFO:              optuna: Not installed
2023-04-29 19:16:23,173:INFO:               skopt: Not installed
2023-04-29 19:16:23,174:INFO:              mlflow: 2.2.1
2023-04-29 19:16:23,174:INFO:              gradio: Not installed
2023-04-29 19:16:23,174:INFO:             fastapi: Not installed
2023-04-29 19:16:23,175:INFO:             uvicorn: Not installed
2023-04-29 19:16:23,175:INFO:              m2cgen: Not installed
2023-04-29 19:16:23,175:INFO:           evidently: Not installed
2023-04-29 19:16:23,175:INFO:               fugue: Not installed
2023-04-29 19:16:23,175:INFO:           streamlit: 1.21.0
2023-04-29 19:16:23,175:INFO:             prophet: Not installed
2023-04-29 19:16:23,175:INFO:None
2023-04-29 19:16:23,176:INFO:Set up data.
2023-04-29 19:16:23,180:INFO:Set up train/test split.
2023-04-29 19:16:23,184:INFO:Set up index.
2023-04-29 19:16:23,184:INFO:Set up folding strategy.
2023-04-29 19:16:23,184:INFO:Assigning column types.
2023-04-29 19:16:23,191:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:16:23,192:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,203:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,211:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,448:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,460:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,473:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,631:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 19:16:23,641:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,812:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,823:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,834:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:23,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:23,975:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 19:16:23,985:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,099:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,227:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 19:16:24,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,540:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:16:24,657:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,769:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:16:24,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,854:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 19:16:24,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:24,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,118:INFO:Preparing preprocessing pipeline...
2023-04-29 19:16:25,118:INFO:Set up simple imputation.
2023-04-29 19:16:25,119:INFO:Set up column name cleaning.
2023-04-29 19:16:25,140:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:16:25,143:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 19:16:25,143:INFO:Creating final display dataframe.
2023-04-29 19:16:25,213:INFO:Setup _display_container:                     Description             Value
0                    Session id              3412
1                        Target      Density_calc
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              6a46
2023-04-29 19:16:25,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:16:25,550:INFO:setup() successfully completed in 3.06s...............
2023-04-29 19:16:25,557:INFO:Initializing compare_models()
2023-04-29 19:16:25,557:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 19:16:25,557:INFO:Checking exceptions
2023-04-29 19:16:25,561:INFO:Preparing display monitor
2023-04-29 19:16:25,566:INFO:Initializing Linear Regression
2023-04-29 19:16:25,567:INFO:Total runtime is 1.6609827677408855e-05 minutes
2023-04-29 19:16:25,567:INFO:SubProcess create_model() called ==================================
2023-04-29 19:16:25,567:INFO:Initializing create_model()
2023-04-29 19:16:25,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:16:25,568:INFO:Checking exceptions
2023-04-29 19:16:25,568:INFO:Importing libraries
2023-04-29 19:16:25,568:INFO:Copying training dataset
2023-04-29 19:16:25,575:INFO:Defining folds
2023-04-29 19:16:25,576:INFO:Declaring metric variables
2023-04-29 19:16:25,576:INFO:Importing untrained model
2023-04-29 19:16:25,576:INFO:Linear Regression Imported successfully
2023-04-29 19:16:25,577:INFO:Starting cross validation
2023-04-29 19:16:25,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:16:38,914:INFO:Calculating mean and std
2023-04-29 19:16:38,915:INFO:Creating metrics dataframe
2023-04-29 19:16:39,936:INFO:Uploading results into container
2023-04-29 19:16:39,937:INFO:Uploading model into container now
2023-04-29 19:16:39,937:INFO:_master_model_container: 1
2023-04-29 19:16:39,937:INFO:_display_container: 2
2023-04-29 19:16:39,938:INFO:LinearRegression(n_jobs=-1)
2023-04-29 19:16:39,938:INFO:create_model() successfully completed......................................
2023-04-29 19:16:40,051:INFO:SubProcess create_model() end ==================================
2023-04-29 19:16:40,051:INFO:Creating metrics dataframe
2023-04-29 19:16:40,056:INFO:Initializing Lasso Regression
2023-04-29 19:16:40,056:INFO:Total runtime is 0.2414941112200419 minutes
2023-04-29 19:16:40,056:INFO:SubProcess create_model() called ==================================
2023-04-29 19:16:40,057:INFO:Initializing create_model()
2023-04-29 19:16:40,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:16:40,057:INFO:Checking exceptions
2023-04-29 19:16:40,057:INFO:Importing libraries
2023-04-29 19:16:40,057:INFO:Copying training dataset
2023-04-29 19:16:40,061:INFO:Defining folds
2023-04-29 19:16:40,061:INFO:Declaring metric variables
2023-04-29 19:16:40,062:INFO:Importing untrained model
2023-04-29 19:16:40,062:INFO:Lasso Regression Imported successfully
2023-04-29 19:16:40,063:INFO:Starting cross validation
2023-04-29 19:16:40,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:16:46,546:INFO:Calculating mean and std
2023-04-29 19:16:46,547:INFO:Creating metrics dataframe
2023-04-29 19:16:47,477:INFO:Uploading results into container
2023-04-29 19:16:47,478:INFO:Uploading model into container now
2023-04-29 19:16:47,478:INFO:_master_model_container: 2
2023-04-29 19:16:47,478:INFO:_display_container: 2
2023-04-29 19:16:47,479:INFO:Lasso(random_state=3412)
2023-04-29 19:16:47,479:INFO:create_model() successfully completed......................................
2023-04-29 19:16:47,614:INFO:SubProcess create_model() end ==================================
2023-04-29 19:16:47,614:INFO:Creating metrics dataframe
2023-04-29 19:16:47,618:INFO:Initializing Ridge Regression
2023-04-29 19:16:47,618:INFO:Total runtime is 0.36753191550572717 minutes
2023-04-29 19:16:47,618:INFO:SubProcess create_model() called ==================================
2023-04-29 19:16:47,618:INFO:Initializing create_model()
2023-04-29 19:16:47,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:16:47,619:INFO:Checking exceptions
2023-04-29 19:16:47,619:INFO:Importing libraries
2023-04-29 19:16:47,619:INFO:Copying training dataset
2023-04-29 19:16:47,624:INFO:Defining folds
2023-04-29 19:16:47,625:INFO:Declaring metric variables
2023-04-29 19:16:47,625:INFO:Importing untrained model
2023-04-29 19:16:47,626:INFO:Ridge Regression Imported successfully
2023-04-29 19:16:47,627:INFO:Starting cross validation
2023-04-29 19:16:47,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:16:54,218:INFO:Calculating mean and std
2023-04-29 19:16:54,219:INFO:Creating metrics dataframe
2023-04-29 19:16:55,432:INFO:Uploading results into container
2023-04-29 19:16:55,433:INFO:Uploading model into container now
2023-04-29 19:16:55,434:INFO:_master_model_container: 3
2023-04-29 19:16:55,434:INFO:_display_container: 2
2023-04-29 19:16:55,434:INFO:Ridge(random_state=3412)
2023-04-29 19:16:55,434:INFO:create_model() successfully completed......................................
2023-04-29 19:16:55,547:INFO:SubProcess create_model() end ==================================
2023-04-29 19:16:55,547:INFO:Creating metrics dataframe
2023-04-29 19:16:55,559:INFO:Initializing Elastic Net
2023-04-29 19:16:55,559:INFO:Total runtime is 0.4998792886734009 minutes
2023-04-29 19:16:55,560:INFO:SubProcess create_model() called ==================================
2023-04-29 19:16:55,561:INFO:Initializing create_model()
2023-04-29 19:16:55,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:16:55,561:INFO:Checking exceptions
2023-04-29 19:16:55,561:INFO:Importing libraries
2023-04-29 19:16:55,561:INFO:Copying training dataset
2023-04-29 19:16:55,571:INFO:Defining folds
2023-04-29 19:16:55,571:INFO:Declaring metric variables
2023-04-29 19:16:55,572:INFO:Importing untrained model
2023-04-29 19:16:55,573:INFO:Elastic Net Imported successfully
2023-04-29 19:16:55,574:INFO:Starting cross validation
2023-04-29 19:16:55,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:02,376:INFO:Calculating mean and std
2023-04-29 19:17:02,377:INFO:Creating metrics dataframe
2023-04-29 19:17:03,183:INFO:Uploading results into container
2023-04-29 19:17:03,184:INFO:Uploading model into container now
2023-04-29 19:17:03,184:INFO:_master_model_container: 4
2023-04-29 19:17:03,185:INFO:_display_container: 2
2023-04-29 19:17:03,185:INFO:ElasticNet(random_state=3412)
2023-04-29 19:17:03,185:INFO:create_model() successfully completed......................................
2023-04-29 19:17:03,340:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:03,340:INFO:Creating metrics dataframe
2023-04-29 19:17:03,350:INFO:Initializing Least Angle Regression
2023-04-29 19:17:03,351:INFO:Total runtime is 0.6297416607538859 minutes
2023-04-29 19:17:03,351:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:03,351:INFO:Initializing create_model()
2023-04-29 19:17:03,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:03,352:INFO:Checking exceptions
2023-04-29 19:17:03,352:INFO:Importing libraries
2023-04-29 19:17:03,352:INFO:Copying training dataset
2023-04-29 19:17:03,359:INFO:Defining folds
2023-04-29 19:17:03,359:INFO:Declaring metric variables
2023-04-29 19:17:03,359:INFO:Importing untrained model
2023-04-29 19:17:03,359:INFO:Least Angle Regression Imported successfully
2023-04-29 19:17:03,360:INFO:Starting cross validation
2023-04-29 19:17:03,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:03,486:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,496:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,504:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,529:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,541:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,558:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,565:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:03,580:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:04,865:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:04,909:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:09,843:INFO:Calculating mean and std
2023-04-29 19:17:09,844:INFO:Creating metrics dataframe
2023-04-29 19:17:11,434:INFO:Uploading results into container
2023-04-29 19:17:11,435:INFO:Uploading model into container now
2023-04-29 19:17:11,436:INFO:_master_model_container: 5
2023-04-29 19:17:11,436:INFO:_display_container: 2
2023-04-29 19:17:11,437:INFO:Lars(random_state=3412)
2023-04-29 19:17:11,437:INFO:create_model() successfully completed......................................
2023-04-29 19:17:11,561:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:11,562:INFO:Creating metrics dataframe
2023-04-29 19:17:11,572:INFO:Initializing Lasso Least Angle Regression
2023-04-29 19:17:11,572:INFO:Total runtime is 0.7667596459388734 minutes
2023-04-29 19:17:11,572:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:11,573:INFO:Initializing create_model()
2023-04-29 19:17:11,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:11,573:INFO:Checking exceptions
2023-04-29 19:17:11,573:INFO:Importing libraries
2023-04-29 19:17:11,574:INFO:Copying training dataset
2023-04-29 19:17:11,583:INFO:Defining folds
2023-04-29 19:17:11,583:INFO:Declaring metric variables
2023-04-29 19:17:11,584:INFO:Importing untrained model
2023-04-29 19:17:11,585:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 19:17:11,586:INFO:Starting cross validation
2023-04-29 19:17:11,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:11,718:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,726:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,751:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,760:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,771:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,787:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,800:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:11,814:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:13,076:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:13,131:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:17:18,202:INFO:Calculating mean and std
2023-04-29 19:17:18,203:INFO:Creating metrics dataframe
2023-04-29 19:17:18,962:INFO:Uploading results into container
2023-04-29 19:17:18,962:INFO:Uploading model into container now
2023-04-29 19:17:18,962:INFO:_master_model_container: 6
2023-04-29 19:17:18,962:INFO:_display_container: 2
2023-04-29 19:17:18,963:INFO:LassoLars(random_state=3412)
2023-04-29 19:17:18,963:INFO:create_model() successfully completed......................................
2023-04-29 19:17:19,102:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:19,102:INFO:Creating metrics dataframe
2023-04-29 19:17:19,107:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 19:17:19,107:INFO:Total runtime is 0.8923380335172018 minutes
2023-04-29 19:17:19,107:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:19,107:INFO:Initializing create_model()
2023-04-29 19:17:19,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:19,107:INFO:Checking exceptions
2023-04-29 19:17:19,107:INFO:Importing libraries
2023-04-29 19:17:19,107:INFO:Copying training dataset
2023-04-29 19:17:19,111:INFO:Defining folds
2023-04-29 19:17:19,111:INFO:Declaring metric variables
2023-04-29 19:17:19,111:INFO:Importing untrained model
2023-04-29 19:17:19,112:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 19:17:19,112:INFO:Starting cross validation
2023-04-29 19:17:19,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:19,211:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,217:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,231:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,244:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,250:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,265:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,280:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:19,294:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:20,639:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:20,646:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:17:25,639:INFO:Calculating mean and std
2023-04-29 19:17:25,640:INFO:Creating metrics dataframe
2023-04-29 19:17:27,049:INFO:Uploading results into container
2023-04-29 19:17:27,050:INFO:Uploading model into container now
2023-04-29 19:17:27,050:INFO:_master_model_container: 7
2023-04-29 19:17:27,050:INFO:_display_container: 2
2023-04-29 19:17:27,051:INFO:OrthogonalMatchingPursuit()
2023-04-29 19:17:27,051:INFO:create_model() successfully completed......................................
2023-04-29 19:17:27,179:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:27,179:INFO:Creating metrics dataframe
2023-04-29 19:17:27,184:INFO:Initializing Bayesian Ridge
2023-04-29 19:17:27,184:INFO:Total runtime is 1.0269534230232238 minutes
2023-04-29 19:17:27,184:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:27,185:INFO:Initializing create_model()
2023-04-29 19:17:27,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:27,185:INFO:Checking exceptions
2023-04-29 19:17:27,185:INFO:Importing libraries
2023-04-29 19:17:27,185:INFO:Copying training dataset
2023-04-29 19:17:27,188:INFO:Defining folds
2023-04-29 19:17:27,188:INFO:Declaring metric variables
2023-04-29 19:17:27,188:INFO:Importing untrained model
2023-04-29 19:17:27,189:INFO:Bayesian Ridge Imported successfully
2023-04-29 19:17:27,190:INFO:Starting cross validation
2023-04-29 19:17:27,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:33,680:INFO:Calculating mean and std
2023-04-29 19:17:33,681:INFO:Creating metrics dataframe
2023-04-29 19:17:34,440:INFO:Uploading results into container
2023-04-29 19:17:34,441:INFO:Uploading model into container now
2023-04-29 19:17:34,442:INFO:_master_model_container: 8
2023-04-29 19:17:34,442:INFO:_display_container: 2
2023-04-29 19:17:34,442:INFO:BayesianRidge()
2023-04-29 19:17:34,442:INFO:create_model() successfully completed......................................
2023-04-29 19:17:34,567:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:34,568:INFO:Creating metrics dataframe
2023-04-29 19:17:34,583:INFO:Initializing Passive Aggressive Regressor
2023-04-29 19:17:34,583:INFO:Total runtime is 1.1502835234006246 minutes
2023-04-29 19:17:34,585:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:34,585:INFO:Initializing create_model()
2023-04-29 19:17:34,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:34,585:INFO:Checking exceptions
2023-04-29 19:17:34,585:INFO:Importing libraries
2023-04-29 19:17:34,585:INFO:Copying training dataset
2023-04-29 19:17:34,599:INFO:Defining folds
2023-04-29 19:17:34,599:INFO:Declaring metric variables
2023-04-29 19:17:34,600:INFO:Importing untrained model
2023-04-29 19:17:34,601:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 19:17:34,602:INFO:Starting cross validation
2023-04-29 19:17:34,604:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:41,242:INFO:Calculating mean and std
2023-04-29 19:17:41,243:INFO:Creating metrics dataframe
2023-04-29 19:17:42,361:INFO:Uploading results into container
2023-04-29 19:17:42,362:INFO:Uploading model into container now
2023-04-29 19:17:42,363:INFO:_master_model_container: 9
2023-04-29 19:17:42,363:INFO:_display_container: 2
2023-04-29 19:17:42,364:INFO:PassiveAggressiveRegressor(random_state=3412)
2023-04-29 19:17:42,364:INFO:create_model() successfully completed......................................
2023-04-29 19:17:42,472:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:42,472:INFO:Creating metrics dataframe
2023-04-29 19:17:42,481:INFO:Initializing Huber Regressor
2023-04-29 19:17:42,481:INFO:Total runtime is 1.2819186290105185 minutes
2023-04-29 19:17:42,482:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:42,482:INFO:Initializing create_model()
2023-04-29 19:17:42,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:42,484:INFO:Checking exceptions
2023-04-29 19:17:42,484:INFO:Importing libraries
2023-04-29 19:17:42,484:INFO:Copying training dataset
2023-04-29 19:17:42,488:INFO:Defining folds
2023-04-29 19:17:42,490:INFO:Declaring metric variables
2023-04-29 19:17:42,490:INFO:Importing untrained model
2023-04-29 19:17:42,491:INFO:Huber Regressor Imported successfully
2023-04-29 19:17:42,491:INFO:Starting cross validation
2023-04-29 19:17:42,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:42,649:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 19:17:49,033:INFO:Calculating mean and std
2023-04-29 19:17:49,034:INFO:Creating metrics dataframe
2023-04-29 19:17:49,951:INFO:Uploading results into container
2023-04-29 19:17:49,952:INFO:Uploading model into container now
2023-04-29 19:17:49,953:INFO:_master_model_container: 10
2023-04-29 19:17:49,953:INFO:_display_container: 2
2023-04-29 19:17:49,953:INFO:HuberRegressor()
2023-04-29 19:17:49,953:INFO:create_model() successfully completed......................................
2023-04-29 19:17:50,082:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:50,082:INFO:Creating metrics dataframe
2023-04-29 19:17:50,086:INFO:Initializing K Neighbors Regressor
2023-04-29 19:17:50,086:INFO:Total runtime is 1.4086563467979432 minutes
2023-04-29 19:17:50,086:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:50,087:INFO:Initializing create_model()
2023-04-29 19:17:50,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:50,088:INFO:Checking exceptions
2023-04-29 19:17:50,088:INFO:Importing libraries
2023-04-29 19:17:50,088:INFO:Copying training dataset
2023-04-29 19:17:50,091:INFO:Defining folds
2023-04-29 19:17:50,091:INFO:Declaring metric variables
2023-04-29 19:17:50,091:INFO:Importing untrained model
2023-04-29 19:17:50,092:INFO:K Neighbors Regressor Imported successfully
2023-04-29 19:17:50,092:INFO:Starting cross validation
2023-04-29 19:17:50,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:17:56,648:INFO:Calculating mean and std
2023-04-29 19:17:56,649:INFO:Creating metrics dataframe
2023-04-29 19:17:57,517:INFO:Uploading results into container
2023-04-29 19:17:57,517:INFO:Uploading model into container now
2023-04-29 19:17:57,517:INFO:_master_model_container: 11
2023-04-29 19:17:57,517:INFO:_display_container: 2
2023-04-29 19:17:57,519:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 19:17:57,519:INFO:create_model() successfully completed......................................
2023-04-29 19:17:57,663:INFO:SubProcess create_model() end ==================================
2023-04-29 19:17:57,663:INFO:Creating metrics dataframe
2023-04-29 19:17:57,669:INFO:Initializing Decision Tree Regressor
2023-04-29 19:17:57,669:INFO:Total runtime is 1.5350382208824158 minutes
2023-04-29 19:17:57,669:INFO:SubProcess create_model() called ==================================
2023-04-29 19:17:57,669:INFO:Initializing create_model()
2023-04-29 19:17:57,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:17:57,669:INFO:Checking exceptions
2023-04-29 19:17:57,669:INFO:Importing libraries
2023-04-29 19:17:57,669:INFO:Copying training dataset
2023-04-29 19:17:57,673:INFO:Defining folds
2023-04-29 19:17:57,674:INFO:Declaring metric variables
2023-04-29 19:17:57,674:INFO:Importing untrained model
2023-04-29 19:17:57,677:INFO:Decision Tree Regressor Imported successfully
2023-04-29 19:17:57,677:INFO:Starting cross validation
2023-04-29 19:17:57,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:04,282:INFO:Calculating mean and std
2023-04-29 19:18:04,284:INFO:Creating metrics dataframe
2023-04-29 19:18:05,415:INFO:Uploading results into container
2023-04-29 19:18:05,417:INFO:Uploading model into container now
2023-04-29 19:18:05,418:INFO:_master_model_container: 12
2023-04-29 19:18:05,418:INFO:_display_container: 2
2023-04-29 19:18:05,419:INFO:DecisionTreeRegressor(random_state=3412)
2023-04-29 19:18:05,419:INFO:create_model() successfully completed......................................
2023-04-29 19:18:05,548:INFO:SubProcess create_model() end ==================================
2023-04-29 19:18:05,548:INFO:Creating metrics dataframe
2023-04-29 19:18:05,553:INFO:Initializing Random Forest Regressor
2023-04-29 19:18:05,553:INFO:Total runtime is 1.6664455175399782 minutes
2023-04-29 19:18:05,553:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:05,553:INFO:Initializing create_model()
2023-04-29 19:18:05,553:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:05,553:INFO:Checking exceptions
2023-04-29 19:18:05,553:INFO:Importing libraries
2023-04-29 19:18:05,553:INFO:Copying training dataset
2023-04-29 19:18:05,557:INFO:Defining folds
2023-04-29 19:18:05,557:INFO:Declaring metric variables
2023-04-29 19:18:05,557:INFO:Importing untrained model
2023-04-29 19:18:05,558:INFO:Random Forest Regressor Imported successfully
2023-04-29 19:18:05,558:INFO:Starting cross validation
2023-04-29 19:18:05,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:13,888:INFO:Calculating mean and std
2023-04-29 19:18:13,889:INFO:Creating metrics dataframe
2023-04-29 19:18:14,909:INFO:Uploading results into container
2023-04-29 19:18:14,910:INFO:Uploading model into container now
2023-04-29 19:18:14,911:INFO:_master_model_container: 13
2023-04-29 19:18:14,912:INFO:_display_container: 2
2023-04-29 19:18:14,912:INFO:RandomForestRegressor(n_jobs=-1, random_state=3412)
2023-04-29 19:18:14,912:INFO:create_model() successfully completed......................................
2023-04-29 19:18:15,054:INFO:SubProcess create_model() end ==================================
2023-04-29 19:18:15,054:INFO:Creating metrics dataframe
2023-04-29 19:18:15,067:INFO:Initializing Extra Trees Regressor
2023-04-29 19:18:15,067:INFO:Total runtime is 1.8250072876612347 minutes
2023-04-29 19:18:15,068:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:15,068:INFO:Initializing create_model()
2023-04-29 19:18:15,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:15,069:INFO:Checking exceptions
2023-04-29 19:18:15,069:INFO:Importing libraries
2023-04-29 19:18:15,069:INFO:Copying training dataset
2023-04-29 19:18:15,078:INFO:Defining folds
2023-04-29 19:18:15,079:INFO:Declaring metric variables
2023-04-29 19:18:15,079:INFO:Importing untrained model
2023-04-29 19:18:15,080:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:18:15,081:INFO:Starting cross validation
2023-04-29 19:18:15,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:20,904:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:18:20,905:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:18:20,905:INFO:Data columns (total 8 columns):
2023-04-29 19:18:20,905:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:18:20,905:INFO:---  ------          --------------  -----  
2023-04-29 19:18:20,905:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:18:20,905:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:18:20,905:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:18:20,905:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:18:20,905:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:18:20,906:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:18:20,906:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:18:20,906:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:18:20,906:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:18:20,906:INFO:memory usage: 79.8 KB
2023-04-29 19:18:24,581:INFO:Calculating mean and std
2023-04-29 19:18:24,583:INFO:Creating metrics dataframe
2023-04-29 19:18:26,051:INFO:Uploading results into container
2023-04-29 19:18:26,052:INFO:Uploading model into container now
2023-04-29 19:18:26,052:INFO:_master_model_container: 14
2023-04-29 19:18:26,052:INFO:_display_container: 2
2023-04-29 19:18:26,053:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3412)
2023-04-29 19:18:26,053:INFO:create_model() successfully completed......................................
2023-04-29 19:18:26,211:INFO:SubProcess create_model() end ==================================
2023-04-29 19:18:26,211:INFO:Creating metrics dataframe
2023-04-29 19:18:26,227:INFO:Initializing AdaBoost Regressor
2023-04-29 19:18:26,227:INFO:Total runtime is 2.0110037525494895 minutes
2023-04-29 19:18:26,228:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:26,229:INFO:Initializing create_model()
2023-04-29 19:18:26,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:26,229:INFO:Checking exceptions
2023-04-29 19:18:26,229:INFO:Importing libraries
2023-04-29 19:18:26,230:INFO:Copying training dataset
2023-04-29 19:18:26,237:INFO:Defining folds
2023-04-29 19:18:26,237:INFO:Declaring metric variables
2023-04-29 19:18:26,238:INFO:Importing untrained model
2023-04-29 19:18:26,239:INFO:AdaBoost Regressor Imported successfully
2023-04-29 19:18:26,240:INFO:Starting cross validation
2023-04-29 19:18:26,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:27,846:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:18:27,846:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:18:27,846:INFO:Data columns (total 8 columns):
2023-04-29 19:18:27,846:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:18:27,846:INFO:---  ------          --------------  -----  
2023-04-29 19:18:27,846:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:18:27,847:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:18:27,847:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:18:27,848:INFO:memory usage: 79.8 KB
2023-04-29 19:18:29,503:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:18:29,504:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:18:29,504:INFO:Data columns (total 8 columns):
2023-04-29 19:18:29,504:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:18:29,504:INFO:---  ------          --------------  -----  
2023-04-29 19:18:29,504:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:18:29,504:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:18:29,504:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:18:29,504:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:18:29,504:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:18:29,504:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:18:29,505:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:18:29,505:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:18:29,505:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:18:29,505:INFO:memory usage: 79.8 KB
2023-04-29 19:18:30,930:INFO:PyCaret RegressionExperiment
2023-04-29 19:18:30,930:INFO:Logging name: reg-default-name
2023-04-29 19:18:30,931:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 19:18:30,931:INFO:version 3.0.0
2023-04-29 19:18:30,931:INFO:Initializing setup()
2023-04-29 19:18:30,931:INFO:self.USI: 0eaa
2023-04-29 19:18:30,931:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:18:30,931:INFO:Checking environment
2023-04-29 19:18:30,932:INFO:python_version: 3.9.13
2023-04-29 19:18:30,932:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:18:30,932:INFO:machine: AMD64
2023-04-29 19:18:30,932:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:18:30,932:INFO:Memory: svmem(total=16935899136, available=4953960448, percent=70.7, used=11981938688, free=4953960448)
2023-04-29 19:18:30,933:INFO:Physical Core: 4
2023-04-29 19:18:30,933:INFO:Logical Core: 8
2023-04-29 19:18:30,933:INFO:Checking libraries
2023-04-29 19:18:30,933:INFO:System:
2023-04-29 19:18:30,934:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:18:30,934:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:18:30,934:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:18:30,934:INFO:PyCaret required dependencies:
2023-04-29 19:18:30,934:INFO:                 pip: 22.2.2
2023-04-29 19:18:30,934:INFO:          setuptools: 63.4.1
2023-04-29 19:18:30,935:INFO:             pycaret: 3.0.0
2023-04-29 19:18:30,935:INFO:             IPython: 7.31.1
2023-04-29 19:18:30,935:INFO:          ipywidgets: 7.6.5
2023-04-29 19:18:30,935:INFO:                tqdm: 4.64.1
2023-04-29 19:18:30,935:INFO:               numpy: 1.21.5
2023-04-29 19:18:30,935:INFO:              pandas: 1.4.4
2023-04-29 19:18:30,935:INFO:              jinja2: 2.11.3
2023-04-29 19:18:30,936:INFO:               scipy: 1.9.1
2023-04-29 19:18:30,936:INFO:              joblib: 1.2.0
2023-04-29 19:18:30,936:INFO:             sklearn: 1.0.2
2023-04-29 19:18:30,936:INFO:                pyod: 1.0.9
2023-04-29 19:18:30,936:INFO:            imblearn: 0.10.1
2023-04-29 19:18:30,937:INFO:   category_encoders: 2.6.0
2023-04-29 19:18:30,937:INFO:            lightgbm: 3.3.5
2023-04-29 19:18:30,937:INFO:               numba: 0.55.1
2023-04-29 19:18:30,937:INFO:            requests: 2.28.1
2023-04-29 19:18:30,937:INFO:          matplotlib: 3.5.2
2023-04-29 19:18:30,937:INFO:          scikitplot: 0.3.7
2023-04-29 19:18:30,938:INFO:         yellowbrick: 1.5
2023-04-29 19:18:30,938:INFO:              plotly: 5.9.0
2023-04-29 19:18:30,938:INFO:             kaleido: 0.2.1
2023-04-29 19:18:30,938:INFO:         statsmodels: 0.13.2
2023-04-29 19:18:30,938:INFO:              sktime: 0.17.1
2023-04-29 19:18:30,938:INFO:               tbats: 1.1.2
2023-04-29 19:18:30,939:INFO:            pmdarima: 2.0.3
2023-04-29 19:18:30,939:INFO:              psutil: 5.9.0
2023-04-29 19:18:30,939:INFO:PyCaret optional dependencies:
2023-04-29 19:18:30,939:INFO:                shap: 0.41.0
2023-04-29 19:18:30,939:INFO:           interpret: Not installed
2023-04-29 19:18:30,940:INFO:                umap: Not installed
2023-04-29 19:18:30,940:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:18:30,940:INFO:  explainerdashboard: Not installed
2023-04-29 19:18:30,940:INFO:             autoviz: Not installed
2023-04-29 19:18:30,940:INFO:           fairlearn: Not installed
2023-04-29 19:18:30,941:INFO:             xgboost: Not installed
2023-04-29 19:18:30,941:INFO:            catboost: Not installed
2023-04-29 19:18:30,941:INFO:              kmodes: Not installed
2023-04-29 19:18:30,941:INFO:             mlxtend: Not installed
2023-04-29 19:18:30,941:INFO:       statsforecast: Not installed
2023-04-29 19:18:30,941:INFO:        tune_sklearn: Not installed
2023-04-29 19:18:30,941:INFO:                 ray: Not installed
2023-04-29 19:18:30,942:INFO:            hyperopt: Not installed
2023-04-29 19:18:30,942:INFO:              optuna: Not installed
2023-04-29 19:18:30,942:INFO:               skopt: Not installed
2023-04-29 19:18:30,942:INFO:              mlflow: 2.2.1
2023-04-29 19:18:30,942:INFO:              gradio: Not installed
2023-04-29 19:18:30,942:INFO:             fastapi: Not installed
2023-04-29 19:18:30,943:INFO:             uvicorn: Not installed
2023-04-29 19:18:30,943:INFO:              m2cgen: Not installed
2023-04-29 19:18:30,943:INFO:           evidently: Not installed
2023-04-29 19:18:30,943:INFO:               fugue: Not installed
2023-04-29 19:18:30,943:INFO:           streamlit: 1.21.0
2023-04-29 19:18:30,943:INFO:             prophet: Not installed
2023-04-29 19:18:30,944:INFO:None
2023-04-29 19:18:30,944:INFO:Set up data.
2023-04-29 19:18:30,954:INFO:Set up train/test split.
2023-04-29 19:18:30,961:INFO:Set up index.
2023-04-29 19:18:30,961:INFO:Set up folding strategy.
2023-04-29 19:18:30,961:INFO:Assigning column types.
2023-04-29 19:18:30,967:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:18:30,968:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:18:30,977:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:18:30,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,192:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,201:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,207:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,382:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 19:18:31,393:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,619:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,631:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,765:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 19:18:31,774:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:31,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:31,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,174:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 19:18:32,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,426:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:18:32,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:18:32,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,720:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 19:18:32,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:32,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,084:INFO:Preparing preprocessing pipeline...
2023-04-29 19:18:33,084:INFO:Set up simple imputation.
2023-04-29 19:18:33,084:INFO:Set up column name cleaning.
2023-04-29 19:18:33,126:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:18:33,133:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 19:18:33,133:INFO:Creating final display dataframe.
2023-04-29 19:18:33,274:INFO:Setup _display_container:                     Description             Value
0                    Session id              8267
1                        Target      Density_calc
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0eaa
2023-04-29 19:18:33,278:INFO:                    Description             Value
2023-04-29 19:18:33,279:INFO:0                    Session id              8267
2023-04-29 19:18:33,279:INFO:1                        Target      Density_calc
2023-04-29 19:18:33,279:INFO:2                   Target type        Regression
2023-04-29 19:18:33,280:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:18:33,280:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:18:33,281:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:18:33,281:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:18:33,282:INFO:7              Numeric features                 7
2023-04-29 19:18:33,282:INFO:8                    Preprocess              True
2023-04-29 19:18:33,282:INFO:9               Imputation type            simple
2023-04-29 19:18:33,282:INFO:10           Numeric imputation              mean
2023-04-29 19:18:33,283:INFO:11       Categorical imputation              mode
2023-04-29 19:18:33,283:INFO:12               Fold Generator             KFold
2023-04-29 19:18:33,284:INFO:13                  Fold Number                10
2023-04-29 19:18:33,284:INFO:14                     CPU Jobs                -1
2023-04-29 19:18:33,284:INFO:15                      Use GPU             False
2023-04-29 19:18:33,284:INFO:16               Log Experiment             False
2023-04-29 19:18:33,285:INFO:17              Experiment Name  reg-default-name
2023-04-29 19:18:33,285:INFO:18                          USI              0eaa
2023-04-29 19:18:33,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:18:33,632:INFO:setup() successfully completed in 4.12s...............
2023-04-29 19:18:33,638:INFO:Initializing compare_models()
2023-04-29 19:18:33,638:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 19:18:33,638:INFO:Checking exceptions
2023-04-29 19:18:33,642:INFO:Preparing display monitor
2023-04-29 19:18:33,647:WARNING:
2023-04-29 19:18:33,647:WARNING:Processing:   0%|                     | 0/77 [00:00<?, ?it/s]
2023-04-29 19:18:33,647:WARNING:[A
2023-04-29 19:18:33,648:INFO:Initializing Linear Regression
2023-04-29 19:18:33,648:INFO:Total runtime is 0.0 minutes
2023-04-29 19:18:33,648:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:33,649:INFO:Initializing create_model()
2023-04-29 19:18:33,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:33,649:INFO:Checking exceptions
2023-04-29 19:18:33,649:INFO:Importing libraries
2023-04-29 19:18:33,649:INFO:Copying training dataset
2023-04-29 19:18:33,656:INFO:Defining folds
2023-04-29 19:18:33,656:INFO:Declaring metric variables
2023-04-29 19:18:33,656:INFO:Importing untrained model
2023-04-29 19:18:33,657:INFO:Linear Regression Imported successfully
2023-04-29 19:18:33,657:INFO:Starting cross validation
2023-04-29 19:18:33,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:38,837:INFO:Calculating mean and std
2023-04-29 19:18:38,839:INFO:Creating metrics dataframe
2023-04-29 19:18:39,600:INFO:Uploading results into container
2023-04-29 19:18:39,601:INFO:Uploading model into container now
2023-04-29 19:18:39,602:INFO:_master_model_container: 15
2023-04-29 19:18:39,603:INFO:_display_container: 2
2023-04-29 19:18:39,603:INFO:AdaBoostRegressor(random_state=3412)
2023-04-29 19:18:39,603:INFO:create_model() successfully completed......................................
2023-04-29 19:18:39,764:INFO:SubProcess create_model() end ==================================
2023-04-29 19:18:39,765:INFO:Creating metrics dataframe
2023-04-29 19:18:39,777:INFO:Initializing Gradient Boosting Regressor
2023-04-29 19:18:39,777:INFO:Total runtime is 2.2368370016415917 minutes
2023-04-29 19:18:39,777:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:39,778:INFO:Initializing create_model()
2023-04-29 19:18:39,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:39,778:INFO:Checking exceptions
2023-04-29 19:18:39,779:INFO:Importing libraries
2023-04-29 19:18:39,779:INFO:Copying training dataset
2023-04-29 19:18:39,788:INFO:Defining folds
2023-04-29 19:18:39,788:INFO:Declaring metric variables
2023-04-29 19:18:39,789:INFO:Importing untrained model
2023-04-29 19:18:39,790:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 19:18:39,791:INFO:Starting cross validation
2023-04-29 19:18:39,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:47,550:INFO:Calculating mean and std
2023-04-29 19:18:47,551:WARNING:
2023-04-29 19:18:47,552:WARNING:Processing:   6%|8            | 5/77 [00:13<03:20,  2.78s/it]
2023-04-29 19:18:47,552:WARNING:[A
2023-04-29 19:18:47,552:INFO:Creating metrics dataframe
2023-04-29 19:18:48,365:WARNING:
2023-04-29 19:18:48,366:WARNING:Processing:   8%|#            | 6/77 [00:14<02:46,  2.34s/it]
2023-04-29 19:18:48,366:WARNING:[A
2023-04-29 19:18:48,366:INFO:Uploading results into container
2023-04-29 19:18:48,366:INFO:Uploading model into container now
2023-04-29 19:18:48,367:INFO:_master_model_container: 1
2023-04-29 19:18:48,367:INFO:_display_container: 2
2023-04-29 19:18:48,367:INFO:LinearRegression(n_jobs=-1)
2023-04-29 19:18:48,367:INFO:create_model() successfully completed......................................
2023-04-29 19:18:48,484:INFO:SubProcess create_model() end ==================================
2023-04-29 19:18:48,485:INFO:Creating metrics dataframe
2023-04-29 19:18:48,494:INFO:Initializing Lasso Regression
2023-04-29 19:18:48,494:INFO:Total runtime is 0.24742141564687092 minutes
2023-04-29 19:18:48,494:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:48,495:INFO:Initializing create_model()
2023-04-29 19:18:48,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:48,495:INFO:Checking exceptions
2023-04-29 19:18:48,495:INFO:Importing libraries
2023-04-29 19:18:48,495:INFO:Copying training dataset
2023-04-29 19:18:48,499:WARNING:
2023-04-29 19:18:48,499:WARNING:Processing:   9%|#1           | 7/77 [00:14<02:06,  1.81s/it]
2023-04-29 19:18:48,499:WARNING:[A
2023-04-29 19:18:48,499:INFO:Defining folds
2023-04-29 19:18:48,500:INFO:Declaring metric variables
2023-04-29 19:18:48,500:INFO:Importing untrained model
2023-04-29 19:18:48,500:INFO:Lasso Regression Imported successfully
2023-04-29 19:18:48,501:INFO:Starting cross validation
2023-04-29 19:18:48,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:18:55,295:INFO:Calculating mean and std
2023-04-29 19:18:55,296:INFO:Creating metrics dataframe
2023-04-29 19:18:56,046:INFO:Uploading results into container
2023-04-29 19:18:56,046:INFO:Uploading model into container now
2023-04-29 19:18:56,047:INFO:_master_model_container: 16
2023-04-29 19:18:56,047:INFO:_display_container: 2
2023-04-29 19:18:56,047:INFO:GradientBoostingRegressor(random_state=3412)
2023-04-29 19:18:56,047:INFO:create_model() successfully completed......................................
2023-04-29 19:18:56,140:INFO:SubProcess create_model() end ==================================
2023-04-29 19:18:56,140:INFO:Creating metrics dataframe
2023-04-29 19:18:56,143:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:18:56,144:INFO:Total runtime is 2.509610533714295 minutes
2023-04-29 19:18:56,144:INFO:SubProcess create_model() called ==================================
2023-04-29 19:18:56,144:INFO:Initializing create_model()
2023-04-29 19:18:56,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:18:56,144:INFO:Checking exceptions
2023-04-29 19:18:56,144:INFO:Importing libraries
2023-04-29 19:18:56,144:INFO:Copying training dataset
2023-04-29 19:18:56,148:INFO:Defining folds
2023-04-29 19:18:56,148:INFO:Declaring metric variables
2023-04-29 19:18:56,148:INFO:Importing untrained model
2023-04-29 19:18:56,149:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:18:56,149:INFO:Starting cross validation
2023-04-29 19:18:56,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:03,878:INFO:Calculating mean and std
2023-04-29 19:19:03,879:WARNING:
2023-04-29 19:19:03,879:WARNING:Processing:  12%|#5           | 9/77 [00:30<04:46,  4.21s/it]
2023-04-29 19:19:03,879:WARNING:[A
2023-04-29 19:19:03,879:INFO:Creating metrics dataframe
2023-04-29 19:19:04,617:WARNING:
2023-04-29 19:19:04,618:WARNING:Processing:  13%|#5          | 10/77 [00:30<03:49,  3.43s/it]
2023-04-29 19:19:04,618:WARNING:[A
2023-04-29 19:19:04,618:INFO:Uploading results into container
2023-04-29 19:19:04,618:INFO:Uploading model into container now
2023-04-29 19:19:04,619:INFO:_master_model_container: 2
2023-04-29 19:19:04,619:INFO:_display_container: 2
2023-04-29 19:19:04,619:INFO:Lasso(random_state=8267)
2023-04-29 19:19:04,619:INFO:create_model() successfully completed......................................
2023-04-29 19:19:04,707:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:04,707:INFO:Creating metrics dataframe
2023-04-29 19:19:04,711:INFO:Initializing Ridge Regression
2023-04-29 19:19:04,711:INFO:Total runtime is 0.5177173932393392 minutes
2023-04-29 19:19:04,711:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:04,711:INFO:Initializing create_model()
2023-04-29 19:19:04,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:04,711:INFO:Checking exceptions
2023-04-29 19:19:04,711:INFO:Importing libraries
2023-04-29 19:19:04,711:INFO:Copying training dataset
2023-04-29 19:19:04,714:INFO:Defining folds
2023-04-29 19:19:04,714:INFO:Declaring metric variables
2023-04-29 19:19:04,714:INFO:Importing untrained model
2023-04-29 19:19:04,715:INFO:Ridge Regression Imported successfully
2023-04-29 19:19:04,716:INFO:Starting cross validation
2023-04-29 19:19:04,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:10,670:INFO:Calculating mean and std
2023-04-29 19:19:10,671:INFO:Creating metrics dataframe
2023-04-29 19:19:11,400:INFO:Uploading results into container
2023-04-29 19:19:11,400:INFO:Uploading model into container now
2023-04-29 19:19:11,401:INFO:_master_model_container: 17
2023-04-29 19:19:11,401:INFO:_display_container: 2
2023-04-29 19:19:11,401:INFO:LGBMRegressor(random_state=3412)
2023-04-29 19:19:11,401:INFO:create_model() successfully completed......................................
2023-04-29 19:19:11,495:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:11,495:INFO:Creating metrics dataframe
2023-04-29 19:19:11,501:INFO:Initializing Dummy Regressor
2023-04-29 19:19:11,501:INFO:Total runtime is 2.7655745665232345 minutes
2023-04-29 19:19:11,502:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:11,502:INFO:Initializing create_model()
2023-04-29 19:19:11,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:11,502:INFO:Checking exceptions
2023-04-29 19:19:11,502:INFO:Importing libraries
2023-04-29 19:19:11,502:INFO:Copying training dataset
2023-04-29 19:19:11,505:INFO:Defining folds
2023-04-29 19:19:11,506:INFO:Declaring metric variables
2023-04-29 19:19:11,506:INFO:Importing untrained model
2023-04-29 19:19:11,506:INFO:Dummy Regressor Imported successfully
2023-04-29 19:19:11,507:INFO:Starting cross validation
2023-04-29 19:19:11,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:17,550:INFO:Calculating mean and std
2023-04-29 19:19:17,551:WARNING:
2023-04-29 19:19:17,551:WARNING:Processing:  17%|##          | 13/77 [00:43<04:07,  3.86s/it]
2023-04-29 19:19:17,551:WARNING:[A
2023-04-29 19:19:17,551:INFO:Creating metrics dataframe
2023-04-29 19:19:18,347:WARNING:
2023-04-29 19:19:18,347:WARNING:Processing:  18%|##1         | 14/77 [00:44<03:26,  3.28s/it]
2023-04-29 19:19:18,347:WARNING:[A
2023-04-29 19:19:18,347:INFO:Uploading results into container
2023-04-29 19:19:18,348:INFO:Uploading model into container now
2023-04-29 19:19:18,348:INFO:_master_model_container: 3
2023-04-29 19:19:18,348:INFO:_display_container: 2
2023-04-29 19:19:18,348:INFO:Ridge(random_state=8267)
2023-04-29 19:19:18,348:INFO:create_model() successfully completed......................................
2023-04-29 19:19:18,450:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:18,450:INFO:Creating metrics dataframe
2023-04-29 19:19:18,455:INFO:Initializing Elastic Net
2023-04-29 19:19:18,455:INFO:Total runtime is 0.7467759927113851 minutes
2023-04-29 19:19:18,455:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:18,456:INFO:Initializing create_model()
2023-04-29 19:19:18,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:18,456:INFO:Checking exceptions
2023-04-29 19:19:18,456:INFO:Importing libraries
2023-04-29 19:19:18,456:INFO:Copying training dataset
2023-04-29 19:19:18,463:WARNING:
2023-04-29 19:19:18,463:WARNING:Processing:  19%|##3         | 15/77 [00:44<02:41,  2.61s/it]
2023-04-29 19:19:18,463:WARNING:[A
2023-04-29 19:19:18,463:INFO:Defining folds
2023-04-29 19:19:18,464:INFO:Declaring metric variables
2023-04-29 19:19:18,464:INFO:Importing untrained model
2023-04-29 19:19:18,464:INFO:Elastic Net Imported successfully
2023-04-29 19:19:18,464:INFO:Starting cross validation
2023-04-29 19:19:18,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:25,375:INFO:Calculating mean and std
2023-04-29 19:19:25,376:INFO:Creating metrics dataframe
2023-04-29 19:19:26,237:INFO:Uploading results into container
2023-04-29 19:19:26,238:INFO:Uploading model into container now
2023-04-29 19:19:26,238:INFO:_master_model_container: 18
2023-04-29 19:19:26,238:INFO:_display_container: 2
2023-04-29 19:19:26,239:INFO:DummyRegressor()
2023-04-29 19:19:26,239:INFO:create_model() successfully completed......................................
2023-04-29 19:19:26,339:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:26,339:INFO:Creating metrics dataframe
2023-04-29 19:19:26,346:INFO:Initializing create_model()
2023-04-29 19:19:26,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB2ADF0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3412), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:26,346:INFO:Checking exceptions
2023-04-29 19:19:26,347:INFO:Importing libraries
2023-04-29 19:19:26,347:INFO:Copying training dataset
2023-04-29 19:19:26,351:INFO:Defining folds
2023-04-29 19:19:26,352:INFO:Declaring metric variables
2023-04-29 19:19:26,352:INFO:Importing untrained model
2023-04-29 19:19:26,352:INFO:Declaring custom model
2023-04-29 19:19:26,352:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:19:26,353:INFO:Cross validation set to False
2023-04-29 19:19:26,353:INFO:Fitting Model
2023-04-29 19:19:27,495:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3412)
2023-04-29 19:19:27,495:INFO:create_model() successfully completed......................................
2023-04-29 19:19:27,628:INFO:_master_model_container: 18
2023-04-29 19:19:27,628:INFO:_display_container: 2
2023-04-29 19:19:27,628:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3412)
2023-04-29 19:19:27,629:INFO:compare_models() successfully completed......................................
2023-04-29 19:19:32,625:INFO:Calculating mean and std
2023-04-29 19:19:32,626:WARNING:
2023-04-29 19:19:32,626:WARNING:Processing:  22%|##6         | 17/77 [00:58<04:17,  4.30s/it]
2023-04-29 19:19:32,626:WARNING:[A
2023-04-29 19:19:32,626:INFO:Creating metrics dataframe
2023-04-29 19:19:33,338:WARNING:
2023-04-29 19:19:33,338:WARNING:Processing:  23%|##8         | 18/77 [00:59<03:28,  3.54s/it]
2023-04-29 19:19:33,338:WARNING:[A
2023-04-29 19:19:33,338:INFO:Uploading results into container
2023-04-29 19:19:33,339:INFO:Uploading model into container now
2023-04-29 19:19:33,339:INFO:_master_model_container: 4
2023-04-29 19:19:33,339:INFO:_display_container: 2
2023-04-29 19:19:33,340:INFO:ElasticNet(random_state=8267)
2023-04-29 19:19:33,340:INFO:create_model() successfully completed......................................
2023-04-29 19:19:33,441:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:33,441:INFO:Creating metrics dataframe
2023-04-29 19:19:33,446:INFO:Initializing Least Angle Regression
2023-04-29 19:19:33,446:INFO:Total runtime is 0.9966255585352579 minutes
2023-04-29 19:19:33,446:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:33,447:INFO:Initializing create_model()
2023-04-29 19:19:33,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:33,447:INFO:Checking exceptions
2023-04-29 19:19:33,447:INFO:Importing libraries
2023-04-29 19:19:33,447:INFO:Copying training dataset
2023-04-29 19:19:33,450:WARNING:
2023-04-29 19:19:33,450:WARNING:Processing:  25%|##9         | 19/77 [00:59<02:38,  2.74s/it]
2023-04-29 19:19:33,450:WARNING:[A
2023-04-29 19:19:33,451:INFO:Defining folds
2023-04-29 19:19:33,451:INFO:Declaring metric variables
2023-04-29 19:19:33,451:INFO:Importing untrained model
2023-04-29 19:19:33,452:INFO:Least Angle Regression Imported successfully
2023-04-29 19:19:33,452:INFO:Starting cross validation
2023-04-29 19:19:33,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:33,514:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,529:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,532:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,550:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,559:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,573:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,588:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:33,604:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:35,133:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:35,214:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:39,688:INFO:Calculating mean and std
2023-04-29 19:19:39,688:WARNING:
2023-04-29 19:19:39,689:WARNING:Processing:  27%|###2        | 21/77 [01:06<02:41,  2.89s/it]
2023-04-29 19:19:39,689:WARNING:[A
2023-04-29 19:19:39,689:INFO:Creating metrics dataframe
2023-04-29 19:19:40,624:WARNING:
2023-04-29 19:19:40,625:WARNING:Processing:  29%|###4        | 22/77 [01:06<02:15,  2.46s/it]
2023-04-29 19:19:40,625:WARNING:[A
2023-04-29 19:19:40,625:INFO:Uploading results into container
2023-04-29 19:19:40,626:INFO:Uploading model into container now
2023-04-29 19:19:40,626:INFO:_master_model_container: 5
2023-04-29 19:19:40,626:INFO:_display_container: 2
2023-04-29 19:19:40,627:INFO:Lars(random_state=8267)
2023-04-29 19:19:40,627:INFO:create_model() successfully completed......................................
2023-04-29 19:19:40,743:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:40,743:INFO:Creating metrics dataframe
2023-04-29 19:19:40,747:INFO:Initializing Lasso Least Angle Regression
2023-04-29 19:19:40,747:INFO:Total runtime is 1.1183135191599527 minutes
2023-04-29 19:19:40,748:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:40,748:INFO:Initializing create_model()
2023-04-29 19:19:40,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:40,748:INFO:Checking exceptions
2023-04-29 19:19:40,748:INFO:Importing libraries
2023-04-29 19:19:40,748:INFO:Copying training dataset
2023-04-29 19:19:40,751:WARNING:
2023-04-29 19:19:40,751:WARNING:Processing:  30%|###5        | 23/77 [01:07<01:42,  1.90s/it]
2023-04-29 19:19:40,751:WARNING:[A
2023-04-29 19:19:40,751:INFO:Defining folds
2023-04-29 19:19:40,751:INFO:Declaring metric variables
2023-04-29 19:19:40,752:INFO:Importing untrained model
2023-04-29 19:19:40,752:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 19:19:40,752:INFO:Starting cross validation
2023-04-29 19:19:40,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:40,823:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,827:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,854:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,867:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,898:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,903:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,917:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:40,937:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:43,087:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:43,161:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:19:47,266:INFO:Calculating mean and std
2023-04-29 19:19:47,266:WARNING:
2023-04-29 19:19:47,267:WARNING:Processing:  32%|###8        | 25/77 [01:13<02:07,  2.45s/it]
2023-04-29 19:19:47,267:WARNING:[A
2023-04-29 19:19:47,267:INFO:Creating metrics dataframe
2023-04-29 19:19:47,996:WARNING:
2023-04-29 19:19:47,997:WARNING:Processing:  34%|####        | 26/77 [01:14<01:45,  2.06s/it]
2023-04-29 19:19:47,997:WARNING:[A
2023-04-29 19:19:47,997:INFO:Uploading results into container
2023-04-29 19:19:47,997:INFO:Uploading model into container now
2023-04-29 19:19:47,998:INFO:_master_model_container: 6
2023-04-29 19:19:47,998:INFO:_display_container: 2
2023-04-29 19:19:47,998:INFO:LassoLars(random_state=8267)
2023-04-29 19:19:47,998:INFO:create_model() successfully completed......................................
2023-04-29 19:19:48,091:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:48,091:INFO:Creating metrics dataframe
2023-04-29 19:19:48,096:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 19:19:48,096:INFO:Total runtime is 1.2407904426256815 minutes
2023-04-29 19:19:48,096:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:48,096:INFO:Initializing create_model()
2023-04-29 19:19:48,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:48,097:INFO:Checking exceptions
2023-04-29 19:19:48,097:INFO:Importing libraries
2023-04-29 19:19:48,097:INFO:Copying training dataset
2023-04-29 19:19:48,100:WARNING:
2023-04-29 19:19:48,100:WARNING:Processing:  35%|####2       | 27/77 [01:14<01:19,  1.59s/it]
2023-04-29 19:19:48,100:WARNING:[A
2023-04-29 19:19:48,101:INFO:Defining folds
2023-04-29 19:19:48,101:INFO:Declaring metric variables
2023-04-29 19:19:48,101:INFO:Importing untrained model
2023-04-29 19:19:48,102:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 19:19:48,102:INFO:Starting cross validation
2023-04-29 19:19:48,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:48,146:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,159:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,178:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,184:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,203:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,216:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,232:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:48,258:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:49,920:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:49,949:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:19:54,386:INFO:Calculating mean and std
2023-04-29 19:19:54,386:WARNING:
2023-04-29 19:19:54,386:WARNING:Processing:  38%|####5       | 29/77 [01:20<01:46,  2.22s/it]
2023-04-29 19:19:54,386:WARNING:[A
2023-04-29 19:19:54,386:INFO:Creating metrics dataframe
2023-04-29 19:19:55,110:WARNING:
2023-04-29 19:19:55,110:WARNING:Processing:  39%|####6       | 30/77 [01:21<01:28,  1.88s/it]
2023-04-29 19:19:55,111:WARNING:[A
2023-04-29 19:19:55,111:INFO:Uploading results into container
2023-04-29 19:19:55,111:INFO:Uploading model into container now
2023-04-29 19:19:55,112:INFO:_master_model_container: 7
2023-04-29 19:19:55,112:INFO:_display_container: 2
2023-04-29 19:19:55,112:INFO:OrthogonalMatchingPursuit()
2023-04-29 19:19:55,112:INFO:create_model() successfully completed......................................
2023-04-29 19:19:55,200:INFO:SubProcess create_model() end ==================================
2023-04-29 19:19:55,200:INFO:Creating metrics dataframe
2023-04-29 19:19:55,204:INFO:Initializing Bayesian Ridge
2023-04-29 19:19:55,204:INFO:Total runtime is 1.3592681050300597 minutes
2023-04-29 19:19:55,204:INFO:SubProcess create_model() called ==================================
2023-04-29 19:19:55,204:INFO:Initializing create_model()
2023-04-29 19:19:55,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:19:55,204:INFO:Checking exceptions
2023-04-29 19:19:55,204:INFO:Importing libraries
2023-04-29 19:19:55,204:INFO:Copying training dataset
2023-04-29 19:19:55,207:INFO:Defining folds
2023-04-29 19:19:55,207:INFO:Declaring metric variables
2023-04-29 19:19:55,207:INFO:Importing untrained model
2023-04-29 19:19:55,208:INFO:Bayesian Ridge Imported successfully
2023-04-29 19:19:55,208:INFO:Starting cross validation
2023-04-29 19:19:55,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:19:59,365:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:19:59,365:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:19:59,366:INFO:Data columns (total 8 columns):
2023-04-29 19:19:59,366:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:19:59,366:INFO:---  ------          --------------  -----  
2023-04-29 19:19:59,366:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:19:59,366:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:19:59,367:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:19:59,367:INFO:memory usage: 79.8 KB
2023-04-29 19:20:02,562:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:20:02,562:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:20:02,563:INFO:Data columns (total 8 columns):
2023-04-29 19:20:02,564:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:20:02,564:INFO:---  ------          --------------  -----  
2023-04-29 19:20:02,564:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:20:02,564:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:20:02,565:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:20:02,565:INFO:memory usage: 79.8 KB
2023-04-29 19:20:03,065:INFO:Calculating mean and std
2023-04-29 19:20:03,065:WARNING:
2023-04-29 19:20:03,066:WARNING:Processing:  43%|#####1      | 33/77 [01:29<01:39,  2.26s/it]
2023-04-29 19:20:03,066:WARNING:[A
2023-04-29 19:20:03,066:INFO:Creating metrics dataframe
2023-04-29 19:20:03,807:WARNING:
2023-04-29 19:20:03,808:WARNING:Processing:  44%|#####2      | 34/77 [01:30<01:24,  1.97s/it]
2023-04-29 19:20:03,808:WARNING:[A
2023-04-29 19:20:03,808:INFO:Uploading results into container
2023-04-29 19:20:03,809:INFO:Uploading model into container now
2023-04-29 19:20:03,810:INFO:_master_model_container: 8
2023-04-29 19:20:03,810:INFO:_display_container: 2
2023-04-29 19:20:03,810:INFO:BayesianRidge()
2023-04-29 19:20:03,810:INFO:create_model() successfully completed......................................
2023-04-29 19:20:03,938:INFO:SubProcess create_model() end ==================================
2023-04-29 19:20:03,938:INFO:Creating metrics dataframe
2023-04-29 19:20:03,946:INFO:Initializing Passive Aggressive Regressor
2023-04-29 19:20:03,946:INFO:Total runtime is 1.504960795243581 minutes
2023-04-29 19:20:03,946:INFO:SubProcess create_model() called ==================================
2023-04-29 19:20:03,946:INFO:Initializing create_model()
2023-04-29 19:20:03,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:20:03,947:INFO:Checking exceptions
2023-04-29 19:20:03,947:INFO:Importing libraries
2023-04-29 19:20:03,947:INFO:Copying training dataset
2023-04-29 19:20:03,954:WARNING:
2023-04-29 19:20:03,955:WARNING:Processing:  45%|#####4      | 35/77 [01:30<01:06,  1.58s/it]
2023-04-29 19:20:03,955:WARNING:[A
2023-04-29 19:20:03,955:INFO:Defining folds
2023-04-29 19:20:03,955:INFO:Declaring metric variables
2023-04-29 19:20:03,956:INFO:Importing untrained model
2023-04-29 19:20:03,956:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 19:20:03,957:INFO:Starting cross validation
2023-04-29 19:20:03,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:20:05,654:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:20:05,655:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:20:05,655:INFO:Data columns (total 8 columns):
2023-04-29 19:20:05,655:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:20:05,655:INFO:---  ------          --------------  -----  
2023-04-29 19:20:05,655:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:20:05,655:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:20:05,655:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:20:05,656:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:20:05,656:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:20:05,656:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:20:05,656:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:20:05,656:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:20:05,656:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:20:05,656:INFO:memory usage: 79.8 KB
2023-04-29 19:20:10,443:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:20:10,444:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:20:10,444:INFO:Data columns (total 8 columns):
2023-04-29 19:20:10,444:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:20:10,444:INFO:---  ------          --------------  -----  
2023-04-29 19:20:10,444:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:20:10,444:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:20:10,444:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:20:10,444:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:20:10,445:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:20:10,445:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:20:10,445:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:20:10,445:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:20:10,445:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:20:10,445:INFO:memory usage: 79.8 KB
2023-04-29 19:20:12,581:INFO:Calculating mean and std
2023-04-29 19:20:12,581:WARNING:
2023-04-29 19:20:12,581:WARNING:Processing:  48%|#####7      | 37/77 [01:38<01:44,  2.62s/it]
2023-04-29 19:20:12,581:WARNING:[A
2023-04-29 19:20:12,582:INFO:Creating metrics dataframe
2023-04-29 19:20:13,537:WARNING:
2023-04-29 19:20:13,538:WARNING:Processing:  49%|#####9      | 38/77 [01:39<01:28,  2.26s/it]
2023-04-29 19:20:13,538:WARNING:[A
2023-04-29 19:20:13,539:INFO:Uploading results into container
2023-04-29 19:20:13,540:INFO:Uploading model into container now
2023-04-29 19:20:13,540:INFO:_master_model_container: 9
2023-04-29 19:20:13,541:INFO:_display_container: 2
2023-04-29 19:20:13,541:INFO:PassiveAggressiveRegressor(random_state=8267)
2023-04-29 19:20:13,542:INFO:create_model() successfully completed......................................
2023-04-29 19:20:13,675:INFO:SubProcess create_model() end ==================================
2023-04-29 19:20:13,675:INFO:Creating metrics dataframe
2023-04-29 19:20:13,683:INFO:Initializing Huber Regressor
2023-04-29 19:20:13,685:INFO:Total runtime is 1.6672860423723856 minutes
2023-04-29 19:20:13,686:INFO:SubProcess create_model() called ==================================
2023-04-29 19:20:13,687:INFO:Initializing create_model()
2023-04-29 19:20:13,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:20:13,688:INFO:Checking exceptions
2023-04-29 19:20:13,688:INFO:Importing libraries
2023-04-29 19:20:13,688:INFO:Copying training dataset
2023-04-29 19:20:13,700:WARNING:
2023-04-29 19:20:13,700:WARNING:Processing:  51%|######      | 39/77 [01:40<01:07,  1.77s/it]
2023-04-29 19:20:13,700:WARNING:[A
2023-04-29 19:20:13,703:INFO:Defining folds
2023-04-29 19:20:13,704:INFO:Declaring metric variables
2023-04-29 19:20:13,705:INFO:Importing untrained model
2023-04-29 19:20:13,705:INFO:Huber Regressor Imported successfully
2023-04-29 19:20:13,705:INFO:Starting cross validation
2023-04-29 19:20:13,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:20:13,887:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 19:20:13,980:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 19:20:14,002:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 19:20:14,041:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:20:14,042:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:20:14,042:INFO:Data columns (total 8 columns):
2023-04-29 19:20:14,042:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:20:14,042:INFO:---  ------          --------------  -----  
2023-04-29 19:20:14,042:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:20:14,042:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:20:14,042:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:20:14,042:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:20:14,043:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:20:14,043:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:20:14,043:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:20:14,043:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:20:14,043:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:20:14,043:INFO:memory usage: 79.8 KB
2023-04-29 19:20:15,651:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 19:20:17,417:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:20:17,418:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:20:17,418:INFO:Data columns (total 8 columns):
2023-04-29 19:20:17,418:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:20:17,418:INFO:---  ------          --------------  -----  
2023-04-29 19:20:17,418:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:20:17,418:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:20:17,418:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:20:17,419:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:20:17,419:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:20:17,419:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:20:17,419:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:20:17,419:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:20:17,419:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:20:17,419:INFO:memory usage: 79.8 KB
2023-04-29 19:20:22,729:INFO:Calculating mean and std
2023-04-29 19:20:22,730:WARNING:
2023-04-29 19:20:22,730:WARNING:Processing:  53%|######3     | 41/77 [01:49<01:43,  2.87s/it]
2023-04-29 19:20:22,731:WARNING:[A
2023-04-29 19:20:22,731:INFO:Creating metrics dataframe
2023-04-29 19:20:23,885:WARNING:
2023-04-29 19:20:23,885:WARNING:Processing:  55%|######5     | 42/77 [01:50<01:27,  2.49s/it]
2023-04-29 19:20:23,885:WARNING:[A
2023-04-29 19:20:23,885:INFO:Uploading results into container
2023-04-29 19:20:23,886:INFO:Uploading model into container now
2023-04-29 19:20:23,886:INFO:_master_model_container: 10
2023-04-29 19:20:23,887:INFO:_display_container: 2
2023-04-29 19:20:23,887:INFO:HuberRegressor()
2023-04-29 19:20:23,887:INFO:create_model() successfully completed......................................
2023-04-29 19:20:24,039:INFO:SubProcess create_model() end ==================================
2023-04-29 19:20:24,039:INFO:Creating metrics dataframe
2023-04-29 19:20:24,050:INFO:Initializing K Neighbors Regressor
2023-04-29 19:20:24,051:INFO:Total runtime is 1.840042197704315 minutes
2023-04-29 19:20:24,051:INFO:SubProcess create_model() called ==================================
2023-04-29 19:20:24,052:INFO:Initializing create_model()
2023-04-29 19:20:24,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:20:24,053:INFO:Checking exceptions
2023-04-29 19:20:24,053:INFO:Importing libraries
2023-04-29 19:20:24,053:INFO:Copying training dataset
2023-04-29 19:20:24,059:WARNING:
2023-04-29 19:20:24,059:WARNING:Processing:  56%|######7     | 43/77 [01:50<01:05,  1.93s/it]
2023-04-29 19:20:24,059:WARNING:[A
2023-04-29 19:20:24,060:INFO:Defining folds
2023-04-29 19:20:24,060:INFO:Declaring metric variables
2023-04-29 19:20:24,060:INFO:Importing untrained model
2023-04-29 19:20:24,061:INFO:K Neighbors Regressor Imported successfully
2023-04-29 19:20:24,061:INFO:Starting cross validation
2023-04-29 19:20:24,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:20:34,378:INFO:Calculating mean and std
2023-04-29 19:20:34,378:WARNING:
2023-04-29 19:20:34,378:WARNING:Processing:  58%|#######     | 45/77 [02:00<01:43,  3.25s/it]
2023-04-29 19:20:34,378:WARNING:[A
2023-04-29 19:20:34,379:INFO:Creating metrics dataframe
2023-04-29 19:20:35,267:WARNING:
2023-04-29 19:20:35,267:WARNING:Processing:  60%|#######1    | 46/77 [02:01<01:24,  2.72s/it]
2023-04-29 19:20:35,267:WARNING:[A
2023-04-29 19:20:35,267:INFO:Uploading results into container
2023-04-29 19:20:35,268:INFO:Uploading model into container now
2023-04-29 19:20:35,268:INFO:_master_model_container: 11
2023-04-29 19:20:35,268:INFO:_display_container: 2
2023-04-29 19:20:35,269:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 19:20:35,269:INFO:create_model() successfully completed......................................
2023-04-29 19:20:35,369:INFO:SubProcess create_model() end ==================================
2023-04-29 19:20:35,370:INFO:Creating metrics dataframe
2023-04-29 19:20:35,377:INFO:Initializing Decision Tree Regressor
2023-04-29 19:20:35,378:INFO:Total runtime is 2.0288366079330444 minutes
2023-04-29 19:20:35,378:INFO:SubProcess create_model() called ==================================
2023-04-29 19:20:35,379:INFO:Initializing create_model()
2023-04-29 19:20:35,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:20:35,379:INFO:Checking exceptions
2023-04-29 19:20:35,379:INFO:Importing libraries
2023-04-29 19:20:35,379:INFO:Copying training dataset
2023-04-29 19:20:35,385:WARNING:
2023-04-29 19:20:35,385:WARNING:Processing:  61%|#######3    | 47/77 [02:01<01:02,  2.08s/it]
2023-04-29 19:20:35,385:WARNING:[A
2023-04-29 19:20:35,385:INFO:Defining folds
2023-04-29 19:20:35,385:INFO:Declaring metric variables
2023-04-29 19:20:35,386:INFO:Importing untrained model
2023-04-29 19:20:35,387:INFO:Decision Tree Regressor Imported successfully
2023-04-29 19:20:35,387:INFO:Starting cross validation
2023-04-29 19:20:35,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:20:42,654:INFO:Calculating mean and std
2023-04-29 19:20:42,655:WARNING:
2023-04-29 19:20:42,655:WARNING:Processing:  64%|#######6    | 49/77 [02:09<01:16,  2.72s/it]
2023-04-29 19:20:42,655:WARNING:[A
2023-04-29 19:20:42,655:INFO:Creating metrics dataframe
2023-04-29 19:20:43,474:WARNING:
2023-04-29 19:20:43,475:WARNING:Processing:  65%|#######7    | 50/77 [02:09<01:01,  2.29s/it]
2023-04-29 19:20:43,475:WARNING:[A
2023-04-29 19:20:43,475:INFO:Uploading results into container
2023-04-29 19:20:43,475:INFO:Uploading model into container now
2023-04-29 19:20:43,476:INFO:_master_model_container: 12
2023-04-29 19:20:43,476:INFO:_display_container: 2
2023-04-29 19:20:43,476:INFO:DecisionTreeRegressor(random_state=8267)
2023-04-29 19:20:43,476:INFO:create_model() successfully completed......................................
2023-04-29 19:20:43,568:INFO:SubProcess create_model() end ==================================
2023-04-29 19:20:43,568:INFO:Creating metrics dataframe
2023-04-29 19:20:43,575:INFO:Initializing Random Forest Regressor
2023-04-29 19:20:43,575:INFO:Total runtime is 2.1654511014620463 minutes
2023-04-29 19:20:43,575:INFO:SubProcess create_model() called ==================================
2023-04-29 19:20:43,576:INFO:Initializing create_model()
2023-04-29 19:20:43,576:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:20:43,576:INFO:Checking exceptions
2023-04-29 19:20:43,576:INFO:Importing libraries
2023-04-29 19:20:43,576:INFO:Copying training dataset
2023-04-29 19:20:43,582:WARNING:
2023-04-29 19:20:43,583:WARNING:Processing:  66%|#######9    | 51/77 [02:09<00:45,  1.76s/it]
2023-04-29 19:20:43,583:WARNING:[A
2023-04-29 19:20:43,583:INFO:Defining folds
2023-04-29 19:20:43,583:INFO:Declaring metric variables
2023-04-29 19:20:43,583:INFO:Importing untrained model
2023-04-29 19:20:43,584:INFO:Random Forest Regressor Imported successfully
2023-04-29 19:20:43,584:INFO:Starting cross validation
2023-04-29 19:20:43,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:20:51,042:INFO:Calculating mean and std
2023-04-29 19:20:51,043:WARNING:
2023-04-29 19:20:51,043:WARNING:Processing:  69%|########2   | 53/77 [02:17<01:01,  2.57s/it]
2023-04-29 19:20:51,043:WARNING:[A
2023-04-29 19:20:51,043:INFO:Creating metrics dataframe
2023-04-29 19:20:51,867:WARNING:
2023-04-29 19:20:51,868:WARNING:Processing:  70%|########4   | 54/77 [02:18<00:49,  2.17s/it]
2023-04-29 19:20:51,868:WARNING:[A
2023-04-29 19:20:51,868:INFO:Uploading results into container
2023-04-29 19:20:51,869:INFO:Uploading model into container now
2023-04-29 19:20:51,869:INFO:_master_model_container: 13
2023-04-29 19:20:51,869:INFO:_display_container: 2
2023-04-29 19:20:51,869:INFO:RandomForestRegressor(n_jobs=-1, random_state=8267)
2023-04-29 19:20:51,869:INFO:create_model() successfully completed......................................
2023-04-29 19:20:51,959:INFO:SubProcess create_model() end ==================================
2023-04-29 19:20:51,960:INFO:Creating metrics dataframe
2023-04-29 19:20:51,963:INFO:Initializing Extra Trees Regressor
2023-04-29 19:20:51,963:INFO:Total runtime is 2.305253303050995 minutes
2023-04-29 19:20:51,964:INFO:SubProcess create_model() called ==================================
2023-04-29 19:20:51,964:INFO:Initializing create_model()
2023-04-29 19:20:51,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:20:51,964:INFO:Checking exceptions
2023-04-29 19:20:51,964:INFO:Importing libraries
2023-04-29 19:20:51,964:INFO:Copying training dataset
2023-04-29 19:20:51,967:WARNING:
2023-04-29 19:20:51,967:WARNING:Processing:  71%|########5   | 55/77 [02:18<00:36,  1.66s/it]
2023-04-29 19:20:51,967:WARNING:[A
2023-04-29 19:20:51,967:INFO:Defining folds
2023-04-29 19:20:51,967:INFO:Declaring metric variables
2023-04-29 19:20:51,967:INFO:Importing untrained model
2023-04-29 19:20:51,968:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:20:51,968:INFO:Starting cross validation
2023-04-29 19:20:51,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:21:05,096:INFO:Calculating mean and std
2023-04-29 19:21:05,099:WARNING:
2023-04-29 19:21:05,099:WARNING:Processing:  74%|########8   | 57/77 [02:31<01:13,  3.68s/it]
2023-04-29 19:21:05,100:WARNING:[A
2023-04-29 19:21:05,100:INFO:Creating metrics dataframe
2023-04-29 19:21:07,519:WARNING:
2023-04-29 19:21:07,519:WARNING:Processing:  75%|#########   | 58/77 [02:33<01:04,  3.40s/it]
2023-04-29 19:21:07,519:WARNING:[A
2023-04-29 19:21:07,519:INFO:Uploading results into container
2023-04-29 19:21:07,520:INFO:Uploading model into container now
2023-04-29 19:21:07,521:INFO:_master_model_container: 14
2023-04-29 19:21:07,521:INFO:_display_container: 2
2023-04-29 19:21:07,521:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8267)
2023-04-29 19:21:07,521:INFO:create_model() successfully completed......................................
2023-04-29 19:21:07,673:INFO:SubProcess create_model() end ==================================
2023-04-29 19:21:07,673:INFO:Creating metrics dataframe
2023-04-29 19:21:07,687:INFO:Initializing AdaBoost Regressor
2023-04-29 19:21:07,687:INFO:Total runtime is 2.5673104484876 minutes
2023-04-29 19:21:07,688:INFO:SubProcess create_model() called ==================================
2023-04-29 19:21:07,688:INFO:Initializing create_model()
2023-04-29 19:21:07,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:21:07,688:INFO:Checking exceptions
2023-04-29 19:21:07,688:INFO:Importing libraries
2023-04-29 19:21:07,688:INFO:Copying training dataset
2023-04-29 19:21:07,694:WARNING:
2023-04-29 19:21:07,694:WARNING:Processing:  77%|#########1  | 59/77 [02:34<00:46,  2.61s/it]
2023-04-29 19:21:07,694:WARNING:[A
2023-04-29 19:21:07,694:INFO:Defining folds
2023-04-29 19:21:07,694:INFO:Declaring metric variables
2023-04-29 19:21:07,694:INFO:Importing untrained model
2023-04-29 19:21:07,695:INFO:AdaBoost Regressor Imported successfully
2023-04-29 19:21:07,695:INFO:Starting cross validation
2023-04-29 19:21:07,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:21:14,810:INFO:Calculating mean and std
2023-04-29 19:21:14,811:WARNING:
2023-04-29 19:21:14,811:WARNING:Processing:  79%|#########5  | 61/77 [02:41<00:47,  3.00s/it]
2023-04-29 19:21:14,811:WARNING:[A
2023-04-29 19:21:14,811:INFO:Creating metrics dataframe
2023-04-29 19:21:15,530:WARNING:
2023-04-29 19:21:15,530:WARNING:Processing:  81%|#########6  | 62/77 [02:41<00:37,  2.48s/it]
2023-04-29 19:21:15,530:WARNING:[A
2023-04-29 19:21:15,531:INFO:Uploading results into container
2023-04-29 19:21:15,531:INFO:Uploading model into container now
2023-04-29 19:21:15,532:INFO:_master_model_container: 15
2023-04-29 19:21:15,532:INFO:_display_container: 2
2023-04-29 19:21:15,532:INFO:AdaBoostRegressor(random_state=8267)
2023-04-29 19:21:15,532:INFO:create_model() successfully completed......................................
2023-04-29 19:21:15,619:INFO:SubProcess create_model() end ==================================
2023-04-29 19:21:15,619:INFO:Creating metrics dataframe
2023-04-29 19:21:15,624:INFO:Initializing Gradient Boosting Regressor
2023-04-29 19:21:15,624:INFO:Total runtime is 2.699593989054362 minutes
2023-04-29 19:21:15,625:INFO:SubProcess create_model() called ==================================
2023-04-29 19:21:15,625:INFO:Initializing create_model()
2023-04-29 19:21:15,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:21:15,625:INFO:Checking exceptions
2023-04-29 19:21:15,625:INFO:Importing libraries
2023-04-29 19:21:15,625:INFO:Copying training dataset
2023-04-29 19:21:15,629:INFO:Defining folds
2023-04-29 19:21:15,629:INFO:Declaring metric variables
2023-04-29 19:21:15,629:INFO:Importing untrained model
2023-04-29 19:21:15,629:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 19:21:15,629:INFO:Starting cross validation
2023-04-29 19:21:15,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:21:22,326:INFO:Calculating mean and std
2023-04-29 19:21:22,327:WARNING:
2023-04-29 19:21:22,327:WARNING:Processing:  84%|##########1 | 65/77 [02:48<00:28,  2.37s/it]
2023-04-29 19:21:22,327:WARNING:[A
2023-04-29 19:21:22,327:INFO:Creating metrics dataframe
2023-04-29 19:21:23,116:WARNING:
2023-04-29 19:21:23,117:WARNING:Processing:  86%|##########2 | 66/77 [02:49<00:22,  2.07s/it]
2023-04-29 19:21:23,117:WARNING:[A
2023-04-29 19:21:23,117:INFO:Uploading results into container
2023-04-29 19:21:23,118:INFO:Uploading model into container now
2023-04-29 19:21:23,118:INFO:_master_model_container: 16
2023-04-29 19:21:23,118:INFO:_display_container: 2
2023-04-29 19:21:23,119:INFO:GradientBoostingRegressor(random_state=8267)
2023-04-29 19:21:23,119:INFO:create_model() successfully completed......................................
2023-04-29 19:21:23,215:INFO:SubProcess create_model() end ==================================
2023-04-29 19:21:23,215:INFO:Creating metrics dataframe
2023-04-29 19:21:23,219:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:21:23,219:INFO:Total runtime is 2.8261791706085204 minutes
2023-04-29 19:21:23,219:INFO:SubProcess create_model() called ==================================
2023-04-29 19:21:23,220:INFO:Initializing create_model()
2023-04-29 19:21:23,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:21:23,220:INFO:Checking exceptions
2023-04-29 19:21:23,220:INFO:Importing libraries
2023-04-29 19:21:23,220:INFO:Copying training dataset
2023-04-29 19:21:23,223:WARNING:
2023-04-29 19:21:23,223:WARNING:Processing:  87%|##########4 | 67/77 [02:49<00:16,  1.65s/it]
2023-04-29 19:21:23,223:WARNING:[A
2023-04-29 19:21:23,223:INFO:Defining folds
2023-04-29 19:21:23,223:INFO:Declaring metric variables
2023-04-29 19:21:23,223:INFO:Importing untrained model
2023-04-29 19:21:23,224:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:21:23,224:INFO:Starting cross validation
2023-04-29 19:21:23,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:21:30,260:INFO:Calculating mean and std
2023-04-29 19:21:30,260:WARNING:
2023-04-29 19:21:30,260:WARNING:Processing:  90%|##########7 | 69/77 [02:56<00:18,  2.36s/it]
2023-04-29 19:21:30,260:WARNING:[A
2023-04-29 19:21:30,260:INFO:Creating metrics dataframe
2023-04-29 19:21:31,053:WARNING:
2023-04-29 19:21:31,054:WARNING:Processing:  91%|##########9 | 70/77 [02:57<00:14,  2.03s/it]
2023-04-29 19:21:31,054:WARNING:[A
2023-04-29 19:21:31,054:INFO:Uploading results into container
2023-04-29 19:21:31,054:INFO:Uploading model into container now
2023-04-29 19:21:31,055:INFO:_master_model_container: 17
2023-04-29 19:21:31,055:INFO:_display_container: 2
2023-04-29 19:21:31,055:INFO:LGBMRegressor(random_state=8267)
2023-04-29 19:21:31,055:INFO:create_model() successfully completed......................................
2023-04-29 19:21:31,147:INFO:SubProcess create_model() end ==================================
2023-04-29 19:21:31,147:INFO:Creating metrics dataframe
2023-04-29 19:21:31,153:INFO:Initializing Dummy Regressor
2023-04-29 19:21:31,153:INFO:Total runtime is 2.9584107279777525 minutes
2023-04-29 19:21:31,153:INFO:SubProcess create_model() called ==================================
2023-04-29 19:21:31,153:INFO:Initializing create_model()
2023-04-29 19:21:31,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F1377FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:21:31,153:INFO:Checking exceptions
2023-04-29 19:21:31,153:INFO:Importing libraries
2023-04-29 19:21:31,153:INFO:Copying training dataset
2023-04-29 19:21:31,156:WARNING:
2023-04-29 19:21:31,156:WARNING:Processing:  92%|########### | 71/77 [02:57<00:09,  1.58s/it]
2023-04-29 19:21:31,156:WARNING:[A
2023-04-29 19:21:31,156:INFO:Defining folds
2023-04-29 19:21:31,156:INFO:Declaring metric variables
2023-04-29 19:21:31,157:INFO:Importing untrained model
2023-04-29 19:21:31,157:INFO:Dummy Regressor Imported successfully
2023-04-29 19:21:31,157:INFO:Starting cross validation
2023-04-29 19:21:31,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:21:37,316:INFO:Calculating mean and std
2023-04-29 19:21:37,316:WARNING:
2023-04-29 19:21:37,316:WARNING:Processing:  95%|###########3| 73/77 [03:03<00:08,  2.18s/it]
2023-04-29 19:21:37,316:WARNING:[A
2023-04-29 19:21:37,316:INFO:Creating metrics dataframe
2023-04-29 19:21:38,053:WARNING:
2023-04-29 19:21:38,053:WARNING:Processing:  96%|###########5| 74/77 [03:04<00:05,  1.86s/it]
2023-04-29 19:21:38,053:WARNING:[A
2023-04-29 19:21:38,053:INFO:Uploading results into container
2023-04-29 19:21:38,054:INFO:Uploading model into container now
2023-04-29 19:21:38,054:INFO:_master_model_container: 18
2023-04-29 19:21:38,054:INFO:_display_container: 2
2023-04-29 19:21:38,054:INFO:DummyRegressor()
2023-04-29 19:21:38,054:INFO:create_model() successfully completed......................................
2023-04-29 19:21:38,143:INFO:SubProcess create_model() end ==================================
2023-04-29 19:21:38,143:INFO:Creating metrics dataframe
2023-04-29 19:21:38,148:INFO:Initializing create_model()
2023-04-29 19:21:38,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFD6D5E0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8267), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:21:38,148:INFO:Checking exceptions
2023-04-29 19:21:38,149:INFO:Importing libraries
2023-04-29 19:21:38,149:INFO:Copying training dataset
2023-04-29 19:21:38,151:INFO:Defining folds
2023-04-29 19:21:38,151:INFO:Declaring metric variables
2023-04-29 19:21:38,152:INFO:Importing untrained model
2023-04-29 19:21:38,152:INFO:Declaring custom model
2023-04-29 19:21:38,152:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:21:38,153:INFO:Cross validation set to False
2023-04-29 19:21:38,154:INFO:Fitting Model
2023-04-29 19:21:38,795:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8267)
2023-04-29 19:21:38,795:INFO:create_model() successfully completed......................................
2023-04-29 19:21:38,885:WARNING:
2023-04-29 19:21:38,885:WARNING:Processing: 100%|############| 77/77 [03:05<00:00,  1.09s/it]
2023-04-29 19:21:38,885:WARNING:[A
2023-04-29 19:21:38,885:WARNING:
2023-04-29 19:21:38,885:WARNING:                                                             
2023-04-29 19:21:38,885:WARNING:[A
2023-04-29 19:21:38,904:INFO:                                    Model  ...  TT (Sec)
2023-04-29 19:21:38,904:INFO:et                  Extra Trees Regressor  ...     1.313
2023-04-29 19:21:38,904:INFO:rf                Random Forest Regressor  ...     0.746
2023-04-29 19:21:38,904:INFO:lightgbm  Light Gradient Boosting Machine  ...     0.703
2023-04-29 19:21:38,904:INFO:gbr           Gradient Boosting Regressor  ...     0.670
2023-04-29 19:21:38,904:INFO:dt                Decision Tree Regressor  ...     0.726
2023-04-29 19:21:38,904:INFO:knn                 K Neighbors Regressor  ...     1.031
2023-04-29 19:21:38,904:INFO:ada                    AdaBoost Regressor  ...     0.711
2023-04-29 19:21:38,904:INFO:br                         Bayesian Ridge  ...     0.786
2023-04-29 19:21:38,904:INFO:ridge                    Ridge Regression  ...     1.283
2023-04-29 19:21:38,904:INFO:lr                      Linear Regression  ...     1.389
2023-04-29 19:21:38,904:INFO:lar                Least Angle Regression  ...     0.624
2023-04-29 19:21:38,904:INFO:omp           Orthogonal Matching Pursuit  ...     0.628
2023-04-29 19:21:38,904:INFO:en                            Elastic Net  ...     1.416
2023-04-29 19:21:38,904:INFO:lasso                    Lasso Regression  ...     1.537
2023-04-29 19:21:38,905:INFO:llar         Lasso Least Angle Regression  ...     0.651
2023-04-29 19:21:38,905:INFO:dummy                     Dummy Regressor  ...     0.616
2023-04-29 19:21:38,905:INFO:huber                     Huber Regressor  ...     0.902
2023-04-29 19:21:38,905:INFO:par          Passive Aggressive Regressor  ...     0.862
2023-04-29 19:21:38,905:INFO:
2023-04-29 19:21:38,905:INFO:[18 rows x 8 columns]
2023-04-29 19:21:38,905:INFO:_master_model_container: 18
2023-04-29 19:21:38,905:INFO:_display_container: 2
2023-04-29 19:21:38,905:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8267)
2023-04-29 19:21:38,905:INFO:compare_models() successfully completed......................................
2023-04-29 19:30:27,385:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:30:27,385:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:30:27,385:INFO:Data columns (total 8 columns):
2023-04-29 19:30:27,385:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:30:27,385:INFO:---  ------          --------------  -----  
2023-04-29 19:30:27,385:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:30:27,385:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:30:27,385:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:30:27,385:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:30:27,385:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:30:27,386:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:30:27,386:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:30:27,386:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:30:27,386:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:30:27,386:INFO:memory usage: 79.8 KB
2023-04-29 19:30:30,090:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:30:30,091:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:30:30,092:INFO:Data columns (total 8 columns):
2023-04-29 19:30:30,092:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:30:30,092:INFO:---  ------          --------------  -----  
2023-04-29 19:30:30,092:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:30:30,092:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:30:30,092:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:30:30,092:INFO:memory usage: 79.8 KB
2023-04-29 19:30:30,617:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:30:30,617:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:30:30,617:INFO:Data columns (total 8 columns):
2023-04-29 19:30:30,617:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:30:30,617:INFO:---  ------          --------------  -----  
2023-04-29 19:30:30,617:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:30:30,617:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:30:30,617:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:30:30,617:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:30:30,617:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:30:30,618:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:30:30,618:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:30:30,618:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:30:30,618:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:30:30,618:INFO:memory usage: 79.8 KB
2023-04-29 19:30:32,108:INFO:PyCaret RegressionExperiment
2023-04-29 19:30:32,109:INFO:Logging name: reg-default-name
2023-04-29 19:30:32,109:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 19:30:32,109:INFO:version 3.0.0
2023-04-29 19:30:32,109:INFO:Initializing setup()
2023-04-29 19:30:32,109:INFO:self.USI: 77dd
2023-04-29 19:30:32,109:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:30:32,109:INFO:Checking environment
2023-04-29 19:30:32,109:INFO:python_version: 3.9.13
2023-04-29 19:30:32,109:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:30:32,109:INFO:machine: AMD64
2023-04-29 19:30:32,109:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:30:32,109:INFO:Memory: svmem(total=16935899136, available=6142033920, percent=63.7, used=10793865216, free=6142033920)
2023-04-29 19:30:32,109:INFO:Physical Core: 4
2023-04-29 19:30:32,109:INFO:Logical Core: 8
2023-04-29 19:30:32,109:INFO:Checking libraries
2023-04-29 19:30:32,110:INFO:System:
2023-04-29 19:30:32,110:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:30:32,110:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:30:32,110:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:30:32,110:INFO:PyCaret required dependencies:
2023-04-29 19:30:32,110:INFO:                 pip: 22.2.2
2023-04-29 19:30:32,110:INFO:          setuptools: 63.4.1
2023-04-29 19:30:32,110:INFO:             pycaret: 3.0.0
2023-04-29 19:30:32,110:INFO:             IPython: 7.31.1
2023-04-29 19:30:32,110:INFO:          ipywidgets: 7.6.5
2023-04-29 19:30:32,110:INFO:                tqdm: 4.64.1
2023-04-29 19:30:32,110:INFO:               numpy: 1.21.5
2023-04-29 19:30:32,110:INFO:              pandas: 1.4.4
2023-04-29 19:30:32,110:INFO:              jinja2: 2.11.3
2023-04-29 19:30:32,110:INFO:               scipy: 1.9.1
2023-04-29 19:30:32,110:INFO:              joblib: 1.2.0
2023-04-29 19:30:32,110:INFO:             sklearn: 1.0.2
2023-04-29 19:30:32,110:INFO:                pyod: 1.0.9
2023-04-29 19:30:32,110:INFO:            imblearn: 0.10.1
2023-04-29 19:30:32,110:INFO:   category_encoders: 2.6.0
2023-04-29 19:30:32,110:INFO:            lightgbm: 3.3.5
2023-04-29 19:30:32,110:INFO:               numba: 0.55.1
2023-04-29 19:30:32,110:INFO:            requests: 2.28.1
2023-04-29 19:30:32,111:INFO:          matplotlib: 3.5.2
2023-04-29 19:30:32,111:INFO:          scikitplot: 0.3.7
2023-04-29 19:30:32,111:INFO:         yellowbrick: 1.5
2023-04-29 19:30:32,111:INFO:              plotly: 5.9.0
2023-04-29 19:30:32,111:INFO:             kaleido: 0.2.1
2023-04-29 19:30:32,111:INFO:         statsmodels: 0.13.2
2023-04-29 19:30:32,111:INFO:              sktime: 0.17.1
2023-04-29 19:30:32,111:INFO:               tbats: 1.1.2
2023-04-29 19:30:32,111:INFO:            pmdarima: 2.0.3
2023-04-29 19:30:32,111:INFO:              psutil: 5.9.0
2023-04-29 19:30:32,111:INFO:PyCaret optional dependencies:
2023-04-29 19:30:32,111:INFO:                shap: 0.41.0
2023-04-29 19:30:32,111:INFO:           interpret: Not installed
2023-04-29 19:30:32,111:INFO:                umap: Not installed
2023-04-29 19:30:32,111:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:30:32,111:INFO:  explainerdashboard: Not installed
2023-04-29 19:30:32,111:INFO:             autoviz: Not installed
2023-04-29 19:30:32,111:INFO:           fairlearn: Not installed
2023-04-29 19:30:32,111:INFO:             xgboost: Not installed
2023-04-29 19:30:32,111:INFO:            catboost: Not installed
2023-04-29 19:30:32,111:INFO:              kmodes: Not installed
2023-04-29 19:30:32,111:INFO:             mlxtend: Not installed
2023-04-29 19:30:32,111:INFO:       statsforecast: Not installed
2023-04-29 19:30:32,111:INFO:        tune_sklearn: Not installed
2023-04-29 19:30:32,111:INFO:                 ray: Not installed
2023-04-29 19:30:32,111:INFO:            hyperopt: Not installed
2023-04-29 19:30:32,111:INFO:              optuna: Not installed
2023-04-29 19:30:32,111:INFO:               skopt: Not installed
2023-04-29 19:30:32,111:INFO:              mlflow: 2.2.1
2023-04-29 19:30:32,112:INFO:              gradio: Not installed
2023-04-29 19:30:32,112:INFO:             fastapi: Not installed
2023-04-29 19:30:32,112:INFO:             uvicorn: Not installed
2023-04-29 19:30:32,112:INFO:              m2cgen: Not installed
2023-04-29 19:30:32,112:INFO:           evidently: Not installed
2023-04-29 19:30:32,112:INFO:               fugue: Not installed
2023-04-29 19:30:32,112:INFO:           streamlit: 1.21.0
2023-04-29 19:30:32,112:INFO:             prophet: Not installed
2023-04-29 19:30:32,112:INFO:None
2023-04-29 19:30:32,112:INFO:Set up data.
2023-04-29 19:30:32,116:INFO:Set up train/test split.
2023-04-29 19:30:32,119:INFO:Set up index.
2023-04-29 19:30:32,120:INFO:Set up folding strategy.
2023-04-29 19:30:32,120:INFO:Assigning column types.
2023-04-29 19:30:32,121:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:30:32,122:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,292:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,296:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,357:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,403:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 19:30:32,407:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,412:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,551:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,555:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,655:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 19:30:32,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,761:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:32,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:32,939:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 19:30:33,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:33,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:33,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:33,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:30:33,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,202:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:30:33,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:33,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:30:33,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,435:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 19:30:33,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,651:INFO:Preparing preprocessing pipeline...
2023-04-29 19:30:33,651:INFO:Set up simple imputation.
2023-04-29 19:30:33,652:INFO:Set up column name cleaning.
2023-04-29 19:30:33,671:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:30:33,674:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Density_calc', 'dHmix', 'dSmix',
                                             'Atom.Size.Diff', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 19:30:33,675:INFO:Creating final display dataframe.
2023-04-29 19:30:33,755:INFO:Setup _display_container:                     Description             Value
0                    Session id              8620
1                        Target       Num_of_Elem
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              77dd
2023-04-29 19:30:33,758:INFO:                    Description             Value
2023-04-29 19:30:33,758:INFO:0                    Session id              8620
2023-04-29 19:30:33,759:INFO:1                        Target       Num_of_Elem
2023-04-29 19:30:33,759:INFO:2                   Target type        Regression
2023-04-29 19:30:33,759:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:30:33,759:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:30:33,759:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:30:33,759:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:30:33,759:INFO:7              Numeric features                 7
2023-04-29 19:30:33,759:INFO:8                    Preprocess              True
2023-04-29 19:30:33,759:INFO:9               Imputation type            simple
2023-04-29 19:30:33,759:INFO:10           Numeric imputation              mean
2023-04-29 19:30:33,759:INFO:11       Categorical imputation              mode
2023-04-29 19:30:33,759:INFO:12               Fold Generator             KFold
2023-04-29 19:30:33,759:INFO:13                  Fold Number                10
2023-04-29 19:30:33,759:INFO:14                     CPU Jobs                -1
2023-04-29 19:30:33,759:INFO:15                      Use GPU             False
2023-04-29 19:30:33,759:INFO:16               Log Experiment             False
2023-04-29 19:30:33,759:INFO:17              Experiment Name  reg-default-name
2023-04-29 19:30:33,759:INFO:18                          USI              77dd
2023-04-29 19:30:33,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:33,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:34,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:34,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:30:34,016:INFO:setup() successfully completed in 2.6s...............
2023-04-29 19:30:34,022:INFO:Initializing compare_models()
2023-04-29 19:30:34,022:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 19:30:34,022:INFO:Checking exceptions
2023-04-29 19:30:34,024:INFO:Preparing display monitor
2023-04-29 19:30:34,027:WARNING:Processing:   0%|                 | 0/77 [00:00<?, ?it/s]
2023-04-29 19:30:34,028:INFO:Initializing Linear Regression
2023-04-29 19:30:34,028:INFO:Total runtime is 0.0 minutes
2023-04-29 19:30:34,028:INFO:SubProcess create_model() called ==================================
2023-04-29 19:30:34,028:INFO:Initializing create_model()
2023-04-29 19:30:34,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:30:34,028:INFO:Checking exceptions
2023-04-29 19:30:34,028:INFO:Importing libraries
2023-04-29 19:30:34,029:INFO:Copying training dataset
2023-04-29 19:30:34,032:INFO:Defining folds
2023-04-29 19:30:34,033:INFO:Declaring metric variables
2023-04-29 19:30:34,034:INFO:Importing untrained model
2023-04-29 19:30:34,034:INFO:Linear Regression Imported successfully
2023-04-29 19:30:34,035:INFO:Starting cross validation
2023-04-29 19:30:34,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:30:47,319:INFO:Calculating mean and std
2023-04-29 19:30:47,320:WARNING:Processing:   6%|5        | 5/77 [00:13<03:11,  2.66s/it]
2023-04-29 19:30:47,320:INFO:Creating metrics dataframe
2023-04-29 19:30:48,119:WARNING:Processing:   8%|7        | 6/77 [00:14<02:39,  2.25s/it]
2023-04-29 19:30:48,119:INFO:Uploading results into container
2023-04-29 19:30:48,120:INFO:Uploading model into container now
2023-04-29 19:30:48,120:INFO:_master_model_container: 1
2023-04-29 19:30:48,120:INFO:_display_container: 2
2023-04-29 19:30:48,120:INFO:LinearRegression(n_jobs=-1)
2023-04-29 19:30:48,120:INFO:create_model() successfully completed......................................
2023-04-29 19:30:48,243:INFO:SubProcess create_model() end ==================================
2023-04-29 19:30:48,243:INFO:Creating metrics dataframe
2023-04-29 19:30:48,249:INFO:Initializing Lasso Regression
2023-04-29 19:30:48,249:INFO:Total runtime is 0.23701830705006918 minutes
2023-04-29 19:30:48,249:INFO:SubProcess create_model() called ==================================
2023-04-29 19:30:48,250:INFO:Initializing create_model()
2023-04-29 19:30:48,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:30:48,250:INFO:Checking exceptions
2023-04-29 19:30:48,250:INFO:Importing libraries
2023-04-29 19:30:48,250:INFO:Copying training dataset
2023-04-29 19:30:48,253:WARNING:Processing:   9%|8        | 7/77 [00:14<02:01,  1.74s/it]
2023-04-29 19:30:48,253:INFO:Defining folds
2023-04-29 19:30:48,253:INFO:Declaring metric variables
2023-04-29 19:30:48,253:INFO:Importing untrained model
2023-04-29 19:30:48,253:INFO:Lasso Regression Imported successfully
2023-04-29 19:30:48,253:INFO:Starting cross validation
2023-04-29 19:30:48,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:30:55,321:INFO:Calculating mean and std
2023-04-29 19:30:55,322:WARNING:Processing:  12%|#        | 9/77 [00:21<02:47,  2.47s/it]
2023-04-29 19:30:55,323:INFO:Creating metrics dataframe
2023-04-29 19:30:56,993:WARNING:Processing:  13%|#       | 10/77 [00:22<02:33,  2.29s/it]
2023-04-29 19:30:56,993:INFO:Uploading results into container
2023-04-29 19:30:56,994:INFO:Uploading model into container now
2023-04-29 19:30:56,994:INFO:_master_model_container: 2
2023-04-29 19:30:56,994:INFO:_display_container: 2
2023-04-29 19:30:56,995:INFO:Lasso(random_state=8620)
2023-04-29 19:30:56,995:INFO:create_model() successfully completed......................................
2023-04-29 19:30:57,098:INFO:SubProcess create_model() end ==================================
2023-04-29 19:30:57,099:INFO:Creating metrics dataframe
2023-04-29 19:30:57,102:INFO:Initializing Ridge Regression
2023-04-29 19:30:57,102:INFO:Total runtime is 0.38455801804860434 minutes
2023-04-29 19:30:57,102:INFO:SubProcess create_model() called ==================================
2023-04-29 19:30:57,102:INFO:Initializing create_model()
2023-04-29 19:30:57,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:30:57,103:INFO:Checking exceptions
2023-04-29 19:30:57,103:INFO:Importing libraries
2023-04-29 19:30:57,103:INFO:Copying training dataset
2023-04-29 19:30:57,105:WARNING:Processing:  14%|#1      | 11/77 [00:23<01:56,  1.76s/it]
2023-04-29 19:30:57,105:INFO:Defining folds
2023-04-29 19:30:57,105:INFO:Declaring metric variables
2023-04-29 19:30:57,106:INFO:Importing untrained model
2023-04-29 19:30:57,106:INFO:Ridge Regression Imported successfully
2023-04-29 19:30:57,106:INFO:Starting cross validation
2023-04-29 19:30:57,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:04,212:INFO:Calculating mean and std
2023-04-29 19:31:04,213:WARNING:Processing:  17%|#3      | 13/77 [00:30<02:39,  2.50s/it]
2023-04-29 19:31:04,213:INFO:Creating metrics dataframe
2023-04-29 19:31:05,615:WARNING:Processing:  18%|#4      | 14/77 [00:31<02:21,  2.25s/it]
2023-04-29 19:31:05,615:INFO:Uploading results into container
2023-04-29 19:31:05,616:INFO:Uploading model into container now
2023-04-29 19:31:05,617:INFO:_master_model_container: 3
2023-04-29 19:31:05,617:INFO:_display_container: 2
2023-04-29 19:31:05,618:INFO:Ridge(random_state=8620)
2023-04-29 19:31:05,618:INFO:create_model() successfully completed......................................
2023-04-29 19:31:05,741:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:05,741:INFO:Creating metrics dataframe
2023-04-29 19:31:05,745:INFO:Initializing Elastic Net
2023-04-29 19:31:05,746:INFO:Total runtime is 0.5286345402399699 minutes
2023-04-29 19:31:05,746:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:05,746:INFO:Initializing create_model()
2023-04-29 19:31:05,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:05,746:INFO:Checking exceptions
2023-04-29 19:31:05,746:INFO:Importing libraries
2023-04-29 19:31:05,746:INFO:Copying training dataset
2023-04-29 19:31:05,749:WARNING:Processing:  19%|#5      | 15/77 [00:31<01:47,  1.73s/it]
2023-04-29 19:31:05,749:INFO:Defining folds
2023-04-29 19:31:05,749:INFO:Declaring metric variables
2023-04-29 19:31:05,749:INFO:Importing untrained model
2023-04-29 19:31:05,749:INFO:Elastic Net Imported successfully
2023-04-29 19:31:05,750:INFO:Starting cross validation
2023-04-29 19:31:05,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:12,378:INFO:Calculating mean and std
2023-04-29 19:31:12,380:WARNING:Processing:  22%|#7      | 17/77 [00:38<02:22,  2.38s/it]
2023-04-29 19:31:12,380:INFO:Creating metrics dataframe
2023-04-29 19:31:13,168:WARNING:Processing:  23%|#8      | 18/77 [00:39<01:59,  2.02s/it]
2023-04-29 19:31:13,168:INFO:Uploading results into container
2023-04-29 19:31:13,168:INFO:Uploading model into container now
2023-04-29 19:31:13,169:INFO:_master_model_container: 4
2023-04-29 19:31:13,169:INFO:_display_container: 2
2023-04-29 19:31:13,169:INFO:ElasticNet(random_state=8620)
2023-04-29 19:31:13,169:INFO:create_model() successfully completed......................................
2023-04-29 19:31:13,274:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:13,274:INFO:Creating metrics dataframe
2023-04-29 19:31:13,278:INFO:Initializing Least Angle Regression
2023-04-29 19:31:13,278:INFO:Total runtime is 0.6541609207789103 minutes
2023-04-29 19:31:13,278:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:13,278:INFO:Initializing create_model()
2023-04-29 19:31:13,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:13,278:INFO:Checking exceptions
2023-04-29 19:31:13,278:INFO:Importing libraries
2023-04-29 19:31:13,278:INFO:Copying training dataset
2023-04-29 19:31:13,281:WARNING:Processing:  25%|#9      | 19/77 [00:39<01:30,  1.55s/it]
2023-04-29 19:31:13,281:INFO:Defining folds
2023-04-29 19:31:13,281:INFO:Declaring metric variables
2023-04-29 19:31:13,281:INFO:Importing untrained model
2023-04-29 19:31:13,281:INFO:Least Angle Regression Imported successfully
2023-04-29 19:31:13,282:INFO:Starting cross validation
2023-04-29 19:31:13,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:13,378:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,399:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,409:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,430:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,444:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,460:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,470:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:13,487:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:14,800:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:14,867:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:20,100:INFO:Calculating mean and std
2023-04-29 19:31:20,101:WARNING:Processing:  27%|##1     | 21/77 [00:46<02:09,  2.32s/it]
2023-04-29 19:31:20,101:INFO:Creating metrics dataframe
2023-04-29 19:31:21,787:WARNING:Processing:  29%|##2     | 22/77 [00:47<01:59,  2.17s/it]
2023-04-29 19:31:21,788:INFO:Uploading results into container
2023-04-29 19:31:21,789:INFO:Uploading model into container now
2023-04-29 19:31:21,790:INFO:_master_model_container: 5
2023-04-29 19:31:21,790:INFO:_display_container: 2
2023-04-29 19:31:21,791:INFO:Lars(random_state=8620)
2023-04-29 19:31:21,791:INFO:create_model() successfully completed......................................
2023-04-29 19:31:21,919:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:21,919:INFO:Creating metrics dataframe
2023-04-29 19:31:21,927:INFO:Initializing Lasso Least Angle Regression
2023-04-29 19:31:21,927:INFO:Total runtime is 0.7983171264330546 minutes
2023-04-29 19:31:21,928:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:21,928:INFO:Initializing create_model()
2023-04-29 19:31:21,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:21,928:INFO:Checking exceptions
2023-04-29 19:31:21,929:INFO:Importing libraries
2023-04-29 19:31:21,929:INFO:Copying training dataset
2023-04-29 19:31:21,936:WARNING:Processing:  30%|##3     | 23/77 [00:47<01:30,  1.68s/it]
2023-04-29 19:31:21,937:INFO:Defining folds
2023-04-29 19:31:21,938:INFO:Declaring metric variables
2023-04-29 19:31:21,938:INFO:Importing untrained model
2023-04-29 19:31:21,938:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 19:31:21,938:INFO:Starting cross validation
2023-04-29 19:31:21,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:22,032:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,047:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,057:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,075:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,089:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,106:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,118:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:22,131:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:23,429:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:23,518:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:31:28,584:INFO:Calculating mean and std
2023-04-29 19:31:28,585:WARNING:Processing:  32%|##5     | 25/77 [00:54<02:02,  2.36s/it]
2023-04-29 19:31:28,585:INFO:Creating metrics dataframe
2023-04-29 19:31:29,386:WARNING:Processing:  34%|##7     | 26/77 [00:55<01:42,  2.00s/it]
2023-04-29 19:31:29,386:INFO:Uploading results into container
2023-04-29 19:31:29,387:INFO:Uploading model into container now
2023-04-29 19:31:29,387:INFO:_master_model_container: 6
2023-04-29 19:31:29,387:INFO:_display_container: 2
2023-04-29 19:31:29,388:INFO:LassoLars(random_state=8620)
2023-04-29 19:31:29,388:INFO:create_model() successfully completed......................................
2023-04-29 19:31:29,495:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:29,495:INFO:Creating metrics dataframe
2023-04-29 19:31:29,505:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 19:31:29,505:INFO:Total runtime is 0.9246081630388896 minutes
2023-04-29 19:31:29,505:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:29,506:INFO:Initializing create_model()
2023-04-29 19:31:29,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:29,506:INFO:Checking exceptions
2023-04-29 19:31:29,506:INFO:Importing libraries
2023-04-29 19:31:29,507:INFO:Copying training dataset
2023-04-29 19:31:29,514:WARNING:Processing:  35%|##8     | 27/77 [00:55<01:17,  1.54s/it]
2023-04-29 19:31:29,515:INFO:Defining folds
2023-04-29 19:31:29,515:INFO:Declaring metric variables
2023-04-29 19:31:29,515:INFO:Importing untrained model
2023-04-29 19:31:29,515:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 19:31:29,516:INFO:Starting cross validation
2023-04-29 19:31:29,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:29,615:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,624:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,644:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,662:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,667:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,684:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,699:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:29,715:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:31,081:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:31,110:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:31:36,328:INFO:Calculating mean and std
2023-04-29 19:31:36,330:WARNING:Processing:  38%|###     | 29/77 [01:02<01:50,  2.31s/it]
2023-04-29 19:31:36,330:INFO:Creating metrics dataframe
2023-04-29 19:31:37,424:WARNING:Processing:  39%|###1    | 30/77 [01:03<01:35,  2.03s/it]
2023-04-29 19:31:37,424:INFO:Uploading results into container
2023-04-29 19:31:37,425:INFO:Uploading model into container now
2023-04-29 19:31:37,425:INFO:_master_model_container: 7
2023-04-29 19:31:37,425:INFO:_display_container: 2
2023-04-29 19:31:37,425:INFO:OrthogonalMatchingPursuit()
2023-04-29 19:31:37,426:INFO:create_model() successfully completed......................................
2023-04-29 19:31:37,530:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:37,530:INFO:Creating metrics dataframe
2023-04-29 19:31:37,535:INFO:Initializing Bayesian Ridge
2023-04-29 19:31:37,535:INFO:Total runtime is 1.058444654941559 minutes
2023-04-29 19:31:37,535:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:37,535:INFO:Initializing create_model()
2023-04-29 19:31:37,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:37,535:INFO:Checking exceptions
2023-04-29 19:31:37,535:INFO:Importing libraries
2023-04-29 19:31:37,535:INFO:Copying training dataset
2023-04-29 19:31:37,538:WARNING:Processing:  40%|###2    | 31/77 [01:03<01:11,  1.56s/it]
2023-04-29 19:31:37,538:INFO:Defining folds
2023-04-29 19:31:37,538:INFO:Declaring metric variables
2023-04-29 19:31:37,539:INFO:Importing untrained model
2023-04-29 19:31:37,539:INFO:Bayesian Ridge Imported successfully
2023-04-29 19:31:37,539:INFO:Starting cross validation
2023-04-29 19:31:37,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:44,820:INFO:Calculating mean and std
2023-04-29 19:31:44,820:WARNING:Processing:  43%|###4    | 33/77 [01:10<01:46,  2.42s/it]
2023-04-29 19:31:44,820:INFO:Creating metrics dataframe
2023-04-29 19:31:46,437:WARNING:Processing:  44%|###5    | 34/77 [01:12<01:36,  2.24s/it]
2023-04-29 19:31:46,437:INFO:Uploading results into container
2023-04-29 19:31:46,438:INFO:Uploading model into container now
2023-04-29 19:31:46,438:INFO:_master_model_container: 8
2023-04-29 19:31:46,438:INFO:_display_container: 2
2023-04-29 19:31:46,438:INFO:BayesianRidge()
2023-04-29 19:31:46,438:INFO:create_model() successfully completed......................................
2023-04-29 19:31:46,540:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:46,540:INFO:Creating metrics dataframe
2023-04-29 19:31:46,544:INFO:Initializing Passive Aggressive Regressor
2023-04-29 19:31:46,544:INFO:Total runtime is 1.208594012260437 minutes
2023-04-29 19:31:46,544:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:46,544:INFO:Initializing create_model()
2023-04-29 19:31:46,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:46,545:INFO:Checking exceptions
2023-04-29 19:31:46,545:INFO:Importing libraries
2023-04-29 19:31:46,545:INFO:Copying training dataset
2023-04-29 19:31:46,547:WARNING:Processing:  45%|###6    | 35/77 [01:12<01:12,  1.72s/it]
2023-04-29 19:31:46,547:INFO:Defining folds
2023-04-29 19:31:46,548:INFO:Declaring metric variables
2023-04-29 19:31:46,548:INFO:Importing untrained model
2023-04-29 19:31:46,548:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 19:31:46,548:INFO:Starting cross validation
2023-04-29 19:31:46,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:31:53,248:INFO:Calculating mean and std
2023-04-29 19:31:53,248:WARNING:Processing:  48%|###8    | 37/77 [01:19<01:35,  2.39s/it]
2023-04-29 19:31:53,248:INFO:Creating metrics dataframe
2023-04-29 19:31:54,045:WARNING:Processing:  49%|###9    | 38/77 [01:20<01:19,  2.03s/it]
2023-04-29 19:31:54,046:INFO:Uploading results into container
2023-04-29 19:31:54,046:INFO:Uploading model into container now
2023-04-29 19:31:54,047:INFO:_master_model_container: 9
2023-04-29 19:31:54,047:INFO:_display_container: 2
2023-04-29 19:31:54,047:INFO:PassiveAggressiveRegressor(random_state=8620)
2023-04-29 19:31:54,047:INFO:create_model() successfully completed......................................
2023-04-29 19:31:54,160:INFO:SubProcess create_model() end ==================================
2023-04-29 19:31:54,161:INFO:Creating metrics dataframe
2023-04-29 19:31:54,169:INFO:Initializing Huber Regressor
2023-04-29 19:31:54,169:INFO:Total runtime is 1.335684625307719 minutes
2023-04-29 19:31:54,169:INFO:SubProcess create_model() called ==================================
2023-04-29 19:31:54,169:INFO:Initializing create_model()
2023-04-29 19:31:54,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:31:54,170:INFO:Checking exceptions
2023-04-29 19:31:54,170:INFO:Importing libraries
2023-04-29 19:31:54,170:INFO:Copying training dataset
2023-04-29 19:31:54,174:WARNING:Processing:  51%|####    | 39/77 [01:20<00:59,  1.56s/it]
2023-04-29 19:31:54,174:INFO:Defining folds
2023-04-29 19:31:54,174:INFO:Declaring metric variables
2023-04-29 19:31:54,174:INFO:Importing untrained model
2023-04-29 19:31:54,175:INFO:Huber Regressor Imported successfully
2023-04-29 19:31:54,175:INFO:Starting cross validation
2023-04-29 19:31:54,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:01,326:INFO:Calculating mean and std
2023-04-29 19:32:01,327:WARNING:Processing:  53%|####2   | 41/77 [01:27<01:26,  2.39s/it]
2023-04-29 19:32:01,327:INFO:Creating metrics dataframe
2023-04-29 19:32:02,412:WARNING:Processing:  55%|####3   | 42/77 [01:28<01:13,  2.09s/it]
2023-04-29 19:32:02,412:INFO:Uploading results into container
2023-04-29 19:32:02,413:INFO:Uploading model into container now
2023-04-29 19:32:02,413:INFO:_master_model_container: 10
2023-04-29 19:32:02,413:INFO:_display_container: 2
2023-04-29 19:32:02,413:INFO:HuberRegressor()
2023-04-29 19:32:02,413:INFO:create_model() successfully completed......................................
2023-04-29 19:32:02,526:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:02,526:INFO:Creating metrics dataframe
2023-04-29 19:32:02,530:INFO:Initializing K Neighbors Regressor
2023-04-29 19:32:02,530:INFO:Total runtime is 1.4750333587328595 minutes
2023-04-29 19:32:02,530:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:02,530:INFO:Initializing create_model()
2023-04-29 19:32:02,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:02,530:INFO:Checking exceptions
2023-04-29 19:32:02,530:INFO:Importing libraries
2023-04-29 19:32:02,530:INFO:Copying training dataset
2023-04-29 19:32:02,533:WARNING:Processing:  56%|####4   | 43/77 [01:28<00:54,  1.61s/it]
2023-04-29 19:32:02,534:INFO:Defining folds
2023-04-29 19:32:02,534:INFO:Declaring metric variables
2023-04-29 19:32:02,534:INFO:Importing untrained model
2023-04-29 19:32:02,534:INFO:K Neighbors Regressor Imported successfully
2023-04-29 19:32:02,534:INFO:Starting cross validation
2023-04-29 19:32:02,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:09,486:INFO:Calculating mean and std
2023-04-29 19:32:09,487:WARNING:Processing:  58%|####6   | 45/77 [01:35<01:16,  2.38s/it]
2023-04-29 19:32:09,487:INFO:Creating metrics dataframe
2023-04-29 19:32:11,126:WARNING:Processing:  60%|####7   | 46/77 [01:37<01:08,  2.21s/it]
2023-04-29 19:32:11,127:INFO:Uploading results into container
2023-04-29 19:32:11,127:INFO:Uploading model into container now
2023-04-29 19:32:11,127:INFO:_master_model_container: 11
2023-04-29 19:32:11,128:INFO:_display_container: 2
2023-04-29 19:32:11,128:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 19:32:11,128:INFO:create_model() successfully completed......................................
2023-04-29 19:32:11,232:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:11,232:INFO:Creating metrics dataframe
2023-04-29 19:32:11,236:INFO:Initializing Decision Tree Regressor
2023-04-29 19:32:11,236:INFO:Total runtime is 1.620124693711599 minutes
2023-04-29 19:32:11,236:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:11,236:INFO:Initializing create_model()
2023-04-29 19:32:11,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:11,237:INFO:Checking exceptions
2023-04-29 19:32:11,237:INFO:Importing libraries
2023-04-29 19:32:11,237:INFO:Copying training dataset
2023-04-29 19:32:11,239:WARNING:Processing:  61%|####8   | 47/77 [01:37<00:50,  1.70s/it]
2023-04-29 19:32:11,239:INFO:Defining folds
2023-04-29 19:32:11,239:INFO:Declaring metric variables
2023-04-29 19:32:11,240:INFO:Importing untrained model
2023-04-29 19:32:11,240:INFO:Decision Tree Regressor Imported successfully
2023-04-29 19:32:11,240:INFO:Starting cross validation
2023-04-29 19:32:11,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:18,179:INFO:Calculating mean and std
2023-04-29 19:32:18,180:WARNING:Processing:  64%|#####   | 49/77 [01:44<01:07,  2.43s/it]
2023-04-29 19:32:18,180:INFO:Creating metrics dataframe
2023-04-29 19:32:18,964:WARNING:Processing:  65%|#####1  | 50/77 [01:44<00:55,  2.05s/it]
2023-04-29 19:32:18,964:INFO:Uploading results into container
2023-04-29 19:32:18,965:INFO:Uploading model into container now
2023-04-29 19:32:18,965:INFO:_master_model_container: 12
2023-04-29 19:32:18,965:INFO:_display_container: 2
2023-04-29 19:32:18,966:INFO:DecisionTreeRegressor(random_state=8620)
2023-04-29 19:32:18,966:INFO:create_model() successfully completed......................................
2023-04-29 19:32:19,079:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:19,080:INFO:Creating metrics dataframe
2023-04-29 19:32:19,084:INFO:Initializing Random Forest Regressor
2023-04-29 19:32:19,084:INFO:Total runtime is 1.7509290456771853 minutes
2023-04-29 19:32:19,085:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:19,085:INFO:Initializing create_model()
2023-04-29 19:32:19,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:19,085:INFO:Checking exceptions
2023-04-29 19:32:19,085:INFO:Importing libraries
2023-04-29 19:32:19,085:INFO:Copying training dataset
2023-04-29 19:32:19,088:WARNING:Processing:  66%|#####2  | 51/77 [01:45<00:41,  1.58s/it]
2023-04-29 19:32:19,088:INFO:Defining folds
2023-04-29 19:32:19,088:INFO:Declaring metric variables
2023-04-29 19:32:19,089:INFO:Importing untrained model
2023-04-29 19:32:19,089:INFO:Random Forest Regressor Imported successfully
2023-04-29 19:32:19,089:INFO:Starting cross validation
2023-04-29 19:32:19,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:26,847:INFO:Calculating mean and std
2023-04-29 19:32:26,848:WARNING:Processing:  69%|#####5  | 53/77 [01:52<01:00,  2.53s/it]
2023-04-29 19:32:26,848:INFO:Creating metrics dataframe
2023-04-29 19:32:27,734:WARNING:Processing:  70%|#####6  | 54/77 [01:53<00:49,  2.15s/it]
2023-04-29 19:32:27,734:INFO:Uploading results into container
2023-04-29 19:32:27,734:INFO:Uploading model into container now
2023-04-29 19:32:27,735:INFO:_master_model_container: 13
2023-04-29 19:32:27,735:INFO:_display_container: 2
2023-04-29 19:32:27,735:INFO:RandomForestRegressor(n_jobs=-1, random_state=8620)
2023-04-29 19:32:27,735:INFO:create_model() successfully completed......................................
2023-04-29 19:32:27,843:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:27,843:INFO:Creating metrics dataframe
2023-04-29 19:32:27,848:INFO:Initializing Extra Trees Regressor
2023-04-29 19:32:27,848:INFO:Total runtime is 1.8970027804374698 minutes
2023-04-29 19:32:27,848:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:27,849:INFO:Initializing create_model()
2023-04-29 19:32:27,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:27,849:INFO:Checking exceptions
2023-04-29 19:32:27,849:INFO:Importing libraries
2023-04-29 19:32:27,849:INFO:Copying training dataset
2023-04-29 19:32:27,852:WARNING:Processing:  71%|#####7  | 55/77 [01:53<00:36,  1.66s/it]
2023-04-29 19:32:27,853:INFO:Defining folds
2023-04-29 19:32:27,853:INFO:Declaring metric variables
2023-04-29 19:32:27,853:INFO:Importing untrained model
2023-04-29 19:32:27,853:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:32:27,853:INFO:Starting cross validation
2023-04-29 19:32:27,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:35,848:INFO:Calculating mean and std
2023-04-29 19:32:35,848:WARNING:Processing:  74%|#####9  | 57/77 [02:01<00:52,  2.62s/it]
2023-04-29 19:32:35,848:INFO:Creating metrics dataframe
2023-04-29 19:32:37,204:WARNING:Processing:  75%|######  | 58/77 [02:03<00:44,  2.33s/it]
2023-04-29 19:32:37,204:INFO:Uploading results into container
2023-04-29 19:32:37,205:INFO:Uploading model into container now
2023-04-29 19:32:37,205:INFO:_master_model_container: 14
2023-04-29 19:32:37,205:INFO:_display_container: 2
2023-04-29 19:32:37,205:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8620)
2023-04-29 19:32:37,205:INFO:create_model() successfully completed......................................
2023-04-29 19:32:37,307:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:37,307:INFO:Creating metrics dataframe
2023-04-29 19:32:37,312:INFO:Initializing AdaBoost Regressor
2023-04-29 19:32:37,312:INFO:Total runtime is 2.054726906617483 minutes
2023-04-29 19:32:37,312:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:37,313:INFO:Initializing create_model()
2023-04-29 19:32:37,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:37,313:INFO:Checking exceptions
2023-04-29 19:32:37,313:INFO:Importing libraries
2023-04-29 19:32:37,313:INFO:Copying training dataset
2023-04-29 19:32:37,316:WARNING:Processing:  77%|######1 | 59/77 [02:03<00:32,  1.79s/it]
2023-04-29 19:32:37,316:INFO:Defining folds
2023-04-29 19:32:37,316:INFO:Declaring metric variables
2023-04-29 19:32:37,316:INFO:Importing untrained model
2023-04-29 19:32:37,316:INFO:AdaBoost Regressor Imported successfully
2023-04-29 19:32:37,316:INFO:Starting cross validation
2023-04-29 19:32:37,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:44,897:INFO:Calculating mean and std
2023-04-29 19:32:44,898:WARNING:Processing:  79%|######3 | 61/77 [02:10<00:41,  2.61s/it]
2023-04-29 19:32:44,898:INFO:Creating metrics dataframe
2023-04-29 19:32:46,667:WARNING:Processing:  81%|######4 | 62/77 [02:12<00:36,  2.42s/it]
2023-04-29 19:32:46,667:INFO:Uploading results into container
2023-04-29 19:32:46,668:INFO:Uploading model into container now
2023-04-29 19:32:46,668:INFO:_master_model_container: 15
2023-04-29 19:32:46,668:INFO:_display_container: 2
2023-04-29 19:32:46,668:INFO:AdaBoostRegressor(random_state=8620)
2023-04-29 19:32:46,668:INFO:create_model() successfully completed......................................
2023-04-29 19:32:46,788:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:46,789:INFO:Creating metrics dataframe
2023-04-29 19:32:46,800:INFO:Initializing Gradient Boosting Regressor
2023-04-29 19:32:46,800:INFO:Total runtime is 2.2128719607989 minutes
2023-04-29 19:32:46,801:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:46,801:INFO:Initializing create_model()
2023-04-29 19:32:46,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:46,802:INFO:Checking exceptions
2023-04-29 19:32:46,802:INFO:Importing libraries
2023-04-29 19:32:46,802:INFO:Copying training dataset
2023-04-29 19:32:46,809:WARNING:Processing:  82%|######5 | 63/77 [02:12<00:26,  1.86s/it]
2023-04-29 19:32:46,810:INFO:Defining folds
2023-04-29 19:32:46,810:INFO:Declaring metric variables
2023-04-29 19:32:46,810:INFO:Importing untrained model
2023-04-29 19:32:46,811:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 19:32:46,812:INFO:Starting cross validation
2023-04-29 19:32:46,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:32:54,657:INFO:Calculating mean and std
2023-04-29 19:32:54,658:WARNING:Processing:  84%|######7 | 65/77 [02:20<00:32,  2.71s/it]
2023-04-29 19:32:54,658:INFO:Creating metrics dataframe
2023-04-29 19:32:56,455:WARNING:Processing:  86%|######8 | 66/77 [02:22<00:27,  2.50s/it]
2023-04-29 19:32:56,455:INFO:Uploading results into container
2023-04-29 19:32:56,456:INFO:Uploading model into container now
2023-04-29 19:32:56,456:INFO:_master_model_container: 16
2023-04-29 19:32:56,456:INFO:_display_container: 2
2023-04-29 19:32:56,457:INFO:GradientBoostingRegressor(random_state=8620)
2023-04-29 19:32:56,457:INFO:create_model() successfully completed......................................
2023-04-29 19:32:56,559:INFO:SubProcess create_model() end ==================================
2023-04-29 19:32:56,560:INFO:Creating metrics dataframe
2023-04-29 19:32:56,572:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:32:56,573:INFO:Total runtime is 2.3757475892702744 minutes
2023-04-29 19:32:56,573:INFO:SubProcess create_model() called ==================================
2023-04-29 19:32:56,574:INFO:Initializing create_model()
2023-04-29 19:32:56,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:32:56,574:INFO:Checking exceptions
2023-04-29 19:32:56,574:INFO:Importing libraries
2023-04-29 19:32:56,574:INFO:Copying training dataset
2023-04-29 19:32:56,581:WARNING:Processing:  87%|######9 | 67/77 [02:22<00:19,  1.92s/it]
2023-04-29 19:32:56,582:INFO:Defining folds
2023-04-29 19:32:56,582:INFO:Declaring metric variables
2023-04-29 19:32:56,582:INFO:Importing untrained model
2023-04-29 19:32:56,583:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:32:56,584:INFO:Starting cross validation
2023-04-29 19:32:56,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:33:06,365:INFO:Calculating mean and std
2023-04-29 19:33:06,366:WARNING:Processing:  90%|#######1| 69/77 [02:32<00:25,  3.15s/it]
2023-04-29 19:33:06,366:INFO:Creating metrics dataframe
2023-04-29 19:33:07,493:WARNING:Processing:  91%|#######2| 70/77 [02:33<00:18,  2.69s/it]
2023-04-29 19:33:07,493:INFO:Uploading results into container
2023-04-29 19:33:07,493:INFO:Uploading model into container now
2023-04-29 19:33:07,494:INFO:_master_model_container: 17
2023-04-29 19:33:07,494:INFO:_display_container: 2
2023-04-29 19:33:07,494:INFO:LGBMRegressor(random_state=8620)
2023-04-29 19:33:07,494:INFO:create_model() successfully completed......................................
2023-04-29 19:33:07,604:INFO:SubProcess create_model() end ==================================
2023-04-29 19:33:07,604:INFO:Creating metrics dataframe
2023-04-29 19:33:07,609:INFO:Initializing Dummy Regressor
2023-04-29 19:33:07,609:INFO:Total runtime is 2.5596818645795194 minutes
2023-04-29 19:33:07,610:INFO:SubProcess create_model() called ==================================
2023-04-29 19:33:07,610:INFO:Initializing create_model()
2023-04-29 19:33:07,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFD70070>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:33:07,610:INFO:Checking exceptions
2023-04-29 19:33:07,610:INFO:Importing libraries
2023-04-29 19:33:07,610:INFO:Copying training dataset
2023-04-29 19:33:07,614:WARNING:Processing:  92%|#######3| 71/77 [02:33<00:12,  2.06s/it]
2023-04-29 19:33:07,614:INFO:Defining folds
2023-04-29 19:33:07,614:INFO:Declaring metric variables
2023-04-29 19:33:07,614:INFO:Importing untrained model
2023-04-29 19:33:07,614:INFO:Dummy Regressor Imported successfully
2023-04-29 19:33:07,615:INFO:Starting cross validation
2023-04-29 19:33:07,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:33:14,744:INFO:Calculating mean and std
2023-04-29 19:33:14,745:WARNING:Processing:  95%|#######5| 73/77 [02:40<00:10,  2.68s/it]
2023-04-29 19:33:14,746:INFO:Creating metrics dataframe
2023-04-29 19:33:16,299:WARNING:Processing:  96%|#######6| 74/77 [02:42<00:07,  2.42s/it]
2023-04-29 19:33:16,299:INFO:Uploading results into container
2023-04-29 19:33:16,299:INFO:Uploading model into container now
2023-04-29 19:33:16,300:INFO:_master_model_container: 18
2023-04-29 19:33:16,300:INFO:_display_container: 2
2023-04-29 19:33:16,300:INFO:DummyRegressor()
2023-04-29 19:33:16,300:INFO:create_model() successfully completed......................................
2023-04-29 19:33:16,425:INFO:SubProcess create_model() end ==================================
2023-04-29 19:33:16,425:INFO:Creating metrics dataframe
2023-04-29 19:33:16,431:WARNING:Processing:  97%|#######7| 75/77 [02:42<00:03,  1.86s/it]
2023-04-29 19:33:16,432:INFO:Initializing create_model()
2023-04-29 19:33:16,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8620), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:33:16,433:INFO:Checking exceptions
2023-04-29 19:33:16,434:INFO:Importing libraries
2023-04-29 19:33:16,434:INFO:Copying training dataset
2023-04-29 19:33:16,436:INFO:Defining folds
2023-04-29 19:33:16,436:INFO:Declaring metric variables
2023-04-29 19:33:16,437:INFO:Importing untrained model
2023-04-29 19:33:16,437:INFO:Declaring custom model
2023-04-29 19:33:16,437:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:33:16,438:INFO:Cross validation set to False
2023-04-29 19:33:16,438:INFO:Fitting Model
2023-04-29 19:33:17,231:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8620)
2023-04-29 19:33:17,231:INFO:create_model() successfully completed......................................
2023-04-29 19:33:17,332:WARNING:Processing: 100%|########| 77/77 [02:43<00:00,  1.28s/it]
2023-04-29 19:33:17,333:WARNING:                                                         
2023-04-29 19:33:17,347:INFO:                                    Model     MAE     MSE    RMSE      R2  \
2023-04-29 19:33:17,347:INFO:et                  Extra Trees Regressor  0.0562  0.0335  0.1735  0.9428   
2023-04-29 19:33:17,347:INFO:rf                Random Forest Regressor  0.0581  0.0352  0.1832  0.9427   
2023-04-29 19:33:17,347:INFO:lightgbm  Light Gradient Boosting Machine  0.0803  0.0418  0.1995  0.9322   
2023-04-29 19:33:17,347:INFO:dt                Decision Tree Regressor  0.0400  0.0471  0.2130  0.9245   
2023-04-29 19:33:17,347:INFO:gbr           Gradient Boosting Regressor  0.1136  0.0483  0.2173  0.9214   
2023-04-29 19:33:17,347:INFO:knn                 K Neighbors Regressor  0.1569  0.1138  0.3352  0.8180   
2023-04-29 19:33:17,348:INFO:ada                    AdaBoost Regressor  0.3401  0.1584  0.3950  0.7397   
2023-04-29 19:33:17,348:INFO:br                         Bayesian Ridge  0.3757  0.2670  0.5151  0.5755   
2023-04-29 19:33:17,348:INFO:ridge                    Ridge Regression  0.3757  0.2671  0.5151  0.5752   
2023-04-29 19:33:17,348:INFO:lar                Least Angle Regression  0.3757  0.2671  0.5151  0.5752   
2023-04-29 19:33:17,348:INFO:lr                      Linear Regression  0.3757  0.2671  0.5151  0.5752   
2023-04-29 19:33:17,348:INFO:huber                     Huber Regressor  0.3454  0.3189  0.5596  0.4897   
2023-04-29 19:33:17,348:INFO:omp           Orthogonal Matching Pursuit  0.4238  0.3242  0.5669  0.4847   
2023-04-29 19:33:17,348:INFO:par          Passive Aggressive Regressor  0.4407  0.3286  0.5715  0.4743   
2023-04-29 19:33:17,348:INFO:en                            Elastic Net  0.4725  0.4213  0.6472  0.3466   
2023-04-29 19:33:17,348:INFO:lasso                    Lasso Regression  0.5570  0.6149  0.7810  0.0524   
2023-04-29 19:33:17,348:INFO:llar         Lasso Least Angle Regression  0.5566  0.6584  0.8085 -0.0153   
2023-04-29 19:33:17,348:INFO:dummy                     Dummy Regressor  0.5566  0.6584  0.8085 -0.0153   
2023-04-29 19:33:17,349:INFO:
2023-04-29 19:33:17,349:INFO:           RMSLE    MAPE  TT (Sec)  
2023-04-29 19:33:17,349:INFO:et        0.0290  0.0114     0.799  
2023-04-29 19:33:17,349:INFO:rf        0.0304  0.0116     0.776  
2023-04-29 19:33:17,349:INFO:lightgbm  0.0336  0.0163     0.978  
2023-04-29 19:33:17,349:INFO:dt        0.0357  0.0077     0.694  
2023-04-29 19:33:17,349:INFO:gbr       0.0362  0.0232     0.784  
2023-04-29 19:33:17,349:INFO:knn       0.0565  0.0316     0.695  
2023-04-29 19:33:17,349:INFO:ada       0.0671  0.0708     0.758  
2023-04-29 19:33:17,349:INFO:br        0.0941  0.0805     0.728  
2023-04-29 19:33:17,349:INFO:ridge     0.0942  0.0804     0.711  
2023-04-29 19:33:17,349:INFO:lar       0.0942  0.0804     0.682  
2023-04-29 19:33:17,349:INFO:lr        0.0942  0.0804     1.328  
2023-04-29 19:33:17,349:INFO:huber     0.1149  0.0709     0.715  
2023-04-29 19:33:17,349:INFO:omp       0.1051  0.0905     0.681  
2023-04-29 19:33:17,349:INFO:par       0.1000  0.0917     0.670  
2023-04-29 19:33:17,349:INFO:en        0.1156  0.1046     0.663  
2023-04-29 19:33:17,349:INFO:lasso     0.1386  0.1247     0.707  
2023-04-29 19:33:17,349:INFO:llar      0.1431  0.1248     0.664  
2023-04-29 19:33:17,349:INFO:dummy     0.1431  0.1248     0.713  
2023-04-29 19:33:17,349:INFO:_master_model_container: 18
2023-04-29 19:33:17,350:INFO:_display_container: 2
2023-04-29 19:33:17,350:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8620)
2023-04-29 19:33:17,350:INFO:compare_models() successfully completed......................................
2023-04-29 19:33:17,352:INFO:Initializing predict_model()
2023-04-29 19:33:17,352:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EFE2D550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8620), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236E9E2B1F0>)
2023-04-29 19:33:17,352:INFO:Checking exceptions
2023-04-29 19:33:17,352:INFO:Preloading libraries
2023-04-29 19:33:17,353:INFO:Set up data.
2023-04-29 19:33:17,357:INFO:Set up index.
2023-04-29 19:33:17,411:INFO:                   Model     MAE  ...  RMSLE    MAPE
2023-04-29 19:33:17,411:INFO:0  Extra Trees Regressor  0.0232  ...  0.025  0.0049
2023-04-29 19:33:17,411:INFO:
2023-04-29 19:33:17,411:INFO:[1 rows x 7 columns]
2023-04-29 19:33:26,976:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:33:26,976:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:33:26,976:INFO:Data columns (total 8 columns):
2023-04-29 19:33:26,977:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:33:26,977:INFO:---  ------          --------------  -----  
2023-04-29 19:33:26,977:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:33:26,977:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:33:26,977:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:33:26,977:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:33:26,978:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:33:26,978:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:33:26,978:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:33:26,978:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:33:26,978:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:33:26,978:INFO:memory usage: 79.8 KB
2023-04-29 19:33:28,172:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:33:28,172:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:33:28,172:INFO:Data columns (total 8 columns):
2023-04-29 19:33:28,172:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:33:28,172:INFO:---  ------          --------------  -----  
2023-04-29 19:33:28,173:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:33:28,173:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:33:28,173:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:33:28,173:INFO:memory usage: 79.8 KB
2023-04-29 19:33:29,478:INFO:PyCaret RegressionExperiment
2023-04-29 19:33:29,478:INFO:Logging name: reg-default-name
2023-04-29 19:33:29,479:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 19:33:29,479:INFO:version 3.0.0
2023-04-29 19:33:29,479:INFO:Initializing setup()
2023-04-29 19:33:29,479:INFO:self.USI: 4065
2023-04-29 19:33:29,480:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:33:29,480:INFO:Checking environment
2023-04-29 19:33:29,480:INFO:python_version: 3.9.13
2023-04-29 19:33:29,480:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:33:29,480:INFO:machine: AMD64
2023-04-29 19:33:29,480:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:33:29,480:INFO:Memory: svmem(total=16935899136, available=5053587456, percent=70.2, used=11882311680, free=5053587456)
2023-04-29 19:33:29,480:INFO:Physical Core: 4
2023-04-29 19:33:29,480:INFO:Logical Core: 8
2023-04-29 19:33:29,480:INFO:Checking libraries
2023-04-29 19:33:29,480:INFO:System:
2023-04-29 19:33:29,480:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:33:29,480:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:33:29,480:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:33:29,480:INFO:PyCaret required dependencies:
2023-04-29 19:33:29,480:INFO:                 pip: 22.2.2
2023-04-29 19:33:29,480:INFO:          setuptools: 63.4.1
2023-04-29 19:33:29,480:INFO:             pycaret: 3.0.0
2023-04-29 19:33:29,480:INFO:             IPython: 7.31.1
2023-04-29 19:33:29,480:INFO:          ipywidgets: 7.6.5
2023-04-29 19:33:29,480:INFO:                tqdm: 4.64.1
2023-04-29 19:33:29,480:INFO:               numpy: 1.21.5
2023-04-29 19:33:29,480:INFO:              pandas: 1.4.4
2023-04-29 19:33:29,480:INFO:              jinja2: 2.11.3
2023-04-29 19:33:29,480:INFO:               scipy: 1.9.1
2023-04-29 19:33:29,480:INFO:              joblib: 1.2.0
2023-04-29 19:33:29,480:INFO:             sklearn: 1.0.2
2023-04-29 19:33:29,480:INFO:                pyod: 1.0.9
2023-04-29 19:33:29,480:INFO:            imblearn: 0.10.1
2023-04-29 19:33:29,480:INFO:   category_encoders: 2.6.0
2023-04-29 19:33:29,480:INFO:            lightgbm: 3.3.5
2023-04-29 19:33:29,480:INFO:               numba: 0.55.1
2023-04-29 19:33:29,480:INFO:            requests: 2.28.1
2023-04-29 19:33:29,480:INFO:          matplotlib: 3.5.2
2023-04-29 19:33:29,480:INFO:          scikitplot: 0.3.7
2023-04-29 19:33:29,480:INFO:         yellowbrick: 1.5
2023-04-29 19:33:29,480:INFO:              plotly: 5.9.0
2023-04-29 19:33:29,480:INFO:             kaleido: 0.2.1
2023-04-29 19:33:29,480:INFO:         statsmodels: 0.13.2
2023-04-29 19:33:29,481:INFO:              sktime: 0.17.1
2023-04-29 19:33:29,481:INFO:               tbats: 1.1.2
2023-04-29 19:33:29,481:INFO:            pmdarima: 2.0.3
2023-04-29 19:33:29,481:INFO:              psutil: 5.9.0
2023-04-29 19:33:29,481:INFO:PyCaret optional dependencies:
2023-04-29 19:33:29,481:INFO:                shap: 0.41.0
2023-04-29 19:33:29,481:INFO:           interpret: Not installed
2023-04-29 19:33:29,481:INFO:                umap: Not installed
2023-04-29 19:33:29,481:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:33:29,481:INFO:  explainerdashboard: Not installed
2023-04-29 19:33:29,481:INFO:             autoviz: Not installed
2023-04-29 19:33:29,481:INFO:           fairlearn: Not installed
2023-04-29 19:33:29,481:INFO:             xgboost: Not installed
2023-04-29 19:33:29,481:INFO:            catboost: Not installed
2023-04-29 19:33:29,481:INFO:              kmodes: Not installed
2023-04-29 19:33:29,481:INFO:             mlxtend: Not installed
2023-04-29 19:33:29,481:INFO:       statsforecast: Not installed
2023-04-29 19:33:29,481:INFO:        tune_sklearn: Not installed
2023-04-29 19:33:29,481:INFO:                 ray: Not installed
2023-04-29 19:33:29,481:INFO:            hyperopt: Not installed
2023-04-29 19:33:29,481:INFO:              optuna: Not installed
2023-04-29 19:33:29,481:INFO:               skopt: Not installed
2023-04-29 19:33:29,481:INFO:              mlflow: 2.2.1
2023-04-29 19:33:29,481:INFO:              gradio: Not installed
2023-04-29 19:33:29,481:INFO:             fastapi: Not installed
2023-04-29 19:33:29,481:INFO:             uvicorn: Not installed
2023-04-29 19:33:29,481:INFO:              m2cgen: Not installed
2023-04-29 19:33:29,481:INFO:           evidently: Not installed
2023-04-29 19:33:29,481:INFO:               fugue: Not installed
2023-04-29 19:33:29,481:INFO:           streamlit: 1.21.0
2023-04-29 19:33:29,481:INFO:             prophet: Not installed
2023-04-29 19:33:29,481:INFO:None
2023-04-29 19:33:29,482:INFO:Set up data.
2023-04-29 19:33:29,485:INFO:Set up train/test split.
2023-04-29 19:33:29,488:INFO:Set up index.
2023-04-29 19:33:29,488:INFO:Set up folding strategy.
2023-04-29 19:33:29,488:INFO:Assigning column types.
2023-04-29 19:33:29,490:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:33:29,490:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,495:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:29,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:29,683:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,688:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:29,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:29,818:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 19:33:29,823:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:29,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:29,953:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:33:29,958:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,116:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 19:33:30,133:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,281:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,297:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 19:33:30,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,712:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,815:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:33:30,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:30,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:30,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:33:31,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,081:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 19:33:31,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,435:INFO:Preparing preprocessing pipeline...
2023-04-29 19:33:31,436:INFO:Set up simple imputation.
2023-04-29 19:33:31,436:INFO:Set up column name cleaning.
2023-04-29 19:33:31,474:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:33:31,482:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 19:33:31,482:INFO:Creating final display dataframe.
2023-04-29 19:33:31,553:INFO:Setup _display_container:                     Description             Value
0                    Session id              5435
1                        Target             dSmix
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4065
2023-04-29 19:33:31,562:INFO:                    Description             Value
2023-04-29 19:33:31,563:INFO:0                    Session id              5435
2023-04-29 19:33:31,563:INFO:1                        Target             dSmix
2023-04-29 19:33:31,563:INFO:2                   Target type        Regression
2023-04-29 19:33:31,563:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:33:31,563:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:33:31,563:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:33:31,563:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:33:31,564:INFO:7              Numeric features                 7
2023-04-29 19:33:31,564:INFO:8                    Preprocess              True
2023-04-29 19:33:31,564:INFO:9               Imputation type            simple
2023-04-29 19:33:31,564:INFO:10           Numeric imputation              mean
2023-04-29 19:33:31,564:INFO:11       Categorical imputation              mode
2023-04-29 19:33:31,564:INFO:12               Fold Generator             KFold
2023-04-29 19:33:31,564:INFO:13                  Fold Number                10
2023-04-29 19:33:31,564:INFO:14                     CPU Jobs                -1
2023-04-29 19:33:31,564:INFO:15                      Use GPU             False
2023-04-29 19:33:31,564:INFO:16               Log Experiment             False
2023-04-29 19:33:31,565:INFO:17              Experiment Name  reg-default-name
2023-04-29 19:33:31,565:INFO:18                          USI              4065
2023-04-29 19:33:31,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:33:31,980:INFO:setup() successfully completed in 3.18s...............
2023-04-29 19:33:31,987:INFO:Initializing compare_models()
2023-04-29 19:33:31,988:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 19:33:31,988:INFO:Checking exceptions
2023-04-29 19:33:31,992:INFO:Preparing display monitor
2023-04-29 19:33:31,996:WARNING:
2023-04-29 19:33:31,996:WARNING:Processing:   0%|                 | 0/77 [00:00<?, ?it/s]
2023-04-29 19:33:31,997:INFO:Initializing Linear Regression
2023-04-29 19:33:31,997:INFO:Total runtime is 0.0 minutes
2023-04-29 19:33:31,998:INFO:SubProcess create_model() called ==================================
2023-04-29 19:33:31,998:INFO:Initializing create_model()
2023-04-29 19:33:31,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:33:31,998:INFO:Checking exceptions
2023-04-29 19:33:31,998:INFO:Importing libraries
2023-04-29 19:33:31,999:INFO:Copying training dataset
2023-04-29 19:33:32,008:INFO:Defining folds
2023-04-29 19:33:32,008:INFO:Declaring metric variables
2023-04-29 19:33:32,009:INFO:Importing untrained model
2023-04-29 19:33:32,010:INFO:Linear Regression Imported successfully
2023-04-29 19:33:32,011:INFO:Starting cross validation
2023-04-29 19:33:32,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:33:40,145:INFO:Calculating mean and std
2023-04-29 19:33:40,146:WARNING:Processing:   6%|5        | 5/77 [00:08<01:57,  1.63s/it]
2023-04-29 19:33:40,146:INFO:Creating metrics dataframe
2023-04-29 19:33:41,466:WARNING:Processing:   8%|7        | 6/77 [00:09<01:50,  1.56s/it]
2023-04-29 19:33:41,466:INFO:Uploading results into container
2023-04-29 19:33:41,467:INFO:Uploading model into container now
2023-04-29 19:33:41,468:INFO:_master_model_container: 1
2023-04-29 19:33:41,468:INFO:_display_container: 2
2023-04-29 19:33:41,468:INFO:LinearRegression(n_jobs=-1)
2023-04-29 19:33:41,468:INFO:create_model() successfully completed......................................
2023-04-29 19:33:41,647:INFO:SubProcess create_model() end ==================================
2023-04-29 19:33:41,647:INFO:Creating metrics dataframe
2023-04-29 19:33:41,658:INFO:Initializing Lasso Regression
2023-04-29 19:33:41,658:INFO:Total runtime is 0.1610087474187215 minutes
2023-04-29 19:33:41,658:INFO:SubProcess create_model() called ==================================
2023-04-29 19:33:41,659:INFO:Initializing create_model()
2023-04-29 19:33:41,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:33:41,659:INFO:Checking exceptions
2023-04-29 19:33:41,659:INFO:Importing libraries
2023-04-29 19:33:41,659:INFO:Copying training dataset
2023-04-29 19:33:41,664:WARNING:Processing:   9%|8        | 7/77 [00:09<01:26,  1.23s/it]
2023-04-29 19:33:41,664:INFO:Defining folds
2023-04-29 19:33:41,664:INFO:Declaring metric variables
2023-04-29 19:33:41,664:INFO:Importing untrained model
2023-04-29 19:33:41,665:INFO:Lasso Regression Imported successfully
2023-04-29 19:33:41,665:INFO:Starting cross validation
2023-04-29 19:33:41,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:33:49,817:INFO:Calculating mean and std
2023-04-29 19:33:49,817:WARNING:Processing:  12%|#        | 9/77 [00:17<02:42,  2.39s/it]
2023-04-29 19:33:49,817:INFO:Creating metrics dataframe
2023-04-29 19:33:51,260:WARNING:Processing:  13%|#       | 10/77 [00:19<02:25,  2.18s/it]
2023-04-29 19:33:51,260:INFO:Uploading results into container
2023-04-29 19:33:51,261:INFO:Uploading model into container now
2023-04-29 19:33:51,262:INFO:_master_model_container: 2
2023-04-29 19:33:51,262:INFO:_display_container: 2
2023-04-29 19:33:51,263:INFO:Lasso(random_state=5435)
2023-04-29 19:33:51,263:INFO:create_model() successfully completed......................................
2023-04-29 19:33:51,384:INFO:SubProcess create_model() end ==================================
2023-04-29 19:33:51,384:INFO:Creating metrics dataframe
2023-04-29 19:33:51,394:INFO:Initializing Ridge Regression
2023-04-29 19:33:51,394:INFO:Total runtime is 0.32327614625295004 minutes
2023-04-29 19:33:51,395:INFO:SubProcess create_model() called ==================================
2023-04-29 19:33:51,395:INFO:Initializing create_model()
2023-04-29 19:33:51,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:33:51,395:INFO:Checking exceptions
2023-04-29 19:33:51,395:INFO:Importing libraries
2023-04-29 19:33:51,395:INFO:Copying training dataset
2023-04-29 19:33:51,401:WARNING:Processing:  14%|#1      | 11/77 [00:19<01:50,  1.68s/it]
2023-04-29 19:33:51,401:INFO:Defining folds
2023-04-29 19:33:51,401:INFO:Declaring metric variables
2023-04-29 19:33:51,401:INFO:Importing untrained model
2023-04-29 19:33:51,402:INFO:Ridge Regression Imported successfully
2023-04-29 19:33:51,402:INFO:Starting cross validation
2023-04-29 19:33:51,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:00,734:INFO:Calculating mean and std
2023-04-29 19:34:00,736:WARNING:Processing:  17%|#3      | 13/77 [00:28<03:06,  2.91s/it]
2023-04-29 19:34:00,736:INFO:Creating metrics dataframe
2023-04-29 19:34:01,918:WARNING:Processing:  18%|#4      | 14/77 [00:29<02:38,  2.52s/it]
2023-04-29 19:34:01,918:INFO:Uploading results into container
2023-04-29 19:34:01,919:INFO:Uploading model into container now
2023-04-29 19:34:01,920:INFO:_master_model_container: 3
2023-04-29 19:34:01,920:INFO:_display_container: 2
2023-04-29 19:34:01,920:INFO:Ridge(random_state=5435)
2023-04-29 19:34:01,920:INFO:create_model() successfully completed......................................
2023-04-29 19:34:02,055:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:02,055:INFO:Creating metrics dataframe
2023-04-29 19:34:02,065:INFO:Initializing Elastic Net
2023-04-29 19:34:02,066:INFO:Total runtime is 0.5011459867159526 minutes
2023-04-29 19:34:02,066:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:02,067:INFO:Initializing create_model()
2023-04-29 19:34:02,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:02,068:INFO:Checking exceptions
2023-04-29 19:34:02,069:INFO:Importing libraries
2023-04-29 19:34:02,069:INFO:Copying training dataset
2023-04-29 19:34:02,078:WARNING:Processing:  19%|#5      | 15/77 [00:30<02:00,  1.94s/it]
2023-04-29 19:34:02,078:INFO:Defining folds
2023-04-29 19:34:02,078:INFO:Declaring metric variables
2023-04-29 19:34:02,079:INFO:Importing untrained model
2023-04-29 19:34:02,080:INFO:Elastic Net Imported successfully
2023-04-29 19:34:02,080:INFO:Starting cross validation
2023-04-29 19:34:02,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:11,664:INFO:Calculating mean and std
2023-04-29 19:34:11,665:WARNING:Processing:  22%|#7      | 17/77 [00:39<03:06,  3.11s/it]
2023-04-29 19:34:11,665:INFO:Creating metrics dataframe
2023-04-29 19:34:12,827:WARNING:Processing:  23%|#8      | 18/77 [00:40<02:37,  2.67s/it]
2023-04-29 19:34:12,827:INFO:Uploading results into container
2023-04-29 19:34:12,827:INFO:Uploading model into container now
2023-04-29 19:34:12,827:INFO:_master_model_container: 4
2023-04-29 19:34:12,828:INFO:_display_container: 2
2023-04-29 19:34:12,828:INFO:ElasticNet(random_state=5435)
2023-04-29 19:34:12,828:INFO:create_model() successfully completed......................................
2023-04-29 19:34:12,936:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:12,936:INFO:Creating metrics dataframe
2023-04-29 19:34:12,949:INFO:Initializing Least Angle Regression
2023-04-29 19:34:12,949:INFO:Total runtime is 0.6825246373812357 minutes
2023-04-29 19:34:12,949:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:12,950:INFO:Initializing create_model()
2023-04-29 19:34:12,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:12,950:INFO:Checking exceptions
2023-04-29 19:34:12,950:INFO:Importing libraries
2023-04-29 19:34:12,950:INFO:Copying training dataset
2023-04-29 19:34:12,958:WARNING:Processing:  25%|#9      | 19/77 [00:40<01:58,  2.05s/it]
2023-04-29 19:34:12,958:INFO:Defining folds
2023-04-29 19:34:12,958:INFO:Declaring metric variables
2023-04-29 19:34:12,958:INFO:Importing untrained model
2023-04-29 19:34:12,959:INFO:Least Angle Regression Imported successfully
2023-04-29 19:34:12,960:INFO:Starting cross validation
2023-04-29 19:34:12,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:13,055:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,069:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,077:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,096:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,107:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,124:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,131:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:13,146:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:15,316:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:15,349:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:21,486:INFO:Calculating mean and std
2023-04-29 19:34:21,487:WARNING:Processing:  27%|##1     | 21/77 [00:49<02:45,  2.96s/it]
2023-04-29 19:34:21,487:INFO:Creating metrics dataframe
2023-04-29 19:34:22,572:WARNING:Processing:  29%|##2     | 22/77 [00:50<02:19,  2.53s/it]
2023-04-29 19:34:22,573:INFO:Uploading results into container
2023-04-29 19:34:22,573:INFO:Uploading model into container now
2023-04-29 19:34:22,574:INFO:_master_model_container: 5
2023-04-29 19:34:22,574:INFO:_display_container: 2
2023-04-29 19:34:22,574:INFO:Lars(random_state=5435)
2023-04-29 19:34:22,574:INFO:create_model() successfully completed......................................
2023-04-29 19:34:22,700:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:22,700:INFO:Creating metrics dataframe
2023-04-29 19:34:22,708:INFO:Initializing Lasso Least Angle Regression
2023-04-29 19:34:22,708:INFO:Total runtime is 0.8451740821202596 minutes
2023-04-29 19:34:22,708:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:22,708:INFO:Initializing create_model()
2023-04-29 19:34:22,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:22,709:INFO:Checking exceptions
2023-04-29 19:34:22,709:INFO:Importing libraries
2023-04-29 19:34:22,709:INFO:Copying training dataset
2023-04-29 19:34:22,713:WARNING:Processing:  30%|##3     | 23/77 [00:50<01:45,  1.95s/it]
2023-04-29 19:34:22,713:INFO:Defining folds
2023-04-29 19:34:22,713:INFO:Declaring metric variables
2023-04-29 19:34:22,713:INFO:Importing untrained model
2023-04-29 19:34:22,713:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 19:34:22,714:INFO:Starting cross validation
2023-04-29 19:34:22,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:22,816:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,838:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,846:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,853:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,877:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,893:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,909:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:22,925:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:24,590:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:34:31,457:INFO:Calculating mean and std
2023-04-29 19:34:31,458:WARNING:Processing:  32%|##5     | 25/77 [00:59<02:33,  2.95s/it]
2023-04-29 19:34:31,458:INFO:Creating metrics dataframe
2023-04-29 19:34:32,565:WARNING:Processing:  34%|##7     | 26/77 [01:00<02:08,  2.53s/it]
2023-04-29 19:34:32,565:INFO:Uploading results into container
2023-04-29 19:34:32,566:INFO:Uploading model into container now
2023-04-29 19:34:32,568:INFO:_master_model_container: 6
2023-04-29 19:34:32,568:INFO:_display_container: 2
2023-04-29 19:34:32,569:INFO:LassoLars(random_state=5435)
2023-04-29 19:34:32,569:INFO:create_model() successfully completed......................................
2023-04-29 19:34:32,696:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:32,697:INFO:Creating metrics dataframe
2023-04-29 19:34:32,705:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 19:34:32,705:INFO:Total runtime is 1.0117937088012696 minutes
2023-04-29 19:34:32,705:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:32,705:INFO:Initializing create_model()
2023-04-29 19:34:32,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:32,705:INFO:Checking exceptions
2023-04-29 19:34:32,705:INFO:Importing libraries
2023-04-29 19:34:32,705:INFO:Copying training dataset
2023-04-29 19:34:32,708:WARNING:Processing:  35%|##8     | 27/77 [01:00<01:37,  1.94s/it]
2023-04-29 19:34:32,708:INFO:Defining folds
2023-04-29 19:34:32,708:INFO:Declaring metric variables
2023-04-29 19:34:32,709:INFO:Importing untrained model
2023-04-29 19:34:32,709:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 19:34:32,709:INFO:Starting cross validation
2023-04-29 19:34:32,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:32,785:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,798:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,816:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,832:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,859:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,866:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,885:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:32,901:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:34,636:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:34,696:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:34:40,794:INFO:Calculating mean and std
2023-04-29 19:34:40,795:WARNING:Processing:  38%|###     | 29/77 [01:08<02:14,  2.81s/it]
2023-04-29 19:34:40,795:INFO:Creating metrics dataframe
2023-04-29 19:34:42,124:WARNING:Processing:  39%|###1    | 30/77 [01:10<01:56,  2.47s/it]
2023-04-29 19:34:42,124:INFO:Uploading results into container
2023-04-29 19:34:42,124:INFO:Uploading model into container now
2023-04-29 19:34:42,125:INFO:_master_model_container: 7
2023-04-29 19:34:42,125:INFO:_display_container: 2
2023-04-29 19:34:42,125:INFO:OrthogonalMatchingPursuit()
2023-04-29 19:34:42,125:INFO:create_model() successfully completed......................................
2023-04-29 19:34:42,231:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:42,231:INFO:Creating metrics dataframe
2023-04-29 19:34:42,235:INFO:Initializing Bayesian Ridge
2023-04-29 19:34:42,235:INFO:Total runtime is 1.1706226428349813 minutes
2023-04-29 19:34:42,236:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:42,236:INFO:Initializing create_model()
2023-04-29 19:34:42,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:42,236:INFO:Checking exceptions
2023-04-29 19:34:42,236:INFO:Importing libraries
2023-04-29 19:34:42,236:INFO:Copying training dataset
2023-04-29 19:34:42,245:WARNING:Processing:  40%|###2    | 31/77 [01:10<01:27,  1.90s/it]
2023-04-29 19:34:42,246:INFO:Defining folds
2023-04-29 19:34:42,246:INFO:Declaring metric variables
2023-04-29 19:34:42,246:INFO:Importing untrained model
2023-04-29 19:34:42,247:INFO:Bayesian Ridge Imported successfully
2023-04-29 19:34:42,248:INFO:Starting cross validation
2023-04-29 19:34:42,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:49,799:INFO:Calculating mean and std
2023-04-29 19:34:49,800:WARNING:Processing:  43%|###4    | 33/77 [01:17<01:57,  2.67s/it]
2023-04-29 19:34:49,800:INFO:Creating metrics dataframe
2023-04-29 19:34:51,390:WARNING:Processing:  44%|###5    | 34/77 [01:19<01:44,  2.43s/it]
2023-04-29 19:34:51,390:INFO:Uploading results into container
2023-04-29 19:34:51,391:INFO:Uploading model into container now
2023-04-29 19:34:51,391:INFO:_master_model_container: 8
2023-04-29 19:34:51,392:INFO:_display_container: 2
2023-04-29 19:34:51,392:INFO:BayesianRidge()
2023-04-29 19:34:51,392:INFO:create_model() successfully completed......................................
2023-04-29 19:34:51,495:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:51,495:INFO:Creating metrics dataframe
2023-04-29 19:34:51,499:INFO:Initializing Passive Aggressive Regressor
2023-04-29 19:34:51,499:INFO:Total runtime is 1.3250258406003317 minutes
2023-04-29 19:34:51,499:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:51,499:INFO:Initializing create_model()
2023-04-29 19:34:51,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:51,499:INFO:Checking exceptions
2023-04-29 19:34:51,499:INFO:Importing libraries
2023-04-29 19:34:51,499:INFO:Copying training dataset
2023-04-29 19:34:51,502:WARNING:Processing:  45%|###6    | 35/77 [01:19<01:18,  1.86s/it]
2023-04-29 19:34:51,502:INFO:Defining folds
2023-04-29 19:34:51,502:INFO:Declaring metric variables
2023-04-29 19:34:51,502:INFO:Importing untrained model
2023-04-29 19:34:51,502:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 19:34:51,503:INFO:Starting cross validation
2023-04-29 19:34:51,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:34:58,556:INFO:Calculating mean and std
2023-04-29 19:34:58,557:WARNING:Processing:  48%|###8    | 37/77 [01:26<01:41,  2.55s/it]
2023-04-29 19:34:58,558:INFO:Creating metrics dataframe
2023-04-29 19:34:59,389:WARNING:Processing:  49%|###9    | 38/77 [01:27<01:24,  2.16s/it]
2023-04-29 19:34:59,389:INFO:Uploading results into container
2023-04-29 19:34:59,390:INFO:Uploading model into container now
2023-04-29 19:34:59,390:INFO:_master_model_container: 9
2023-04-29 19:34:59,390:INFO:_display_container: 2
2023-04-29 19:34:59,391:INFO:PassiveAggressiveRegressor(random_state=5435)
2023-04-29 19:34:59,391:INFO:create_model() successfully completed......................................
2023-04-29 19:34:59,495:INFO:SubProcess create_model() end ==================================
2023-04-29 19:34:59,495:INFO:Creating metrics dataframe
2023-04-29 19:34:59,499:INFO:Initializing Huber Regressor
2023-04-29 19:34:59,499:INFO:Total runtime is 1.4583576242129008 minutes
2023-04-29 19:34:59,499:INFO:SubProcess create_model() called ==================================
2023-04-29 19:34:59,499:INFO:Initializing create_model()
2023-04-29 19:34:59,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:34:59,500:INFO:Checking exceptions
2023-04-29 19:34:59,500:INFO:Importing libraries
2023-04-29 19:34:59,500:INFO:Copying training dataset
2023-04-29 19:34:59,503:WARNING:Processing:  51%|####    | 39/77 [01:27<01:02,  1.66s/it]
2023-04-29 19:34:59,503:INFO:Defining folds
2023-04-29 19:34:59,503:INFO:Declaring metric variables
2023-04-29 19:34:59,503:INFO:Importing untrained model
2023-04-29 19:34:59,503:INFO:Huber Regressor Imported successfully
2023-04-29 19:34:59,503:INFO:Starting cross validation
2023-04-29 19:34:59,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:35:06,890:INFO:Calculating mean and std
2023-04-29 19:35:06,891:WARNING:Processing:  53%|####2   | 41/77 [01:34<01:29,  2.50s/it]
2023-04-29 19:35:06,891:INFO:Creating metrics dataframe
2023-04-29 19:35:07,724:WARNING:Processing:  55%|####3   | 42/77 [01:35<01:14,  2.12s/it]
2023-04-29 19:35:07,724:INFO:Uploading results into container
2023-04-29 19:35:07,724:INFO:Uploading model into container now
2023-04-29 19:35:07,725:INFO:_master_model_container: 10
2023-04-29 19:35:07,725:INFO:_display_container: 2
2023-04-29 19:35:07,725:INFO:HuberRegressor()
2023-04-29 19:35:07,725:INFO:create_model() successfully completed......................................
2023-04-29 19:35:07,833:INFO:SubProcess create_model() end ==================================
2023-04-29 19:35:07,834:INFO:Creating metrics dataframe
2023-04-29 19:35:07,838:INFO:Initializing K Neighbors Regressor
2023-04-29 19:35:07,838:INFO:Total runtime is 1.5973534186681113 minutes
2023-04-29 19:35:07,839:INFO:SubProcess create_model() called ==================================
2023-04-29 19:35:07,839:INFO:Initializing create_model()
2023-04-29 19:35:07,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:35:07,839:INFO:Checking exceptions
2023-04-29 19:35:07,839:INFO:Importing libraries
2023-04-29 19:35:07,839:INFO:Copying training dataset
2023-04-29 19:35:07,844:WARNING:Processing:  56%|####4   | 43/77 [01:35<00:55,  1.63s/it]
2023-04-29 19:35:07,844:INFO:Defining folds
2023-04-29 19:35:07,844:INFO:Declaring metric variables
2023-04-29 19:35:07,844:INFO:Importing untrained model
2023-04-29 19:35:07,846:INFO:K Neighbors Regressor Imported successfully
2023-04-29 19:35:07,847:INFO:Starting cross validation
2023-04-29 19:35:07,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:35:15,429:INFO:Calculating mean and std
2023-04-29 19:35:15,431:WARNING:Processing:  58%|####6   | 45/77 [01:43<01:20,  2.52s/it]
2023-04-29 19:35:15,431:INFO:Creating metrics dataframe
2023-04-29 19:35:17,075:WARNING:Processing:  60%|####7   | 46/77 [01:45<01:11,  2.32s/it]
2023-04-29 19:35:17,075:INFO:Uploading results into container
2023-04-29 19:35:17,076:INFO:Uploading model into container now
2023-04-29 19:35:17,076:INFO:_master_model_container: 11
2023-04-29 19:35:17,076:INFO:_display_container: 2
2023-04-29 19:35:17,076:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 19:35:17,076:INFO:create_model() successfully completed......................................
2023-04-29 19:35:17,184:INFO:SubProcess create_model() end ==================================
2023-04-29 19:35:17,184:INFO:Creating metrics dataframe
2023-04-29 19:35:17,190:INFO:Initializing Decision Tree Regressor
2023-04-29 19:35:17,190:INFO:Total runtime is 1.7532154758771261 minutes
2023-04-29 19:35:17,190:INFO:SubProcess create_model() called ==================================
2023-04-29 19:35:17,191:INFO:Initializing create_model()
2023-04-29 19:35:17,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:35:17,191:INFO:Checking exceptions
2023-04-29 19:35:17,191:INFO:Importing libraries
2023-04-29 19:35:17,191:INFO:Copying training dataset
2023-04-29 19:35:17,196:WARNING:Processing:  61%|####8   | 47/77 [01:45<00:53,  1.78s/it]
2023-04-29 19:35:17,197:INFO:Defining folds
2023-04-29 19:35:17,197:INFO:Declaring metric variables
2023-04-29 19:35:17,198:INFO:Importing untrained model
2023-04-29 19:35:17,198:INFO:Decision Tree Regressor Imported successfully
2023-04-29 19:35:17,198:INFO:Starting cross validation
2023-04-29 19:35:17,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:35:24,045:INFO:Calculating mean and std
2023-04-29 19:35:24,046:WARNING:Processing:  64%|#####   | 49/77 [01:52<01:08,  2.46s/it]
2023-04-29 19:35:24,046:INFO:Creating metrics dataframe
2023-04-29 19:35:25,052:WARNING:Processing:  65%|#####1  | 50/77 [01:53<00:57,  2.13s/it]
2023-04-29 19:35:25,052:INFO:Uploading results into container
2023-04-29 19:35:25,053:INFO:Uploading model into container now
2023-04-29 19:35:25,053:INFO:_master_model_container: 12
2023-04-29 19:35:25,053:INFO:_display_container: 2
2023-04-29 19:35:25,054:INFO:DecisionTreeRegressor(random_state=5435)
2023-04-29 19:35:25,054:INFO:create_model() successfully completed......................................
2023-04-29 19:35:25,165:INFO:SubProcess create_model() end ==================================
2023-04-29 19:35:25,165:INFO:Creating metrics dataframe
2023-04-29 19:35:25,170:INFO:Initializing Random Forest Regressor
2023-04-29 19:35:25,170:INFO:Total runtime is 1.8862202882766725 minutes
2023-04-29 19:35:25,170:INFO:SubProcess create_model() called ==================================
2023-04-29 19:35:25,170:INFO:Initializing create_model()
2023-04-29 19:35:25,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:35:25,171:INFO:Checking exceptions
2023-04-29 19:35:25,171:INFO:Importing libraries
2023-04-29 19:35:25,171:INFO:Copying training dataset
2023-04-29 19:35:25,174:WARNING:Processing:  66%|#####2  | 51/77 [01:53<00:42,  1.64s/it]
2023-04-29 19:35:25,174:INFO:Defining folds
2023-04-29 19:35:25,174:INFO:Declaring metric variables
2023-04-29 19:35:25,174:INFO:Importing untrained model
2023-04-29 19:35:25,175:INFO:Random Forest Regressor Imported successfully
2023-04-29 19:35:25,175:INFO:Starting cross validation
2023-04-29 19:35:25,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:35:37,378:INFO:Calculating mean and std
2023-04-29 19:35:37,379:WARNING:Processing:  69%|#####5  | 53/77 [02:05<01:23,  3.48s/it]
2023-04-29 19:35:37,379:INFO:Creating metrics dataframe
2023-04-29 19:35:38,199:WARNING:Processing:  70%|#####6  | 54/77 [02:06<01:06,  2.87s/it]
2023-04-29 19:35:38,199:INFO:Uploading results into container
2023-04-29 19:35:38,200:INFO:Uploading model into container now
2023-04-29 19:35:38,200:INFO:_master_model_container: 13
2023-04-29 19:35:38,200:INFO:_display_container: 2
2023-04-29 19:35:38,201:INFO:RandomForestRegressor(n_jobs=-1, random_state=5435)
2023-04-29 19:35:38,201:INFO:create_model() successfully completed......................................
2023-04-29 19:35:38,307:INFO:SubProcess create_model() end ==================================
2023-04-29 19:35:38,307:INFO:Creating metrics dataframe
2023-04-29 19:35:38,312:INFO:Initializing Extra Trees Regressor
2023-04-29 19:35:38,312:INFO:Total runtime is 2.105251669883728 minutes
2023-04-29 19:35:38,312:INFO:SubProcess create_model() called ==================================
2023-04-29 19:35:38,313:INFO:Initializing create_model()
2023-04-29 19:35:38,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:35:38,313:INFO:Checking exceptions
2023-04-29 19:35:38,313:INFO:Importing libraries
2023-04-29 19:35:38,313:INFO:Copying training dataset
2023-04-29 19:35:38,316:WARNING:Processing:  71%|#####7  | 55/77 [02:06<00:48,  2.20s/it]
2023-04-29 19:35:38,316:INFO:Defining folds
2023-04-29 19:35:38,316:INFO:Declaring metric variables
2023-04-29 19:35:38,316:INFO:Importing untrained model
2023-04-29 19:35:38,317:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:35:38,317:INFO:Starting cross validation
2023-04-29 19:35:38,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:35:46,793:INFO:Calculating mean and std
2023-04-29 19:35:46,795:WARNING:Processing:  74%|#####9  | 57/77 [02:14<01:00,  3.04s/it]
2023-04-29 19:35:46,795:INFO:Creating metrics dataframe
2023-04-29 19:35:47,666:WARNING:Processing:  75%|######  | 58/77 [02:15<00:48,  2.55s/it]
2023-04-29 19:35:47,667:INFO:Uploading results into container
2023-04-29 19:35:47,667:INFO:Uploading model into container now
2023-04-29 19:35:47,667:INFO:_master_model_container: 14
2023-04-29 19:35:47,668:INFO:_display_container: 2
2023-04-29 19:35:47,668:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5435)
2023-04-29 19:35:47,668:INFO:create_model() successfully completed......................................
2023-04-29 19:35:47,780:INFO:SubProcess create_model() end ==================================
2023-04-29 19:35:47,780:INFO:Creating metrics dataframe
2023-04-29 19:35:47,789:INFO:Initializing AdaBoost Regressor
2023-04-29 19:35:47,790:INFO:Total runtime is 2.263209088643392 minutes
2023-04-29 19:35:47,790:INFO:SubProcess create_model() called ==================================
2023-04-29 19:35:47,790:INFO:Initializing create_model()
2023-04-29 19:35:47,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:35:47,790:INFO:Checking exceptions
2023-04-29 19:35:47,790:INFO:Importing libraries
2023-04-29 19:35:47,790:INFO:Copying training dataset
2023-04-29 19:35:47,796:WARNING:Processing:  77%|######1 | 59/77 [02:15<00:35,  1.95s/it]
2023-04-29 19:35:47,796:INFO:Defining folds
2023-04-29 19:35:47,796:INFO:Declaring metric variables
2023-04-29 19:35:47,796:INFO:Importing untrained model
2023-04-29 19:35:47,797:INFO:AdaBoost Regressor Imported successfully
2023-04-29 19:35:47,797:INFO:Starting cross validation
2023-04-29 19:35:47,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:35:56,676:INFO:Calculating mean and std
2023-04-29 19:35:56,677:WARNING:Processing:  79%|######3 | 61/77 [02:24<00:47,  2.98s/it]
2023-04-29 19:35:56,677:INFO:Creating metrics dataframe
2023-04-29 19:35:57,632:WARNING:Processing:  81%|######4 | 62/77 [02:25<00:37,  2.52s/it]
2023-04-29 19:35:57,632:INFO:Uploading results into container
2023-04-29 19:35:57,632:INFO:Uploading model into container now
2023-04-29 19:35:57,633:INFO:_master_model_container: 15
2023-04-29 19:35:57,633:INFO:_display_container: 2
2023-04-29 19:35:57,633:INFO:AdaBoostRegressor(random_state=5435)
2023-04-29 19:35:57,633:INFO:create_model() successfully completed......................................
2023-04-29 19:35:57,744:INFO:SubProcess create_model() end ==================================
2023-04-29 19:35:57,745:INFO:Creating metrics dataframe
2023-04-29 19:35:57,749:INFO:Initializing Gradient Boosting Regressor
2023-04-29 19:35:57,749:INFO:Total runtime is 2.429202167193095 minutes
2023-04-29 19:35:57,749:INFO:SubProcess create_model() called ==================================
2023-04-29 19:35:57,749:INFO:Initializing create_model()
2023-04-29 19:35:57,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:35:57,749:INFO:Checking exceptions
2023-04-29 19:35:57,749:INFO:Importing libraries
2023-04-29 19:35:57,749:INFO:Copying training dataset
2023-04-29 19:35:57,752:WARNING:Processing:  82%|######5 | 63/77 [02:25<00:27,  1.93s/it]
2023-04-29 19:35:57,752:INFO:Defining folds
2023-04-29 19:35:57,753:INFO:Declaring metric variables
2023-04-29 19:35:57,753:INFO:Importing untrained model
2023-04-29 19:35:57,753:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 19:35:57,753:INFO:Starting cross validation
2023-04-29 19:35:57,755:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:36:12,297:INFO:Calculating mean and std
2023-04-29 19:36:12,298:WARNING:Processing:  84%|######7 | 65/77 [02:40<00:49,  4.13s/it]
2023-04-29 19:36:12,299:INFO:Creating metrics dataframe
2023-04-29 19:36:13,199:WARNING:Processing:  86%|######8 | 66/77 [02:41<00:37,  3.40s/it]
2023-04-29 19:36:13,199:INFO:Uploading results into container
2023-04-29 19:36:13,199:INFO:Uploading model into container now
2023-04-29 19:36:13,200:INFO:_master_model_container: 16
2023-04-29 19:36:13,200:INFO:_display_container: 2
2023-04-29 19:36:13,200:INFO:GradientBoostingRegressor(random_state=5435)
2023-04-29 19:36:13,200:INFO:create_model() successfully completed......................................
2023-04-29 19:36:13,324:INFO:SubProcess create_model() end ==================================
2023-04-29 19:36:13,324:INFO:Creating metrics dataframe
2023-04-29 19:36:13,334:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:36:13,334:INFO:Total runtime is 2.6889493862787885 minutes
2023-04-29 19:36:13,334:INFO:SubProcess create_model() called ==================================
2023-04-29 19:36:13,335:INFO:Initializing create_model()
2023-04-29 19:36:13,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:36:13,335:INFO:Checking exceptions
2023-04-29 19:36:13,335:INFO:Importing libraries
2023-04-29 19:36:13,335:INFO:Copying training dataset
2023-04-29 19:36:13,340:WARNING:Processing:  87%|######9 | 67/77 [02:41<00:25,  2.60s/it]
2023-04-29 19:36:13,341:INFO:Defining folds
2023-04-29 19:36:13,341:INFO:Declaring metric variables
2023-04-29 19:36:13,341:INFO:Importing untrained model
2023-04-29 19:36:13,342:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:36:13,342:INFO:Starting cross validation
2023-04-29 19:36:13,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:36:21,267:INFO:Calculating mean and std
2023-04-29 19:36:21,267:WARNING:Processing:  90%|#######1| 69/77 [02:49<00:25,  3.16s/it]
2023-04-29 19:36:21,268:INFO:Creating metrics dataframe
2023-04-29 19:36:22,431:WARNING:Processing:  91%|#######2| 70/77 [02:50<00:18,  2.71s/it]
2023-04-29 19:36:22,431:INFO:Uploading results into container
2023-04-29 19:36:22,432:INFO:Uploading model into container now
2023-04-29 19:36:22,432:INFO:_master_model_container: 17
2023-04-29 19:36:22,432:INFO:_display_container: 2
2023-04-29 19:36:22,433:INFO:LGBMRegressor(random_state=5435)
2023-04-29 19:36:22,433:INFO:create_model() successfully completed......................................
2023-04-29 19:36:22,548:INFO:SubProcess create_model() end ==================================
2023-04-29 19:36:22,549:INFO:Creating metrics dataframe
2023-04-29 19:36:22,553:INFO:Initializing Dummy Regressor
2023-04-29 19:36:22,553:INFO:Total runtime is 2.842603135108948 minutes
2023-04-29 19:36:22,553:INFO:SubProcess create_model() called ==================================
2023-04-29 19:36:22,553:INFO:Initializing create_model()
2023-04-29 19:36:22,553:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB2AF10>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:36:22,553:INFO:Checking exceptions
2023-04-29 19:36:22,553:INFO:Importing libraries
2023-04-29 19:36:22,553:INFO:Copying training dataset
2023-04-29 19:36:22,556:WARNING:Processing:  92%|#######3| 71/77 [02:50<00:12,  2.07s/it]
2023-04-29 19:36:22,556:INFO:Defining folds
2023-04-29 19:36:22,556:INFO:Declaring metric variables
2023-04-29 19:36:22,556:INFO:Importing untrained model
2023-04-29 19:36:22,557:INFO:Dummy Regressor Imported successfully
2023-04-29 19:36:22,557:INFO:Starting cross validation
2023-04-29 19:36:22,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:36:29,843:INFO:Calculating mean and std
2023-04-29 19:36:29,843:WARNING:Processing:  95%|#######5| 73/77 [02:57<00:10,  2.72s/it]
2023-04-29 19:36:29,843:INFO:Creating metrics dataframe
2023-04-29 19:36:31,311:WARNING:Processing:  96%|#######6| 74/77 [02:59<00:07,  2.44s/it]
2023-04-29 19:36:31,311:INFO:Uploading results into container
2023-04-29 19:36:31,313:INFO:Uploading model into container now
2023-04-29 19:36:31,314:INFO:_master_model_container: 18
2023-04-29 19:36:31,314:INFO:_display_container: 2
2023-04-29 19:36:31,314:INFO:DummyRegressor()
2023-04-29 19:36:31,314:INFO:create_model() successfully completed......................................
2023-04-29 19:36:31,439:INFO:SubProcess create_model() end ==================================
2023-04-29 19:36:31,439:INFO:Creating metrics dataframe
2023-04-29 19:36:31,444:WARNING:Processing:  97%|#######7| 75/77 [02:59<00:03,  1.87s/it]
2023-04-29 19:36:31,446:INFO:Initializing create_model()
2023-04-29 19:36:31,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5435), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:36:31,446:INFO:Checking exceptions
2023-04-29 19:36:31,447:INFO:Importing libraries
2023-04-29 19:36:31,447:INFO:Copying training dataset
2023-04-29 19:36:31,450:INFO:Defining folds
2023-04-29 19:36:31,450:INFO:Declaring metric variables
2023-04-29 19:36:31,450:INFO:Importing untrained model
2023-04-29 19:36:31,450:INFO:Declaring custom model
2023-04-29 19:36:31,451:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:36:31,452:INFO:Cross validation set to False
2023-04-29 19:36:31,452:INFO:Fitting Model
2023-04-29 19:36:32,449:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5435)
2023-04-29 19:36:32,449:INFO:create_model() successfully completed......................................
2023-04-29 19:36:32,549:WARNING:Processing: 100%|########| 77/77 [03:00<00:00,  1.33s/it]
2023-04-29 19:36:32,549:WARNING:                                                         
2023-04-29 19:36:32,562:INFO:                                    Model     MAE     MSE    RMSE      R2  \
2023-04-29 19:36:32,562:INFO:et                  Extra Trees Regressor  0.1529  0.2794  0.4927  0.9016   
2023-04-29 19:36:32,562:INFO:rf                Random Forest Regressor  0.1904  0.3278  0.5448  0.8842   
2023-04-29 19:36:32,562:INFO:lightgbm  Light Gradient Boosting Machine  0.2317  0.3521  0.5753  0.8830   
2023-04-29 19:36:32,562:INFO:gbr           Gradient Boosting Regressor  0.3220  0.4069  0.6174  0.8637   
2023-04-29 19:36:32,562:INFO:dt                Decision Tree Regressor  0.1718  0.4325  0.5984  0.8573   
2023-04-29 19:36:32,562:INFO:knn                 K Neighbors Regressor  0.4057  0.7325  0.8434  0.7467   
2023-04-29 19:36:32,562:INFO:ada                    AdaBoost Regressor  0.8510  1.1669  1.0741  0.5968   
2023-04-29 19:36:32,562:INFO:ridge                    Ridge Regression  0.8081  1.5183  1.2113  0.4980   
2023-04-29 19:36:32,562:INFO:lar                Least Angle Regression  0.8080  1.5183  1.2113  0.4980   
2023-04-29 19:36:32,562:INFO:lr                      Linear Regression  0.8080  1.5183  1.2113  0.4980   
2023-04-29 19:36:32,562:INFO:br                         Bayesian Ridge  0.8083  1.5185  1.2115  0.4979   
2023-04-29 19:36:32,562:INFO:omp           Orthogonal Matching Pursuit  0.8210  1.6834  1.2711  0.4497   
2023-04-29 19:36:32,562:INFO:huber                     Huber Regressor  0.7180  1.7005  1.2711  0.4482   
2023-04-29 19:36:32,562:INFO:en                            Elastic Net  1.1189  2.4000  1.5387  0.2067   
2023-04-29 19:36:32,562:INFO:lasso                    Lasso Regression  1.2727  2.9315  1.7030  0.0261   
2023-04-29 19:36:32,562:INFO:llar         Lasso Least Angle Regression  1.2982  3.0596  1.7396 -0.0161   
2023-04-29 19:36:32,562:INFO:dummy                     Dummy Regressor  1.2982  3.0596  1.7396 -0.0161   
2023-04-29 19:36:32,562:INFO:par          Passive Aggressive Regressor  1.6707  4.5186  2.0628 -0.5944   
2023-04-29 19:36:32,562:INFO:
2023-04-29 19:36:32,562:INFO:           RMSLE    MAPE  TT (Sec)  
2023-04-29 19:36:32,562:INFO:et        0.0413  0.0140     0.848  
2023-04-29 19:36:32,562:INFO:rf        0.0485  0.0181     1.220  
2023-04-29 19:36:32,562:INFO:lightgbm  0.0529  0.0225     0.792  
2023-04-29 19:36:32,562:INFO:gbr       0.0546  0.0297     1.454  
2023-04-29 19:36:32,562:INFO:dt        0.0545  0.0157     0.685  
2023-04-29 19:36:32,563:INFO:knn       0.0731  0.0370     0.758  
2023-04-29 19:36:32,563:INFO:ada       0.0892  0.0733     0.888  
2023-04-29 19:36:32,563:INFO:ridge     0.1095  0.0771     0.933  
2023-04-29 19:36:32,563:INFO:lar       0.1095  0.0771     0.852  
2023-04-29 19:36:32,563:INFO:lr        0.1095  0.0771     0.813  
2023-04-29 19:36:32,563:INFO:br        0.1096  0.0771     0.755  
2023-04-29 19:36:32,563:INFO:omp       0.1155  0.0799     0.808  
2023-04-29 19:36:32,563:INFO:huber     0.1157  0.0728     0.739  
2023-04-29 19:36:32,563:INFO:en        0.1354  0.1062     0.958  
2023-04-29 19:36:32,563:INFO:lasso     0.1466  0.1193     0.815  
2023-04-29 19:36:32,563:INFO:llar      0.1492  0.1217     0.874  
2023-04-29 19:36:32,564:INFO:dummy     0.1492  0.1217     0.729  
2023-04-29 19:36:32,564:INFO:par       0.1662  0.1415     0.705  
2023-04-29 19:36:32,564:INFO:_master_model_container: 18
2023-04-29 19:36:32,564:INFO:_display_container: 2
2023-04-29 19:36:32,564:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5435)
2023-04-29 19:36:32,564:INFO:compare_models() successfully completed......................................
2023-04-29 19:36:32,568:INFO:Initializing predict_model()
2023-04-29 19:36:32,569:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236EEB94E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5435), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236EEB7E550>)
2023-04-29 19:36:32,569:INFO:Checking exceptions
2023-04-29 19:36:32,569:INFO:Preloading libraries
2023-04-29 19:36:32,569:INFO:Set up data.
2023-04-29 19:36:32,573:INFO:Set up index.
2023-04-29 19:36:32,631:INFO:                   Model     MAE  ...   RMSLE    MAPE
2023-04-29 19:36:32,631:INFO:0  Extra Trees Regressor  0.0343  ...  0.0147  0.0027
2023-04-29 19:36:32,631:INFO:
2023-04-29 19:36:32,631:INFO:[1 rows x 7 columns]
2023-04-29 19:37:02,714:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:37:02,714:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:37:02,714:INFO:Data columns (total 8 columns):
2023-04-29 19:37:02,714:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:37:02,714:INFO:---  ------          --------------  -----  
2023-04-29 19:37:02,714:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:37:02,714:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:37:02,714:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:37:02,714:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:37:02,715:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:37:02,715:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:37:02,715:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:37:02,715:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:37:02,715:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:37:02,715:INFO:memory usage: 79.8 KB
2023-04-29 19:37:12,953:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:37:12,954:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:37:12,954:INFO:Data columns (total 8 columns):
2023-04-29 19:37:12,954:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:37:12,954:INFO:---  ------          --------------  -----  
2023-04-29 19:37:12,954:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:37:12,954:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:37:12,954:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:37:12,954:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:37:12,955:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:37:12,955:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:37:12,955:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:37:12,955:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:37:12,955:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:37:12,955:INFO:memory usage: 79.8 KB
2023-04-29 19:37:37,395:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:37:37,395:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:37:37,395:INFO:Data columns (total 8 columns):
2023-04-29 19:37:37,395:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:37:37,395:INFO:---  ------          --------------  -----  
2023-04-29 19:37:37,395:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:37:37,396:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:37:37,396:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:37:37,396:INFO:memory usage: 79.8 KB
2023-04-29 19:37:47,830:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:37:47,830:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:37:47,830:INFO:Data columns (total 8 columns):
2023-04-29 19:37:47,830:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:37:47,830:INFO:---  ------          --------------  -----  
2023-04-29 19:37:47,830:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:37:47,830:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:37:47,830:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:37:47,830:INFO:memory usage: 79.8 KB
2023-04-29 19:37:55,876:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:37:55,876:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:37:55,876:INFO:Data columns (total 8 columns):
2023-04-29 19:37:55,876:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:37:55,876:INFO:---  ------          --------------  -----  
2023-04-29 19:37:55,876:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:37:55,876:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:37:55,876:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:37:55,876:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:37:55,876:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:37:55,876:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:37:55,877:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:37:55,877:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:37:55,877:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:37:55,877:INFO:memory usage: 79.8 KB
2023-04-29 19:37:57,435:INFO:PyCaret ClassificationExperiment
2023-04-29 19:37:57,435:INFO:Logging name: clf-default-name
2023-04-29 19:37:57,436:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 19:37:57,436:INFO:version 3.0.0
2023-04-29 19:37:57,436:INFO:Initializing setup()
2023-04-29 19:37:57,436:INFO:self.USI: d0b1
2023-04-29 19:37:57,436:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'X_test', 'y', 'is_multiclass', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:37:57,436:INFO:Checking environment
2023-04-29 19:37:57,437:INFO:python_version: 3.9.13
2023-04-29 19:37:57,437:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:37:57,437:INFO:machine: AMD64
2023-04-29 19:37:57,437:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:37:57,437:INFO:Memory: svmem(total=16935899136, available=5268312064, percent=68.9, used=11667587072, free=5268312064)
2023-04-29 19:37:57,437:INFO:Physical Core: 4
2023-04-29 19:37:57,437:INFO:Logical Core: 8
2023-04-29 19:37:57,437:INFO:Checking libraries
2023-04-29 19:37:57,437:INFO:System:
2023-04-29 19:37:57,437:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:37:57,438:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:37:57,438:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:37:57,438:INFO:PyCaret required dependencies:
2023-04-29 19:37:57,438:INFO:                 pip: 22.2.2
2023-04-29 19:37:57,438:INFO:          setuptools: 63.4.1
2023-04-29 19:37:57,438:INFO:             pycaret: 3.0.0
2023-04-29 19:37:57,438:INFO:             IPython: 7.31.1
2023-04-29 19:37:57,438:INFO:          ipywidgets: 7.6.5
2023-04-29 19:37:57,438:INFO:                tqdm: 4.64.1
2023-04-29 19:37:57,438:INFO:               numpy: 1.21.5
2023-04-29 19:37:57,439:INFO:              pandas: 1.4.4
2023-04-29 19:37:57,439:INFO:              jinja2: 2.11.3
2023-04-29 19:37:57,439:INFO:               scipy: 1.9.1
2023-04-29 19:37:57,439:INFO:              joblib: 1.2.0
2023-04-29 19:37:57,439:INFO:             sklearn: 1.0.2
2023-04-29 19:37:57,439:INFO:                pyod: 1.0.9
2023-04-29 19:37:57,439:INFO:            imblearn: 0.10.1
2023-04-29 19:37:57,439:INFO:   category_encoders: 2.6.0
2023-04-29 19:37:57,439:INFO:            lightgbm: 3.3.5
2023-04-29 19:37:57,439:INFO:               numba: 0.55.1
2023-04-29 19:37:57,439:INFO:            requests: 2.28.1
2023-04-29 19:37:57,440:INFO:          matplotlib: 3.5.2
2023-04-29 19:37:57,440:INFO:          scikitplot: 0.3.7
2023-04-29 19:37:57,440:INFO:         yellowbrick: 1.5
2023-04-29 19:37:57,440:INFO:              plotly: 5.9.0
2023-04-29 19:37:57,440:INFO:             kaleido: 0.2.1
2023-04-29 19:37:57,440:INFO:         statsmodels: 0.13.2
2023-04-29 19:37:57,440:INFO:              sktime: 0.17.1
2023-04-29 19:37:57,440:INFO:               tbats: 1.1.2
2023-04-29 19:37:57,440:INFO:            pmdarima: 2.0.3
2023-04-29 19:37:57,440:INFO:              psutil: 5.9.0
2023-04-29 19:37:57,440:INFO:PyCaret optional dependencies:
2023-04-29 19:37:57,441:INFO:                shap: 0.41.0
2023-04-29 19:37:57,441:INFO:           interpret: Not installed
2023-04-29 19:37:57,441:INFO:                umap: Not installed
2023-04-29 19:37:57,441:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:37:57,441:INFO:  explainerdashboard: Not installed
2023-04-29 19:37:57,441:INFO:             autoviz: Not installed
2023-04-29 19:37:57,441:INFO:           fairlearn: Not installed
2023-04-29 19:37:57,441:INFO:             xgboost: Not installed
2023-04-29 19:37:57,441:INFO:            catboost: Not installed
2023-04-29 19:37:57,441:INFO:              kmodes: Not installed
2023-04-29 19:37:57,441:INFO:             mlxtend: Not installed
2023-04-29 19:37:57,442:INFO:       statsforecast: Not installed
2023-04-29 19:37:57,442:INFO:        tune_sklearn: Not installed
2023-04-29 19:37:57,442:INFO:                 ray: Not installed
2023-04-29 19:37:57,442:INFO:            hyperopt: Not installed
2023-04-29 19:37:57,442:INFO:              optuna: Not installed
2023-04-29 19:37:57,442:INFO:               skopt: Not installed
2023-04-29 19:37:57,442:INFO:              mlflow: 2.2.1
2023-04-29 19:37:57,442:INFO:              gradio: Not installed
2023-04-29 19:37:57,442:INFO:             fastapi: Not installed
2023-04-29 19:37:57,442:INFO:             uvicorn: Not installed
2023-04-29 19:37:57,442:INFO:              m2cgen: Not installed
2023-04-29 19:37:57,442:INFO:           evidently: Not installed
2023-04-29 19:37:57,443:INFO:               fugue: Not installed
2023-04-29 19:37:57,443:INFO:           streamlit: 1.21.0
2023-04-29 19:37:57,443:INFO:             prophet: Not installed
2023-04-29 19:37:57,443:INFO:None
2023-04-29 19:37:57,443:INFO:Set up data.
2023-04-29 19:37:57,449:INFO:Set up train/test split.
2023-04-29 19:37:57,825:INFO:Set up index.
2023-04-29 19:37:57,826:INFO:Set up folding strategy.
2023-04-29 19:37:57,826:INFO:Assigning column types.
2023-04-29 19:37:57,832:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:37:57,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:37:57,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:37:58,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:37:58,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:37:58,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,111:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:37:58,185:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:37:58,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:37:58,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,317:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 19:37:58,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,509:INFO:Preparing preprocessing pipeline...
2023-04-29 19:37:58,629:INFO:Set up simple imputation.
2023-04-29 19:37:58,630:INFO:Set up column name cleaning.
2023-04-29 19:37:58,675:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:37:58,683:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'VEC'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 19:37:58,684:INFO:Creating final display dataframe.
2023-04-29 19:37:58,801:INFO:Setup _display_container:                     Description             Value
0                    Session id              5847
1                        Target            Phases
2                   Target type        Multiclass
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d0b1
2023-04-29 19:37:58,805:INFO:                    Description             Value
2023-04-29 19:37:58,805:INFO:0                    Session id              5847
2023-04-29 19:37:58,805:INFO:1                        Target            Phases
2023-04-29 19:37:58,805:INFO:2                   Target type        Multiclass
2023-04-29 19:37:58,805:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:37:58,805:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:37:58,805:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:37:58,805:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:37:58,805:INFO:7              Numeric features                 7
2023-04-29 19:37:58,805:INFO:8                    Preprocess              True
2023-04-29 19:37:58,805:INFO:9               Imputation type            simple
2023-04-29 19:37:58,805:INFO:10           Numeric imputation              mean
2023-04-29 19:37:58,805:INFO:11       Categorical imputation              mode
2023-04-29 19:37:58,805:INFO:12               Fold Generator   StratifiedKFold
2023-04-29 19:37:58,805:INFO:13                  Fold Number                10
2023-04-29 19:37:58,805:INFO:14                     CPU Jobs                -1
2023-04-29 19:37:58,806:INFO:15                      Use GPU             False
2023-04-29 19:37:58,806:INFO:16               Log Experiment             False
2023-04-29 19:37:58,806:INFO:17              Experiment Name  clf-default-name
2023-04-29 19:37:58,806:INFO:18                          USI              d0b1
2023-04-29 19:37:58,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:58,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:59,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:59,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:37:59,015:INFO:setup() successfully completed in 2.36s...............
2023-04-29 19:37:59,021:INFO:Initializing compare_models()
2023-04-29 19:37:59,021:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-29 19:37:59,022:INFO:Checking exceptions
2023-04-29 19:37:59,133:INFO:Preparing display monitor
2023-04-29 19:37:59,139:WARNING:
2023-04-29 19:37:59,139:WARNING:Processing:   0%|                 | 0/61 [00:00<?, ?it/s]
2023-04-29 19:37:59,140:INFO:Initializing Logistic Regression
2023-04-29 19:37:59,140:INFO:Total runtime is 0.0 minutes
2023-04-29 19:37:59,140:INFO:SubProcess create_model() called ==================================
2023-04-29 19:37:59,141:INFO:Initializing create_model()
2023-04-29 19:37:59,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:37:59,141:INFO:Checking exceptions
2023-04-29 19:37:59,141:INFO:Importing libraries
2023-04-29 19:37:59,141:INFO:Copying training dataset
2023-04-29 19:37:59,148:INFO:Defining folds
2023-04-29 19:37:59,148:INFO:Declaring metric variables
2023-04-29 19:37:59,148:INFO:Importing untrained model
2023-04-29 19:37:59,149:INFO:Logistic Regression Imported successfully
2023-04-29 19:37:59,149:INFO:Starting cross validation
2023-04-29 19:37:59,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:38:00,400:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:00,529:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:38:06,708:INFO:Calculating mean and std
2023-04-29 19:38:06,709:WARNING:Processing:   8%|7        | 5/61 [00:07<01:24,  1.51s/it]
2023-04-29 19:38:06,709:INFO:Creating metrics dataframe
2023-04-29 19:38:07,591:WARNING:Processing:  10%|8        | 6/61 [00:08<01:15,  1.37s/it]
2023-04-29 19:38:07,591:INFO:Uploading results into container
2023-04-29 19:38:07,592:INFO:Uploading model into container now
2023-04-29 19:38:07,592:INFO:_master_model_container: 1
2023-04-29 19:38:07,592:INFO:_display_container: 2
2023-04-29 19:38:07,593:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5847, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 19:38:07,593:INFO:create_model() successfully completed......................................
2023-04-29 19:38:07,717:INFO:SubProcess create_model() end ==================================
2023-04-29 19:38:07,717:INFO:Creating metrics dataframe
2023-04-29 19:38:07,721:INFO:Initializing K Neighbors Classifier
2023-04-29 19:38:07,721:INFO:Total runtime is 0.14302064577738444 minutes
2023-04-29 19:38:07,721:INFO:SubProcess create_model() called ==================================
2023-04-29 19:38:07,721:INFO:Initializing create_model()
2023-04-29 19:38:07,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:38:07,722:INFO:Checking exceptions
2023-04-29 19:38:07,722:INFO:Importing libraries
2023-04-29 19:38:07,722:INFO:Copying training dataset
2023-04-29 19:38:07,725:WARNING:Processing:  11%|#        | 7/61 [00:08<00:58,  1.07s/it]
2023-04-29 19:38:07,725:INFO:Defining folds
2023-04-29 19:38:07,725:INFO:Declaring metric variables
2023-04-29 19:38:07,726:INFO:Importing untrained model
2023-04-29 19:38:07,726:INFO:K Neighbors Classifier Imported successfully
2023-04-29 19:38:07,726:INFO:Starting cross validation
2023-04-29 19:38:07,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:38:07,999:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:07,999:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:08,000:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:08,000:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:08,000:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:10,146:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:10,153:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:38:15,126:INFO:Calculating mean and std
2023-04-29 19:38:15,126:WARNING:Processing:  15%|#3       | 9/61 [00:15<01:51,  2.15s/it]
2023-04-29 19:38:15,127:INFO:Creating metrics dataframe
2023-04-29 19:38:15,919:WARNING:Processing:  16%|#3      | 10/61 [00:16<01:33,  1.84s/it]
2023-04-29 19:38:15,919:INFO:Uploading results into container
2023-04-29 19:38:15,920:INFO:Uploading model into container now
2023-04-29 19:38:15,920:INFO:_master_model_container: 2
2023-04-29 19:38:15,921:INFO:_display_container: 2
2023-04-29 19:38:15,921:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 19:38:15,921:INFO:create_model() successfully completed......................................
2023-04-29 19:38:16,021:INFO:SubProcess create_model() end ==================================
2023-04-29 19:38:16,021:INFO:Creating metrics dataframe
2023-04-29 19:38:16,026:INFO:Initializing Naive Bayes
2023-04-29 19:38:16,026:INFO:Total runtime is 0.2814254601796468 minutes
2023-04-29 19:38:16,026:INFO:SubProcess create_model() called ==================================
2023-04-29 19:38:16,026:INFO:Initializing create_model()
2023-04-29 19:38:16,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:38:16,026:INFO:Checking exceptions
2023-04-29 19:38:16,026:INFO:Importing libraries
2023-04-29 19:38:16,026:INFO:Copying training dataset
2023-04-29 19:38:16,030:WARNING:Processing:  18%|#4      | 11/61 [00:16<01:10,  1.42s/it]
2023-04-29 19:38:16,030:INFO:Defining folds
2023-04-29 19:38:16,031:INFO:Declaring metric variables
2023-04-29 19:38:16,031:INFO:Importing untrained model
2023-04-29 19:38:16,031:INFO:Naive Bayes Imported successfully
2023-04-29 19:38:16,031:INFO:Starting cross validation
2023-04-29 19:38:16,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:38:22,564:INFO:Calculating mean and std
2023-04-29 19:38:22,565:WARNING:Processing:  21%|#7      | 13/61 [00:23<01:44,  2.18s/it]
2023-04-29 19:38:22,565:INFO:Creating metrics dataframe
2023-04-29 19:38:23,395:WARNING:Processing:  23%|#8      | 14/61 [00:24<01:27,  1.87s/it]
2023-04-29 19:38:23,396:INFO:Uploading results into container
2023-04-29 19:38:23,396:INFO:Uploading model into container now
2023-04-29 19:38:23,397:INFO:_master_model_container: 3
2023-04-29 19:38:23,397:INFO:_display_container: 2
2023-04-29 19:38:23,397:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 19:38:23,397:INFO:create_model() successfully completed......................................
2023-04-29 19:38:23,508:INFO:SubProcess create_model() end ==================================
2023-04-29 19:38:23,508:INFO:Creating metrics dataframe
2023-04-29 19:38:23,512:INFO:Initializing Decision Tree Classifier
2023-04-29 19:38:23,512:INFO:Total runtime is 0.4061968366305033 minutes
2023-04-29 19:38:23,512:INFO:SubProcess create_model() called ==================================
2023-04-29 19:38:23,513:INFO:Initializing create_model()
2023-04-29 19:38:23,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:38:23,513:INFO:Checking exceptions
2023-04-29 19:38:23,513:INFO:Importing libraries
2023-04-29 19:38:23,513:INFO:Copying training dataset
2023-04-29 19:38:23,515:WARNING:Processing:  25%|#9      | 15/61 [00:24<01:06,  1.44s/it]
2023-04-29 19:38:23,516:INFO:Defining folds
2023-04-29 19:38:23,516:INFO:Declaring metric variables
2023-04-29 19:38:23,516:INFO:Importing untrained model
2023-04-29 19:38:23,516:INFO:Decision Tree Classifier Imported successfully
2023-04-29 19:38:23,516:INFO:Starting cross validation
2023-04-29 19:38:23,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:38:31,386:INFO:Calculating mean and std
2023-04-29 19:38:31,387:WARNING:Processing:  28%|##2     | 17/61 [00:32<01:48,  2.47s/it]
2023-04-29 19:38:31,387:INFO:Creating metrics dataframe
2023-04-29 19:38:32,396:WARNING:Processing:  30%|##3     | 18/61 [00:33<01:31,  2.14s/it]
2023-04-29 19:38:32,397:INFO:Uploading results into container
2023-04-29 19:38:32,398:INFO:Uploading model into container now
2023-04-29 19:38:32,398:INFO:_master_model_container: 4
2023-04-29 19:38:32,398:INFO:_display_container: 2
2023-04-29 19:38:32,399:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5847, splitter='best')
2023-04-29 19:38:32,399:INFO:create_model() successfully completed......................................
2023-04-29 19:38:32,532:INFO:SubProcess create_model() end ==================================
2023-04-29 19:38:32,532:INFO:Creating metrics dataframe
2023-04-29 19:38:32,542:INFO:Initializing SVM - Linear Kernel
2023-04-29 19:38:32,542:INFO:Total runtime is 0.5566945791244506 minutes
2023-04-29 19:38:32,543:INFO:SubProcess create_model() called ==================================
2023-04-29 19:38:32,543:INFO:Initializing create_model()
2023-04-29 19:38:32,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:38:32,543:INFO:Checking exceptions
2023-04-29 19:38:32,543:INFO:Importing libraries
2023-04-29 19:38:32,543:INFO:Copying training dataset
2023-04-29 19:38:32,552:WARNING:Processing:  31%|##4     | 19/61 [00:33<01:09,  1.65s/it]
2023-04-29 19:38:32,553:INFO:Defining folds
2023-04-29 19:38:32,553:INFO:Declaring metric variables
2023-04-29 19:38:32,553:INFO:Importing untrained model
2023-04-29 19:38:32,554:INFO:SVM - Linear Kernel Imported successfully
2023-04-29 19:38:32,554:INFO:Starting cross validation
2023-04-29 19:38:32,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:38:32,948:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:32,948:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:32,948:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:32,948:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:32,950:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:32,952:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:32,953:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:32,954:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:35,162:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:35,178:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:38:35,185:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:39,887:INFO:Calculating mean and std
2023-04-29 19:38:39,888:WARNING:Processing:  34%|##7     | 21/61 [00:40<01:39,  2.48s/it]
2023-04-29 19:38:39,888:INFO:Creating metrics dataframe
2023-04-29 19:38:40,690:WARNING:Processing:  36%|##8     | 22/61 [00:41<01:21,  2.10s/it]
2023-04-29 19:38:40,690:INFO:Uploading results into container
2023-04-29 19:38:40,691:INFO:Uploading model into container now
2023-04-29 19:38:40,691:INFO:_master_model_container: 5
2023-04-29 19:38:40,692:INFO:_display_container: 2
2023-04-29 19:38:40,692:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5847, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-29 19:38:40,692:INFO:create_model() successfully completed......................................
2023-04-29 19:38:40,790:INFO:SubProcess create_model() end ==================================
2023-04-29 19:38:40,790:INFO:Creating metrics dataframe
2023-04-29 19:38:40,794:INFO:Initializing Ridge Classifier
2023-04-29 19:38:40,794:INFO:Total runtime is 0.6942260185877481 minutes
2023-04-29 19:38:40,794:INFO:SubProcess create_model() called ==================================
2023-04-29 19:38:40,794:INFO:Initializing create_model()
2023-04-29 19:38:40,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:38:40,795:INFO:Checking exceptions
2023-04-29 19:38:40,795:INFO:Importing libraries
2023-04-29 19:38:40,795:INFO:Copying training dataset
2023-04-29 19:38:40,798:WARNING:Processing:  38%|###     | 23/61 [00:41<01:01,  1.61s/it]
2023-04-29 19:38:40,798:INFO:Defining folds
2023-04-29 19:38:40,798:INFO:Declaring metric variables
2023-04-29 19:38:40,798:INFO:Importing untrained model
2023-04-29 19:38:40,799:INFO:Ridge Classifier Imported successfully
2023-04-29 19:38:40,799:INFO:Starting cross validation
2023-04-29 19:38:40,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:38:41,137:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,137:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,137:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,141:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,142:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,142:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,144:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,145:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,146:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,147:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,149:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,150:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,153:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:41,154:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,155:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:41,158:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:43,403:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:43,408:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:43,412:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:38:43,420:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:38:49,563:INFO:Calculating mean and std
2023-04-29 19:38:49,564:WARNING:Processing:  41%|###2    | 25/61 [00:50<01:39,  2.75s/it]
2023-04-29 19:38:49,564:INFO:Creating metrics dataframe
2023-04-29 19:38:50,472:WARNING:Processing:  43%|###4    | 26/61 [00:51<01:21,  2.33s/it]
2023-04-29 19:38:50,472:INFO:Uploading results into container
2023-04-29 19:38:50,472:INFO:Uploading model into container now
2023-04-29 19:38:50,473:INFO:_master_model_container: 6
2023-04-29 19:38:50,473:INFO:_display_container: 2
2023-04-29 19:38:50,473:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5847, solver='auto', tol=0.001)
2023-04-29 19:38:50,473:INFO:create_model() successfully completed......................................
2023-04-29 19:38:50,568:INFO:SubProcess create_model() end ==================================
2023-04-29 19:38:50,569:INFO:Creating metrics dataframe
2023-04-29 19:38:50,572:INFO:Initializing Random Forest Classifier
2023-04-29 19:38:50,572:INFO:Total runtime is 0.8571966091791787 minutes
2023-04-29 19:38:50,572:INFO:SubProcess create_model() called ==================================
2023-04-29 19:38:50,573:INFO:Initializing create_model()
2023-04-29 19:38:50,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:38:50,573:INFO:Checking exceptions
2023-04-29 19:38:50,573:INFO:Importing libraries
2023-04-29 19:38:50,573:INFO:Copying training dataset
2023-04-29 19:38:50,575:WARNING:Processing:  44%|###5    | 27/61 [00:51<01:00,  1.79s/it]
2023-04-29 19:38:50,575:INFO:Defining folds
2023-04-29 19:38:50,575:INFO:Declaring metric variables
2023-04-29 19:38:50,576:INFO:Importing untrained model
2023-04-29 19:38:50,576:INFO:Random Forest Classifier Imported successfully
2023-04-29 19:38:50,576:INFO:Starting cross validation
2023-04-29 19:38:50,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:39:00,694:INFO:Calculating mean and std
2023-04-29 19:39:00,695:WARNING:Processing:  48%|###8    | 29/61 [01:01<01:40,  3.14s/it]
2023-04-29 19:39:00,695:INFO:Creating metrics dataframe
2023-04-29 19:39:01,821:WARNING:Processing:  49%|###9    | 30/61 [01:02<01:23,  2.68s/it]
2023-04-29 19:39:01,821:INFO:Uploading results into container
2023-04-29 19:39:01,822:INFO:Uploading model into container now
2023-04-29 19:39:01,822:INFO:_master_model_container: 7
2023-04-29 19:39:01,822:INFO:_display_container: 2
2023-04-29 19:39:01,823:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5847, verbose=0, warm_start=False)
2023-04-29 19:39:01,823:INFO:create_model() successfully completed......................................
2023-04-29 19:39:01,936:INFO:SubProcess create_model() end ==================================
2023-04-29 19:39:01,936:INFO:Creating metrics dataframe
2023-04-29 19:39:01,940:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 19:39:01,940:INFO:Total runtime is 1.0466702183087666 minutes
2023-04-29 19:39:01,941:INFO:SubProcess create_model() called ==================================
2023-04-29 19:39:01,941:INFO:Initializing create_model()
2023-04-29 19:39:01,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:39:01,941:INFO:Checking exceptions
2023-04-29 19:39:01,941:INFO:Importing libraries
2023-04-29 19:39:01,941:INFO:Copying training dataset
2023-04-29 19:39:01,944:WARNING:Processing:  51%|####    | 31/61 [01:02<01:01,  2.05s/it]
2023-04-29 19:39:01,944:INFO:Defining folds
2023-04-29 19:39:01,944:INFO:Declaring metric variables
2023-04-29 19:39:01,944:INFO:Importing untrained model
2023-04-29 19:39:01,944:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 19:39:01,945:INFO:Starting cross validation
2023-04-29 19:39:01,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:39:10,363:INFO:Calculating mean and std
2023-04-29 19:39:10,365:WARNING:Processing:  54%|####3   | 33/61 [01:11<01:22,  2.94s/it]
2023-04-29 19:39:10,365:INFO:Creating metrics dataframe
2023-04-29 19:39:11,442:WARNING:Processing:  56%|####4   | 34/61 [01:12<01:07,  2.52s/it]
2023-04-29 19:39:11,442:INFO:Uploading results into container
2023-04-29 19:39:11,442:INFO:Uploading model into container now
2023-04-29 19:39:11,443:INFO:_master_model_container: 8
2023-04-29 19:39:11,443:INFO:_display_container: 2
2023-04-29 19:39:11,443:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 19:39:11,443:INFO:create_model() successfully completed......................................
2023-04-29 19:39:11,561:INFO:SubProcess create_model() end ==================================
2023-04-29 19:39:11,561:INFO:Creating metrics dataframe
2023-04-29 19:39:11,568:INFO:Initializing Ada Boost Classifier
2023-04-29 19:39:11,568:INFO:Total runtime is 1.2071262001991272 minutes
2023-04-29 19:39:11,568:INFO:SubProcess create_model() called ==================================
2023-04-29 19:39:11,568:INFO:Initializing create_model()
2023-04-29 19:39:11,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:39:11,569:INFO:Checking exceptions
2023-04-29 19:39:11,569:INFO:Importing libraries
2023-04-29 19:39:11,569:INFO:Copying training dataset
2023-04-29 19:39:11,571:WARNING:Processing:  57%|####5   | 35/61 [01:12<00:50,  1.93s/it]
2023-04-29 19:39:11,571:INFO:Defining folds
2023-04-29 19:39:11,571:INFO:Declaring metric variables
2023-04-29 19:39:11,572:INFO:Importing untrained model
2023-04-29 19:39:11,572:INFO:Ada Boost Classifier Imported successfully
2023-04-29 19:39:11,572:INFO:Starting cross validation
2023-04-29 19:39:11,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:39:20,952:INFO:Calculating mean and std
2023-04-29 19:39:20,953:WARNING:Processing:  61%|####8   | 37/61 [01:21<01:13,  3.07s/it]
2023-04-29 19:39:20,953:INFO:Creating metrics dataframe
2023-04-29 19:39:21,971:WARNING:Processing:  62%|####9   | 38/61 [01:22<00:59,  2.60s/it]
2023-04-29 19:39:21,972:INFO:Uploading results into container
2023-04-29 19:39:21,972:INFO:Uploading model into container now
2023-04-29 19:39:21,972:INFO:_master_model_container: 9
2023-04-29 19:39:21,973:INFO:_display_container: 2
2023-04-29 19:39:21,973:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5847)
2023-04-29 19:39:21,973:INFO:create_model() successfully completed......................................
2023-04-29 19:39:22,093:INFO:SubProcess create_model() end ==================================
2023-04-29 19:39:22,093:INFO:Creating metrics dataframe
2023-04-29 19:39:22,101:INFO:Initializing Gradient Boosting Classifier
2023-04-29 19:39:22,101:INFO:Total runtime is 1.38267746369044 minutes
2023-04-29 19:39:22,101:INFO:SubProcess create_model() called ==================================
2023-04-29 19:39:22,102:INFO:Initializing create_model()
2023-04-29 19:39:22,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:39:22,102:INFO:Checking exceptions
2023-04-29 19:39:22,102:INFO:Importing libraries
2023-04-29 19:39:22,102:INFO:Copying training dataset
2023-04-29 19:39:22,105:WARNING:Processing:  64%|#####1  | 39/61 [01:22<00:43,  2.00s/it]
2023-04-29 19:39:22,105:INFO:Defining folds
2023-04-29 19:39:22,105:INFO:Declaring metric variables
2023-04-29 19:39:22,105:INFO:Importing untrained model
2023-04-29 19:39:22,105:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 19:39:22,106:INFO:Starting cross validation
2023-04-29 19:39:22,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:39:24,382:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,390:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,395:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,489:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,587:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,651:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,692:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:24,792:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:39:34,957:INFO:Calculating mean and std
2023-04-29 19:39:34,957:WARNING:Processing:  67%|#####3  | 41/61 [01:35<01:16,  3.82s/it]
2023-04-29 19:39:34,957:INFO:Creating metrics dataframe
2023-04-29 19:39:36,004:WARNING:Processing:  69%|#####5  | 42/61 [01:36<01:00,  3.19s/it]
2023-04-29 19:39:36,004:INFO:Uploading results into container
2023-04-29 19:39:36,004:INFO:Uploading model into container now
2023-04-29 19:39:36,005:INFO:_master_model_container: 10
2023-04-29 19:39:36,005:INFO:_display_container: 2
2023-04-29 19:39:36,005:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5847, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 19:39:36,005:INFO:create_model() successfully completed......................................
2023-04-29 19:39:36,125:INFO:SubProcess create_model() end ==================================
2023-04-29 19:39:36,125:INFO:Creating metrics dataframe
2023-04-29 19:39:36,132:INFO:Initializing Linear Discriminant Analysis
2023-04-29 19:39:36,132:INFO:Total runtime is 1.6165249864260356 minutes
2023-04-29 19:39:36,133:INFO:SubProcess create_model() called ==================================
2023-04-29 19:39:36,133:INFO:Initializing create_model()
2023-04-29 19:39:36,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:39:36,133:INFO:Checking exceptions
2023-04-29 19:39:36,133:INFO:Importing libraries
2023-04-29 19:39:36,133:INFO:Copying training dataset
2023-04-29 19:39:36,136:WARNING:Processing:  70%|#####6  | 43/61 [01:36<00:43,  2.44s/it]
2023-04-29 19:39:36,136:INFO:Defining folds
2023-04-29 19:39:36,136:INFO:Declaring metric variables
2023-04-29 19:39:36,136:INFO:Importing untrained model
2023-04-29 19:39:36,137:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 19:39:36,137:INFO:Starting cross validation
2023-04-29 19:39:36,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:39:36,832:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:39:39,502:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:39:45,489:INFO:Calculating mean and std
2023-04-29 19:39:45,490:WARNING:Processing:  74%|#####9  | 45/61 [01:46<00:53,  3.36s/it]
2023-04-29 19:39:45,490:INFO:Creating metrics dataframe
2023-04-29 19:39:46,617:WARNING:Processing:  75%|######  | 46/61 [01:47<00:42,  2.85s/it]
2023-04-29 19:39:46,617:INFO:Uploading results into container
2023-04-29 19:39:46,618:INFO:Uploading model into container now
2023-04-29 19:39:46,618:INFO:_master_model_container: 11
2023-04-29 19:39:46,618:INFO:_display_container: 2
2023-04-29 19:39:46,618:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 19:39:46,618:INFO:create_model() successfully completed......................................
2023-04-29 19:39:46,736:INFO:SubProcess create_model() end ==================================
2023-04-29 19:39:46,736:INFO:Creating metrics dataframe
2023-04-29 19:39:46,741:INFO:Initializing Extra Trees Classifier
2023-04-29 19:39:46,741:INFO:Total runtime is 1.7933421969413756 minutes
2023-04-29 19:39:46,741:INFO:SubProcess create_model() called ==================================
2023-04-29 19:39:46,741:INFO:Initializing create_model()
2023-04-29 19:39:46,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:39:46,742:INFO:Checking exceptions
2023-04-29 19:39:46,742:INFO:Importing libraries
2023-04-29 19:39:46,742:INFO:Copying training dataset
2023-04-29 19:39:46,749:WARNING:Processing:  77%|######1 | 47/61 [01:47<00:30,  2.19s/it]
2023-04-29 19:39:46,749:INFO:Defining folds
2023-04-29 19:39:46,749:INFO:Declaring metric variables
2023-04-29 19:39:46,750:INFO:Importing untrained model
2023-04-29 19:39:46,750:INFO:Extra Trees Classifier Imported successfully
2023-04-29 19:39:46,751:INFO:Starting cross validation
2023-04-29 19:39:46,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:39:57,174:INFO:Calculating mean and std
2023-04-29 19:39:57,175:WARNING:Processing:  80%|######4 | 49/61 [01:58<00:41,  3.43s/it]
2023-04-29 19:39:57,176:INFO:Creating metrics dataframe
2023-04-29 19:39:58,240:WARNING:Processing:  82%|######5 | 50/61 [01:59<00:31,  2.89s/it]
2023-04-29 19:39:58,240:INFO:Uploading results into container
2023-04-29 19:39:58,242:INFO:Uploading model into container now
2023-04-29 19:39:58,242:INFO:_master_model_container: 12
2023-04-29 19:39:58,243:INFO:_display_container: 2
2023-04-29 19:39:58,244:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5847, verbose=0, warm_start=False)
2023-04-29 19:39:58,244:INFO:create_model() successfully completed......................................
2023-04-29 19:39:58,356:INFO:SubProcess create_model() end ==================================
2023-04-29 19:39:58,356:INFO:Creating metrics dataframe
2023-04-29 19:39:58,366:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:39:58,367:INFO:Total runtime is 1.98711173137029 minutes
2023-04-29 19:39:58,367:INFO:SubProcess create_model() called ==================================
2023-04-29 19:39:58,367:INFO:Initializing create_model()
2023-04-29 19:39:58,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:39:58,367:INFO:Checking exceptions
2023-04-29 19:39:58,367:INFO:Importing libraries
2023-04-29 19:39:58,367:INFO:Copying training dataset
2023-04-29 19:39:58,371:WARNING:Processing:  84%|######6 | 51/61 [01:59<00:22,  2.22s/it]
2023-04-29 19:39:58,371:INFO:Defining folds
2023-04-29 19:39:58,371:INFO:Declaring metric variables
2023-04-29 19:39:58,371:INFO:Importing untrained model
2023-04-29 19:39:58,371:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:39:58,372:INFO:Starting cross validation
2023-04-29 19:39:58,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:40:09,770:INFO:Calculating mean and std
2023-04-29 19:40:09,770:WARNING:Processing:  87%|######9 | 53/61 [02:10<00:29,  3.65s/it]
2023-04-29 19:40:09,771:INFO:Creating metrics dataframe
2023-04-29 19:40:10,835:WARNING:Processing:  89%|####### | 54/61 [02:11<00:21,  3.06s/it]
2023-04-29 19:40:10,835:INFO:Uploading results into container
2023-04-29 19:40:10,836:INFO:Uploading model into container now
2023-04-29 19:40:10,836:INFO:_master_model_container: 13
2023-04-29 19:40:10,836:INFO:_display_container: 2
2023-04-29 19:40:10,837:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5847, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 19:40:10,837:INFO:create_model() successfully completed......................................
2023-04-29 19:40:10,995:INFO:SubProcess create_model() end ==================================
2023-04-29 19:40:10,995:INFO:Creating metrics dataframe
2023-04-29 19:40:11,006:INFO:Initializing Dummy Classifier
2023-04-29 19:40:11,007:INFO:Total runtime is 2.1977797309557596 minutes
2023-04-29 19:40:11,009:INFO:SubProcess create_model() called ==================================
2023-04-29 19:40:11,011:INFO:Initializing create_model()
2023-04-29 19:40:11,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFE271C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:40:11,011:INFO:Checking exceptions
2023-04-29 19:40:11,011:INFO:Importing libraries
2023-04-29 19:40:11,011:INFO:Copying training dataset
2023-04-29 19:40:11,021:WARNING:Processing:  90%|#######2| 55/61 [02:11<00:14,  2.36s/it]
2023-04-29 19:40:11,021:INFO:Defining folds
2023-04-29 19:40:11,022:INFO:Declaring metric variables
2023-04-29 19:40:11,022:INFO:Importing untrained model
2023-04-29 19:40:11,023:INFO:Dummy Classifier Imported successfully
2023-04-29 19:40:11,024:INFO:Starting cross validation
2023-04-29 19:40:11,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:40:11,213:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,217:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,237:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,245:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,284:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,286:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,287:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:11,294:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:13,785:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:13,800:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:40:20,121:INFO:Calculating mean and std
2023-04-29 19:40:20,122:WARNING:Processing:  93%|#######4| 57/61 [02:20<00:13,  3.26s/it]
2023-04-29 19:40:20,122:INFO:Creating metrics dataframe
2023-04-29 19:40:21,230:WARNING:Processing:  95%|#######6| 58/61 [02:22<00:08,  2.77s/it]
2023-04-29 19:40:21,230:INFO:Uploading results into container
2023-04-29 19:40:21,230:INFO:Uploading model into container now
2023-04-29 19:40:21,231:INFO:_master_model_container: 14
2023-04-29 19:40:21,231:INFO:_display_container: 2
2023-04-29 19:40:21,231:INFO:DummyClassifier(constant=None, random_state=5847, strategy='prior')
2023-04-29 19:40:21,231:INFO:create_model() successfully completed......................................
2023-04-29 19:40:21,349:INFO:SubProcess create_model() end ==================================
2023-04-29 19:40:21,350:INFO:Creating metrics dataframe
2023-04-29 19:40:21,355:WARNING:Processing:  97%|#######7| 59/61 [02:22<00:04,  2.12s/it]
2023-04-29 19:40:21,358:INFO:Initializing create_model()
2023-04-29 19:40:21,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5847, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:40:21,358:INFO:Checking exceptions
2023-04-29 19:40:21,359:INFO:Importing libraries
2023-04-29 19:40:21,359:INFO:Copying training dataset
2023-04-29 19:40:21,363:INFO:Defining folds
2023-04-29 19:40:21,363:INFO:Declaring metric variables
2023-04-29 19:40:21,363:INFO:Importing untrained model
2023-04-29 19:40:21,363:INFO:Declaring custom model
2023-04-29 19:40:21,364:INFO:Random Forest Classifier Imported successfully
2023-04-29 19:40:21,365:INFO:Cross validation set to False
2023-04-29 19:40:21,365:INFO:Fitting Model
2023-04-29 19:40:22,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5847, verbose=0, warm_start=False)
2023-04-29 19:40:22,269:INFO:create_model() successfully completed......................................
2023-04-29 19:40:22,367:WARNING:Processing: 100%|########| 61/61 [02:23<00:00,  1.46s/it]
2023-04-29 19:40:22,367:WARNING:                                                         
2023-04-29 19:40:22,379:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2023-04-29 19:40:22,379:INFO:rf               Random Forest Classifier    0.8507  0.9497  0.8507  0.8560   
2023-04-29 19:40:22,379:INFO:et                 Extra Trees Classifier    0.8465  0.9390  0.8465  0.8508   
2023-04-29 19:40:22,379:INFO:lightgbm  Light Gradient Boosting Machine    0.8434  0.9537  0.8434  0.8494   
2023-04-29 19:40:22,379:INFO:gbc          Gradient Boosting Classifier    0.8402  0.9535  0.8402  0.8431   
2023-04-29 19:40:22,379:INFO:dt               Decision Tree Classifier    0.8287  0.9085  0.8287  0.8350   
2023-04-29 19:40:22,379:INFO:knn                K Neighbors Classifier    0.8013  0.9210  0.8013  0.8035   
2023-04-29 19:40:22,379:INFO:lr                    Logistic Regression    0.7129  0.8889  0.7129  0.7038   
2023-04-29 19:40:22,379:INFO:lda          Linear Discriminant Analysis    0.7129  0.8821  0.7129  0.6957   
2023-04-29 19:40:22,379:INFO:ridge                    Ridge Classifier    0.7098  0.0000  0.7098  0.6616   
2023-04-29 19:40:22,379:INFO:ada                  Ada Boost Classifier    0.6551  0.7941  0.6551  0.6595   
2023-04-29 19:40:22,379:INFO:qda       Quadratic Discriminant Analysis    0.6479  0.8828  0.6479  0.6768   
2023-04-29 19:40:22,380:INFO:nb                            Naive Bayes    0.6457  0.8565  0.6457  0.7012   
2023-04-29 19:40:22,380:INFO:svm                   SVM - Linear Kernel    0.6015  0.0000  0.6015  0.6667   
2023-04-29 19:40:22,380:INFO:dummy                    Dummy Classifier    0.3407  0.5000  0.3407  0.1161   
2023-04-29 19:40:22,380:INFO:
2023-04-29 19:40:22,380:INFO:              F1   Kappa     MCC  TT (Sec)  
2023-04-29 19:40:22,380:INFO:rf        0.8491  0.7889  0.7917     1.012  
2023-04-29 19:40:22,380:INFO:et        0.8449  0.7831  0.7855     1.042  
2023-04-29 19:40:22,380:INFO:lightgbm  0.8428  0.7789  0.7813     1.140  
2023-04-29 19:40:22,380:INFO:gbc       0.8377  0.7736  0.7756     1.285  
2023-04-29 19:40:22,380:INFO:dt        0.8283  0.7591  0.7612     0.787  
2023-04-29 19:40:22,380:INFO:knn       0.7989  0.7184  0.7205     0.740  
2023-04-29 19:40:22,380:INFO:lr        0.7009  0.5896  0.5935     0.756  
2023-04-29 19:40:22,380:INFO:lda       0.6964  0.5887  0.5928     0.935  
2023-04-29 19:40:22,380:INFO:ridge     0.6814  0.5798  0.5860     0.876  
2023-04-29 19:40:22,380:INFO:ada       0.6487  0.5079  0.5129     0.938  
2023-04-29 19:40:22,380:INFO:qda       0.6369  0.5214  0.5366     0.842  
2023-04-29 19:40:22,380:INFO:nb        0.6559  0.5189  0.5292     0.653  
2023-04-29 19:40:22,381:INFO:svm       0.5763  0.4332  0.4809     0.733  
2023-04-29 19:40:22,381:INFO:dummy     0.1732  0.0000  0.0000     0.909  
2023-04-29 19:40:22,381:INFO:_master_model_container: 14
2023-04-29 19:40:22,381:INFO:_display_container: 2
2023-04-29 19:40:22,381:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5847, verbose=0, warm_start=False)
2023-04-29 19:40:22,381:INFO:compare_models() successfully completed......................................
2023-04-29 19:40:22,384:INFO:Initializing predict_model()
2023-04-29 19:40:22,384:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13DFF70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5847, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236EFFABF70>)
2023-04-29 19:40:22,384:INFO:Checking exceptions
2023-04-29 19:40:22,384:INFO:Preloading libraries
2023-04-29 19:40:22,384:INFO:Set up data.
2023-04-29 19:40:22,389:INFO:Set up index.
2023-04-29 19:40:22,500:INFO:                      Model  Accuracy  ...   Kappa     MCC
2023-04-29 19:40:22,500:INFO:0  Random Forest Classifier    0.8963  ...  0.8534  0.8537
2023-04-29 19:40:22,500:INFO:
2023-04-29 19:40:22,500:INFO:[1 rows x 8 columns]
2023-04-29 19:42:47,162:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:42:47,162:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:42:47,162:INFO:Data columns (total 8 columns):
2023-04-29 19:42:47,162:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:42:47,162:INFO:---  ------          --------------  -----  
2023-04-29 19:42:47,162:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:42:47,162:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:42:47,162:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:42:47,162:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:42:47,163:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:42:47,163:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:42:47,163:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:42:47,163:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:42:47,163:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:42:47,163:INFO:memory usage: 79.8 KB
2023-04-29 19:42:52,449:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:42:52,449:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:42:52,450:INFO:Data columns (total 8 columns):
2023-04-29 19:42:52,450:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:42:52,450:INFO:---  ------          --------------  -----  
2023-04-29 19:42:52,450:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:42:52,450:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:42:52,450:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:42:52,450:INFO:memory usage: 79.8 KB
2023-04-29 19:42:54,046:INFO:PyCaret ClassificationExperiment
2023-04-29 19:42:54,046:INFO:Logging name: clf-default-name
2023-04-29 19:42:54,046:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 19:42:54,046:INFO:version 3.0.0
2023-04-29 19:42:54,046:INFO:Initializing setup()
2023-04-29 19:42:54,047:INFO:self.USI: 70e6
2023-04-29 19:42:54,047:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'X_test', 'y', 'is_multiclass', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:42:54,047:INFO:Checking environment
2023-04-29 19:42:54,047:INFO:python_version: 3.9.13
2023-04-29 19:42:54,047:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:42:54,047:INFO:machine: AMD64
2023-04-29 19:42:54,047:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:42:54,047:INFO:Memory: svmem(total=16935899136, available=5142163456, percent=69.6, used=11793735680, free=5142163456)
2023-04-29 19:42:54,047:INFO:Physical Core: 4
2023-04-29 19:42:54,048:INFO:Logical Core: 8
2023-04-29 19:42:54,048:INFO:Checking libraries
2023-04-29 19:42:54,048:INFO:System:
2023-04-29 19:42:54,048:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:42:54,048:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:42:54,048:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:42:54,048:INFO:PyCaret required dependencies:
2023-04-29 19:42:54,048:INFO:                 pip: 22.2.2
2023-04-29 19:42:54,048:INFO:          setuptools: 63.4.1
2023-04-29 19:42:54,048:INFO:             pycaret: 3.0.0
2023-04-29 19:42:54,049:INFO:             IPython: 7.31.1
2023-04-29 19:42:54,049:INFO:          ipywidgets: 7.6.5
2023-04-29 19:42:54,049:INFO:                tqdm: 4.64.1
2023-04-29 19:42:54,049:INFO:               numpy: 1.21.5
2023-04-29 19:42:54,049:INFO:              pandas: 1.4.4
2023-04-29 19:42:54,049:INFO:              jinja2: 2.11.3
2023-04-29 19:42:54,049:INFO:               scipy: 1.9.1
2023-04-29 19:42:54,049:INFO:              joblib: 1.2.0
2023-04-29 19:42:54,049:INFO:             sklearn: 1.0.2
2023-04-29 19:42:54,049:INFO:                pyod: 1.0.9
2023-04-29 19:42:54,049:INFO:            imblearn: 0.10.1
2023-04-29 19:42:54,050:INFO:   category_encoders: 2.6.0
2023-04-29 19:42:54,050:INFO:            lightgbm: 3.3.5
2023-04-29 19:42:54,050:INFO:               numba: 0.55.1
2023-04-29 19:42:54,050:INFO:            requests: 2.28.1
2023-04-29 19:42:54,050:INFO:          matplotlib: 3.5.2
2023-04-29 19:42:54,050:INFO:          scikitplot: 0.3.7
2023-04-29 19:42:54,050:INFO:         yellowbrick: 1.5
2023-04-29 19:42:54,050:INFO:              plotly: 5.9.0
2023-04-29 19:42:54,050:INFO:             kaleido: 0.2.1
2023-04-29 19:42:54,050:INFO:         statsmodels: 0.13.2
2023-04-29 19:42:54,050:INFO:              sktime: 0.17.1
2023-04-29 19:42:54,050:INFO:               tbats: 1.1.2
2023-04-29 19:42:54,051:INFO:            pmdarima: 2.0.3
2023-04-29 19:42:54,051:INFO:              psutil: 5.9.0
2023-04-29 19:42:54,051:INFO:PyCaret optional dependencies:
2023-04-29 19:42:54,051:INFO:                shap: 0.41.0
2023-04-29 19:42:54,051:INFO:           interpret: Not installed
2023-04-29 19:42:54,051:INFO:                umap: Not installed
2023-04-29 19:42:54,051:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:42:54,051:INFO:  explainerdashboard: Not installed
2023-04-29 19:42:54,051:INFO:             autoviz: Not installed
2023-04-29 19:42:54,052:INFO:           fairlearn: Not installed
2023-04-29 19:42:54,052:INFO:             xgboost: Not installed
2023-04-29 19:42:54,052:INFO:            catboost: Not installed
2023-04-29 19:42:54,052:INFO:              kmodes: Not installed
2023-04-29 19:42:54,052:INFO:             mlxtend: Not installed
2023-04-29 19:42:54,052:INFO:       statsforecast: Not installed
2023-04-29 19:42:54,052:INFO:        tune_sklearn: Not installed
2023-04-29 19:42:54,052:INFO:                 ray: Not installed
2023-04-29 19:42:54,052:INFO:            hyperopt: Not installed
2023-04-29 19:42:54,052:INFO:              optuna: Not installed
2023-04-29 19:42:54,052:INFO:               skopt: Not installed
2023-04-29 19:42:54,052:INFO:              mlflow: 2.2.1
2023-04-29 19:42:54,053:INFO:              gradio: Not installed
2023-04-29 19:42:54,053:INFO:             fastapi: Not installed
2023-04-29 19:42:54,053:INFO:             uvicorn: Not installed
2023-04-29 19:42:54,053:INFO:              m2cgen: Not installed
2023-04-29 19:42:54,053:INFO:           evidently: Not installed
2023-04-29 19:42:54,053:INFO:               fugue: Not installed
2023-04-29 19:42:54,053:INFO:           streamlit: 1.21.0
2023-04-29 19:42:54,053:INFO:             prophet: Not installed
2023-04-29 19:42:54,053:INFO:None
2023-04-29 19:42:54,053:INFO:Set up data.
2023-04-29 19:42:54,061:INFO:Set up train/test split.
2023-04-29 19:42:54,068:INFO:Set up index.
2023-04-29 19:42:54,068:INFO:Set up folding strategy.
2023-04-29 19:42:54,069:INFO:Assigning column types.
2023-04-29 19:42:54,073:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:42:54,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:42:54,149:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:42:54,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:42:54,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:42:54,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,268:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:42:54,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:42:54,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:42:54,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,458:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 19:42:54,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,634:INFO:Preparing preprocessing pipeline...
2023-04-29 19:42:54,635:INFO:Set up simple imputation.
2023-04-29 19:42:54,636:INFO:Set up column name cleaning.
2023-04-29 19:42:54,655:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:42:54,659:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'VEC'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 19:42:54,659:INFO:Creating final display dataframe.
2023-04-29 19:42:54,738:INFO:Setup _display_container:                     Description             Value
0                    Session id               294
1                        Target            Phases
2                   Target type        Multiclass
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              70e6
2023-04-29 19:42:54,748:INFO:                    Description             Value
2023-04-29 19:42:54,748:INFO:0                    Session id               294
2023-04-29 19:42:54,748:INFO:1                        Target            Phases
2023-04-29 19:42:54,748:INFO:2                   Target type        Multiclass
2023-04-29 19:42:54,748:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:42:54,748:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:42:54,748:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:42:54,748:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:42:54,749:INFO:7              Numeric features                 7
2023-04-29 19:42:54,749:INFO:8                    Preprocess              True
2023-04-29 19:42:54,749:INFO:9               Imputation type            simple
2023-04-29 19:42:54,749:INFO:10           Numeric imputation              mean
2023-04-29 19:42:54,749:INFO:11       Categorical imputation              mode
2023-04-29 19:42:54,749:INFO:12               Fold Generator   StratifiedKFold
2023-04-29 19:42:54,749:INFO:13                  Fold Number                10
2023-04-29 19:42:54,749:INFO:14                     CPU Jobs                -1
2023-04-29 19:42:54,749:INFO:15                      Use GPU             False
2023-04-29 19:42:54,749:INFO:16               Log Experiment             False
2023-04-29 19:42:54,749:INFO:17              Experiment Name  clf-default-name
2023-04-29 19:42:54,750:INFO:18                          USI              70e6
2023-04-29 19:42:54,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:42:54,984:INFO:setup() successfully completed in 1.75s...............
2023-04-29 19:42:54,992:INFO:Initializing compare_models()
2023-04-29 19:42:54,992:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-29 19:42:54,993:INFO:Checking exceptions
2023-04-29 19:42:55,004:INFO:Preparing display monitor
2023-04-29 19:42:55,009:WARNING:
2023-04-29 19:42:55,009:WARNING:Processing:   0%|                 | 0/61 [00:00<?, ?it/s]
2023-04-29 19:42:55,009:INFO:Initializing Logistic Regression
2023-04-29 19:42:55,009:INFO:Total runtime is 1.579920450846354e-05 minutes
2023-04-29 19:42:55,009:INFO:SubProcess create_model() called ==================================
2023-04-29 19:42:55,009:INFO:Initializing create_model()
2023-04-29 19:42:55,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:42:55,011:INFO:Checking exceptions
2023-04-29 19:42:55,011:INFO:Importing libraries
2023-04-29 19:42:55,011:INFO:Copying training dataset
2023-04-29 19:42:55,016:INFO:Defining folds
2023-04-29 19:42:55,016:INFO:Declaring metric variables
2023-04-29 19:42:55,017:INFO:Importing untrained model
2023-04-29 19:42:55,017:INFO:Logistic Regression Imported successfully
2023-04-29 19:42:55,018:INFO:Starting cross validation
2023-04-29 19:42:55,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:42:55,870:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:42:55,879:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:42:55,884:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:42:55,910:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:42:55,951:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:42:55,959:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:42:57,843:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-29 19:43:03,368:INFO:Calculating mean and std
2023-04-29 19:43:03,369:WARNING:Processing:   8%|7        | 5/61 [00:08<01:33,  1.67s/it]
2023-04-29 19:43:03,369:INFO:Creating metrics dataframe
2023-04-29 19:43:04,217:WARNING:Processing:  10%|8        | 6/61 [00:09<01:21,  1.49s/it]
2023-04-29 19:43:04,217:INFO:Uploading results into container
2023-04-29 19:43:04,218:INFO:Uploading model into container now
2023-04-29 19:43:04,218:INFO:_master_model_container: 1
2023-04-29 19:43:04,218:INFO:_display_container: 2
2023-04-29 19:43:04,219:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=294, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 19:43:04,219:INFO:create_model() successfully completed......................................
2023-04-29 19:43:04,359:INFO:SubProcess create_model() end ==================================
2023-04-29 19:43:04,359:INFO:Creating metrics dataframe
2023-04-29 19:43:04,364:INFO:Initializing K Neighbors Classifier
2023-04-29 19:43:04,364:INFO:Total runtime is 0.15592195590337118 minutes
2023-04-29 19:43:04,364:INFO:SubProcess create_model() called ==================================
2023-04-29 19:43:04,365:INFO:Initializing create_model()
2023-04-29 19:43:04,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:43:04,365:INFO:Checking exceptions
2023-04-29 19:43:04,365:INFO:Importing libraries
2023-04-29 19:43:04,365:INFO:Copying training dataset
2023-04-29 19:43:04,368:WARNING:Processing:  11%|#        | 7/61 [00:09<01:02,  1.17s/it]
2023-04-29 19:43:04,368:INFO:Defining folds
2023-04-29 19:43:04,369:INFO:Declaring metric variables
2023-04-29 19:43:04,369:INFO:Importing untrained model
2023-04-29 19:43:04,369:INFO:K Neighbors Classifier Imported successfully
2023-04-29 19:43:04,369:INFO:Starting cross validation
2023-04-29 19:43:04,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:43:04,485:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,485:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,496:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,510:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,510:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,515:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,519:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:04,530:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:06,110:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:06,125:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:43:12,271:INFO:Calculating mean and std
2023-04-29 19:43:12,272:WARNING:Processing:  15%|#3       | 9/61 [00:17<01:59,  2.30s/it]
2023-04-29 19:43:12,272:INFO:Creating metrics dataframe
2023-04-29 19:43:13,119:WARNING:Processing:  16%|#3      | 10/61 [00:18<01:40,  1.97s/it]
2023-04-29 19:43:13,119:INFO:Uploading results into container
2023-04-29 19:43:13,121:INFO:Uploading model into container now
2023-04-29 19:43:13,121:INFO:_master_model_container: 2
2023-04-29 19:43:13,121:INFO:_display_container: 2
2023-04-29 19:43:13,122:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 19:43:13,122:INFO:create_model() successfully completed......................................
2023-04-29 19:43:13,247:INFO:SubProcess create_model() end ==================================
2023-04-29 19:43:13,247:INFO:Creating metrics dataframe
2023-04-29 19:43:13,251:INFO:Initializing Naive Bayes
2023-04-29 19:43:13,251:INFO:Total runtime is 0.3040490031242371 minutes
2023-04-29 19:43:13,252:INFO:SubProcess create_model() called ==================================
2023-04-29 19:43:13,252:INFO:Initializing create_model()
2023-04-29 19:43:13,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:43:13,252:INFO:Checking exceptions
2023-04-29 19:43:13,252:INFO:Importing libraries
2023-04-29 19:43:13,252:INFO:Copying training dataset
2023-04-29 19:43:13,254:WARNING:Processing:  18%|#4      | 11/61 [00:18<01:16,  1.53s/it]
2023-04-29 19:43:13,254:INFO:Defining folds
2023-04-29 19:43:13,255:INFO:Declaring metric variables
2023-04-29 19:43:13,256:INFO:Importing untrained model
2023-04-29 19:43:13,256:INFO:Naive Bayes Imported successfully
2023-04-29 19:43:13,257:INFO:Starting cross validation
2023-04-29 19:43:13,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:43:21,070:INFO:Calculating mean and std
2023-04-29 19:43:21,071:WARNING:Processing:  21%|#7      | 13/61 [00:26<02:00,  2.50s/it]
2023-04-29 19:43:21,071:INFO:Creating metrics dataframe
2023-04-29 19:43:22,300:WARNING:Processing:  23%|#8      | 14/61 [00:27<01:44,  2.21s/it]
2023-04-29 19:43:22,301:INFO:Uploading results into container
2023-04-29 19:43:22,302:INFO:Uploading model into container now
2023-04-29 19:43:22,302:INFO:_master_model_container: 3
2023-04-29 19:43:22,302:INFO:_display_container: 2
2023-04-29 19:43:22,302:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 19:43:22,302:INFO:create_model() successfully completed......................................
2023-04-29 19:43:22,436:INFO:SubProcess create_model() end ==================================
2023-04-29 19:43:22,437:INFO:Creating metrics dataframe
2023-04-29 19:43:22,445:INFO:Initializing Decision Tree Classifier
2023-04-29 19:43:22,445:INFO:Total runtime is 0.45727523167928064 minutes
2023-04-29 19:43:22,445:INFO:SubProcess create_model() called ==================================
2023-04-29 19:43:22,445:INFO:Initializing create_model()
2023-04-29 19:43:22,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:43:22,446:INFO:Checking exceptions
2023-04-29 19:43:22,446:INFO:Importing libraries
2023-04-29 19:43:22,446:INFO:Copying training dataset
2023-04-29 19:43:22,449:WARNING:Processing:  25%|#9      | 15/61 [00:27<01:18,  1.71s/it]
2023-04-29 19:43:22,449:INFO:Defining folds
2023-04-29 19:43:22,449:INFO:Declaring metric variables
2023-04-29 19:43:22,450:INFO:Importing untrained model
2023-04-29 19:43:22,450:INFO:Decision Tree Classifier Imported successfully
2023-04-29 19:43:22,450:INFO:Starting cross validation
2023-04-29 19:43:22,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:43:30,311:INFO:Calculating mean and std
2023-04-29 19:43:30,312:WARNING:Processing:  28%|##2     | 17/61 [00:35<01:55,  2.62s/it]
2023-04-29 19:43:30,313:INFO:Creating metrics dataframe
2023-04-29 19:43:31,704:WARNING:Processing:  30%|##3     | 18/61 [00:36<01:40,  2.34s/it]
2023-04-29 19:43:31,705:INFO:Uploading results into container
2023-04-29 19:43:31,705:INFO:Uploading model into container now
2023-04-29 19:43:31,706:INFO:_master_model_container: 4
2023-04-29 19:43:31,706:INFO:_display_container: 2
2023-04-29 19:43:31,706:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=294, splitter='best')
2023-04-29 19:43:31,706:INFO:create_model() successfully completed......................................
2023-04-29 19:43:31,853:INFO:SubProcess create_model() end ==================================
2023-04-29 19:43:31,853:INFO:Creating metrics dataframe
2023-04-29 19:43:31,861:INFO:Initializing SVM - Linear Kernel
2023-04-29 19:43:31,861:INFO:Total runtime is 0.6142157514890035 minutes
2023-04-29 19:43:31,862:INFO:SubProcess create_model() called ==================================
2023-04-29 19:43:31,862:INFO:Initializing create_model()
2023-04-29 19:43:31,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:43:31,862:INFO:Checking exceptions
2023-04-29 19:43:31,862:INFO:Importing libraries
2023-04-29 19:43:31,862:INFO:Copying training dataset
2023-04-29 19:43:31,866:WARNING:Processing:  31%|##4     | 19/61 [00:36<01:15,  1.81s/it]
2023-04-29 19:43:31,866:INFO:Defining folds
2023-04-29 19:43:31,866:INFO:Declaring metric variables
2023-04-29 19:43:31,866:INFO:Importing untrained model
2023-04-29 19:43:31,867:INFO:SVM - Linear Kernel Imported successfully
2023-04-29 19:43:31,867:INFO:Starting cross validation
2023-04-29 19:43:31,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:43:32,028:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,047:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,052:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:32,067:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,069:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,078:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,080:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,083:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:32,084:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,098:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:32,103:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:33,706:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:33,732:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:43:33,735:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:39,152:INFO:Calculating mean and std
2023-04-29 19:43:39,152:WARNING:Processing:  34%|##7     | 21/61 [00:44<01:42,  2.56s/it]
2023-04-29 19:43:39,152:INFO:Creating metrics dataframe
2023-04-29 19:43:40,404:WARNING:Processing:  36%|##8     | 22/61 [00:45<01:28,  2.27s/it]
2023-04-29 19:43:40,405:INFO:Uploading results into container
2023-04-29 19:43:40,406:INFO:Uploading model into container now
2023-04-29 19:43:40,407:INFO:_master_model_container: 5
2023-04-29 19:43:40,408:INFO:_display_container: 2
2023-04-29 19:43:40,409:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=294, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-29 19:43:40,410:INFO:create_model() successfully completed......................................
2023-04-29 19:43:40,578:INFO:SubProcess create_model() end ==================================
2023-04-29 19:43:40,578:INFO:Creating metrics dataframe
2023-04-29 19:43:40,583:INFO:Initializing Ridge Classifier
2023-04-29 19:43:40,583:INFO:Total runtime is 0.759571905930837 minutes
2023-04-29 19:43:40,584:INFO:SubProcess create_model() called ==================================
2023-04-29 19:43:40,584:INFO:Initializing create_model()
2023-04-29 19:43:40,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:43:40,584:INFO:Checking exceptions
2023-04-29 19:43:40,584:INFO:Importing libraries
2023-04-29 19:43:40,584:INFO:Copying training dataset
2023-04-29 19:43:40,587:WARNING:Processing:  38%|###     | 23/61 [00:45<01:06,  1.76s/it]
2023-04-29 19:43:40,587:INFO:Defining folds
2023-04-29 19:43:40,587:INFO:Declaring metric variables
2023-04-29 19:43:40,587:INFO:Importing untrained model
2023-04-29 19:43:40,588:INFO:Ridge Classifier Imported successfully
2023-04-29 19:43:40,588:INFO:Starting cross validation
2023-04-29 19:43:40,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:43:40,682:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,682:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,686:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,686:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,692:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,697:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,705:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,710:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,714:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,720:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,727:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,732:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,743:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,748:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:40,748:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:40,753:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:42,341:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:42,346:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:42,375:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:43:42,379:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:43:48,123:INFO:Calculating mean and std
2023-04-29 19:43:48,124:WARNING:Processing:  41%|###2    | 25/61 [00:53<01:33,  2.58s/it]
2023-04-29 19:43:48,124:INFO:Creating metrics dataframe
2023-04-29 19:43:48,983:WARNING:Processing:  43%|###4    | 26/61 [00:53<01:16,  2.19s/it]
2023-04-29 19:43:48,984:INFO:Uploading results into container
2023-04-29 19:43:48,984:INFO:Uploading model into container now
2023-04-29 19:43:48,985:INFO:_master_model_container: 6
2023-04-29 19:43:48,985:INFO:_display_container: 2
2023-04-29 19:43:48,985:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=294, solver='auto', tol=0.001)
2023-04-29 19:43:48,985:INFO:create_model() successfully completed......................................
2023-04-29 19:43:49,129:INFO:SubProcess create_model() end ==================================
2023-04-29 19:43:49,129:INFO:Creating metrics dataframe
2023-04-29 19:43:49,138:INFO:Initializing Random Forest Classifier
2023-04-29 19:43:49,138:INFO:Total runtime is 0.9021645824114481 minutes
2023-04-29 19:43:49,139:INFO:SubProcess create_model() called ==================================
2023-04-29 19:43:49,139:INFO:Initializing create_model()
2023-04-29 19:43:49,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:43:49,139:INFO:Checking exceptions
2023-04-29 19:43:49,139:INFO:Importing libraries
2023-04-29 19:43:49,139:INFO:Copying training dataset
2023-04-29 19:43:49,146:WARNING:Processing:  44%|###5    | 27/61 [00:54<00:57,  1.69s/it]
2023-04-29 19:43:49,146:INFO:Defining folds
2023-04-29 19:43:49,146:INFO:Declaring metric variables
2023-04-29 19:43:49,147:INFO:Importing untrained model
2023-04-29 19:43:49,148:INFO:Random Forest Classifier Imported successfully
2023-04-29 19:43:49,148:INFO:Starting cross validation
2023-04-29 19:43:49,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:43:59,102:INFO:Calculating mean and std
2023-04-29 19:43:59,102:WARNING:Processing:  48%|###8    | 29/61 [01:04<01:37,  3.05s/it]
2023-04-29 19:43:59,103:INFO:Creating metrics dataframe
2023-04-29 19:44:00,289:WARNING:Processing:  49%|###9    | 30/61 [01:05<01:21,  2.62s/it]
2023-04-29 19:44:00,289:INFO:Uploading results into container
2023-04-29 19:44:00,291:INFO:Uploading model into container now
2023-04-29 19:44:00,291:INFO:_master_model_container: 7
2023-04-29 19:44:00,291:INFO:_display_container: 2
2023-04-29 19:44:00,292:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=294, verbose=0, warm_start=False)
2023-04-29 19:44:00,292:INFO:create_model() successfully completed......................................
2023-04-29 19:44:00,415:INFO:SubProcess create_model() end ==================================
2023-04-29 19:44:00,415:INFO:Creating metrics dataframe
2023-04-29 19:44:00,421:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 19:44:00,421:INFO:Total runtime is 1.090210215250651 minutes
2023-04-29 19:44:00,422:INFO:SubProcess create_model() called ==================================
2023-04-29 19:44:00,422:INFO:Initializing create_model()
2023-04-29 19:44:00,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:44:00,423:INFO:Checking exceptions
2023-04-29 19:44:00,423:INFO:Importing libraries
2023-04-29 19:44:00,423:INFO:Copying training dataset
2023-04-29 19:44:00,430:WARNING:Processing:  51%|####    | 31/61 [01:05<01:00,  2.02s/it]
2023-04-29 19:44:00,430:INFO:Defining folds
2023-04-29 19:44:00,431:INFO:Declaring metric variables
2023-04-29 19:44:00,431:INFO:Importing untrained model
2023-04-29 19:44:00,431:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 19:44:00,431:INFO:Starting cross validation
2023-04-29 19:44:00,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:44:08,579:INFO:Calculating mean and std
2023-04-29 19:44:08,580:WARNING:Processing:  54%|####3   | 33/61 [01:13<01:20,  2.86s/it]
2023-04-29 19:44:08,580:INFO:Creating metrics dataframe
2023-04-29 19:44:09,430:WARNING:Processing:  56%|####4   | 34/61 [01:14<01:04,  2.41s/it]
2023-04-29 19:44:09,430:INFO:Uploading results into container
2023-04-29 19:44:09,430:INFO:Uploading model into container now
2023-04-29 19:44:09,431:INFO:_master_model_container: 8
2023-04-29 19:44:09,431:INFO:_display_container: 2
2023-04-29 19:44:09,431:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 19:44:09,431:INFO:create_model() successfully completed......................................
2023-04-29 19:44:09,565:INFO:SubProcess create_model() end ==================================
2023-04-29 19:44:09,566:INFO:Creating metrics dataframe
2023-04-29 19:44:09,574:INFO:Initializing Ada Boost Classifier
2023-04-29 19:44:09,574:INFO:Total runtime is 1.242759350935618 minutes
2023-04-29 19:44:09,574:INFO:SubProcess create_model() called ==================================
2023-04-29 19:44:09,574:INFO:Initializing create_model()
2023-04-29 19:44:09,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:44:09,574:INFO:Checking exceptions
2023-04-29 19:44:09,574:INFO:Importing libraries
2023-04-29 19:44:09,574:INFO:Copying training dataset
2023-04-29 19:44:09,578:WARNING:Processing:  57%|####5   | 35/61 [01:14<00:48,  1.85s/it]
2023-04-29 19:44:09,578:INFO:Defining folds
2023-04-29 19:44:09,578:INFO:Declaring metric variables
2023-04-29 19:44:09,578:INFO:Importing untrained model
2023-04-29 19:44:09,578:INFO:Ada Boost Classifier Imported successfully
2023-04-29 19:44:09,579:INFO:Starting cross validation
2023-04-29 19:44:09,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:44:17,846:INFO:Calculating mean and std
2023-04-29 19:44:17,847:WARNING:Processing:  61%|####8   | 37/61 [01:22<01:07,  2.79s/it]
2023-04-29 19:44:17,847:INFO:Creating metrics dataframe
2023-04-29 19:44:18,706:WARNING:Processing:  62%|####9   | 38/61 [01:23<00:54,  2.35s/it]
2023-04-29 19:44:18,706:INFO:Uploading results into container
2023-04-29 19:44:18,707:INFO:Uploading model into container now
2023-04-29 19:44:18,707:INFO:_master_model_container: 9
2023-04-29 19:44:18,707:INFO:_display_container: 2
2023-04-29 19:44:18,707:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=294)
2023-04-29 19:44:18,708:INFO:create_model() successfully completed......................................
2023-04-29 19:44:18,832:INFO:SubProcess create_model() end ==================================
2023-04-29 19:44:18,832:INFO:Creating metrics dataframe
2023-04-29 19:44:18,836:INFO:Initializing Gradient Boosting Classifier
2023-04-29 19:44:18,836:INFO:Total runtime is 1.3971307357152303 minutes
2023-04-29 19:44:18,836:INFO:SubProcess create_model() called ==================================
2023-04-29 19:44:18,836:INFO:Initializing create_model()
2023-04-29 19:44:18,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:44:18,836:INFO:Checking exceptions
2023-04-29 19:44:18,836:INFO:Importing libraries
2023-04-29 19:44:18,837:INFO:Copying training dataset
2023-04-29 19:44:18,840:WARNING:Processing:  64%|#####1  | 39/61 [01:23<00:39,  1.81s/it]
2023-04-29 19:44:18,840:INFO:Defining folds
2023-04-29 19:44:18,840:INFO:Declaring metric variables
2023-04-29 19:44:18,840:INFO:Importing untrained model
2023-04-29 19:44:18,840:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 19:44:18,841:INFO:Starting cross validation
2023-04-29 19:44:18,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:44:29,468:INFO:Calculating mean and std
2023-04-29 19:44:29,469:WARNING:Processing:  67%|#####3  | 41/61 [01:34<01:05,  3.25s/it]
2023-04-29 19:44:29,469:INFO:Creating metrics dataframe
2023-04-29 19:44:31,144:WARNING:Processing:  69%|#####5  | 42/61 [01:36<00:54,  2.89s/it]
2023-04-29 19:44:31,144:INFO:Uploading results into container
2023-04-29 19:44:31,147:INFO:Uploading model into container now
2023-04-29 19:44:31,148:INFO:_master_model_container: 10
2023-04-29 19:44:31,149:INFO:_display_container: 2
2023-04-29 19:44:31,149:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=294, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 19:44:31,149:INFO:create_model() successfully completed......................................
2023-04-29 19:44:31,301:INFO:SubProcess create_model() end ==================================
2023-04-29 19:44:31,301:INFO:Creating metrics dataframe
2023-04-29 19:44:31,312:INFO:Initializing Linear Discriminant Analysis
2023-04-29 19:44:31,313:INFO:Total runtime is 1.605082635084788 minutes
2023-04-29 19:44:31,313:INFO:SubProcess create_model() called ==================================
2023-04-29 19:44:31,314:INFO:Initializing create_model()
2023-04-29 19:44:31,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:44:31,314:INFO:Checking exceptions
2023-04-29 19:44:31,315:INFO:Importing libraries
2023-04-29 19:44:31,315:INFO:Copying training dataset
2023-04-29 19:44:31,322:WARNING:Processing:  70%|#####6  | 43/61 [01:36<00:40,  2.23s/it]
2023-04-29 19:44:31,323:INFO:Defining folds
2023-04-29 19:44:31,324:INFO:Declaring metric variables
2023-04-29 19:44:31,325:INFO:Importing untrained model
2023-04-29 19:44:31,325:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 19:44:31,326:INFO:Starting cross validation
2023-04-29 19:44:31,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:44:33,323:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:44:39,183:INFO:Calculating mean and std
2023-04-29 19:44:39,184:WARNING:Processing:  74%|#####9  | 45/61 [01:44<00:46,  2.93s/it]
2023-04-29 19:44:39,184:INFO:Creating metrics dataframe
2023-04-29 19:44:40,384:WARNING:Processing:  75%|######  | 46/61 [01:45<00:38,  2.54s/it]
2023-04-29 19:44:40,384:INFO:Uploading results into container
2023-04-29 19:44:40,385:INFO:Uploading model into container now
2023-04-29 19:44:40,386:INFO:_master_model_container: 11
2023-04-29 19:44:40,387:INFO:_display_container: 2
2023-04-29 19:44:40,387:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 19:44:40,388:INFO:create_model() successfully completed......................................
2023-04-29 19:44:40,509:INFO:SubProcess create_model() end ==================================
2023-04-29 19:44:40,509:INFO:Creating metrics dataframe
2023-04-29 19:44:40,520:INFO:Initializing Extra Trees Classifier
2023-04-29 19:44:40,521:INFO:Total runtime is 1.758538262049357 minutes
2023-04-29 19:44:40,521:INFO:SubProcess create_model() called ==================================
2023-04-29 19:44:40,522:INFO:Initializing create_model()
2023-04-29 19:44:40,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:44:40,522:INFO:Checking exceptions
2023-04-29 19:44:40,522:INFO:Importing libraries
2023-04-29 19:44:40,522:INFO:Copying training dataset
2023-04-29 19:44:40,529:WARNING:Processing:  77%|######1 | 47/61 [01:45<00:27,  1.95s/it]
2023-04-29 19:44:40,529:INFO:Defining folds
2023-04-29 19:44:40,529:INFO:Declaring metric variables
2023-04-29 19:44:40,530:INFO:Importing untrained model
2023-04-29 19:44:40,531:INFO:Extra Trees Classifier Imported successfully
2023-04-29 19:44:40,531:INFO:Starting cross validation
2023-04-29 19:44:40,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:44:49,879:INFO:Calculating mean and std
2023-04-29 19:44:49,880:WARNING:Processing:  80%|######4 | 49/61 [01:54<00:36,  3.07s/it]
2023-04-29 19:44:49,880:INFO:Creating metrics dataframe
2023-04-29 19:44:51,308:WARNING:Processing:  82%|######5 | 50/61 [01:56<00:29,  2.70s/it]
2023-04-29 19:44:51,308:INFO:Uploading results into container
2023-04-29 19:44:51,309:INFO:Uploading model into container now
2023-04-29 19:44:51,309:INFO:_master_model_container: 12
2023-04-29 19:44:51,309:INFO:_display_container: 2
2023-04-29 19:44:51,310:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=294, verbose=0, warm_start=False)
2023-04-29 19:44:51,310:INFO:create_model() successfully completed......................................
2023-04-29 19:44:51,456:INFO:SubProcess create_model() end ==================================
2023-04-29 19:44:51,457:INFO:Creating metrics dataframe
2023-04-29 19:44:51,473:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:44:51,473:INFO:Total runtime is 1.941080896059672 minutes
2023-04-29 19:44:51,474:INFO:SubProcess create_model() called ==================================
2023-04-29 19:44:51,475:INFO:Initializing create_model()
2023-04-29 19:44:51,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:44:51,475:INFO:Checking exceptions
2023-04-29 19:44:51,475:INFO:Importing libraries
2023-04-29 19:44:51,476:INFO:Copying training dataset
2023-04-29 19:44:51,484:WARNING:Processing:  84%|######6 | 51/61 [01:56<00:20,  2.08s/it]
2023-04-29 19:44:51,484:INFO:Defining folds
2023-04-29 19:44:51,484:INFO:Declaring metric variables
2023-04-29 19:44:51,485:INFO:Importing untrained model
2023-04-29 19:44:51,486:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:44:51,487:INFO:Starting cross validation
2023-04-29 19:44:51,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:45:01,862:INFO:Calculating mean and std
2023-04-29 19:45:01,863:WARNING:Processing:  87%|######9 | 53/61 [02:06<00:26,  3.36s/it]
2023-04-29 19:45:01,863:INFO:Creating metrics dataframe
2023-04-29 19:45:02,776:WARNING:Processing:  89%|####### | 54/61 [02:07<00:19,  2.80s/it]
2023-04-29 19:45:02,776:INFO:Uploading results into container
2023-04-29 19:45:02,777:INFO:Uploading model into container now
2023-04-29 19:45:02,777:INFO:_master_model_container: 13
2023-04-29 19:45:02,778:INFO:_display_container: 2
2023-04-29 19:45:02,779:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=294, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 19:45:02,779:INFO:create_model() successfully completed......................................
2023-04-29 19:45:02,898:INFO:SubProcess create_model() end ==================================
2023-04-29 19:45:02,898:INFO:Creating metrics dataframe
2023-04-29 19:45:02,902:INFO:Initializing Dummy Classifier
2023-04-29 19:45:02,902:INFO:Total runtime is 2.1315630594889323 minutes
2023-04-29 19:45:02,902:INFO:SubProcess create_model() called ==================================
2023-04-29 19:45:02,903:INFO:Initializing create_model()
2023-04-29 19:45:02,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEB52C70>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:45:02,903:INFO:Checking exceptions
2023-04-29 19:45:02,903:INFO:Importing libraries
2023-04-29 19:45:02,903:INFO:Copying training dataset
2023-04-29 19:45:02,906:WARNING:Processing:  90%|#######2| 55/61 [02:07<00:12,  2.15s/it]
2023-04-29 19:45:02,906:INFO:Defining folds
2023-04-29 19:45:02,906:INFO:Declaring metric variables
2023-04-29 19:45:02,906:INFO:Importing untrained model
2023-04-29 19:45:02,906:INFO:Dummy Classifier Imported successfully
2023-04-29 19:45:02,906:INFO:Starting cross validation
2023-04-29 19:45:02,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:45:03,053:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,055:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,056:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,074:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,080:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,091:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,106:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:03,110:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:04,870:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:04,897:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:45:11,444:INFO:Calculating mean and std
2023-04-29 19:45:11,445:WARNING:Processing:  93%|#######4| 57/61 [02:16<00:12,  3.02s/it]
2023-04-29 19:45:11,445:INFO:Creating metrics dataframe
2023-04-29 19:45:12,620:WARNING:Processing:  95%|#######6| 58/61 [02:17<00:07,  2.60s/it]
2023-04-29 19:45:12,620:INFO:Uploading results into container
2023-04-29 19:45:12,621:INFO:Uploading model into container now
2023-04-29 19:45:12,621:INFO:_master_model_container: 14
2023-04-29 19:45:12,621:INFO:_display_container: 2
2023-04-29 19:45:12,621:INFO:DummyClassifier(constant=None, random_state=294, strategy='prior')
2023-04-29 19:45:12,621:INFO:create_model() successfully completed......................................
2023-04-29 19:45:12,750:INFO:SubProcess create_model() end ==================================
2023-04-29 19:45:12,750:INFO:Creating metrics dataframe
2023-04-29 19:45:12,754:WARNING:Processing:  97%|#######7| 59/61 [02:17<00:03,  2.00s/it]
2023-04-29 19:45:12,756:INFO:Initializing create_model()
2023-04-29 19:45:12,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=294, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:45:12,756:INFO:Checking exceptions
2023-04-29 19:45:12,757:INFO:Importing libraries
2023-04-29 19:45:12,757:INFO:Copying training dataset
2023-04-29 19:45:12,760:INFO:Defining folds
2023-04-29 19:45:12,760:INFO:Declaring metric variables
2023-04-29 19:45:12,760:INFO:Importing untrained model
2023-04-29 19:45:12,760:INFO:Declaring custom model
2023-04-29 19:45:12,761:INFO:Random Forest Classifier Imported successfully
2023-04-29 19:45:12,761:INFO:Cross validation set to False
2023-04-29 19:45:12,761:INFO:Fitting Model
2023-04-29 19:45:13,788:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=294, verbose=0, warm_start=False)
2023-04-29 19:45:13,788:INFO:create_model() successfully completed......................................
2023-04-29 19:45:13,913:WARNING:Processing: 100%|########| 61/61 [02:18<00:00,  1.41s/it]
2023-04-29 19:45:13,913:WARNING:                                                         
2023-04-29 19:45:13,946:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2023-04-29 19:45:13,946:INFO:rf               Random Forest Classifier    0.8317  0.9458  0.8317  0.8393   
2023-04-29 19:45:13,947:INFO:et                 Extra Trees Classifier    0.8307  0.9323  0.8307  0.8368   
2023-04-29 19:45:13,947:INFO:lightgbm  Light Gradient Boosting Machine    0.8244  0.9455  0.8244  0.8332   
2023-04-29 19:45:13,947:INFO:gbc          Gradient Boosting Classifier    0.8170  0.9427  0.8170  0.8265   
2023-04-29 19:45:13,947:INFO:dt               Decision Tree Classifier    0.8023  0.8923  0.8023  0.8115   
2023-04-29 19:45:13,947:INFO:knn                K Neighbors Classifier    0.7855  0.9150  0.7855  0.7918   
2023-04-29 19:45:13,947:INFO:ridge                    Ridge Classifier    0.7003  0.0000  0.7003  0.6500   
2023-04-29 19:45:13,947:INFO:lda          Linear Discriminant Analysis    0.6877  0.8720  0.6877  0.6737   
2023-04-29 19:45:13,947:INFO:lr                    Logistic Regression    0.6876  0.8794  0.6876  0.6821   
2023-04-29 19:45:13,947:INFO:nb                            Naive Bayes    0.6613  0.8504  0.6613  0.6931   
2023-04-29 19:45:13,947:INFO:qda       Quadratic Discriminant Analysis    0.6182  0.8737  0.6182  0.6426   
2023-04-29 19:45:13,948:INFO:ada                  Ada Boost Classifier    0.6162  0.7539  0.6162  0.6420   
2023-04-29 19:45:13,948:INFO:svm                   SVM - Linear Kernel    0.6108  0.0000  0.6108  0.6457   
2023-04-29 19:45:13,948:INFO:dummy                    Dummy Classifier    0.3407  0.5000  0.3407  0.1161   
2023-04-29 19:45:13,948:INFO:
2023-04-29 19:45:13,948:INFO:              F1   Kappa     MCC  TT (Sec)  
2023-04-29 19:45:13,948:INFO:rf        0.8312  0.7614  0.7644     0.995  
2023-04-29 19:45:13,948:INFO:et        0.8297  0.7608  0.7635     0.935  
2023-04-29 19:45:13,948:INFO:lightgbm  0.8245  0.7524  0.7552     1.037  
2023-04-29 19:45:13,948:INFO:gbc       0.8174  0.7412  0.7443     1.063  
2023-04-29 19:45:13,948:INFO:dt        0.8017  0.7222  0.7257     0.786  
2023-04-29 19:45:13,948:INFO:knn       0.7838  0.6962  0.6994     0.790  
2023-04-29 19:45:13,948:INFO:ridge     0.6712  0.5661  0.5718     0.753  
2023-04-29 19:45:13,949:INFO:lda       0.6710  0.5534  0.5583     0.785  
2023-04-29 19:45:13,949:INFO:lr        0.6759  0.5543  0.5588     0.835  
2023-04-29 19:45:13,949:INFO:nb        0.6617  0.5371  0.5480     0.781  
2023-04-29 19:45:13,949:INFO:qda       0.6026  0.4831  0.4997     0.815  
2023-04-29 19:45:13,949:INFO:ada       0.6129  0.4482  0.4565     0.827  
2023-04-29 19:45:13,949:INFO:svm       0.5857  0.4602  0.4894     0.728  
2023-04-29 19:45:13,949:INFO:dummy     0.1732  0.0000  0.0000     0.854  
2023-04-29 19:45:13,949:INFO:_master_model_container: 14
2023-04-29 19:45:13,949:INFO:_display_container: 2
2023-04-29 19:45:13,950:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=294, verbose=0, warm_start=False)
2023-04-29 19:45:13,950:INFO:compare_models() successfully completed......................................
2023-04-29 19:45:13,954:INFO:Initializing predict_model()
2023-04-29 19:45:13,954:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F13BC580>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=294, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236F145C9D0>)
2023-04-29 19:45:13,954:INFO:Checking exceptions
2023-04-29 19:45:13,955:INFO:Preloading libraries
2023-04-29 19:45:13,955:INFO:Set up data.
2023-04-29 19:45:13,966:INFO:Set up index.
2023-04-29 19:45:14,092:INFO:                      Model  Accuracy  ...   Kappa    MCC
2023-04-29 19:45:14,093:INFO:0  Random Forest Classifier    0.8956  ...  0.8524  0.853
2023-04-29 19:45:14,093:INFO:
2023-04-29 19:45:14,093:INFO:[1 rows x 8 columns]
2023-04-29 19:46:56,242:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:46:56,243:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:46:56,243:INFO:Data columns (total 8 columns):
2023-04-29 19:46:56,243:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:46:56,243:INFO:---  ------          --------------  -----  
2023-04-29 19:46:56,243:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:46:56,243:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:46:56,243:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:46:56,243:INFO:memory usage: 79.8 KB
2023-04-29 19:47:08,494:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:47:08,494:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:47:08,494:INFO:Data columns (total 8 columns):
2023-04-29 19:47:08,494:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:47:08,495:INFO:---  ------          --------------  -----  
2023-04-29 19:47:08,495:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:47:08,495:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:47:08,495:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:47:08,495:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:47:08,495:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:47:08,495:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:47:08,496:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:47:08,497:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:47:08,497:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:47:08,497:INFO:memory usage: 79.8 KB
2023-04-29 19:47:10,040:INFO:PyCaret RegressionExperiment
2023-04-29 19:47:10,040:INFO:Logging name: reg-default-name
2023-04-29 19:47:10,040:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 19:47:10,040:INFO:version 3.0.0
2023-04-29 19:47:10,041:INFO:Initializing setup()
2023-04-29 19:47:10,041:INFO:self.USI: cfa4
2023-04-29 19:47:10,042:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:47:10,042:INFO:Checking environment
2023-04-29 19:47:10,043:INFO:python_version: 3.9.13
2023-04-29 19:47:10,043:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:47:10,043:INFO:machine: AMD64
2023-04-29 19:47:10,044:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:47:10,044:INFO:Memory: svmem(total=16935899136, available=5268664320, percent=68.9, used=11667234816, free=5268664320)
2023-04-29 19:47:10,045:INFO:Physical Core: 4
2023-04-29 19:47:10,045:INFO:Logical Core: 8
2023-04-29 19:47:10,046:INFO:Checking libraries
2023-04-29 19:47:10,046:INFO:System:
2023-04-29 19:47:10,046:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:47:10,046:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:47:10,046:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:47:10,047:INFO:PyCaret required dependencies:
2023-04-29 19:47:10,047:INFO:                 pip: 22.2.2
2023-04-29 19:47:10,047:INFO:          setuptools: 63.4.1
2023-04-29 19:47:10,048:INFO:             pycaret: 3.0.0
2023-04-29 19:47:10,048:INFO:             IPython: 7.31.1
2023-04-29 19:47:10,048:INFO:          ipywidgets: 7.6.5
2023-04-29 19:47:10,048:INFO:                tqdm: 4.64.1
2023-04-29 19:47:10,048:INFO:               numpy: 1.21.5
2023-04-29 19:47:10,049:INFO:              pandas: 1.4.4
2023-04-29 19:47:10,049:INFO:              jinja2: 2.11.3
2023-04-29 19:47:10,049:INFO:               scipy: 1.9.1
2023-04-29 19:47:10,049:INFO:              joblib: 1.2.0
2023-04-29 19:47:10,049:INFO:             sklearn: 1.0.2
2023-04-29 19:47:10,051:INFO:                pyod: 1.0.9
2023-04-29 19:47:10,051:INFO:            imblearn: 0.10.1
2023-04-29 19:47:10,051:INFO:   category_encoders: 2.6.0
2023-04-29 19:47:10,051:INFO:            lightgbm: 3.3.5
2023-04-29 19:47:10,051:INFO:               numba: 0.55.1
2023-04-29 19:47:10,052:INFO:            requests: 2.28.1
2023-04-29 19:47:10,052:INFO:          matplotlib: 3.5.2
2023-04-29 19:47:10,052:INFO:          scikitplot: 0.3.7
2023-04-29 19:47:10,052:INFO:         yellowbrick: 1.5
2023-04-29 19:47:10,053:INFO:              plotly: 5.9.0
2023-04-29 19:47:10,053:INFO:             kaleido: 0.2.1
2023-04-29 19:47:10,053:INFO:         statsmodels: 0.13.2
2023-04-29 19:47:10,054:INFO:              sktime: 0.17.1
2023-04-29 19:47:10,054:INFO:               tbats: 1.1.2
2023-04-29 19:47:10,055:INFO:            pmdarima: 2.0.3
2023-04-29 19:47:10,055:INFO:              psutil: 5.9.0
2023-04-29 19:47:10,056:INFO:PyCaret optional dependencies:
2023-04-29 19:47:10,056:INFO:                shap: 0.41.0
2023-04-29 19:47:10,056:INFO:           interpret: Not installed
2023-04-29 19:47:10,057:INFO:                umap: Not installed
2023-04-29 19:47:10,057:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:47:10,057:INFO:  explainerdashboard: Not installed
2023-04-29 19:47:10,057:INFO:             autoviz: Not installed
2023-04-29 19:47:10,058:INFO:           fairlearn: Not installed
2023-04-29 19:47:10,058:INFO:             xgboost: Not installed
2023-04-29 19:47:10,058:INFO:            catboost: Not installed
2023-04-29 19:47:10,059:INFO:              kmodes: Not installed
2023-04-29 19:47:10,059:INFO:             mlxtend: Not installed
2023-04-29 19:47:10,060:INFO:       statsforecast: Not installed
2023-04-29 19:47:10,060:INFO:        tune_sklearn: Not installed
2023-04-29 19:47:10,060:INFO:                 ray: Not installed
2023-04-29 19:47:10,060:INFO:            hyperopt: Not installed
2023-04-29 19:47:10,061:INFO:              optuna: Not installed
2023-04-29 19:47:10,061:INFO:               skopt: Not installed
2023-04-29 19:47:10,062:INFO:              mlflow: 2.2.1
2023-04-29 19:47:10,062:INFO:              gradio: Not installed
2023-04-29 19:47:10,063:INFO:             fastapi: Not installed
2023-04-29 19:47:10,063:INFO:             uvicorn: Not installed
2023-04-29 19:47:10,066:INFO:              m2cgen: Not installed
2023-04-29 19:47:10,066:INFO:           evidently: Not installed
2023-04-29 19:47:10,066:INFO:               fugue: Not installed
2023-04-29 19:47:10,067:INFO:           streamlit: 1.21.0
2023-04-29 19:47:10,067:INFO:             prophet: Not installed
2023-04-29 19:47:10,067:INFO:None
2023-04-29 19:47:10,068:INFO:Set up data.
2023-04-29 19:47:10,077:INFO:Set up train/test split.
2023-04-29 19:47:10,083:INFO:Set up index.
2023-04-29 19:47:10,083:INFO:Set up folding strategy.
2023-04-29 19:47:10,084:INFO:Assigning column types.
2023-04-29 19:47:10,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:47:10,090:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,097:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,272:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,283:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,500:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 19:47:10,505:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,509:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,628:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,733:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 19:47:10,742:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:10,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:10,942:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,088:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 19:47:11,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,394:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:47:11,469:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 19:47:11,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,627:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 19:47:11,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:11,969:INFO:Preparing preprocessing pipeline...
2023-04-29 19:47:11,969:INFO:Set up simple imputation.
2023-04-29 19:47:11,970:INFO:Set up column name cleaning.
2023-04-29 19:47:11,995:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:47:11,999:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 19:47:11,999:INFO:Creating final display dataframe.
2023-04-29 19:47:12,083:INFO:Setup _display_container:                     Description             Value
0                    Session id              3128
1                        Target             dSmix
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              cfa4
2023-04-29 19:47:12,093:INFO:                    Description             Value
2023-04-29 19:47:12,094:INFO:0                    Session id              3128
2023-04-29 19:47:12,094:INFO:1                        Target             dSmix
2023-04-29 19:47:12,094:INFO:2                   Target type        Regression
2023-04-29 19:47:12,094:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:47:12,095:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:47:12,095:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:47:12,095:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:47:12,095:INFO:7              Numeric features                 7
2023-04-29 19:47:12,095:INFO:8                    Preprocess              True
2023-04-29 19:47:12,095:INFO:9               Imputation type            simple
2023-04-29 19:47:12,096:INFO:10           Numeric imputation              mean
2023-04-29 19:47:12,096:INFO:11       Categorical imputation              mode
2023-04-29 19:47:12,096:INFO:12               Fold Generator             KFold
2023-04-29 19:47:12,096:INFO:13                  Fold Number                10
2023-04-29 19:47:12,096:INFO:14                     CPU Jobs                -1
2023-04-29 19:47:12,096:INFO:15                      Use GPU             False
2023-04-29 19:47:12,096:INFO:16               Log Experiment             False
2023-04-29 19:47:12,097:INFO:17              Experiment Name  reg-default-name
2023-04-29 19:47:12,097:INFO:18                          USI              cfa4
2023-04-29 19:47:12,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:12,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:12,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:12,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:47:12,436:INFO:setup() successfully completed in 3.12s...............
2023-04-29 19:47:12,443:INFO:Initializing compare_models()
2023-04-29 19:47:12,443:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 19:47:12,444:INFO:Checking exceptions
2023-04-29 19:47:12,447:INFO:Preparing display monitor
2023-04-29 19:47:12,452:WARNING:
2023-04-29 19:47:12,453:WARNING:Processing:   0%|                 | 0/77 [00:00<?, ?it/s]
2023-04-29 19:47:12,454:INFO:Initializing Linear Regression
2023-04-29 19:47:12,454:INFO:Total runtime is 0.0 minutes
2023-04-29 19:47:12,455:INFO:SubProcess create_model() called ==================================
2023-04-29 19:47:12,455:INFO:Initializing create_model()
2023-04-29 19:47:12,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:47:12,456:INFO:Checking exceptions
2023-04-29 19:47:12,456:INFO:Importing libraries
2023-04-29 19:47:12,456:INFO:Copying training dataset
2023-04-29 19:47:12,466:INFO:Defining folds
2023-04-29 19:47:12,466:INFO:Declaring metric variables
2023-04-29 19:47:12,466:INFO:Importing untrained model
2023-04-29 19:47:12,467:INFO:Linear Regression Imported successfully
2023-04-29 19:47:12,467:INFO:Starting cross validation
2023-04-29 19:47:12,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:47:20,092:INFO:Calculating mean and std
2023-04-29 19:47:20,093:WARNING:Processing:   6%|5        | 5/77 [00:07<01:49,  1.53s/it]
2023-04-29 19:47:20,094:INFO:Creating metrics dataframe
2023-04-29 19:47:21,769:WARNING:Processing:   8%|7        | 6/77 [00:09<01:50,  1.56s/it]
2023-04-29 19:47:21,769:INFO:Uploading results into container
2023-04-29 19:47:21,770:INFO:Uploading model into container now
2023-04-29 19:47:21,770:INFO:_master_model_container: 1
2023-04-29 19:47:21,770:INFO:_display_container: 2
2023-04-29 19:47:21,771:INFO:LinearRegression(n_jobs=-1)
2023-04-29 19:47:21,771:INFO:create_model() successfully completed......................................
2023-04-29 19:47:21,906:INFO:SubProcess create_model() end ==================================
2023-04-29 19:47:21,907:INFO:Creating metrics dataframe
2023-04-29 19:47:21,910:INFO:Initializing Lasso Regression
2023-04-29 19:47:21,910:INFO:Total runtime is 0.15761099656422933 minutes
2023-04-29 19:47:21,911:INFO:SubProcess create_model() called ==================================
2023-04-29 19:47:21,911:INFO:Initializing create_model()
2023-04-29 19:47:21,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:47:21,911:INFO:Checking exceptions
2023-04-29 19:47:21,911:INFO:Importing libraries
2023-04-29 19:47:21,911:INFO:Copying training dataset
2023-04-29 19:47:21,914:WARNING:Processing:   9%|8        | 7/77 [00:09<01:25,  1.22s/it]
2023-04-29 19:47:21,914:INFO:Defining folds
2023-04-29 19:47:21,914:INFO:Declaring metric variables
2023-04-29 19:47:21,914:INFO:Importing untrained model
2023-04-29 19:47:21,914:INFO:Lasso Regression Imported successfully
2023-04-29 19:47:21,914:INFO:Starting cross validation
2023-04-29 19:47:21,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:47:29,406:INFO:Calculating mean and std
2023-04-29 19:47:29,407:WARNING:Processing:  12%|#        | 9/77 [00:16<02:33,  2.25s/it]
2023-04-29 19:47:29,407:INFO:Creating metrics dataframe
2023-04-29 19:47:30,725:WARNING:Processing:  13%|#       | 10/77 [00:18<02:16,  2.04s/it]
2023-04-29 19:47:30,725:INFO:Uploading results into container
2023-04-29 19:47:30,725:INFO:Uploading model into container now
2023-04-29 19:47:30,726:INFO:_master_model_container: 2
2023-04-29 19:47:30,726:INFO:_display_container: 2
2023-04-29 19:47:30,726:INFO:Lasso(random_state=3128)
2023-04-29 19:47:30,726:INFO:create_model() successfully completed......................................
2023-04-29 19:47:30,864:INFO:SubProcess create_model() end ==================================
2023-04-29 19:47:30,864:INFO:Creating metrics dataframe
2023-04-29 19:47:30,877:INFO:Initializing Ridge Regression
2023-04-29 19:47:30,878:INFO:Total runtime is 0.30707676808039347 minutes
2023-04-29 19:47:30,878:INFO:SubProcess create_model() called ==================================
2023-04-29 19:47:30,879:INFO:Initializing create_model()
2023-04-29 19:47:30,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:47:30,879:INFO:Checking exceptions
2023-04-29 19:47:30,879:INFO:Importing libraries
2023-04-29 19:47:30,879:INFO:Copying training dataset
2023-04-29 19:47:30,890:WARNING:Processing:  14%|#1      | 11/77 [00:18<01:44,  1.58s/it]
2023-04-29 19:47:30,890:INFO:Defining folds
2023-04-29 19:47:30,891:INFO:Declaring metric variables
2023-04-29 19:47:30,891:INFO:Importing untrained model
2023-04-29 19:47:30,893:INFO:Ridge Regression Imported successfully
2023-04-29 19:47:30,893:INFO:Starting cross validation
2023-04-29 19:47:30,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:47:38,441:INFO:Calculating mean and std
2023-04-29 19:47:38,442:WARNING:Processing:  17%|#3      | 13/77 [00:25<02:38,  2.48s/it]
2023-04-29 19:47:38,442:INFO:Creating metrics dataframe
2023-04-29 19:47:39,293:WARNING:Processing:  18%|#4      | 14/77 [00:26<02:13,  2.11s/it]
2023-04-29 19:47:39,293:INFO:Uploading results into container
2023-04-29 19:47:39,294:INFO:Uploading model into container now
2023-04-29 19:47:39,294:INFO:_master_model_container: 3
2023-04-29 19:47:39,294:INFO:_display_container: 2
2023-04-29 19:47:39,295:INFO:Ridge(random_state=3128)
2023-04-29 19:47:39,295:INFO:create_model() successfully completed......................................
2023-04-29 19:47:39,411:INFO:SubProcess create_model() end ==================================
2023-04-29 19:47:39,411:INFO:Creating metrics dataframe
2023-04-29 19:47:39,415:INFO:Initializing Elastic Net
2023-04-29 19:47:39,415:INFO:Total runtime is 0.44935407638549807 minutes
2023-04-29 19:47:39,416:INFO:SubProcess create_model() called ==================================
2023-04-29 19:47:39,416:INFO:Initializing create_model()
2023-04-29 19:47:39,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:47:39,416:INFO:Checking exceptions
2023-04-29 19:47:39,416:INFO:Importing libraries
2023-04-29 19:47:39,416:INFO:Copying training dataset
2023-04-29 19:47:39,420:WARNING:Processing:  19%|#5      | 15/77 [00:26<01:40,  1.63s/it]
2023-04-29 19:47:39,420:INFO:Defining folds
2023-04-29 19:47:39,420:INFO:Declaring metric variables
2023-04-29 19:47:39,420:INFO:Importing untrained model
2023-04-29 19:47:39,420:INFO:Elastic Net Imported successfully
2023-04-29 19:47:39,421:INFO:Starting cross validation
2023-04-29 19:47:39,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:47:47,317:INFO:Calculating mean and std
2023-04-29 19:47:47,318:WARNING:Processing:  22%|#7      | 17/77 [00:34<02:34,  2.58s/it]
2023-04-29 19:47:47,318:INFO:Creating metrics dataframe
2023-04-29 19:47:48,185:WARNING:Processing:  23%|#8      | 18/77 [00:35<02:09,  2.19s/it]
2023-04-29 19:47:48,186:INFO:Uploading results into container
2023-04-29 19:47:48,186:INFO:Uploading model into container now
2023-04-29 19:47:48,187:INFO:_master_model_container: 4
2023-04-29 19:47:48,187:INFO:_display_container: 2
2023-04-29 19:47:48,187:INFO:ElasticNet(random_state=3128)
2023-04-29 19:47:48,187:INFO:create_model() successfully completed......................................
2023-04-29 19:47:48,307:INFO:SubProcess create_model() end ==================================
2023-04-29 19:47:48,308:INFO:Creating metrics dataframe
2023-04-29 19:47:48,312:INFO:Initializing Least Angle Regression
2023-04-29 19:47:48,312:INFO:Total runtime is 0.5976345459620158 minutes
2023-04-29 19:47:48,313:INFO:SubProcess create_model() called ==================================
2023-04-29 19:47:48,313:INFO:Initializing create_model()
2023-04-29 19:47:48,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:47:48,313:INFO:Checking exceptions
2023-04-29 19:47:48,313:INFO:Importing libraries
2023-04-29 19:47:48,313:INFO:Copying training dataset
2023-04-29 19:47:48,319:WARNING:Processing:  25%|#9      | 19/77 [00:35<01:37,  1.69s/it]
2023-04-29 19:47:48,319:INFO:Defining folds
2023-04-29 19:47:48,320:INFO:Declaring metric variables
2023-04-29 19:47:48,320:INFO:Importing untrained model
2023-04-29 19:47:48,321:INFO:Least Angle Regression Imported successfully
2023-04-29 19:47:48,321:INFO:Starting cross validation
2023-04-29 19:47:48,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:47:48,387:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,397:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,407:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,420:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,434:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,449:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,460:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:48,474:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:50,040:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:50,086:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:47:56,109:INFO:Calculating mean and std
2023-04-29 19:47:56,110:WARNING:Processing:  27%|##1     | 21/77 [00:43<02:25,  2.60s/it]
2023-04-29 19:47:56,110:INFO:Creating metrics dataframe
2023-04-29 19:47:57,464:WARNING:Processing:  29%|##2     | 22/77 [00:45<02:07,  2.31s/it]
2023-04-29 19:47:57,465:INFO:Uploading results into container
2023-04-29 19:47:57,465:INFO:Uploading model into container now
2023-04-29 19:47:57,466:INFO:_master_model_container: 5
2023-04-29 19:47:57,466:INFO:_display_container: 2
2023-04-29 19:47:57,466:INFO:Lars(random_state=3128)
2023-04-29 19:47:57,466:INFO:create_model() successfully completed......................................
2023-04-29 19:47:57,579:INFO:SubProcess create_model() end ==================================
2023-04-29 19:47:57,579:INFO:Creating metrics dataframe
2023-04-29 19:47:57,588:INFO:Initializing Lasso Least Angle Regression
2023-04-29 19:47:57,588:INFO:Total runtime is 0.7522328138351441 minutes
2023-04-29 19:47:57,588:INFO:SubProcess create_model() called ==================================
2023-04-29 19:47:57,588:INFO:Initializing create_model()
2023-04-29 19:47:57,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:47:57,589:INFO:Checking exceptions
2023-04-29 19:47:57,589:INFO:Importing libraries
2023-04-29 19:47:57,589:INFO:Copying training dataset
2023-04-29 19:47:57,591:WARNING:Processing:  30%|##3     | 23/77 [00:45<01:36,  1.78s/it]
2023-04-29 19:47:57,592:INFO:Defining folds
2023-04-29 19:47:57,592:INFO:Declaring metric variables
2023-04-29 19:47:57,592:INFO:Importing untrained model
2023-04-29 19:47:57,592:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 19:47:57,592:INFO:Starting cross validation
2023-04-29 19:47:57,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:47:57,662:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,669:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,680:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,693:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,702:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,714:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,729:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:57,745:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:59,386:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:47:59,386:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 19:48:06,282:INFO:Calculating mean and std
2023-04-29 19:48:06,282:WARNING:Processing:  32%|##5     | 25/77 [00:53<02:27,  2.84s/it]
2023-04-29 19:48:06,282:INFO:Creating metrics dataframe
2023-04-29 19:48:07,414:WARNING:Processing:  34%|##7     | 26/77 [00:54<02:04,  2.45s/it]
2023-04-29 19:48:07,414:INFO:Uploading results into container
2023-04-29 19:48:07,414:INFO:Uploading model into container now
2023-04-29 19:48:07,415:INFO:_master_model_container: 6
2023-04-29 19:48:07,415:INFO:_display_container: 2
2023-04-29 19:48:07,415:INFO:LassoLars(random_state=3128)
2023-04-29 19:48:07,415:INFO:create_model() successfully completed......................................
2023-04-29 19:48:07,545:INFO:SubProcess create_model() end ==================================
2023-04-29 19:48:07,545:INFO:Creating metrics dataframe
2023-04-29 19:48:07,550:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 19:48:07,550:INFO:Total runtime is 0.9182666460673015 minutes
2023-04-29 19:48:07,550:INFO:SubProcess create_model() called ==================================
2023-04-29 19:48:07,550:INFO:Initializing create_model()
2023-04-29 19:48:07,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:48:07,551:INFO:Checking exceptions
2023-04-29 19:48:07,551:INFO:Importing libraries
2023-04-29 19:48:07,551:INFO:Copying training dataset
2023-04-29 19:48:07,555:WARNING:Processing:  35%|##8     | 27/77 [00:55<01:34,  1.88s/it]
2023-04-29 19:48:07,556:INFO:Defining folds
2023-04-29 19:48:07,556:INFO:Declaring metric variables
2023-04-29 19:48:07,556:INFO:Importing untrained model
2023-04-29 19:48:07,556:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 19:48:07,556:INFO:Starting cross validation
2023-04-29 19:48:07,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:48:07,641:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,661:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,673:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,680:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,697:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,711:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,725:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:07,739:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:09,353:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:09,367:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 19:48:15,887:INFO:Calculating mean and std
2023-04-29 19:48:15,887:WARNING:Processing:  38%|###     | 29/77 [01:03<02:15,  2.82s/it]
2023-04-29 19:48:15,887:INFO:Creating metrics dataframe
2023-04-29 19:48:17,288:WARNING:Processing:  39%|###1    | 30/77 [01:04<01:57,  2.50s/it]
2023-04-29 19:48:17,288:INFO:Uploading results into container
2023-04-29 19:48:17,289:INFO:Uploading model into container now
2023-04-29 19:48:17,289:INFO:_master_model_container: 7
2023-04-29 19:48:17,289:INFO:_display_container: 2
2023-04-29 19:48:17,289:INFO:OrthogonalMatchingPursuit()
2023-04-29 19:48:17,290:INFO:create_model() successfully completed......................................
2023-04-29 19:48:17,409:INFO:SubProcess create_model() end ==================================
2023-04-29 19:48:17,409:INFO:Creating metrics dataframe
2023-04-29 19:48:17,413:INFO:Initializing Bayesian Ridge
2023-04-29 19:48:17,414:INFO:Total runtime is 1.0826770941416424 minutes
2023-04-29 19:48:17,414:INFO:SubProcess create_model() called ==================================
2023-04-29 19:48:17,414:INFO:Initializing create_model()
2023-04-29 19:48:17,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:48:17,414:INFO:Checking exceptions
2023-04-29 19:48:17,414:INFO:Importing libraries
2023-04-29 19:48:17,414:INFO:Copying training dataset
2023-04-29 19:48:17,417:WARNING:Processing:  40%|###2    | 31/77 [01:04<01:28,  1.92s/it]
2023-04-29 19:48:17,417:INFO:Defining folds
2023-04-29 19:48:17,417:INFO:Declaring metric variables
2023-04-29 19:48:17,418:INFO:Importing untrained model
2023-04-29 19:48:17,418:INFO:Bayesian Ridge Imported successfully
2023-04-29 19:48:17,418:INFO:Starting cross validation
2023-04-29 19:48:17,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:48:25,402:INFO:Calculating mean and std
2023-04-29 19:48:25,403:WARNING:Processing:  43%|###4    | 33/77 [01:12<02:02,  2.77s/it]
2023-04-29 19:48:25,403:INFO:Creating metrics dataframe
2023-04-29 19:48:26,953:WARNING:Processing:  44%|###5    | 34/77 [01:14<01:47,  2.50s/it]
2023-04-29 19:48:26,953:INFO:Uploading results into container
2023-04-29 19:48:26,954:INFO:Uploading model into container now
2023-04-29 19:48:26,955:INFO:_master_model_container: 8
2023-04-29 19:48:26,955:INFO:_display_container: 2
2023-04-29 19:48:26,956:INFO:BayesianRidge()
2023-04-29 19:48:26,956:INFO:create_model() successfully completed......................................
2023-04-29 19:48:27,114:INFO:SubProcess create_model() end ==================================
2023-04-29 19:48:27,115:INFO:Creating metrics dataframe
2023-04-29 19:48:27,124:INFO:Initializing Passive Aggressive Regressor
2023-04-29 19:48:27,124:INFO:Total runtime is 1.2445056319236756 minutes
2023-04-29 19:48:27,124:INFO:SubProcess create_model() called ==================================
2023-04-29 19:48:27,125:INFO:Initializing create_model()
2023-04-29 19:48:27,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:48:27,125:INFO:Checking exceptions
2023-04-29 19:48:27,125:INFO:Importing libraries
2023-04-29 19:48:27,125:INFO:Copying training dataset
2023-04-29 19:48:27,132:WARNING:Processing:  45%|###6    | 35/77 [01:14<01:20,  1.93s/it]
2023-04-29 19:48:27,132:INFO:Defining folds
2023-04-29 19:48:27,132:INFO:Declaring metric variables
2023-04-29 19:48:27,132:INFO:Importing untrained model
2023-04-29 19:48:27,133:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 19:48:27,135:INFO:Starting cross validation
2023-04-29 19:48:27,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:48:34,871:INFO:Calculating mean and std
2023-04-29 19:48:34,871:WARNING:Processing:  48%|###8    | 37/77 [01:22<01:49,  2.73s/it]
2023-04-29 19:48:34,872:INFO:Creating metrics dataframe
2023-04-29 19:48:36,667:WARNING:Processing:  49%|###9    | 38/77 [01:24<01:38,  2.52s/it]
2023-04-29 19:48:36,667:INFO:Uploading results into container
2023-04-29 19:48:36,669:INFO:Uploading model into container now
2023-04-29 19:48:36,671:INFO:_master_model_container: 9
2023-04-29 19:48:36,671:INFO:_display_container: 2
2023-04-29 19:48:36,672:INFO:PassiveAggressiveRegressor(random_state=3128)
2023-04-29 19:48:36,672:INFO:create_model() successfully completed......................................
2023-04-29 19:48:36,837:INFO:SubProcess create_model() end ==================================
2023-04-29 19:48:36,837:INFO:Creating metrics dataframe
2023-04-29 19:48:36,844:INFO:Initializing Huber Regressor
2023-04-29 19:48:36,844:INFO:Total runtime is 1.406499695777893 minutes
2023-04-29 19:48:36,844:INFO:SubProcess create_model() called ==================================
2023-04-29 19:48:36,845:INFO:Initializing create_model()
2023-04-29 19:48:36,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:48:36,845:INFO:Checking exceptions
2023-04-29 19:48:36,845:INFO:Importing libraries
2023-04-29 19:48:36,845:INFO:Copying training dataset
2023-04-29 19:48:36,848:WARNING:Processing:  51%|####    | 39/77 [01:24<01:13,  1.94s/it]
2023-04-29 19:48:36,848:INFO:Defining folds
2023-04-29 19:48:36,849:INFO:Declaring metric variables
2023-04-29 19:48:36,849:INFO:Importing untrained model
2023-04-29 19:48:36,849:INFO:Huber Regressor Imported successfully
2023-04-29 19:48:36,849:INFO:Starting cross validation
2023-04-29 19:48:36,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:48:44,893:INFO:Calculating mean and std
2023-04-29 19:48:44,895:WARNING:Processing:  53%|####2   | 41/77 [01:32<01:40,  2.80s/it]
2023-04-29 19:48:44,896:INFO:Creating metrics dataframe
2023-04-29 19:48:46,605:WARNING:Processing:  55%|####3   | 42/77 [01:34<01:29,  2.55s/it]
2023-04-29 19:48:46,605:INFO:Uploading results into container
2023-04-29 19:48:46,606:INFO:Uploading model into container now
2023-04-29 19:48:46,606:INFO:_master_model_container: 10
2023-04-29 19:48:46,606:INFO:_display_container: 2
2023-04-29 19:48:46,606:INFO:HuberRegressor()
2023-04-29 19:48:46,606:INFO:create_model() successfully completed......................................
2023-04-29 19:48:46,731:INFO:SubProcess create_model() end ==================================
2023-04-29 19:48:46,732:INFO:Creating metrics dataframe
2023-04-29 19:48:46,742:INFO:Initializing K Neighbors Regressor
2023-04-29 19:48:46,743:INFO:Total runtime is 1.571485428015391 minutes
2023-04-29 19:48:46,743:INFO:SubProcess create_model() called ==================================
2023-04-29 19:48:46,743:INFO:Initializing create_model()
2023-04-29 19:48:46,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:48:46,744:INFO:Checking exceptions
2023-04-29 19:48:46,744:INFO:Importing libraries
2023-04-29 19:48:46,744:INFO:Copying training dataset
2023-04-29 19:48:46,749:WARNING:Processing:  56%|####4   | 43/77 [01:34<01:06,  1.96s/it]
2023-04-29 19:48:46,749:INFO:Defining folds
2023-04-29 19:48:46,749:INFO:Declaring metric variables
2023-04-29 19:48:46,750:INFO:Importing untrained model
2023-04-29 19:48:46,750:INFO:K Neighbors Regressor Imported successfully
2023-04-29 19:48:46,751:INFO:Starting cross validation
2023-04-29 19:48:46,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:48:54,454:INFO:Calculating mean and std
2023-04-29 19:48:54,454:WARNING:Processing:  58%|####6   | 45/77 [01:42<01:27,  2.74s/it]
2023-04-29 19:48:54,454:INFO:Creating metrics dataframe
2023-04-29 19:48:56,185:WARNING:Processing:  60%|####7   | 46/77 [01:43<01:17,  2.51s/it]
2023-04-29 19:48:56,185:INFO:Uploading results into container
2023-04-29 19:48:56,186:INFO:Uploading model into container now
2023-04-29 19:48:56,186:INFO:_master_model_container: 11
2023-04-29 19:48:56,186:INFO:_display_container: 2
2023-04-29 19:48:56,187:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 19:48:56,187:INFO:create_model() successfully completed......................................
2023-04-29 19:48:56,317:INFO:SubProcess create_model() end ==================================
2023-04-29 19:48:56,318:INFO:Creating metrics dataframe
2023-04-29 19:48:56,331:INFO:Initializing Decision Tree Regressor
2023-04-29 19:48:56,331:INFO:Total runtime is 1.7312846581141152 minutes
2023-04-29 19:48:56,332:INFO:SubProcess create_model() called ==================================
2023-04-29 19:48:56,333:INFO:Initializing create_model()
2023-04-29 19:48:56,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:48:56,334:INFO:Checking exceptions
2023-04-29 19:48:56,334:INFO:Importing libraries
2023-04-29 19:48:56,334:INFO:Copying training dataset
2023-04-29 19:48:56,341:WARNING:Processing:  61%|####8   | 47/77 [01:43<00:58,  1.93s/it]
2023-04-29 19:48:56,342:INFO:Defining folds
2023-04-29 19:48:56,342:INFO:Declaring metric variables
2023-04-29 19:48:56,342:INFO:Importing untrained model
2023-04-29 19:48:56,343:INFO:Decision Tree Regressor Imported successfully
2023-04-29 19:48:56,343:INFO:Starting cross validation
2023-04-29 19:48:56,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:49:03,989:INFO:Calculating mean and std
2023-04-29 19:49:03,990:WARNING:Processing:  64%|#####   | 49/77 [01:51<01:15,  2.71s/it]
2023-04-29 19:49:03,990:INFO:Creating metrics dataframe
2023-04-29 19:49:05,200:WARNING:Processing:  65%|#####1  | 50/77 [01:52<01:04,  2.37s/it]
2023-04-29 19:49:05,200:INFO:Uploading results into container
2023-04-29 19:49:05,201:INFO:Uploading model into container now
2023-04-29 19:49:05,202:INFO:_master_model_container: 12
2023-04-29 19:49:05,202:INFO:_display_container: 2
2023-04-29 19:49:05,202:INFO:DecisionTreeRegressor(random_state=3128)
2023-04-29 19:49:05,202:INFO:create_model() successfully completed......................................
2023-04-29 19:49:05,337:INFO:SubProcess create_model() end ==================================
2023-04-29 19:49:05,337:INFO:Creating metrics dataframe
2023-04-29 19:49:05,343:INFO:Initializing Random Forest Regressor
2023-04-29 19:49:05,343:INFO:Total runtime is 1.881483232975006 minutes
2023-04-29 19:49:05,344:INFO:SubProcess create_model() called ==================================
2023-04-29 19:49:05,344:INFO:Initializing create_model()
2023-04-29 19:49:05,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:49:05,344:INFO:Checking exceptions
2023-04-29 19:49:05,344:INFO:Importing libraries
2023-04-29 19:49:05,345:INFO:Copying training dataset
2023-04-29 19:49:05,349:WARNING:Processing:  66%|#####2  | 51/77 [01:52<00:47,  1.83s/it]
2023-04-29 19:49:05,349:INFO:Defining folds
2023-04-29 19:49:05,349:INFO:Declaring metric variables
2023-04-29 19:49:05,350:INFO:Importing untrained model
2023-04-29 19:49:05,351:INFO:Random Forest Regressor Imported successfully
2023-04-29 19:49:05,351:INFO:Starting cross validation
2023-04-29 19:49:05,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:49:14,968:INFO:Calculating mean and std
2023-04-29 19:49:14,970:WARNING:Processing:  69%|#####5  | 53/77 [02:02<01:13,  3.06s/it]
2023-04-29 19:49:14,970:INFO:Creating metrics dataframe
2023-04-29 19:49:16,611:WARNING:Processing:  70%|#####6  | 54/77 [02:04<01:02,  2.73s/it]
2023-04-29 19:49:16,611:INFO:Uploading results into container
2023-04-29 19:49:16,612:INFO:Uploading model into container now
2023-04-29 19:49:16,612:INFO:_master_model_container: 13
2023-04-29 19:49:16,612:INFO:_display_container: 2
2023-04-29 19:49:16,612:INFO:RandomForestRegressor(n_jobs=-1, random_state=3128)
2023-04-29 19:49:16,613:INFO:create_model() successfully completed......................................
2023-04-29 19:49:16,739:INFO:SubProcess create_model() end ==================================
2023-04-29 19:49:16,739:INFO:Creating metrics dataframe
2023-04-29 19:49:16,751:INFO:Initializing Extra Trees Regressor
2023-04-29 19:49:16,751:INFO:Total runtime is 2.071614062786102 minutes
2023-04-29 19:49:16,751:INFO:SubProcess create_model() called ==================================
2023-04-29 19:49:16,752:INFO:Initializing create_model()
2023-04-29 19:49:16,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:49:16,752:INFO:Checking exceptions
2023-04-29 19:49:16,753:INFO:Importing libraries
2023-04-29 19:49:16,753:INFO:Copying training dataset
2023-04-29 19:49:16,760:WARNING:Processing:  71%|#####7  | 55/77 [02:04<00:46,  2.10s/it]
2023-04-29 19:49:16,760:INFO:Defining folds
2023-04-29 19:49:16,760:INFO:Declaring metric variables
2023-04-29 19:49:16,760:INFO:Importing untrained model
2023-04-29 19:49:16,761:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:49:16,762:INFO:Starting cross validation
2023-04-29 19:49:16,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:49:26,258:INFO:Calculating mean and std
2023-04-29 19:49:26,258:WARNING:Processing:  74%|#####9  | 57/77 [02:13<01:03,  3.19s/it]
2023-04-29 19:49:26,259:INFO:Creating metrics dataframe
2023-04-29 19:49:27,477:WARNING:Processing:  75%|######  | 58/77 [02:15<00:52,  2.74s/it]
2023-04-29 19:49:27,477:INFO:Uploading results into container
2023-04-29 19:49:27,478:INFO:Uploading model into container now
2023-04-29 19:49:27,478:INFO:_master_model_container: 14
2023-04-29 19:49:27,478:INFO:_display_container: 2
2023-04-29 19:49:27,478:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3128)
2023-04-29 19:49:27,478:INFO:create_model() successfully completed......................................
2023-04-29 19:49:27,600:INFO:SubProcess create_model() end ==================================
2023-04-29 19:49:27,600:INFO:Creating metrics dataframe
2023-04-29 19:49:27,604:INFO:Initializing AdaBoost Regressor
2023-04-29 19:49:27,604:INFO:Total runtime is 2.2525072971979774 minutes
2023-04-29 19:49:27,604:INFO:SubProcess create_model() called ==================================
2023-04-29 19:49:27,604:INFO:Initializing create_model()
2023-04-29 19:49:27,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:49:27,604:INFO:Checking exceptions
2023-04-29 19:49:27,604:INFO:Importing libraries
2023-04-29 19:49:27,604:INFO:Copying training dataset
2023-04-29 19:49:27,607:WARNING:Processing:  77%|######1 | 59/77 [02:15<00:37,  2.10s/it]
2023-04-29 19:49:27,607:INFO:Defining folds
2023-04-29 19:49:27,607:INFO:Declaring metric variables
2023-04-29 19:49:27,607:INFO:Importing untrained model
2023-04-29 19:49:27,608:INFO:AdaBoost Regressor Imported successfully
2023-04-29 19:49:27,608:INFO:Starting cross validation
2023-04-29 19:49:27,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:49:36,455:INFO:Calculating mean and std
2023-04-29 19:49:36,458:WARNING:Processing:  79%|######3 | 61/77 [02:24<00:48,  3.06s/it]
2023-04-29 19:49:36,458:INFO:Creating metrics dataframe
2023-04-29 19:49:37,622:WARNING:Processing:  81%|######4 | 62/77 [02:25<00:39,  2.63s/it]
2023-04-29 19:49:37,622:INFO:Uploading results into container
2023-04-29 19:49:37,622:INFO:Uploading model into container now
2023-04-29 19:49:37,623:INFO:_master_model_container: 15
2023-04-29 19:49:37,623:INFO:_display_container: 2
2023-04-29 19:49:37,623:INFO:AdaBoostRegressor(random_state=3128)
2023-04-29 19:49:37,623:INFO:create_model() successfully completed......................................
2023-04-29 19:49:37,735:INFO:SubProcess create_model() end ==================================
2023-04-29 19:49:37,736:INFO:Creating metrics dataframe
2023-04-29 19:49:37,740:INFO:Initializing Gradient Boosting Regressor
2023-04-29 19:49:37,741:INFO:Total runtime is 2.4214483698209124 minutes
2023-04-29 19:49:37,741:INFO:SubProcess create_model() called ==================================
2023-04-29 19:49:37,741:INFO:Initializing create_model()
2023-04-29 19:49:37,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:49:37,741:INFO:Checking exceptions
2023-04-29 19:49:37,741:INFO:Importing libraries
2023-04-29 19:49:37,741:INFO:Copying training dataset
2023-04-29 19:49:37,744:WARNING:Processing:  82%|######5 | 63/77 [02:25<00:28,  2.01s/it]
2023-04-29 19:49:37,744:INFO:Defining folds
2023-04-29 19:49:37,744:INFO:Declaring metric variables
2023-04-29 19:49:37,744:INFO:Importing untrained model
2023-04-29 19:49:37,744:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 19:49:37,744:INFO:Starting cross validation
2023-04-29 19:49:37,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:49:46,570:INFO:Calculating mean and std
2023-04-29 19:49:46,572:WARNING:Processing:  84%|######7 | 65/77 [02:34<00:36,  3.00s/it]
2023-04-29 19:49:46,572:INFO:Creating metrics dataframe
2023-04-29 19:49:47,867:WARNING:Processing:  86%|######8 | 66/77 [02:35<00:28,  2.61s/it]
2023-04-29 19:49:47,867:INFO:Uploading results into container
2023-04-29 19:49:47,868:INFO:Uploading model into container now
2023-04-29 19:49:47,868:INFO:_master_model_container: 16
2023-04-29 19:49:47,868:INFO:_display_container: 2
2023-04-29 19:49:47,869:INFO:GradientBoostingRegressor(random_state=3128)
2023-04-29 19:49:47,869:INFO:create_model() successfully completed......................................
2023-04-29 19:49:48,016:INFO:SubProcess create_model() end ==================================
2023-04-29 19:49:48,016:INFO:Creating metrics dataframe
2023-04-29 19:49:48,026:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:49:48,026:INFO:Total runtime is 2.5928770780563353 minutes
2023-04-29 19:49:48,027:INFO:SubProcess create_model() called ==================================
2023-04-29 19:49:48,027:INFO:Initializing create_model()
2023-04-29 19:49:48,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:49:48,028:INFO:Checking exceptions
2023-04-29 19:49:48,028:INFO:Importing libraries
2023-04-29 19:49:48,028:INFO:Copying training dataset
2023-04-29 19:49:48,035:WARNING:Processing:  87%|######9 | 67/77 [02:35<00:20,  2.01s/it]
2023-04-29 19:49:48,035:INFO:Defining folds
2023-04-29 19:49:48,035:INFO:Declaring metric variables
2023-04-29 19:49:48,037:INFO:Importing untrained model
2023-04-29 19:49:48,037:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:49:48,038:INFO:Starting cross validation
2023-04-29 19:49:48,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:49:57,184:INFO:Calculating mean and std
2023-04-29 19:49:57,185:WARNING:Processing:  90%|#######1| 69/77 [02:44<00:24,  3.07s/it]
2023-04-29 19:49:57,185:INFO:Creating metrics dataframe
2023-04-29 19:49:58,090:WARNING:Processing:  91%|#######2| 70/77 [02:45<00:18,  2.58s/it]
2023-04-29 19:49:58,090:INFO:Uploading results into container
2023-04-29 19:49:58,091:INFO:Uploading model into container now
2023-04-29 19:49:58,091:INFO:_master_model_container: 17
2023-04-29 19:49:58,091:INFO:_display_container: 2
2023-04-29 19:49:58,092:INFO:LGBMRegressor(random_state=3128)
2023-04-29 19:49:58,092:INFO:create_model() successfully completed......................................
2023-04-29 19:49:58,209:INFO:SubProcess create_model() end ==================================
2023-04-29 19:49:58,209:INFO:Creating metrics dataframe
2023-04-29 19:49:58,213:INFO:Initializing Dummy Regressor
2023-04-29 19:49:58,213:INFO:Total runtime is 2.7626557628313697 minutes
2023-04-29 19:49:58,214:INFO:SubProcess create_model() called ==================================
2023-04-29 19:49:58,214:INFO:Initializing create_model()
2023-04-29 19:49:58,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EFA2C730>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:49:58,214:INFO:Checking exceptions
2023-04-29 19:49:58,214:INFO:Importing libraries
2023-04-29 19:49:58,214:INFO:Copying training dataset
2023-04-29 19:49:58,217:WARNING:Processing:  92%|#######3| 71/77 [02:45<00:11,  1.98s/it]
2023-04-29 19:49:58,217:INFO:Defining folds
2023-04-29 19:49:58,217:INFO:Declaring metric variables
2023-04-29 19:49:58,217:INFO:Importing untrained model
2023-04-29 19:49:58,217:INFO:Dummy Regressor Imported successfully
2023-04-29 19:49:58,217:INFO:Starting cross validation
2023-04-29 19:49:58,218:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:50:06,566:INFO:Calculating mean and std
2023-04-29 19:50:06,567:WARNING:Processing:  95%|#######5| 73/77 [02:54<00:11,  2.88s/it]
2023-04-29 19:50:06,567:INFO:Creating metrics dataframe
2023-04-29 19:50:07,676:WARNING:Processing:  96%|#######6| 74/77 [02:55<00:07,  2.48s/it]
2023-04-29 19:50:07,677:INFO:Uploading results into container
2023-04-29 19:50:07,677:INFO:Uploading model into container now
2023-04-29 19:50:07,678:INFO:_master_model_container: 18
2023-04-29 19:50:07,678:INFO:_display_container: 2
2023-04-29 19:50:07,678:INFO:DummyRegressor()
2023-04-29 19:50:07,679:INFO:create_model() successfully completed......................................
2023-04-29 19:50:07,798:INFO:SubProcess create_model() end ==================================
2023-04-29 19:50:07,798:INFO:Creating metrics dataframe
2023-04-29 19:50:07,804:WARNING:Processing:  97%|#######7| 75/77 [02:55<00:03,  1.90s/it]
2023-04-29 19:50:07,807:INFO:Initializing create_model()
2023-04-29 19:50:07,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3128), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:50:07,807:INFO:Checking exceptions
2023-04-29 19:50:07,807:INFO:Importing libraries
2023-04-29 19:50:07,808:INFO:Copying training dataset
2023-04-29 19:50:07,811:INFO:Defining folds
2023-04-29 19:50:07,811:INFO:Declaring metric variables
2023-04-29 19:50:07,811:INFO:Importing untrained model
2023-04-29 19:50:07,811:INFO:Declaring custom model
2023-04-29 19:50:07,812:INFO:Extra Trees Regressor Imported successfully
2023-04-29 19:50:07,812:INFO:Cross validation set to False
2023-04-29 19:50:07,812:INFO:Fitting Model
2023-04-29 19:50:08,997:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3128)
2023-04-29 19:50:08,998:INFO:create_model() successfully completed......................................
2023-04-29 19:50:09,111:WARNING:Processing: 100%|########| 77/77 [02:56<00:00,  1.39s/it]
2023-04-29 19:50:09,111:WARNING:                                                         
2023-04-29 19:50:09,130:INFO:                                    Model     MAE     MSE    RMSE      R2  \
2023-04-29 19:50:09,130:INFO:et                  Extra Trees Regressor  0.1480  0.3186  0.5073  0.9016   
2023-04-29 19:50:09,131:INFO:rf                Random Forest Regressor  0.1833  0.3271  0.5271  0.8982   
2023-04-29 19:50:09,131:INFO:lightgbm  Light Gradient Boosting Machine  0.2231  0.3639  0.5638  0.8853   
2023-04-29 19:50:09,131:INFO:gbr           Gradient Boosting Regressor  0.3181  0.3850  0.5822  0.8785   
2023-04-29 19:50:09,132:INFO:dt                Decision Tree Regressor  0.1792  0.5751  0.6664  0.8195   
2023-04-29 19:50:09,132:INFO:knn                 K Neighbors Regressor  0.3768  0.5899  0.7541  0.8035   
2023-04-29 19:50:09,132:INFO:ada                    AdaBoost Regressor  0.8017  1.0662  1.0235  0.6369   
2023-04-29 19:50:09,132:INFO:br                         Bayesian Ridge  0.7820  1.3631  1.1284  0.5654   
2023-04-29 19:50:09,132:INFO:ridge                    Ridge Regression  0.7820  1.3633  1.1284  0.5653   
2023-04-29 19:50:09,132:INFO:lr                      Linear Regression  0.7820  1.3635  1.1284  0.5652   
2023-04-29 19:50:09,132:INFO:lar                Least Angle Regression  0.7820  1.3635  1.1284  0.5652   
2023-04-29 19:50:09,132:INFO:huber                     Huber Regressor  0.7060  1.5195  1.1751  0.5240   
2023-04-29 19:50:09,132:INFO:omp           Orthogonal Matching Pursuit  0.7990  1.5258  1.1858  0.5198   
2023-04-29 19:50:09,132:INFO:en                            Elastic Net  1.0768  2.2581  1.4823  0.2591   
2023-04-29 19:50:09,132:INFO:lasso                    Lasso Regression  1.2482  2.8758  1.6816  0.0400   
2023-04-29 19:50:09,132:INFO:llar         Lasso Least Angle Regression  1.2786  3.0160  1.7226 -0.0075   
2023-04-29 19:50:09,132:INFO:dummy                     Dummy Regressor  1.2786  3.0160  1.7226 -0.0075   
2023-04-29 19:50:09,132:INFO:par          Passive Aggressive Regressor  1.3359  3.2983  1.7536 -0.2013   
2023-04-29 19:50:09,132:INFO:
2023-04-29 19:50:09,132:INFO:           RMSLE    MAPE  TT (Sec)  
2023-04-29 19:50:09,132:INFO:et        0.0438  0.0142     0.949  
2023-04-29 19:50:09,132:INFO:rf        0.0465  0.0175     0.962  
2023-04-29 19:50:09,132:INFO:lightgbm  0.0498  0.0212     0.914  
2023-04-29 19:50:09,132:INFO:gbr       0.0503  0.0285     0.882  
2023-04-29 19:50:09,132:INFO:dt        0.0582  0.0170     0.764  
2023-04-29 19:50:09,132:INFO:knn       0.0629  0.0330     0.770  
2023-04-29 19:50:09,132:INFO:ada       0.0834  0.0685     0.885  
2023-04-29 19:50:09,132:INFO:br        0.1001  0.0734     0.798  
2023-04-29 19:50:09,132:INFO:ridge     0.1000  0.0734     0.755  
2023-04-29 19:50:09,132:INFO:lr        0.1000  0.0734     0.762  
2023-04-29 19:50:09,132:INFO:lar       0.1000  0.0734     0.779  
2023-04-29 19:50:09,132:INFO:huber     0.1050  0.0700     0.804  
2023-04-29 19:50:09,132:INFO:omp       0.1056  0.0764     0.833  
2023-04-29 19:50:09,132:INFO:en        0.1293  0.1016     0.789  
2023-04-29 19:50:09,132:INFO:lasso     0.1433  0.1163     0.749  
2023-04-29 19:50:09,132:INFO:llar      0.1462  0.1191     0.869  
2023-04-29 19:50:09,132:INFO:dummy     0.1462  0.1191     0.835  
2023-04-29 19:50:09,132:INFO:par       0.1376  0.1165     0.774  
2023-04-29 19:50:09,132:INFO:_master_model_container: 18
2023-04-29 19:50:09,132:INFO:_display_container: 2
2023-04-29 19:50:09,132:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3128)
2023-04-29 19:50:09,132:INFO:compare_models() successfully completed......................................
2023-04-29 19:50:09,135:INFO:Initializing predict_model()
2023-04-29 19:50:09,135:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236F14F1610>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3128), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236F17B01F0>)
2023-04-29 19:50:09,135:INFO:Checking exceptions
2023-04-29 19:50:09,135:INFO:Preloading libraries
2023-04-29 19:50:09,135:INFO:Set up data.
2023-04-29 19:50:09,143:INFO:Set up index.
2023-04-29 19:50:09,226:INFO:                   Model     MAE  ...   RMSLE   MAPE
2023-04-29 19:50:09,226:INFO:0  Extra Trees Regressor  0.0478  ...  0.0317  0.005
2023-04-29 19:50:09,226:INFO:
2023-04-29 19:50:09,226:INFO:[1 rows x 7 columns]
2023-04-29 19:50:31,548:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:50:31,549:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:50:31,550:INFO:Data columns (total 8 columns):
2023-04-29 19:50:31,550:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:50:31,550:INFO:---  ------          --------------  -----  
2023-04-29 19:50:31,550:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:50:31,550:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:50:31,550:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:50:31,550:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:50:31,551:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:50:31,551:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:50:31,551:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:50:31,551:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:50:31,551:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:50:31,551:INFO:memory usage: 79.8 KB
2023-04-29 19:50:42,834:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:50:42,834:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:50:42,834:INFO:Data columns (total 8 columns):
2023-04-29 19:50:42,834:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:50:42,834:INFO:---  ------          --------------  -----  
2023-04-29 19:50:42,834:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:50:42,835:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:50:42,835:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:50:42,835:INFO:memory usage: 79.8 KB
2023-04-29 19:50:44,479:INFO:PyCaret ClassificationExperiment
2023-04-29 19:50:44,479:INFO:Logging name: clf-default-name
2023-04-29 19:50:44,480:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 19:50:44,480:INFO:version 3.0.0
2023-04-29 19:50:44,480:INFO:Initializing setup()
2023-04-29 19:50:44,480:INFO:self.USI: 3b80
2023-04-29 19:50:44,480:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'X_test', 'y', 'is_multiclass', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 19:50:44,480:INFO:Checking environment
2023-04-29 19:50:44,480:INFO:python_version: 3.9.13
2023-04-29 19:50:44,480:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 19:50:44,480:INFO:machine: AMD64
2023-04-29 19:50:44,480:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 19:50:44,480:INFO:Memory: svmem(total=16935899136, available=5234073600, percent=69.1, used=11701825536, free=5234073600)
2023-04-29 19:50:44,480:INFO:Physical Core: 4
2023-04-29 19:50:44,480:INFO:Logical Core: 8
2023-04-29 19:50:44,480:INFO:Checking libraries
2023-04-29 19:50:44,480:INFO:System:
2023-04-29 19:50:44,480:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 19:50:44,480:INFO:executable: D:\Anaconda\python.exe
2023-04-29 19:50:44,480:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 19:50:44,480:INFO:PyCaret required dependencies:
2023-04-29 19:50:44,480:INFO:                 pip: 22.2.2
2023-04-29 19:50:44,480:INFO:          setuptools: 63.4.1
2023-04-29 19:50:44,480:INFO:             pycaret: 3.0.0
2023-04-29 19:50:44,480:INFO:             IPython: 7.31.1
2023-04-29 19:50:44,480:INFO:          ipywidgets: 7.6.5
2023-04-29 19:50:44,480:INFO:                tqdm: 4.64.1
2023-04-29 19:50:44,480:INFO:               numpy: 1.21.5
2023-04-29 19:50:44,480:INFO:              pandas: 1.4.4
2023-04-29 19:50:44,480:INFO:              jinja2: 2.11.3
2023-04-29 19:50:44,480:INFO:               scipy: 1.9.1
2023-04-29 19:50:44,480:INFO:              joblib: 1.2.0
2023-04-29 19:50:44,480:INFO:             sklearn: 1.0.2
2023-04-29 19:50:44,480:INFO:                pyod: 1.0.9
2023-04-29 19:50:44,480:INFO:            imblearn: 0.10.1
2023-04-29 19:50:44,480:INFO:   category_encoders: 2.6.0
2023-04-29 19:50:44,480:INFO:            lightgbm: 3.3.5
2023-04-29 19:50:44,482:INFO:               numba: 0.55.1
2023-04-29 19:50:44,482:INFO:            requests: 2.28.1
2023-04-29 19:50:44,482:INFO:          matplotlib: 3.5.2
2023-04-29 19:50:44,482:INFO:          scikitplot: 0.3.7
2023-04-29 19:50:44,482:INFO:         yellowbrick: 1.5
2023-04-29 19:50:44,482:INFO:              plotly: 5.9.0
2023-04-29 19:50:44,482:INFO:             kaleido: 0.2.1
2023-04-29 19:50:44,482:INFO:         statsmodels: 0.13.2
2023-04-29 19:50:44,482:INFO:              sktime: 0.17.1
2023-04-29 19:50:44,482:INFO:               tbats: 1.1.2
2023-04-29 19:50:44,482:INFO:            pmdarima: 2.0.3
2023-04-29 19:50:44,482:INFO:              psutil: 5.9.0
2023-04-29 19:50:44,482:INFO:PyCaret optional dependencies:
2023-04-29 19:50:44,482:INFO:                shap: 0.41.0
2023-04-29 19:50:44,482:INFO:           interpret: Not installed
2023-04-29 19:50:44,482:INFO:                umap: Not installed
2023-04-29 19:50:44,482:INFO:    pandas_profiling: 4.1.2
2023-04-29 19:50:44,482:INFO:  explainerdashboard: Not installed
2023-04-29 19:50:44,482:INFO:             autoviz: Not installed
2023-04-29 19:50:44,482:INFO:           fairlearn: Not installed
2023-04-29 19:50:44,482:INFO:             xgboost: Not installed
2023-04-29 19:50:44,482:INFO:            catboost: Not installed
2023-04-29 19:50:44,482:INFO:              kmodes: Not installed
2023-04-29 19:50:44,482:INFO:             mlxtend: Not installed
2023-04-29 19:50:44,482:INFO:       statsforecast: Not installed
2023-04-29 19:50:44,482:INFO:        tune_sklearn: Not installed
2023-04-29 19:50:44,482:INFO:                 ray: Not installed
2023-04-29 19:50:44,482:INFO:            hyperopt: Not installed
2023-04-29 19:50:44,482:INFO:              optuna: Not installed
2023-04-29 19:50:44,482:INFO:               skopt: Not installed
2023-04-29 19:50:44,483:INFO:              mlflow: 2.2.1
2023-04-29 19:50:44,483:INFO:              gradio: Not installed
2023-04-29 19:50:44,483:INFO:             fastapi: Not installed
2023-04-29 19:50:44,483:INFO:             uvicorn: Not installed
2023-04-29 19:50:44,483:INFO:              m2cgen: Not installed
2023-04-29 19:50:44,483:INFO:           evidently: Not installed
2023-04-29 19:50:44,483:INFO:               fugue: Not installed
2023-04-29 19:50:44,483:INFO:           streamlit: 1.21.0
2023-04-29 19:50:44,483:INFO:             prophet: Not installed
2023-04-29 19:50:44,483:INFO:None
2023-04-29 19:50:44,483:INFO:Set up data.
2023-04-29 19:50:44,486:INFO:Set up train/test split.
2023-04-29 19:50:44,489:INFO:Set up index.
2023-04-29 19:50:44,489:INFO:Set up folding strategy.
2023-04-29 19:50:44,489:INFO:Assigning column types.
2023-04-29 19:50:44,491:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 19:50:44,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:50:44,546:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:50:44,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 19:50:44,633:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:50:44,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,674:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 19:50:44,733:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:50:44,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,804:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 19:50:44,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,842:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 19:50:44,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:44,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,054:INFO:Preparing preprocessing pipeline...
2023-04-29 19:50:45,056:INFO:Set up simple imputation.
2023-04-29 19:50:45,057:INFO:Set up column name cleaning.
2023-04-29 19:50:45,098:INFO:Finished creating preprocessing pipeline.
2023-04-29 19:50:45,103:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'VEC'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 19:50:45,103:INFO:Creating final display dataframe.
2023-04-29 19:50:45,210:INFO:Setup _display_container:                     Description             Value
0                    Session id              2395
1                        Target            Phases
2                   Target type        Multiclass
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3b80
2023-04-29 19:50:45,219:INFO:                    Description             Value
2023-04-29 19:50:45,220:INFO:0                    Session id              2395
2023-04-29 19:50:45,220:INFO:1                        Target            Phases
2023-04-29 19:50:45,221:INFO:2                   Target type        Multiclass
2023-04-29 19:50:45,221:INFO:3           Original data shape         (1360, 8)
2023-04-29 19:50:45,221:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 19:50:45,221:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 19:50:45,222:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 19:50:45,222:INFO:7              Numeric features                 7
2023-04-29 19:50:45,223:INFO:8                    Preprocess              True
2023-04-29 19:50:45,223:INFO:9               Imputation type            simple
2023-04-29 19:50:45,224:INFO:10           Numeric imputation              mean
2023-04-29 19:50:45,224:INFO:11       Categorical imputation              mode
2023-04-29 19:50:45,225:INFO:12               Fold Generator   StratifiedKFold
2023-04-29 19:50:45,225:INFO:13                  Fold Number                10
2023-04-29 19:50:45,225:INFO:14                     CPU Jobs                -1
2023-04-29 19:50:45,225:INFO:15                      Use GPU             False
2023-04-29 19:50:45,226:INFO:16               Log Experiment             False
2023-04-29 19:50:45,226:INFO:17              Experiment Name  clf-default-name
2023-04-29 19:50:45,226:INFO:18                          USI              3b80
2023-04-29 19:50:45,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 19:50:45,577:INFO:setup() successfully completed in 1.98s...............
2023-04-29 19:50:45,586:INFO:Initializing compare_models()
2023-04-29 19:50:45,587:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-29 19:50:45,588:INFO:Checking exceptions
2023-04-29 19:50:45,595:INFO:Preparing display monitor
2023-04-29 19:50:45,600:WARNING:
2023-04-29 19:50:45,600:WARNING:Processing:   0%|                 | 0/61 [00:00<?, ?it/s]
2023-04-29 19:50:45,601:INFO:Initializing Logistic Regression
2023-04-29 19:50:45,601:INFO:Total runtime is 0.0 minutes
2023-04-29 19:50:45,601:INFO:SubProcess create_model() called ==================================
2023-04-29 19:50:45,602:INFO:Initializing create_model()
2023-04-29 19:50:45,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:50:45,602:INFO:Checking exceptions
2023-04-29 19:50:45,602:INFO:Importing libraries
2023-04-29 19:50:45,602:INFO:Copying training dataset
2023-04-29 19:50:45,611:INFO:Defining folds
2023-04-29 19:50:45,611:INFO:Declaring metric variables
2023-04-29 19:50:45,612:INFO:Importing untrained model
2023-04-29 19:50:45,612:INFO:Logistic Regression Imported successfully
2023-04-29 19:50:45,613:INFO:Starting cross validation
2023-04-29 19:50:45,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:50:54,310:INFO:Calculating mean and std
2023-04-29 19:50:54,311:WARNING:Processing:   8%|7        | 5/61 [00:08<01:37,  1.74s/it]
2023-04-29 19:50:54,311:INFO:Creating metrics dataframe
2023-04-29 19:50:56,279:WARNING:Processing:  10%|8        | 6/61 [00:10<01:38,  1.79s/it]
2023-04-29 19:50:56,279:INFO:Uploading results into container
2023-04-29 19:50:56,280:INFO:Uploading model into container now
2023-04-29 19:50:56,280:INFO:_master_model_container: 1
2023-04-29 19:50:56,280:INFO:_display_container: 2
2023-04-29 19:50:56,280:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2395, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 19:50:56,281:INFO:create_model() successfully completed......................................
2023-04-29 19:50:56,411:INFO:SubProcess create_model() end ==================================
2023-04-29 19:50:56,412:INFO:Creating metrics dataframe
2023-04-29 19:50:56,415:INFO:Initializing K Neighbors Classifier
2023-04-29 19:50:56,415:INFO:Total runtime is 0.18022092978159587 minutes
2023-04-29 19:50:56,416:INFO:SubProcess create_model() called ==================================
2023-04-29 19:50:56,416:INFO:Initializing create_model()
2023-04-29 19:50:56,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:50:56,416:INFO:Checking exceptions
2023-04-29 19:50:56,416:INFO:Importing libraries
2023-04-29 19:50:56,416:INFO:Copying training dataset
2023-04-29 19:50:56,419:WARNING:Processing:  11%|#        | 7/61 [00:10<01:15,  1.39s/it]
2023-04-29 19:50:56,419:INFO:Defining folds
2023-04-29 19:50:56,419:INFO:Declaring metric variables
2023-04-29 19:50:56,419:INFO:Importing untrained model
2023-04-29 19:50:56,419:INFO:K Neighbors Classifier Imported successfully
2023-04-29 19:50:56,420:INFO:Starting cross validation
2023-04-29 19:50:56,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:50:56,534:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,537:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,551:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,552:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,579:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,584:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,587:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:56,606:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:58,380:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:50:58,427:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 19:51:12,621:INFO:Calculating mean and std
2023-04-29 19:51:12,623:WARNING:Processing:  15%|#3       | 9/61 [00:27<03:34,  4.13s/it]
2023-04-29 19:51:12,623:INFO:Creating metrics dataframe
2023-04-29 19:51:13,829:WARNING:Processing:  16%|#3      | 10/61 [00:28<02:56,  3.47s/it]
2023-04-29 19:51:13,829:INFO:Uploading results into container
2023-04-29 19:51:13,829:INFO:Uploading model into container now
2023-04-29 19:51:13,829:INFO:_master_model_container: 2
2023-04-29 19:51:13,829:INFO:_display_container: 2
2023-04-29 19:51:13,830:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 19:51:13,830:INFO:create_model() successfully completed......................................
2023-04-29 19:51:14,022:INFO:SubProcess create_model() end ==================================
2023-04-29 19:51:14,023:INFO:Creating metrics dataframe
2023-04-29 19:51:14,034:INFO:Initializing Naive Bayes
2023-04-29 19:51:14,034:INFO:Total runtime is 0.47388299703598025 minutes
2023-04-29 19:51:14,034:INFO:SubProcess create_model() called ==================================
2023-04-29 19:51:14,035:INFO:Initializing create_model()
2023-04-29 19:51:14,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:51:14,035:INFO:Checking exceptions
2023-04-29 19:51:14,035:INFO:Importing libraries
2023-04-29 19:51:14,035:INFO:Copying training dataset
2023-04-29 19:51:14,045:WARNING:Processing:  18%|#4      | 11/61 [00:28<02:13,  2.68s/it]
2023-04-29 19:51:14,046:INFO:Defining folds
2023-04-29 19:51:14,046:INFO:Declaring metric variables
2023-04-29 19:51:14,046:INFO:Importing untrained model
2023-04-29 19:51:14,046:INFO:Naive Bayes Imported successfully
2023-04-29 19:51:14,046:INFO:Starting cross validation
2023-04-29 19:51:14,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:51:26,792:INFO:Calculating mean and std
2023-04-29 19:51:26,793:WARNING:Processing:  21%|#7      | 13/61 [00:41<03:21,  4.19s/it]
2023-04-29 19:51:26,793:INFO:Creating metrics dataframe
2023-04-29 19:51:28,440:WARNING:Processing:  23%|#8      | 14/61 [00:42<02:49,  3.62s/it]
2023-04-29 19:51:28,441:INFO:Uploading results into container
2023-04-29 19:51:28,442:INFO:Uploading model into container now
2023-04-29 19:51:28,442:INFO:_master_model_container: 3
2023-04-29 19:51:28,442:INFO:_display_container: 2
2023-04-29 19:51:28,442:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 19:51:28,443:INFO:create_model() successfully completed......................................
2023-04-29 19:51:28,613:INFO:SubProcess create_model() end ==================================
2023-04-29 19:51:28,613:INFO:Creating metrics dataframe
2023-04-29 19:51:28,617:INFO:Initializing Decision Tree Classifier
2023-04-29 19:51:28,618:INFO:Total runtime is 0.7169235547383627 minutes
2023-04-29 19:51:28,618:INFO:SubProcess create_model() called ==================================
2023-04-29 19:51:28,618:INFO:Initializing create_model()
2023-04-29 19:51:28,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:51:28,618:INFO:Checking exceptions
2023-04-29 19:51:28,618:INFO:Importing libraries
2023-04-29 19:51:28,618:INFO:Copying training dataset
2023-04-29 19:51:28,626:WARNING:Processing:  25%|#9      | 15/61 [00:43<02:07,  2.78s/it]
2023-04-29 19:51:28,626:INFO:Defining folds
2023-04-29 19:51:28,626:INFO:Declaring metric variables
2023-04-29 19:51:28,626:INFO:Importing untrained model
2023-04-29 19:51:28,627:INFO:Decision Tree Classifier Imported successfully
2023-04-29 19:51:28,627:INFO:Starting cross validation
2023-04-29 19:51:28,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:51:41,517:INFO:Calculating mean and std
2023-04-29 19:51:41,518:WARNING:Processing:  28%|##2     | 17/61 [00:55<03:08,  4.29s/it]
2023-04-29 19:51:41,518:INFO:Creating metrics dataframe
2023-04-29 19:51:42,725:WARNING:Processing:  30%|##3     | 18/61 [00:57<02:34,  3.59s/it]
2023-04-29 19:51:42,725:INFO:Uploading results into container
2023-04-29 19:51:42,725:INFO:Uploading model into container now
2023-04-29 19:51:42,726:INFO:_master_model_container: 4
2023-04-29 19:51:42,726:INFO:_display_container: 2
2023-04-29 19:51:42,726:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2395, splitter='best')
2023-04-29 19:51:42,726:INFO:create_model() successfully completed......................................
2023-04-29 19:51:42,885:INFO:SubProcess create_model() end ==================================
2023-04-29 19:51:42,886:INFO:Creating metrics dataframe
2023-04-29 19:51:42,898:INFO:Initializing SVM - Linear Kernel
2023-04-29 19:51:42,898:INFO:Total runtime is 0.9549433906873068 minutes
2023-04-29 19:51:42,899:INFO:SubProcess create_model() called ==================================
2023-04-29 19:51:42,899:INFO:Initializing create_model()
2023-04-29 19:51:42,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:51:42,899:INFO:Checking exceptions
2023-04-29 19:51:42,899:INFO:Importing libraries
2023-04-29 19:51:42,899:INFO:Copying training dataset
2023-04-29 19:51:42,909:WARNING:Processing:  31%|##4     | 19/61 [00:57<01:55,  2.75s/it]
2023-04-29 19:51:42,910:INFO:Defining folds
2023-04-29 19:51:42,910:INFO:Declaring metric variables
2023-04-29 19:51:42,910:INFO:Importing untrained model
2023-04-29 19:51:42,910:INFO:SVM - Linear Kernel Imported successfully
2023-04-29 19:51:42,911:INFO:Starting cross validation
2023-04-29 19:51:42,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:51:43,096:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,112:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,125:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,141:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:43,144:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,160:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,167:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:43,172:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,178:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:43,183:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:43,189:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:46,093:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:46,135:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 19:51:55,857:INFO:Calculating mean and std
2023-04-29 19:51:55,858:WARNING:Processing:  34%|##7     | 21/61 [01:10<02:51,  4.29s/it]
2023-04-29 19:51:55,860:INFO:Creating metrics dataframe
2023-04-29 19:51:57,228:WARNING:Processing:  36%|##8     | 22/61 [01:11<02:21,  3.62s/it]
2023-04-29 19:51:57,228:INFO:Uploading results into container
2023-04-29 19:51:57,229:INFO:Uploading model into container now
2023-04-29 19:51:57,229:INFO:_master_model_container: 5
2023-04-29 19:51:57,230:INFO:_display_container: 2
2023-04-29 19:51:57,230:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2395, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-29 19:51:57,230:INFO:create_model() successfully completed......................................
2023-04-29 19:51:57,378:INFO:SubProcess create_model() end ==================================
2023-04-29 19:51:57,379:INFO:Creating metrics dataframe
2023-04-29 19:51:57,388:INFO:Initializing Ridge Classifier
2023-04-29 19:51:57,388:INFO:Total runtime is 1.1964476148287457 minutes
2023-04-29 19:51:57,388:INFO:SubProcess create_model() called ==================================
2023-04-29 19:51:57,388:INFO:Initializing create_model()
2023-04-29 19:51:57,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:51:57,389:INFO:Checking exceptions
2023-04-29 19:51:57,389:INFO:Importing libraries
2023-04-29 19:51:57,389:INFO:Copying training dataset
2023-04-29 19:51:57,392:WARNING:Processing:  38%|###     | 23/61 [01:11<01:45,  2.78s/it]
2023-04-29 19:51:57,392:INFO:Defining folds
2023-04-29 19:51:57,392:INFO:Declaring metric variables
2023-04-29 19:51:57,392:INFO:Importing untrained model
2023-04-29 19:51:57,393:INFO:Ridge Classifier Imported successfully
2023-04-29 19:51:57,393:INFO:Starting cross validation
2023-04-29 19:51:57,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:51:57,552:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,563:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,566:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,566:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,574:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,575:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,608:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,618:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,618:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,626:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,628:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,633:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,640:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,642:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:51:57,645:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:51:57,661:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:52:00,572:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:52:00,576:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:52:00,578:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 19:52:00,585:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:52:08,698:INFO:Calculating mean and std
2023-04-29 19:52:08,699:WARNING:Processing:  41%|###2    | 25/61 [01:23<02:22,  3.96s/it]
2023-04-29 19:52:08,699:INFO:Creating metrics dataframe
2023-04-29 19:52:10,083:WARNING:Processing:  43%|###4    | 26/61 [01:24<01:58,  3.37s/it]
2023-04-29 19:52:10,083:INFO:Uploading results into container
2023-04-29 19:52:10,084:INFO:Uploading model into container now
2023-04-29 19:52:10,084:INFO:_master_model_container: 6
2023-04-29 19:52:10,084:INFO:_display_container: 2
2023-04-29 19:52:10,085:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2395, solver='auto', tol=0.001)
2023-04-29 19:52:10,085:INFO:create_model() successfully completed......................................
2023-04-29 19:52:10,199:INFO:SubProcess create_model() end ==================================
2023-04-29 19:52:10,199:INFO:Creating metrics dataframe
2023-04-29 19:52:10,203:INFO:Initializing Random Forest Classifier
2023-04-29 19:52:10,203:INFO:Total runtime is 1.4100335637728376 minutes
2023-04-29 19:52:10,203:INFO:SubProcess create_model() called ==================================
2023-04-29 19:52:10,203:INFO:Initializing create_model()
2023-04-29 19:52:10,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:52:10,203:INFO:Checking exceptions
2023-04-29 19:52:10,204:INFO:Importing libraries
2023-04-29 19:52:10,204:INFO:Copying training dataset
2023-04-29 19:52:10,206:WARNING:Processing:  44%|###5    | 27/61 [01:24<01:27,  2.58s/it]
2023-04-29 19:52:10,206:INFO:Defining folds
2023-04-29 19:52:10,206:INFO:Declaring metric variables
2023-04-29 19:52:10,206:INFO:Importing untrained model
2023-04-29 19:52:10,207:INFO:Random Forest Classifier Imported successfully
2023-04-29 19:52:10,207:INFO:Starting cross validation
2023-04-29 19:52:10,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:52:22,201:INFO:Calculating mean and std
2023-04-29 19:52:22,202:WARNING:Processing:  48%|###8    | 29/61 [01:36<02:07,  3.99s/it]
2023-04-29 19:52:22,202:INFO:Creating metrics dataframe
2023-04-29 19:52:23,211:WARNING:Processing:  49%|###9    | 30/61 [01:37<01:42,  3.31s/it]
2023-04-29 19:52:23,212:INFO:Uploading results into container
2023-04-29 19:52:23,212:INFO:Uploading model into container now
2023-04-29 19:52:23,213:INFO:_master_model_container: 7
2023-04-29 19:52:23,213:INFO:_display_container: 2
2023-04-29 19:52:23,213:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2395, verbose=0, warm_start=False)
2023-04-29 19:52:23,213:INFO:create_model() successfully completed......................................
2023-04-29 19:52:23,331:INFO:SubProcess create_model() end ==================================
2023-04-29 19:52:23,333:INFO:Creating metrics dataframe
2023-04-29 19:52:23,345:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 19:52:23,345:INFO:Total runtime is 1.6290620764096582 minutes
2023-04-29 19:52:23,345:INFO:SubProcess create_model() called ==================================
2023-04-29 19:52:23,346:INFO:Initializing create_model()
2023-04-29 19:52:23,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:52:23,346:INFO:Checking exceptions
2023-04-29 19:52:23,346:INFO:Importing libraries
2023-04-29 19:52:23,346:INFO:Copying training dataset
2023-04-29 19:52:23,351:WARNING:Processing:  51%|####    | 31/61 [01:37<01:15,  2.53s/it]
2023-04-29 19:52:23,351:INFO:Defining folds
2023-04-29 19:52:23,351:INFO:Declaring metric variables
2023-04-29 19:52:23,352:INFO:Importing untrained model
2023-04-29 19:52:23,352:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 19:52:23,353:INFO:Starting cross validation
2023-04-29 19:52:23,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:52:33,744:INFO:Calculating mean and std
2023-04-29 19:52:33,746:WARNING:Processing:  54%|####3   | 33/61 [01:48<01:41,  3.63s/it]
2023-04-29 19:52:33,746:INFO:Creating metrics dataframe
2023-04-29 19:52:34,991:WARNING:Processing:  56%|####4   | 34/61 [01:49<01:23,  3.09s/it]
2023-04-29 19:52:34,991:INFO:Uploading results into container
2023-04-29 19:52:34,992:INFO:Uploading model into container now
2023-04-29 19:52:34,993:INFO:_master_model_container: 8
2023-04-29 19:52:34,993:INFO:_display_container: 2
2023-04-29 19:52:34,994:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 19:52:34,994:INFO:create_model() successfully completed......................................
2023-04-29 19:52:35,151:INFO:SubProcess create_model() end ==================================
2023-04-29 19:52:35,151:INFO:Creating metrics dataframe
2023-04-29 19:52:35,157:INFO:Initializing Ada Boost Classifier
2023-04-29 19:52:35,157:INFO:Total runtime is 1.8259305397669479 minutes
2023-04-29 19:52:35,157:INFO:SubProcess create_model() called ==================================
2023-04-29 19:52:35,157:INFO:Initializing create_model()
2023-04-29 19:52:35,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:52:35,158:INFO:Checking exceptions
2023-04-29 19:52:35,158:INFO:Importing libraries
2023-04-29 19:52:35,158:INFO:Copying training dataset
2023-04-29 19:52:35,163:WARNING:Processing:  57%|####5   | 35/61 [01:49<01:01,  2.37s/it]
2023-04-29 19:52:35,163:INFO:Defining folds
2023-04-29 19:52:35,163:INFO:Declaring metric variables
2023-04-29 19:52:35,163:INFO:Importing untrained model
2023-04-29 19:52:35,163:INFO:Ada Boost Classifier Imported successfully
2023-04-29 19:52:35,164:INFO:Starting cross validation
2023-04-29 19:52:35,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:52:38,357:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:52:45,988:INFO:Calculating mean and std
2023-04-29 19:52:45,989:WARNING:Processing:  61%|####8   | 37/61 [02:00<01:27,  3.63s/it]
2023-04-29 19:52:45,989:INFO:Creating metrics dataframe
2023-04-29 19:52:47,289:WARNING:Processing:  62%|####9   | 38/61 [02:01<01:11,  3.10s/it]
2023-04-29 19:52:47,290:INFO:Uploading results into container
2023-04-29 19:52:47,290:INFO:Uploading model into container now
2023-04-29 19:52:47,291:INFO:_master_model_container: 9
2023-04-29 19:52:47,291:INFO:_display_container: 2
2023-04-29 19:52:47,291:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2395)
2023-04-29 19:52:47,291:INFO:create_model() successfully completed......................................
2023-04-29 19:52:47,417:INFO:SubProcess create_model() end ==================================
2023-04-29 19:52:47,417:INFO:Creating metrics dataframe
2023-04-29 19:52:47,422:INFO:Initializing Gradient Boosting Classifier
2023-04-29 19:52:47,422:INFO:Total runtime is 2.030336511135102 minutes
2023-04-29 19:52:47,422:INFO:SubProcess create_model() called ==================================
2023-04-29 19:52:47,422:INFO:Initializing create_model()
2023-04-29 19:52:47,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:52:47,422:INFO:Checking exceptions
2023-04-29 19:52:47,423:INFO:Importing libraries
2023-04-29 19:52:47,423:INFO:Copying training dataset
2023-04-29 19:52:47,428:WARNING:Processing:  64%|#####1  | 39/61 [02:01<00:52,  2.37s/it]
2023-04-29 19:52:47,428:INFO:Defining folds
2023-04-29 19:52:47,428:INFO:Declaring metric variables
2023-04-29 19:52:47,428:INFO:Importing untrained model
2023-04-29 19:52:47,429:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 19:52:47,429:INFO:Starting cross validation
2023-04-29 19:52:47,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:53:00,582:INFO:Calculating mean and std
2023-04-29 19:53:00,582:WARNING:Processing:  67%|#####3  | 41/61 [02:14<01:22,  4.10s/it]
2023-04-29 19:53:00,583:INFO:Creating metrics dataframe
2023-04-29 19:53:02,127:WARNING:Processing:  69%|#####5  | 42/61 [02:16<01:06,  3.52s/it]
2023-04-29 19:53:02,127:INFO:Uploading results into container
2023-04-29 19:53:02,127:INFO:Uploading model into container now
2023-04-29 19:53:02,128:INFO:_master_model_container: 10
2023-04-29 19:53:02,128:INFO:_display_container: 2
2023-04-29 19:53:02,129:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2395, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 19:53:02,129:INFO:create_model() successfully completed......................................
2023-04-29 19:53:02,284:INFO:SubProcess create_model() end ==================================
2023-04-29 19:53:02,284:INFO:Creating metrics dataframe
2023-04-29 19:53:02,294:INFO:Initializing Linear Discriminant Analysis
2023-04-29 19:53:02,294:INFO:Total runtime is 2.2782077471415207 minutes
2023-04-29 19:53:02,295:INFO:SubProcess create_model() called ==================================
2023-04-29 19:53:02,295:INFO:Initializing create_model()
2023-04-29 19:53:02,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:53:02,296:INFO:Checking exceptions
2023-04-29 19:53:02,296:INFO:Importing libraries
2023-04-29 19:53:02,296:INFO:Copying training dataset
2023-04-29 19:53:02,304:WARNING:Processing:  70%|#####6  | 43/61 [02:16<00:48,  2.70s/it]
2023-04-29 19:53:02,304:INFO:Defining folds
2023-04-29 19:53:02,304:INFO:Declaring metric variables
2023-04-29 19:53:02,304:INFO:Importing untrained model
2023-04-29 19:53:02,305:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 19:53:02,305:INFO:Starting cross validation
2023-04-29 19:53:02,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:53:12,666:INFO:Calculating mean and std
2023-04-29 19:53:12,667:WARNING:Processing:  74%|#####9  | 45/61 [02:27<00:59,  3.72s/it]
2023-04-29 19:53:12,667:INFO:Creating metrics dataframe
2023-04-29 19:53:14,387:WARNING:Processing:  75%|######  | 46/61 [02:28<00:49,  3.27s/it]
2023-04-29 19:53:14,388:INFO:Uploading results into container
2023-04-29 19:53:14,389:INFO:Uploading model into container now
2023-04-29 19:53:14,390:INFO:_master_model_container: 11
2023-04-29 19:53:14,390:INFO:_display_container: 2
2023-04-29 19:53:14,390:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 19:53:14,391:INFO:create_model() successfully completed......................................
2023-04-29 19:53:14,571:INFO:SubProcess create_model() end ==================================
2023-04-29 19:53:14,571:INFO:Creating metrics dataframe
2023-04-29 19:53:14,579:INFO:Initializing Extra Trees Classifier
2023-04-29 19:53:14,579:INFO:Total runtime is 2.4829519271850593 minutes
2023-04-29 19:53:14,579:INFO:SubProcess create_model() called ==================================
2023-04-29 19:53:14,580:INFO:Initializing create_model()
2023-04-29 19:53:14,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:53:14,580:INFO:Checking exceptions
2023-04-29 19:53:14,580:INFO:Importing libraries
2023-04-29 19:53:14,581:INFO:Copying training dataset
2023-04-29 19:53:14,591:WARNING:Processing:  77%|######1 | 47/61 [02:28<00:35,  2.52s/it]
2023-04-29 19:53:14,591:INFO:Defining folds
2023-04-29 19:53:14,591:INFO:Declaring metric variables
2023-04-29 19:53:14,592:INFO:Importing untrained model
2023-04-29 19:53:14,593:INFO:Extra Trees Classifier Imported successfully
2023-04-29 19:53:14,594:INFO:Starting cross validation
2023-04-29 19:53:14,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:53:29,299:INFO:Calculating mean and std
2023-04-29 19:53:29,299:WARNING:Processing:  80%|######4 | 49/61 [02:43<00:54,  4.51s/it]
2023-04-29 19:53:29,300:INFO:Creating metrics dataframe
2023-04-29 19:53:30,711:WARNING:Processing:  82%|######5 | 50/61 [02:45<00:41,  3.81s/it]
2023-04-29 19:53:30,711:INFO:Uploading results into container
2023-04-29 19:53:30,711:INFO:Uploading model into container now
2023-04-29 19:53:30,712:INFO:_master_model_container: 12
2023-04-29 19:53:30,712:INFO:_display_container: 2
2023-04-29 19:53:30,712:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2395, verbose=0, warm_start=False)
2023-04-29 19:53:30,712:INFO:create_model() successfully completed......................................
2023-04-29 19:53:30,873:INFO:SubProcess create_model() end ==================================
2023-04-29 19:53:30,874:INFO:Creating metrics dataframe
2023-04-29 19:53:30,885:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 19:53:30,885:INFO:Total runtime is 2.7547233064969388 minutes
2023-04-29 19:53:30,885:INFO:SubProcess create_model() called ==================================
2023-04-29 19:53:30,886:INFO:Initializing create_model()
2023-04-29 19:53:30,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:53:30,886:INFO:Checking exceptions
2023-04-29 19:53:30,886:INFO:Importing libraries
2023-04-29 19:53:30,886:INFO:Copying training dataset
2023-04-29 19:53:30,896:WARNING:Processing:  84%|######6 | 51/61 [02:45<00:29,  2.92s/it]
2023-04-29 19:53:30,896:INFO:Defining folds
2023-04-29 19:53:30,896:INFO:Declaring metric variables
2023-04-29 19:53:30,897:INFO:Importing untrained model
2023-04-29 19:53:30,897:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 19:53:30,898:INFO:Starting cross validation
2023-04-29 19:53:30,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:53:32,877:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 19:53:44,543:INFO:Calculating mean and std
2023-04-29 19:53:44,544:WARNING:Processing:  87%|######9 | 53/61 [02:58<00:36,  4.53s/it]
2023-04-29 19:53:44,544:INFO:Creating metrics dataframe
2023-04-29 19:53:45,935:WARNING:Processing:  89%|####### | 54/61 [03:00<00:26,  3.81s/it]
2023-04-29 19:53:45,935:INFO:Uploading results into container
2023-04-29 19:53:45,937:INFO:Uploading model into container now
2023-04-29 19:53:45,937:INFO:_master_model_container: 13
2023-04-29 19:53:45,937:INFO:_display_container: 2
2023-04-29 19:53:45,938:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2395, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 19:53:45,938:INFO:create_model() successfully completed......................................
2023-04-29 19:53:46,090:INFO:SubProcess create_model() end ==================================
2023-04-29 19:53:46,090:INFO:Creating metrics dataframe
2023-04-29 19:53:46,104:INFO:Initializing Dummy Classifier
2023-04-29 19:53:46,104:INFO:Total runtime is 3.0083707213401802 minutes
2023-04-29 19:53:46,104:INFO:SubProcess create_model() called ==================================
2023-04-29 19:53:46,105:INFO:Initializing create_model()
2023-04-29 19:53:46,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236F13CCB20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:53:46,105:INFO:Checking exceptions
2023-04-29 19:53:46,105:INFO:Importing libraries
2023-04-29 19:53:46,105:INFO:Copying training dataset
2023-04-29 19:53:46,112:WARNING:Processing:  90%|#######2| 55/61 [03:00<00:17,  2.92s/it]
2023-04-29 19:53:46,112:INFO:Defining folds
2023-04-29 19:53:46,113:INFO:Declaring metric variables
2023-04-29 19:53:46,113:INFO:Importing untrained model
2023-04-29 19:53:46,114:INFO:Dummy Classifier Imported successfully
2023-04-29 19:53:46,114:INFO:Starting cross validation
2023-04-29 19:53:46,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 19:53:46,273:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,280:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,280:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,299:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,299:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,322:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,332:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:46,338:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:48,574:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:48,574:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 19:53:55,983:INFO:Calculating mean and std
2023-04-29 19:53:55,984:WARNING:Processing:  93%|#######4| 57/61 [03:10<00:15,  3.75s/it]
2023-04-29 19:53:55,984:INFO:Creating metrics dataframe
2023-04-29 19:53:57,254:WARNING:Processing:  95%|#######6| 58/61 [03:11<00:09,  3.19s/it]
2023-04-29 19:53:57,254:INFO:Uploading results into container
2023-04-29 19:53:57,255:INFO:Uploading model into container now
2023-04-29 19:53:57,255:INFO:_master_model_container: 14
2023-04-29 19:53:57,255:INFO:_display_container: 2
2023-04-29 19:53:57,256:INFO:DummyClassifier(constant=None, random_state=2395, strategy='prior')
2023-04-29 19:53:57,256:INFO:create_model() successfully completed......................................
2023-04-29 19:53:57,384:INFO:SubProcess create_model() end ==================================
2023-04-29 19:53:57,385:INFO:Creating metrics dataframe
2023-04-29 19:53:57,398:WARNING:Processing:  97%|#######7| 59/61 [03:11<00:04,  2.44s/it]
2023-04-29 19:53:57,402:INFO:Initializing create_model()
2023-04-29 19:53:57,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2395, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 19:53:57,403:INFO:Checking exceptions
2023-04-29 19:53:57,405:INFO:Importing libraries
2023-04-29 19:53:57,405:INFO:Copying training dataset
2023-04-29 19:53:57,412:INFO:Defining folds
2023-04-29 19:53:57,412:INFO:Declaring metric variables
2023-04-29 19:53:57,412:INFO:Importing untrained model
2023-04-29 19:53:57,412:INFO:Declaring custom model
2023-04-29 19:53:57,414:INFO:Random Forest Classifier Imported successfully
2023-04-29 19:53:57,415:INFO:Cross validation set to False
2023-04-29 19:53:57,415:INFO:Fitting Model
2023-04-29 19:53:58,677:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2395, verbose=0, warm_start=False)
2023-04-29 19:53:58,677:INFO:create_model() successfully completed......................................
2023-04-29 19:53:58,825:WARNING:Processing: 100%|########| 61/61 [03:13<00:00,  1.73s/it]
2023-04-29 19:53:58,825:WARNING:                                                         
2023-04-29 19:53:58,838:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2023-04-29 19:53:58,838:INFO:rf               Random Forest Classifier    0.8444  0.9504  0.8444  0.8521   
2023-04-29 19:53:58,838:INFO:et                 Extra Trees Classifier    0.8423  0.9405  0.8423  0.8470   
2023-04-29 19:53:58,838:INFO:lightgbm  Light Gradient Boosting Machine    0.8381  0.9521  0.8381  0.8455   
2023-04-29 19:53:58,838:INFO:gbc          Gradient Boosting Classifier    0.8371  0.9521  0.8371  0.8421   
2023-04-29 19:53:58,838:INFO:dt               Decision Tree Classifier    0.8244  0.9017  0.8244  0.8303   
2023-04-29 19:53:58,838:INFO:knn                K Neighbors Classifier    0.7865  0.9221  0.7865  0.7890   
2023-04-29 19:53:58,838:INFO:lr                    Logistic Regression    0.7150  0.8893  0.7150  0.7116   
2023-04-29 19:53:58,838:INFO:ridge                    Ridge Classifier    0.7087  0.0000  0.7087  0.6592   
2023-04-29 19:53:58,838:INFO:lda          Linear Discriminant Analysis    0.7066  0.8809  0.7066  0.7035   
2023-04-29 19:53:58,838:INFO:qda       Quadratic Discriminant Analysis    0.6520  0.8733  0.6520  0.6784   
2023-04-29 19:53:58,838:INFO:nb                            Naive Bayes    0.6456  0.8569  0.6456  0.7076   
2023-04-29 19:53:58,838:INFO:svm                   SVM - Linear Kernel    0.6172  0.0000  0.6172  0.6924   
2023-04-29 19:53:58,838:INFO:ada                  Ada Boost Classifier    0.4920  0.7780  0.4920  0.5274   
2023-04-29 19:53:58,838:INFO:dummy                    Dummy Classifier    0.3407  0.5000  0.3407  0.1161   
2023-04-29 19:53:58,838:INFO:
2023-04-29 19:53:58,838:INFO:              F1   Kappa     MCC  TT (Sec)  
2023-04-29 19:53:58,838:INFO:rf        0.8441  0.7790  0.7814     1.199  
2023-04-29 19:53:58,838:INFO:et        0.8419  0.7764  0.7782     1.470  
2023-04-29 19:53:58,839:INFO:lightgbm  0.8379  0.7701  0.7723     1.364  
2023-04-29 19:53:58,839:INFO:gbc       0.8354  0.7681  0.7705     1.315  
2023-04-29 19:53:58,839:INFO:dt        0.8243  0.7520  0.7540     1.289  
2023-04-29 19:53:58,839:INFO:knn       0.7814  0.6977  0.7018     1.620  
2023-04-29 19:53:58,839:INFO:lr        0.7047  0.5929  0.5967     0.870  
2023-04-29 19:53:58,839:INFO:ridge     0.6796  0.5783  0.5844     1.131  
2023-04-29 19:53:58,839:INFO:lda       0.6928  0.5811  0.5861     1.036  
2023-04-29 19:53:58,839:INFO:qda       0.6416  0.5282  0.5428     1.039  
2023-04-29 19:53:58,839:INFO:nb        0.6601  0.5202  0.5313     1.274  
2023-04-29 19:53:58,839:INFO:svm       0.5796  0.4738  0.5102     1.295  
2023-04-29 19:53:58,839:INFO:ada       0.4841  0.2979  0.3108     1.082  
2023-04-29 19:53:58,839:INFO:dummy     0.1732  0.0000  0.0000     0.987  
2023-04-29 19:53:58,839:INFO:_master_model_container: 14
2023-04-29 19:53:58,839:INFO:_display_container: 2
2023-04-29 19:53:58,840:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2395, verbose=0, warm_start=False)
2023-04-29 19:53:58,840:INFO:compare_models() successfully completed......................................
2023-04-29 19:53:58,842:INFO:Initializing predict_model()
2023-04-29 19:53:58,842:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236F1A5D640>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2395, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236F1CFE0D0>)
2023-04-29 19:53:58,842:INFO:Checking exceptions
2023-04-29 19:53:58,842:INFO:Preloading libraries
2023-04-29 19:53:58,842:INFO:Set up data.
2023-04-29 19:53:58,846:INFO:Set up index.
2023-04-29 19:53:58,982:INFO:                      Model  Accuracy  ...   Kappa     MCC
2023-04-29 19:53:58,982:INFO:0  Random Forest Classifier    0.8956  ...  0.8525  0.8526
2023-04-29 19:53:58,982:INFO:
2023-04-29 19:53:58,983:INFO:[1 rows x 8 columns]
2023-04-29 19:59:24,197:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:59:24,197:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:59:24,197:INFO:Data columns (total 8 columns):
2023-04-29 19:59:24,197:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:59:24,197:INFO:---  ------          --------------  -----  
2023-04-29 19:59:24,197:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:59:24,198:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:59:24,198:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:59:24,198:INFO:memory usage: 79.8 KB
2023-04-29 19:59:32,331:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 19:59:32,331:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 19:59:32,331:INFO:Data columns (total 8 columns):
2023-04-29 19:59:32,331:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 19:59:32,331:INFO:---  ------          --------------  -----  
2023-04-29 19:59:32,331:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 19:59:32,331:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 19:59:32,331:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 19:59:32,332:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 19:59:32,332:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 19:59:32,332:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 19:59:32,332:INFO: 6   VEC             1360 non-null   float64
2023-04-29 19:59:32,332:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 19:59:32,332:INFO:dtypes: float64(7), int32(1)
2023-04-29 19:59:32,332:INFO:memory usage: 79.8 KB
2023-04-29 20:00:49,207:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 20:00:49,207:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 20:00:49,207:INFO:Data columns (total 8 columns):
2023-04-29 20:00:49,207:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 20:00:49,207:INFO:---  ------          --------------  -----  
2023-04-29 20:00:49,208:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 6   VEC             1360 non-null   float64
2023-04-29 20:00:49,208:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 20:00:49,208:INFO:dtypes: float64(7), int32(1)
2023-04-29 20:00:49,208:INFO:memory usage: 79.8 KB
2023-04-29 20:00:50,849:INFO:PyCaret ClassificationExperiment
2023-04-29 20:00:50,849:INFO:Logging name: clf-default-name
2023-04-29 20:00:50,849:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 20:00:50,849:INFO:version 3.0.0
2023-04-29 20:00:50,849:INFO:Initializing setup()
2023-04-29 20:00:50,850:INFO:self.USI: 92a1
2023-04-29 20:00:50,850:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'X_test', 'y', 'is_multiclass', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 20:00:50,850:INFO:Checking environment
2023-04-29 20:00:50,850:INFO:python_version: 3.9.13
2023-04-29 20:00:50,850:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 20:00:50,850:INFO:machine: AMD64
2023-04-29 20:00:50,850:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 20:00:50,851:INFO:Memory: svmem(total=16935899136, available=5967945728, percent=64.8, used=10967953408, free=5967945728)
2023-04-29 20:00:50,851:INFO:Physical Core: 4
2023-04-29 20:00:50,851:INFO:Logical Core: 8
2023-04-29 20:00:50,851:INFO:Checking libraries
2023-04-29 20:00:50,851:INFO:System:
2023-04-29 20:00:50,851:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 20:00:50,851:INFO:executable: D:\Anaconda\python.exe
2023-04-29 20:00:50,851:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 20:00:50,851:INFO:PyCaret required dependencies:
2023-04-29 20:00:50,851:INFO:                 pip: 22.2.2
2023-04-29 20:00:50,852:INFO:          setuptools: 63.4.1
2023-04-29 20:00:50,852:INFO:             pycaret: 3.0.0
2023-04-29 20:00:50,852:INFO:             IPython: 7.31.1
2023-04-29 20:00:50,852:INFO:          ipywidgets: 7.6.5
2023-04-29 20:00:50,852:INFO:                tqdm: 4.64.1
2023-04-29 20:00:50,852:INFO:               numpy: 1.21.5
2023-04-29 20:00:50,852:INFO:              pandas: 1.4.4
2023-04-29 20:00:50,852:INFO:              jinja2: 2.11.3
2023-04-29 20:00:50,852:INFO:               scipy: 1.9.1
2023-04-29 20:00:50,852:INFO:              joblib: 1.2.0
2023-04-29 20:00:50,852:INFO:             sklearn: 1.0.2
2023-04-29 20:00:50,852:INFO:                pyod: 1.0.9
2023-04-29 20:00:50,852:INFO:            imblearn: 0.10.1
2023-04-29 20:00:50,852:INFO:   category_encoders: 2.6.0
2023-04-29 20:00:50,852:INFO:            lightgbm: 3.3.5
2023-04-29 20:00:50,852:INFO:               numba: 0.55.1
2023-04-29 20:00:50,852:INFO:            requests: 2.28.1
2023-04-29 20:00:50,852:INFO:          matplotlib: 3.5.2
2023-04-29 20:00:50,852:INFO:          scikitplot: 0.3.7
2023-04-29 20:00:50,852:INFO:         yellowbrick: 1.5
2023-04-29 20:00:50,853:INFO:              plotly: 5.9.0
2023-04-29 20:00:50,853:INFO:             kaleido: 0.2.1
2023-04-29 20:00:50,853:INFO:         statsmodels: 0.13.2
2023-04-29 20:00:50,853:INFO:              sktime: 0.17.1
2023-04-29 20:00:50,853:INFO:               tbats: 1.1.2
2023-04-29 20:00:50,853:INFO:            pmdarima: 2.0.3
2023-04-29 20:00:50,853:INFO:              psutil: 5.9.0
2023-04-29 20:00:50,853:INFO:PyCaret optional dependencies:
2023-04-29 20:00:50,853:INFO:                shap: 0.41.0
2023-04-29 20:00:50,853:INFO:           interpret: Not installed
2023-04-29 20:00:50,853:INFO:                umap: Not installed
2023-04-29 20:00:50,853:INFO:    pandas_profiling: 4.1.2
2023-04-29 20:00:50,853:INFO:  explainerdashboard: Not installed
2023-04-29 20:00:50,853:INFO:             autoviz: Not installed
2023-04-29 20:00:50,853:INFO:           fairlearn: Not installed
2023-04-29 20:00:50,853:INFO:             xgboost: Not installed
2023-04-29 20:00:50,853:INFO:            catboost: Not installed
2023-04-29 20:00:50,853:INFO:              kmodes: Not installed
2023-04-29 20:00:50,853:INFO:             mlxtend: Not installed
2023-04-29 20:00:50,853:INFO:       statsforecast: Not installed
2023-04-29 20:00:50,853:INFO:        tune_sklearn: Not installed
2023-04-29 20:00:50,853:INFO:                 ray: Not installed
2023-04-29 20:00:50,853:INFO:            hyperopt: Not installed
2023-04-29 20:00:50,854:INFO:              optuna: Not installed
2023-04-29 20:00:50,854:INFO:               skopt: Not installed
2023-04-29 20:00:50,854:INFO:              mlflow: 2.2.1
2023-04-29 20:00:50,854:INFO:              gradio: Not installed
2023-04-29 20:00:50,854:INFO:             fastapi: Not installed
2023-04-29 20:00:50,854:INFO:             uvicorn: Not installed
2023-04-29 20:00:50,854:INFO:              m2cgen: Not installed
2023-04-29 20:00:50,854:INFO:           evidently: Not installed
2023-04-29 20:00:50,854:INFO:               fugue: Not installed
2023-04-29 20:00:50,854:INFO:           streamlit: 1.21.0
2023-04-29 20:00:50,854:INFO:             prophet: Not installed
2023-04-29 20:00:50,854:INFO:None
2023-04-29 20:00:50,854:INFO:Set up data.
2023-04-29 20:00:50,859:INFO:Set up train/test split.
2023-04-29 20:00:50,867:INFO:Set up index.
2023-04-29 20:00:50,868:INFO:Set up folding strategy.
2023-04-29 20:00:50,868:INFO:Assigning column types.
2023-04-29 20:00:50,874:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 20:00:50,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:00:50,958:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 20:00:50,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:50,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:00:51,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 20:00:51,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,099:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 20:00:51,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 20:00:51,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,300:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 20:00:51,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,359:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 20:00:51,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,543:INFO:Preparing preprocessing pipeline...
2023-04-29 20:00:51,545:INFO:Set up simple imputation.
2023-04-29 20:00:51,546:INFO:Set up column name cleaning.
2023-04-29 20:00:51,588:INFO:Finished creating preprocessing pipeline.
2023-04-29 20:00:51,594:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Atom.Size.Diff',
                                             'Elect.Diff', 'VEC'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 20:00:51,594:INFO:Creating final display dataframe.
2023-04-29 20:00:51,716:INFO:Setup _display_container:                     Description             Value
0                    Session id              3442
1                        Target            Phases
2                   Target type        Multiclass
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              92a1
2023-04-29 20:00:51,725:INFO:                    Description             Value
2023-04-29 20:00:51,725:INFO:0                    Session id              3442
2023-04-29 20:00:51,725:INFO:1                        Target            Phases
2023-04-29 20:00:51,725:INFO:2                   Target type        Multiclass
2023-04-29 20:00:51,725:INFO:3           Original data shape         (1360, 8)
2023-04-29 20:00:51,725:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 20:00:51,725:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 20:00:51,726:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 20:00:51,726:INFO:7              Numeric features                 7
2023-04-29 20:00:51,726:INFO:8                    Preprocess              True
2023-04-29 20:00:51,726:INFO:9               Imputation type            simple
2023-04-29 20:00:51,726:INFO:10           Numeric imputation              mean
2023-04-29 20:00:51,726:INFO:11       Categorical imputation              mode
2023-04-29 20:00:51,726:INFO:12               Fold Generator   StratifiedKFold
2023-04-29 20:00:51,726:INFO:13                  Fold Number                10
2023-04-29 20:00:51,726:INFO:14                     CPU Jobs                -1
2023-04-29 20:00:51,726:INFO:15                      Use GPU             False
2023-04-29 20:00:51,726:INFO:16               Log Experiment             False
2023-04-29 20:00:51,727:INFO:17              Experiment Name  clf-default-name
2023-04-29 20:00:51,727:INFO:18                          USI              92a1
2023-04-29 20:00:51,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:00:51,973:INFO:setup() successfully completed in 1.91s...............
2023-04-29 20:00:51,978:INFO:Initializing compare_models()
2023-04-29 20:00:51,978:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-29 20:00:51,978:INFO:Checking exceptions
2023-04-29 20:00:51,981:INFO:Preparing display monitor
2023-04-29 20:00:51,983:WARNING:
2023-04-29 20:00:51,985:WARNING:Processing:   0%|                 | 0/61 [00:00<?, ?it/s]
2023-04-29 20:00:51,986:INFO:Initializing Logistic Regression
2023-04-29 20:00:51,986:INFO:Total runtime is 8.253256479899089e-06 minutes
2023-04-29 20:00:51,986:INFO:SubProcess create_model() called ==================================
2023-04-29 20:00:51,986:INFO:Initializing create_model()
2023-04-29 20:00:51,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:00:51,986:INFO:Checking exceptions
2023-04-29 20:00:51,986:INFO:Importing libraries
2023-04-29 20:00:51,987:INFO:Copying training dataset
2023-04-29 20:00:51,991:INFO:Defining folds
2023-04-29 20:00:51,991:INFO:Declaring metric variables
2023-04-29 20:00:51,992:INFO:Importing untrained model
2023-04-29 20:00:51,992:INFO:Logistic Regression Imported successfully
2023-04-29 20:00:51,993:INFO:Starting cross validation
2023-04-29 20:00:51,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:01:09,035:INFO:Calculating mean and std
2023-04-29 20:01:09,036:WARNING:Processing:   8%|7        | 5/61 [00:17<03:10,  3.41s/it]
2023-04-29 20:01:09,036:INFO:Creating metrics dataframe
2023-04-29 20:01:10,453:WARNING:Processing:  10%|8        | 6/61 [00:18<02:43,  2.97s/it]
2023-04-29 20:01:10,453:INFO:Uploading results into container
2023-04-29 20:01:10,455:INFO:Uploading model into container now
2023-04-29 20:01:10,456:INFO:_master_model_container: 1
2023-04-29 20:01:10,456:INFO:_display_container: 2
2023-04-29 20:01:10,457:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3442, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 20:01:10,457:INFO:create_model() successfully completed......................................
2023-04-29 20:01:10,620:INFO:SubProcess create_model() end ==================================
2023-04-29 20:01:10,620:INFO:Creating metrics dataframe
2023-04-29 20:01:10,634:INFO:Initializing K Neighbors Classifier
2023-04-29 20:01:10,635:INFO:Total runtime is 0.3108339508374532 minutes
2023-04-29 20:01:10,635:INFO:SubProcess create_model() called ==================================
2023-04-29 20:01:10,636:INFO:Initializing create_model()
2023-04-29 20:01:10,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:01:10,637:INFO:Checking exceptions
2023-04-29 20:01:10,637:INFO:Importing libraries
2023-04-29 20:01:10,637:INFO:Copying training dataset
2023-04-29 20:01:10,648:WARNING:Processing:  11%|#        | 7/61 [00:18<02:04,  2.30s/it]
2023-04-29 20:01:10,648:INFO:Defining folds
2023-04-29 20:01:10,649:INFO:Declaring metric variables
2023-04-29 20:01:10,650:INFO:Importing untrained model
2023-04-29 20:01:10,651:INFO:K Neighbors Classifier Imported successfully
2023-04-29 20:01:10,651:INFO:Starting cross validation
2023-04-29 20:01:10,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:01:10,810:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,818:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,823:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,832:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,844:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,852:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,858:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:10,884:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:12,855:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:12,867:WARNING:D:\Anaconda\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-29 20:01:19,195:INFO:Calculating mean and std
2023-04-29 20:01:19,196:WARNING:Processing:  15%|#3       | 9/61 [00:27<02:41,  3.10s/it]
2023-04-29 20:01:19,196:INFO:Creating metrics dataframe
2023-04-29 20:01:20,678:WARNING:Processing:  16%|#3      | 10/61 [00:28<02:19,  2.74s/it]
2023-04-29 20:01:20,678:INFO:Uploading results into container
2023-04-29 20:01:20,679:INFO:Uploading model into container now
2023-04-29 20:01:20,679:INFO:_master_model_container: 2
2023-04-29 20:01:20,679:INFO:_display_container: 2
2023-04-29 20:01:20,680:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 20:01:20,680:INFO:create_model() successfully completed......................................
2023-04-29 20:01:20,795:INFO:SubProcess create_model() end ==================================
2023-04-29 20:01:20,795:INFO:Creating metrics dataframe
2023-04-29 20:01:20,800:INFO:Initializing Naive Bayes
2023-04-29 20:01:20,800:INFO:Total runtime is 0.48024144570032756 minutes
2023-04-29 20:01:20,800:INFO:SubProcess create_model() called ==================================
2023-04-29 20:01:20,800:INFO:Initializing create_model()
2023-04-29 20:01:20,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:01:20,800:INFO:Checking exceptions
2023-04-29 20:01:20,800:INFO:Importing libraries
2023-04-29 20:01:20,800:INFO:Copying training dataset
2023-04-29 20:01:20,802:WARNING:Processing:  18%|#4      | 11/61 [00:28<01:45,  2.10s/it]
2023-04-29 20:01:20,802:INFO:Defining folds
2023-04-29 20:01:20,802:INFO:Declaring metric variables
2023-04-29 20:01:20,802:INFO:Importing untrained model
2023-04-29 20:01:20,803:INFO:Naive Bayes Imported successfully
2023-04-29 20:01:20,803:INFO:Starting cross validation
2023-04-29 20:01:20,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:01:29,254:INFO:Calculating mean and std
2023-04-29 20:01:29,256:WARNING:Processing:  21%|#7      | 13/61 [00:37<02:22,  2.97s/it]
2023-04-29 20:01:29,256:INFO:Creating metrics dataframe
2023-04-29 20:01:30,896:WARNING:Processing:  23%|#8      | 14/61 [00:38<02:05,  2.67s/it]
2023-04-29 20:01:30,896:INFO:Uploading results into container
2023-04-29 20:01:30,897:INFO:Uploading model into container now
2023-04-29 20:01:30,898:INFO:_master_model_container: 3
2023-04-29 20:01:30,898:INFO:_display_container: 2
2023-04-29 20:01:30,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 20:01:30,899:INFO:create_model() successfully completed......................................
2023-04-29 20:01:31,028:INFO:SubProcess create_model() end ==================================
2023-04-29 20:01:31,028:INFO:Creating metrics dataframe
2023-04-29 20:01:31,040:INFO:Initializing Decision Tree Classifier
2023-04-29 20:01:31,040:INFO:Total runtime is 0.6509198983510336 minutes
2023-04-29 20:01:31,041:INFO:SubProcess create_model() called ==================================
2023-04-29 20:01:31,041:INFO:Initializing create_model()
2023-04-29 20:01:31,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:01:31,041:INFO:Checking exceptions
2023-04-29 20:01:31,041:INFO:Importing libraries
2023-04-29 20:01:31,042:INFO:Copying training dataset
2023-04-29 20:01:31,047:WARNING:Processing:  25%|#9      | 15/61 [00:39<01:34,  2.05s/it]
2023-04-29 20:01:31,048:INFO:Defining folds
2023-04-29 20:01:31,048:INFO:Declaring metric variables
2023-04-29 20:01:31,048:INFO:Importing untrained model
2023-04-29 20:01:31,049:INFO:Decision Tree Classifier Imported successfully
2023-04-29 20:01:31,049:INFO:Starting cross validation
2023-04-29 20:01:31,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:01:39,471:INFO:Calculating mean and std
2023-04-29 20:01:39,471:WARNING:Processing:  28%|##2     | 17/61 [00:47<02:09,  2.94s/it]
2023-04-29 20:01:39,471:INFO:Creating metrics dataframe
2023-04-29 20:01:41,606:WARNING:Processing:  30%|##3     | 18/61 [00:49<01:58,  2.76s/it]
2023-04-29 20:01:41,606:INFO:Uploading results into container
2023-04-29 20:01:41,607:INFO:Uploading model into container now
2023-04-29 20:01:41,608:INFO:_master_model_container: 4
2023-04-29 20:01:41,608:INFO:_display_container: 2
2023-04-29 20:01:41,609:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3442, splitter='best')
2023-04-29 20:01:41,609:INFO:create_model() successfully completed......................................
2023-04-29 20:01:41,746:INFO:SubProcess create_model() end ==================================
2023-04-29 20:01:41,746:INFO:Creating metrics dataframe
2023-04-29 20:01:41,751:INFO:Initializing SVM - Linear Kernel
2023-04-29 20:01:41,752:INFO:Total runtime is 0.8294562737147014 minutes
2023-04-29 20:01:41,752:INFO:SubProcess create_model() called ==================================
2023-04-29 20:01:41,752:INFO:Initializing create_model()
2023-04-29 20:01:41,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:01:41,752:INFO:Checking exceptions
2023-04-29 20:01:41,752:INFO:Importing libraries
2023-04-29 20:01:41,752:INFO:Copying training dataset
2023-04-29 20:01:41,756:WARNING:Processing:  31%|##4     | 19/61 [00:49<01:29,  2.12s/it]
2023-04-29 20:01:41,756:INFO:Defining folds
2023-04-29 20:01:41,756:INFO:Declaring metric variables
2023-04-29 20:01:41,756:INFO:Importing untrained model
2023-04-29 20:01:41,757:INFO:SVM - Linear Kernel Imported successfully
2023-04-29 20:01:41,757:INFO:Starting cross validation
2023-04-29 20:01:41,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:01:41,878:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,885:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:41,896:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,899:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,904:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:41,930:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,932:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,936:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:41,937:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,940:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,943:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:41,947:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:41,950:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:43,858:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:43,870:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "D:\Anaconda\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-29 20:01:50,665:INFO:Calculating mean and std
2023-04-29 20:01:50,666:WARNING:Processing:  34%|##7     | 21/61 [00:58<02:03,  3.08s/it]
2023-04-29 20:01:50,666:INFO:Creating metrics dataframe
2023-04-29 20:01:52,344:WARNING:Processing:  36%|##8     | 22/61 [01:00<01:47,  2.76s/it]
2023-04-29 20:01:52,345:INFO:Uploading results into container
2023-04-29 20:01:52,345:INFO:Uploading model into container now
2023-04-29 20:01:52,346:INFO:_master_model_container: 5
2023-04-29 20:01:52,346:INFO:_display_container: 2
2023-04-29 20:01:52,347:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3442, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-29 20:01:52,347:INFO:create_model() successfully completed......................................
2023-04-29 20:01:52,468:INFO:SubProcess create_model() end ==================================
2023-04-29 20:01:52,468:INFO:Creating metrics dataframe
2023-04-29 20:01:52,479:INFO:Initializing Ridge Classifier
2023-04-29 20:01:52,479:INFO:Total runtime is 1.0082372585932415 minutes
2023-04-29 20:01:52,480:INFO:SubProcess create_model() called ==================================
2023-04-29 20:01:52,480:INFO:Initializing create_model()
2023-04-29 20:01:52,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:01:52,481:INFO:Checking exceptions
2023-04-29 20:01:52,481:INFO:Importing libraries
2023-04-29 20:01:52,481:INFO:Copying training dataset
2023-04-29 20:01:52,484:WARNING:Processing:  38%|###     | 23/61 [01:00<01:20,  2.12s/it]
2023-04-29 20:01:52,485:INFO:Defining folds
2023-04-29 20:01:52,485:INFO:Declaring metric variables
2023-04-29 20:01:52,485:INFO:Importing untrained model
2023-04-29 20:01:52,486:INFO:Ridge Classifier Imported successfully
2023-04-29 20:01:52,487:INFO:Starting cross validation
2023-04-29 20:01:52,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:01:52,601:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,608:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,610:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,615:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,618:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,625:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,626:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,631:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,641:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,648:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,653:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,653:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,659:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,659:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:52,662:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:52,667:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:54,516:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:54,521:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:01:54,539:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-29 20:01:54,541:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:02:01,155:INFO:Calculating mean and std
2023-04-29 20:02:01,156:WARNING:Processing:  41%|###2    | 25/61 [01:09<01:49,  3.03s/it]
2023-04-29 20:02:01,156:INFO:Creating metrics dataframe
2023-04-29 20:02:02,487:WARNING:Processing:  43%|###4    | 26/61 [01:10<01:32,  2.65s/it]
2023-04-29 20:02:02,487:INFO:Uploading results into container
2023-04-29 20:02:02,488:INFO:Uploading model into container now
2023-04-29 20:02:02,489:INFO:_master_model_container: 6
2023-04-29 20:02:02,489:INFO:_display_container: 2
2023-04-29 20:02:02,489:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=3442, solver='auto', tol=0.001)
2023-04-29 20:02:02,489:INFO:create_model() successfully completed......................................
2023-04-29 20:02:02,617:INFO:SubProcess create_model() end ==================================
2023-04-29 20:02:02,617:INFO:Creating metrics dataframe
2023-04-29 20:02:02,622:INFO:Initializing Random Forest Classifier
2023-04-29 20:02:02,622:INFO:Total runtime is 1.177282758553823 minutes
2023-04-29 20:02:02,622:INFO:SubProcess create_model() called ==================================
2023-04-29 20:02:02,623:INFO:Initializing create_model()
2023-04-29 20:02:02,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:02:02,623:INFO:Checking exceptions
2023-04-29 20:02:02,623:INFO:Importing libraries
2023-04-29 20:02:02,623:INFO:Copying training dataset
2023-04-29 20:02:02,627:WARNING:Processing:  44%|###5    | 27/61 [01:10<01:09,  2.03s/it]
2023-04-29 20:02:02,627:INFO:Defining folds
2023-04-29 20:02:02,627:INFO:Declaring metric variables
2023-04-29 20:02:02,627:INFO:Importing untrained model
2023-04-29 20:02:02,627:INFO:Random Forest Classifier Imported successfully
2023-04-29 20:02:02,628:INFO:Starting cross validation
2023-04-29 20:02:02,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:02:12,740:INFO:Calculating mean and std
2023-04-29 20:02:12,741:WARNING:Processing:  48%|###8    | 29/61 [01:20<01:44,  3.28s/it]
2023-04-29 20:02:12,742:INFO:Creating metrics dataframe
2023-04-29 20:02:13,674:WARNING:Processing:  49%|###9    | 30/61 [01:21<01:25,  2.74s/it]
2023-04-29 20:02:13,674:INFO:Uploading results into container
2023-04-29 20:02:13,676:INFO:Uploading model into container now
2023-04-29 20:02:13,676:INFO:_master_model_container: 7
2023-04-29 20:02:13,677:INFO:_display_container: 2
2023-04-29 20:02:13,677:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3442, verbose=0, warm_start=False)
2023-04-29 20:02:13,677:INFO:create_model() successfully completed......................................
2023-04-29 20:02:13,795:INFO:SubProcess create_model() end ==================================
2023-04-29 20:02:13,796:INFO:Creating metrics dataframe
2023-04-29 20:02:13,801:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 20:02:13,801:INFO:Total runtime is 1.36360319852829 minutes
2023-04-29 20:02:13,801:INFO:SubProcess create_model() called ==================================
2023-04-29 20:02:13,802:INFO:Initializing create_model()
2023-04-29 20:02:13,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:02:13,802:INFO:Checking exceptions
2023-04-29 20:02:13,802:INFO:Importing libraries
2023-04-29 20:02:13,802:INFO:Copying training dataset
2023-04-29 20:02:13,805:WARNING:Processing:  51%|####    | 31/61 [01:21<01:03,  2.10s/it]
2023-04-29 20:02:13,805:INFO:Defining folds
2023-04-29 20:02:13,805:INFO:Declaring metric variables
2023-04-29 20:02:13,805:INFO:Importing untrained model
2023-04-29 20:02:13,805:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 20:02:13,805:INFO:Starting cross validation
2023-04-29 20:02:13,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:02:22,781:INFO:Calculating mean and std
2023-04-29 20:02:22,782:WARNING:Processing:  54%|####3   | 33/61 [01:30<01:26,  3.09s/it]
2023-04-29 20:02:22,782:INFO:Creating metrics dataframe
2023-04-29 20:02:23,764:WARNING:Processing:  56%|####4   | 34/61 [01:31<01:10,  2.61s/it]
2023-04-29 20:02:23,764:INFO:Uploading results into container
2023-04-29 20:02:23,765:INFO:Uploading model into container now
2023-04-29 20:02:23,765:INFO:_master_model_container: 8
2023-04-29 20:02:23,765:INFO:_display_container: 2
2023-04-29 20:02:23,766:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 20:02:23,766:INFO:create_model() successfully completed......................................
2023-04-29 20:02:23,888:INFO:SubProcess create_model() end ==================================
2023-04-29 20:02:23,889:INFO:Creating metrics dataframe
2023-04-29 20:02:23,892:INFO:Initializing Ada Boost Classifier
2023-04-29 20:02:23,893:INFO:Total runtime is 1.531793745358785 minutes
2023-04-29 20:02:23,893:INFO:SubProcess create_model() called ==================================
2023-04-29 20:02:23,893:INFO:Initializing create_model()
2023-04-29 20:02:23,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:02:23,893:INFO:Checking exceptions
2023-04-29 20:02:23,893:INFO:Importing libraries
2023-04-29 20:02:23,893:INFO:Copying training dataset
2023-04-29 20:02:23,896:WARNING:Processing:  57%|####5   | 35/61 [01:31<00:52,  2.00s/it]
2023-04-29 20:02:23,896:INFO:Defining folds
2023-04-29 20:02:23,896:INFO:Declaring metric variables
2023-04-29 20:02:23,896:INFO:Importing untrained model
2023-04-29 20:02:23,896:INFO:Ada Boost Classifier Imported successfully
2023-04-29 20:02:23,896:INFO:Starting cross validation
2023-04-29 20:02:23,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:02:32,827:INFO:Calculating mean and std
2023-04-29 20:02:32,828:WARNING:Processing:  61%|####8   | 37/61 [01:40<01:12,  3.02s/it]
2023-04-29 20:02:32,829:INFO:Creating metrics dataframe
2023-04-29 20:02:33,775:WARNING:Processing:  62%|####9   | 38/61 [01:41<00:58,  2.55s/it]
2023-04-29 20:02:33,775:INFO:Uploading results into container
2023-04-29 20:02:33,776:INFO:Uploading model into container now
2023-04-29 20:02:33,776:INFO:_master_model_container: 9
2023-04-29 20:02:33,777:INFO:_display_container: 2
2023-04-29 20:02:33,777:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3442)
2023-04-29 20:02:33,777:INFO:create_model() successfully completed......................................
2023-04-29 20:02:33,907:INFO:SubProcess create_model() end ==================================
2023-04-29 20:02:33,908:INFO:Creating metrics dataframe
2023-04-29 20:02:33,919:INFO:Initializing Gradient Boosting Classifier
2023-04-29 20:02:33,919:INFO:Total runtime is 1.698898216088613 minutes
2023-04-29 20:02:33,920:INFO:SubProcess create_model() called ==================================
2023-04-29 20:02:33,920:INFO:Initializing create_model()
2023-04-29 20:02:33,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:02:33,920:INFO:Checking exceptions
2023-04-29 20:02:33,920:INFO:Importing libraries
2023-04-29 20:02:33,920:INFO:Copying training dataset
2023-04-29 20:02:33,925:WARNING:Processing:  64%|#####1  | 39/61 [01:41<00:43,  1.96s/it]
2023-04-29 20:02:33,925:INFO:Defining folds
2023-04-29 20:02:33,925:INFO:Declaring metric variables
2023-04-29 20:02:33,926:INFO:Importing untrained model
2023-04-29 20:02:33,926:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 20:02:33,927:INFO:Starting cross validation
2023-04-29 20:02:33,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:02:45,583:INFO:Calculating mean and std
2023-04-29 20:02:45,584:WARNING:Processing:  67%|#####3  | 41/61 [01:53<01:11,  3.55s/it]
2023-04-29 20:02:45,584:INFO:Creating metrics dataframe
2023-04-29 20:02:47,279:WARNING:Processing:  69%|#####5  | 42/61 [01:55<00:59,  3.13s/it]
2023-04-29 20:02:47,279:INFO:Uploading results into container
2023-04-29 20:02:47,280:INFO:Uploading model into container now
2023-04-29 20:02:47,280:INFO:_master_model_container: 10
2023-04-29 20:02:47,280:INFO:_display_container: 2
2023-04-29 20:02:47,281:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3442, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 20:02:47,281:INFO:create_model() successfully completed......................................
2023-04-29 20:02:47,408:INFO:SubProcess create_model() end ==================================
2023-04-29 20:02:47,409:INFO:Creating metrics dataframe
2023-04-29 20:02:47,415:INFO:Initializing Linear Discriminant Analysis
2023-04-29 20:02:47,416:INFO:Total runtime is 1.9238417387008668 minutes
2023-04-29 20:02:47,416:INFO:SubProcess create_model() called ==================================
2023-04-29 20:02:47,416:INFO:Initializing create_model()
2023-04-29 20:02:47,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:02:47,416:INFO:Checking exceptions
2023-04-29 20:02:47,416:INFO:Importing libraries
2023-04-29 20:02:47,416:INFO:Copying training dataset
2023-04-29 20:02:47,420:WARNING:Processing:  70%|#####6  | 43/61 [01:55<00:43,  2.40s/it]
2023-04-29 20:02:47,420:INFO:Defining folds
2023-04-29 20:02:47,420:INFO:Declaring metric variables
2023-04-29 20:02:47,420:INFO:Importing untrained model
2023-04-29 20:02:47,420:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 20:02:47,420:INFO:Starting cross validation
2023-04-29 20:02:47,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:02:56,265:INFO:Calculating mean and std
2023-04-29 20:02:56,266:WARNING:Processing:  74%|#####9  | 45/61 [02:04<00:51,  3.23s/it]
2023-04-29 20:02:56,266:INFO:Creating metrics dataframe
2023-04-29 20:02:57,571:WARNING:Processing:  75%|######  | 46/61 [02:05<00:41,  2.79s/it]
2023-04-29 20:02:57,571:INFO:Uploading results into container
2023-04-29 20:02:57,572:INFO:Uploading model into container now
2023-04-29 20:02:57,572:INFO:_master_model_container: 11
2023-04-29 20:02:57,572:INFO:_display_container: 2
2023-04-29 20:02:57,572:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 20:02:57,572:INFO:create_model() successfully completed......................................
2023-04-29 20:02:57,692:INFO:SubProcess create_model() end ==================================
2023-04-29 20:02:57,693:INFO:Creating metrics dataframe
2023-04-29 20:02:57,698:INFO:Initializing Extra Trees Classifier
2023-04-29 20:02:57,698:INFO:Total runtime is 2.0952238241831465 minutes
2023-04-29 20:02:57,700:INFO:SubProcess create_model() called ==================================
2023-04-29 20:02:57,700:INFO:Initializing create_model()
2023-04-29 20:02:57,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:02:57,700:INFO:Checking exceptions
2023-04-29 20:02:57,700:INFO:Importing libraries
2023-04-29 20:02:57,700:INFO:Copying training dataset
2023-04-29 20:02:57,703:WARNING:Processing:  77%|######1 | 47/61 [02:05<00:29,  2.14s/it]
2023-04-29 20:02:57,703:INFO:Defining folds
2023-04-29 20:02:57,703:INFO:Declaring metric variables
2023-04-29 20:02:57,703:INFO:Importing untrained model
2023-04-29 20:02:57,704:INFO:Extra Trees Classifier Imported successfully
2023-04-29 20:02:57,704:INFO:Starting cross validation
2023-04-29 20:02:57,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:03:07,968:INFO:Calculating mean and std
2023-04-29 20:03:07,970:WARNING:Processing:  80%|######4 | 49/61 [02:15<00:40,  3.37s/it]
2023-04-29 20:03:07,971:INFO:Creating metrics dataframe
2023-04-29 20:03:08,932:WARNING:Processing:  82%|######5 | 50/61 [02:16<00:31,  2.83s/it]
2023-04-29 20:03:08,932:INFO:Uploading results into container
2023-04-29 20:03:08,933:INFO:Uploading model into container now
2023-04-29 20:03:08,933:INFO:_master_model_container: 12
2023-04-29 20:03:08,933:INFO:_display_container: 2
2023-04-29 20:03:08,934:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3442, verbose=0, warm_start=False)
2023-04-29 20:03:08,934:INFO:create_model() successfully completed......................................
2023-04-29 20:03:09,051:INFO:SubProcess create_model() end ==================================
2023-04-29 20:03:09,052:INFO:Creating metrics dataframe
2023-04-29 20:03:09,056:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 20:03:09,056:INFO:Total runtime is 2.284521357218425 minutes
2023-04-29 20:03:09,056:INFO:SubProcess create_model() called ==================================
2023-04-29 20:03:09,056:INFO:Initializing create_model()
2023-04-29 20:03:09,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:03:09,057:INFO:Checking exceptions
2023-04-29 20:03:09,057:INFO:Importing libraries
2023-04-29 20:03:09,057:INFO:Copying training dataset
2023-04-29 20:03:09,059:WARNING:Processing:  84%|######6 | 51/61 [02:17<00:21,  2.16s/it]
2023-04-29 20:03:09,059:INFO:Defining folds
2023-04-29 20:03:09,060:INFO:Declaring metric variables
2023-04-29 20:03:09,060:INFO:Importing untrained model
2023-04-29 20:03:09,060:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 20:03:09,060:INFO:Starting cross validation
2023-04-29 20:03:09,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:03:21,976:INFO:Calculating mean and std
2023-04-29 20:03:21,977:WARNING:Processing:  87%|######9 | 53/61 [02:29<00:31,  3.93s/it]
2023-04-29 20:03:21,977:INFO:Creating metrics dataframe
2023-04-29 20:03:22,957:WARNING:Processing:  89%|####### | 54/61 [02:30<00:22,  3.26s/it]
2023-04-29 20:03:22,957:INFO:Uploading results into container
2023-04-29 20:03:22,957:INFO:Uploading model into container now
2023-04-29 20:03:22,957:INFO:_master_model_container: 13
2023-04-29 20:03:22,957:INFO:_display_container: 2
2023-04-29 20:03:22,958:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3442, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 20:03:22,958:INFO:create_model() successfully completed......................................
2023-04-29 20:03:23,084:INFO:SubProcess create_model() end ==================================
2023-04-29 20:03:23,084:INFO:Creating metrics dataframe
2023-04-29 20:03:23,092:INFO:Initializing Dummy Classifier
2023-04-29 20:03:23,093:INFO:Total runtime is 2.518450240294139 minutes
2023-04-29 20:03:23,093:INFO:SubProcess create_model() called ==================================
2023-04-29 20:03:23,094:INFO:Initializing create_model()
2023-04-29 20:03:23,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEBBDCD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:03:23,095:INFO:Checking exceptions
2023-04-29 20:03:23,095:INFO:Importing libraries
2023-04-29 20:03:23,095:INFO:Copying training dataset
2023-04-29 20:03:23,099:WARNING:Processing:  90%|#######2| 55/61 [02:31<00:14,  2.50s/it]
2023-04-29 20:03:23,099:INFO:Defining folds
2023-04-29 20:03:23,099:INFO:Declaring metric variables
2023-04-29 20:03:23,099:INFO:Importing untrained model
2023-04-29 20:03:23,099:INFO:Dummy Classifier Imported successfully
2023-04-29 20:03:23,100:INFO:Starting cross validation
2023-04-29 20:03:23,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:03:23,255:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,274:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,281:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,287:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,299:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,303:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,310:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:23,333:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:25,289:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:25,300:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-29 20:03:32,095:INFO:Calculating mean and std
2023-04-29 20:03:32,096:WARNING:Processing:  93%|#######4| 57/61 [02:40<00:13,  3.32s/it]
2023-04-29 20:03:32,096:INFO:Creating metrics dataframe
2023-04-29 20:03:33,042:WARNING:Processing:  95%|#######6| 58/61 [02:41<00:08,  2.78s/it]
2023-04-29 20:03:33,042:INFO:Uploading results into container
2023-04-29 20:03:33,043:INFO:Uploading model into container now
2023-04-29 20:03:33,043:INFO:_master_model_container: 14
2023-04-29 20:03:33,043:INFO:_display_container: 2
2023-04-29 20:03:33,043:INFO:DummyClassifier(constant=None, random_state=3442, strategy='prior')
2023-04-29 20:03:33,043:INFO:create_model() successfully completed......................................
2023-04-29 20:03:33,163:INFO:SubProcess create_model() end ==================================
2023-04-29 20:03:33,163:INFO:Creating metrics dataframe
2023-04-29 20:03:33,169:WARNING:Processing:  97%|#######7| 59/61 [02:41<00:04,  2.13s/it]
2023-04-29 20:03:33,171:INFO:Initializing create_model()
2023-04-29 20:03:33,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3442, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:03:33,171:INFO:Checking exceptions
2023-04-29 20:03:33,171:INFO:Importing libraries
2023-04-29 20:03:33,172:INFO:Copying training dataset
2023-04-29 20:03:33,174:INFO:Defining folds
2023-04-29 20:03:33,174:INFO:Declaring metric variables
2023-04-29 20:03:33,175:INFO:Importing untrained model
2023-04-29 20:03:33,175:INFO:Declaring custom model
2023-04-29 20:03:33,175:INFO:Random Forest Classifier Imported successfully
2023-04-29 20:03:33,176:INFO:Cross validation set to False
2023-04-29 20:03:33,176:INFO:Fitting Model
2023-04-29 20:03:34,178:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3442, verbose=0, warm_start=False)
2023-04-29 20:03:34,179:INFO:create_model() successfully completed......................................
2023-04-29 20:03:34,292:WARNING:Processing: 100%|########| 61/61 [02:42<00:00,  1.48s/it]
2023-04-29 20:03:34,292:WARNING:                                                         
2023-04-29 20:03:34,302:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2023-04-29 20:03:34,302:INFO:rf               Random Forest Classifier    0.8517  0.9518  0.8517  0.8565   
2023-04-29 20:03:34,302:INFO:lightgbm  Light Gradient Boosting Machine    0.8444  0.9527  0.8444  0.8484   
2023-04-29 20:03:34,302:INFO:gbc          Gradient Boosting Classifier    0.8402  0.9520  0.8402  0.8433   
2023-04-29 20:03:34,302:INFO:et                 Extra Trees Classifier    0.8391  0.9394  0.8391  0.8416   
2023-04-29 20:03:34,302:INFO:dt               Decision Tree Classifier    0.8318  0.9145  0.8318  0.8363   
2023-04-29 20:03:34,302:INFO:knn                K Neighbors Classifier    0.8034  0.9208  0.8034  0.8071   
2023-04-29 20:03:34,302:INFO:ridge                    Ridge Classifier    0.6930  0.0000  0.6930  0.6458   
2023-04-29 20:03:34,302:INFO:lda          Linear Discriminant Analysis    0.6888  0.8745  0.6888  0.6783   
2023-04-29 20:03:34,302:INFO:lr                    Logistic Regression    0.6846  0.8819  0.6846  0.6782   
2023-04-29 20:03:34,302:INFO:qda       Quadratic Discriminant Analysis    0.6278  0.8803  0.6278  0.6472   
2023-04-29 20:03:34,302:INFO:ada                  Ada Boost Classifier    0.6268  0.7687  0.6268  0.6314   
2023-04-29 20:03:34,302:INFO:nb                            Naive Bayes    0.6236  0.8470  0.6236  0.6946   
2023-04-29 20:03:34,302:INFO:svm                   SVM - Linear Kernel    0.6183  0.0000  0.6183  0.6266   
2023-04-29 20:03:34,302:INFO:dummy                    Dummy Classifier    0.3407  0.5000  0.3407  0.1161   
2023-04-29 20:03:34,302:INFO:
2023-04-29 20:03:34,302:INFO:              F1   Kappa     MCC  TT (Sec)  
2023-04-29 20:03:34,303:INFO:rf        0.8519  0.7901  0.7916     1.011  
2023-04-29 20:03:34,303:INFO:lightgbm  0.8444  0.7800  0.7814     1.291  
2023-04-29 20:03:34,303:INFO:gbc       0.8391  0.7735  0.7754     1.165  
2023-04-29 20:03:34,303:INFO:et        0.8382  0.7725  0.7740     1.026  
2023-04-29 20:03:34,303:INFO:dt        0.8313  0.7631  0.7649     0.842  
2023-04-29 20:03:34,303:INFO:knn       0.8015  0.7218  0.7240     0.854  
2023-04-29 20:03:34,303:INFO:ridge     0.6659  0.5548  0.5599     0.867  
2023-04-29 20:03:34,303:INFO:lda       0.6768  0.5563  0.5601     0.884  
2023-04-29 20:03:34,303:INFO:lr        0.6745  0.5504  0.5537     1.704  
2023-04-29 20:03:34,303:INFO:qda       0.6143  0.4924  0.5069     0.898  
2023-04-29 20:03:34,303:INFO:ada       0.6143  0.4677  0.4743     0.893  
2023-04-29 20:03:34,303:INFO:nb        0.6384  0.4964  0.5117     0.845  
2023-04-29 20:03:34,303:INFO:svm       0.5822  0.4514  0.4768     0.891  
2023-04-29 20:03:34,303:INFO:dummy     0.1732  0.0000  0.0000     0.899  
2023-04-29 20:03:34,303:INFO:_master_model_container: 14
2023-04-29 20:03:34,303:INFO:_display_container: 2
2023-04-29 20:03:34,303:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3442, verbose=0, warm_start=False)
2023-04-29 20:03:34,303:INFO:compare_models() successfully completed......................................
2023-04-29 20:03:34,307:INFO:Initializing predict_model()
2023-04-29 20:03:34,307:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236EF0C8880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3442, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236EFC7E550>)
2023-04-29 20:03:34,307:INFO:Checking exceptions
2023-04-29 20:03:34,307:INFO:Preloading libraries
2023-04-29 20:03:34,307:INFO:Set up data.
2023-04-29 20:03:34,312:INFO:Set up index.
2023-04-29 20:03:34,438:INFO:                      Model  Accuracy  ...   Kappa    MCC
2023-04-29 20:03:34,438:INFO:0  Random Forest Classifier    0.8897  ...  0.8438  0.844
2023-04-29 20:03:34,439:INFO:
2023-04-29 20:03:34,439:INFO:[1 rows x 8 columns]
2023-04-29 20:05:38,535:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 20:05:38,535:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 20:05:38,535:INFO:Data columns (total 8 columns):
2023-04-29 20:05:38,535:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 20:05:38,535:INFO:---  ------          --------------  -----  
2023-04-29 20:05:38,535:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 6   VEC             1360 non-null   float64
2023-04-29 20:05:38,535:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 20:05:38,535:INFO:dtypes: float64(7), int32(1)
2023-04-29 20:05:38,535:INFO:memory usage: 79.8 KB
2023-04-29 20:05:48,845:INFO:<class 'pandas.core.frame.DataFrame'>
2023-04-29 20:05:48,846:INFO:RangeIndex: 1360 entries, 0 to 1359
2023-04-29 20:05:48,846:INFO:Data columns (total 8 columns):
2023-04-29 20:05:48,846:INFO: #   Column          Non-Null Count  Dtype  
2023-04-29 20:05:48,846:INFO:---  ------          --------------  -----  
2023-04-29 20:05:48,846:INFO: 0   Num_of_Elem     1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 1   Density_calc    1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 2   dHmix           1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 3   dSmix           1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 4   Atom.Size.Diff  1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 5   Elect.Diff      1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 6   VEC             1360 non-null   float64
2023-04-29 20:05:48,846:INFO: 7   Phases          1360 non-null   int32  
2023-04-29 20:05:48,846:INFO:dtypes: float64(7), int32(1)
2023-04-29 20:05:48,846:INFO:memory usage: 79.8 KB
2023-04-29 20:05:50,549:INFO:PyCaret RegressionExperiment
2023-04-29 20:05:50,549:INFO:Logging name: reg-default-name
2023-04-29 20:05:50,549:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-29 20:05:50,550:INFO:version 3.0.0
2023-04-29 20:05:50,550:INFO:Initializing setup()
2023-04-29 20:05:50,550:INFO:self.USI: a9ce
2023-04-29 20:05:50,550:INFO:self._variable_keys: {'html_param', '_available_plots', '_ml_usecase', 'fold_shuffle_param', 'memory', 'idx', 'exp_id', 'seed', 'y_train', 'fold_groups_param', 'X', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fold_generator', 'exp_name_log', 'log_plots_param', 'transform_target_param', 'n_jobs_param', 'X_test', 'y', 'USI', 'X_train', 'pipeline', 'logging_param', 'target_param', 'y_test'}
2023-04-29 20:05:50,550:INFO:Checking environment
2023-04-29 20:05:50,550:INFO:python_version: 3.9.13
2023-04-29 20:05:50,550:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-29 20:05:50,550:INFO:machine: AMD64
2023-04-29 20:05:50,550:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-29 20:05:50,551:INFO:Memory: svmem(total=16935899136, available=4966486016, percent=70.7, used=11969413120, free=4966486016)
2023-04-29 20:05:50,551:INFO:Physical Core: 4
2023-04-29 20:05:50,551:INFO:Logical Core: 8
2023-04-29 20:05:50,551:INFO:Checking libraries
2023-04-29 20:05:50,551:INFO:System:
2023-04-29 20:05:50,551:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-29 20:05:50,551:INFO:executable: D:\Anaconda\python.exe
2023-04-29 20:05:50,551:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-29 20:05:50,551:INFO:PyCaret required dependencies:
2023-04-29 20:05:50,551:INFO:                 pip: 22.2.2
2023-04-29 20:05:50,552:INFO:          setuptools: 63.4.1
2023-04-29 20:05:50,552:INFO:             pycaret: 3.0.0
2023-04-29 20:05:50,552:INFO:             IPython: 7.31.1
2023-04-29 20:05:50,552:INFO:          ipywidgets: 7.6.5
2023-04-29 20:05:50,552:INFO:                tqdm: 4.64.1
2023-04-29 20:05:50,552:INFO:               numpy: 1.21.5
2023-04-29 20:05:50,552:INFO:              pandas: 1.4.4
2023-04-29 20:05:50,552:INFO:              jinja2: 2.11.3
2023-04-29 20:05:50,552:INFO:               scipy: 1.9.1
2023-04-29 20:05:50,552:INFO:              joblib: 1.2.0
2023-04-29 20:05:50,552:INFO:             sklearn: 1.0.2
2023-04-29 20:05:50,553:INFO:                pyod: 1.0.9
2023-04-29 20:05:50,553:INFO:            imblearn: 0.10.1
2023-04-29 20:05:50,553:INFO:   category_encoders: 2.6.0
2023-04-29 20:05:50,553:INFO:            lightgbm: 3.3.5
2023-04-29 20:05:50,553:INFO:               numba: 0.55.1
2023-04-29 20:05:50,553:INFO:            requests: 2.28.1
2023-04-29 20:05:50,553:INFO:          matplotlib: 3.5.2
2023-04-29 20:05:50,553:INFO:          scikitplot: 0.3.7
2023-04-29 20:05:50,553:INFO:         yellowbrick: 1.5
2023-04-29 20:05:50,554:INFO:              plotly: 5.9.0
2023-04-29 20:05:50,554:INFO:             kaleido: 0.2.1
2023-04-29 20:05:50,554:INFO:         statsmodels: 0.13.2
2023-04-29 20:05:50,554:INFO:              sktime: 0.17.1
2023-04-29 20:05:50,554:INFO:               tbats: 1.1.2
2023-04-29 20:05:50,554:INFO:            pmdarima: 2.0.3
2023-04-29 20:05:50,554:INFO:              psutil: 5.9.0
2023-04-29 20:05:50,554:INFO:PyCaret optional dependencies:
2023-04-29 20:05:50,554:INFO:                shap: 0.41.0
2023-04-29 20:05:50,554:INFO:           interpret: Not installed
2023-04-29 20:05:50,554:INFO:                umap: Not installed
2023-04-29 20:05:50,554:INFO:    pandas_profiling: 4.1.2
2023-04-29 20:05:50,554:INFO:  explainerdashboard: Not installed
2023-04-29 20:05:50,554:INFO:             autoviz: Not installed
2023-04-29 20:05:50,554:INFO:           fairlearn: Not installed
2023-04-29 20:05:50,554:INFO:             xgboost: Not installed
2023-04-29 20:05:50,554:INFO:            catboost: Not installed
2023-04-29 20:05:50,554:INFO:              kmodes: Not installed
2023-04-29 20:05:50,554:INFO:             mlxtend: Not installed
2023-04-29 20:05:50,554:INFO:       statsforecast: Not installed
2023-04-29 20:05:50,554:INFO:        tune_sklearn: Not installed
2023-04-29 20:05:50,555:INFO:                 ray: Not installed
2023-04-29 20:05:50,555:INFO:            hyperopt: Not installed
2023-04-29 20:05:50,555:INFO:              optuna: Not installed
2023-04-29 20:05:50,555:INFO:               skopt: Not installed
2023-04-29 20:05:50,555:INFO:              mlflow: 2.2.1
2023-04-29 20:05:50,555:INFO:              gradio: Not installed
2023-04-29 20:05:50,555:INFO:             fastapi: Not installed
2023-04-29 20:05:50,555:INFO:             uvicorn: Not installed
2023-04-29 20:05:50,555:INFO:              m2cgen: Not installed
2023-04-29 20:05:50,555:INFO:           evidently: Not installed
2023-04-29 20:05:50,555:INFO:               fugue: Not installed
2023-04-29 20:05:50,555:INFO:           streamlit: 1.21.0
2023-04-29 20:05:50,555:INFO:             prophet: Not installed
2023-04-29 20:05:50,555:INFO:None
2023-04-29 20:05:50,555:INFO:Set up data.
2023-04-29 20:05:50,561:INFO:Set up train/test split.
2023-04-29 20:05:50,564:INFO:Set up index.
2023-04-29 20:05:50,564:INFO:Set up folding strategy.
2023-04-29 20:05:50,564:INFO:Assigning column types.
2023-04-29 20:05:50,567:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 20:05:50,567:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,571:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:50,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:50,741:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,877:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:50,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:50,879:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-29 20:05:50,883:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 20:05:50,887:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,003:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,079:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,084:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,216:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-29 20:05:51,224:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,381:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,497:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-29 20:05:51,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,842:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 20:05:51,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:51,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:51,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,071:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-29 20:05:52,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,117:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-29 20:05:52,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,405:INFO:Preparing preprocessing pipeline...
2023-04-29 20:05:52,405:INFO:Set up simple imputation.
2023-04-29 20:05:52,406:INFO:Set up column name cleaning.
2023-04-29 20:05:52,428:INFO:Finished creating preprocessing pipeline.
2023-04-29 20:05:52,433:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-29 20:05:52,433:INFO:Creating final display dataframe.
2023-04-29 20:05:52,527:INFO:Setup _display_container:                     Description             Value
0                    Session id              8753
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a9ce
2023-04-29 20:05:52,531:INFO:                    Description             Value
2023-04-29 20:05:52,531:INFO:0                    Session id              8753
2023-04-29 20:05:52,531:INFO:1                        Target    Atom.Size.Diff
2023-04-29 20:05:52,531:INFO:2                   Target type        Regression
2023-04-29 20:05:52,531:INFO:3           Original data shape         (1360, 8)
2023-04-29 20:05:52,531:INFO:4        Transformed data shape         (1360, 8)
2023-04-29 20:05:52,531:INFO:5   Transformed train set shape          (951, 8)
2023-04-29 20:05:52,531:INFO:6    Transformed test set shape          (409, 8)
2023-04-29 20:05:52,531:INFO:7              Numeric features                 7
2023-04-29 20:05:52,531:INFO:8                    Preprocess              True
2023-04-29 20:05:52,531:INFO:9               Imputation type            simple
2023-04-29 20:05:52,531:INFO:10           Numeric imputation              mean
2023-04-29 20:05:52,531:INFO:11       Categorical imputation              mode
2023-04-29 20:05:52,531:INFO:12               Fold Generator             KFold
2023-04-29 20:05:52,531:INFO:13                  Fold Number                10
2023-04-29 20:05:52,531:INFO:14                     CPU Jobs                -1
2023-04-29 20:05:52,531:INFO:15                      Use GPU             False
2023-04-29 20:05:52,531:INFO:16               Log Experiment             False
2023-04-29 20:05:52,531:INFO:17              Experiment Name  reg-default-name
2023-04-29 20:05:52,531:INFO:18                          USI              a9ce
2023-04-29 20:05:52,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-29 20:05:52,799:INFO:setup() successfully completed in 3.07s...............
2023-04-29 20:05:52,805:INFO:Initializing compare_models()
2023-04-29 20:05:52,805:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-29 20:05:52,805:INFO:Checking exceptions
2023-04-29 20:05:52,808:INFO:Preparing display monitor
2023-04-29 20:05:52,813:WARNING:
2023-04-29 20:05:52,813:WARNING:Processing:   0%|                 | 0/77 [00:00<?, ?it/s]
2023-04-29 20:05:52,813:INFO:Initializing Linear Regression
2023-04-29 20:05:52,814:INFO:Total runtime is 1.5858809153238932e-05 minutes
2023-04-29 20:05:52,814:INFO:SubProcess create_model() called ==================================
2023-04-29 20:05:52,814:INFO:Initializing create_model()
2023-04-29 20:05:52,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:05:52,815:INFO:Checking exceptions
2023-04-29 20:05:52,815:INFO:Importing libraries
2023-04-29 20:05:52,815:INFO:Copying training dataset
2023-04-29 20:05:52,823:INFO:Defining folds
2023-04-29 20:05:52,823:INFO:Declaring metric variables
2023-04-29 20:05:52,824:INFO:Importing untrained model
2023-04-29 20:05:52,824:INFO:Linear Regression Imported successfully
2023-04-29 20:05:52,826:INFO:Starting cross validation
2023-04-29 20:05:52,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:06:08,570:INFO:Calculating mean and std
2023-04-29 20:06:08,571:WARNING:Processing:   6%|5        | 5/77 [00:15<03:46,  3.15s/it]
2023-04-29 20:06:08,571:INFO:Creating metrics dataframe
2023-04-29 20:06:09,678:WARNING:Processing:   8%|7        | 6/77 [00:16<03:11,  2.70s/it]
2023-04-29 20:06:09,678:INFO:Uploading results into container
2023-04-29 20:06:09,679:INFO:Uploading model into container now
2023-04-29 20:06:09,680:INFO:_master_model_container: 1
2023-04-29 20:06:09,680:INFO:_display_container: 2
2023-04-29 20:06:09,680:INFO:LinearRegression(n_jobs=-1)
2023-04-29 20:06:09,680:INFO:create_model() successfully completed......................................
2023-04-29 20:06:09,819:INFO:SubProcess create_model() end ==================================
2023-04-29 20:06:09,819:INFO:Creating metrics dataframe
2023-04-29 20:06:09,823:INFO:Initializing Lasso Regression
2023-04-29 20:06:09,823:INFO:Total runtime is 0.2834888935089111 minutes
2023-04-29 20:06:09,823:INFO:SubProcess create_model() called ==================================
2023-04-29 20:06:09,824:INFO:Initializing create_model()
2023-04-29 20:06:09,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:06:09,824:INFO:Checking exceptions
2023-04-29 20:06:09,824:INFO:Importing libraries
2023-04-29 20:06:09,824:INFO:Copying training dataset
2023-04-29 20:06:09,827:WARNING:Processing:   9%|8        | 7/77 [00:17<02:25,  2.08s/it]
2023-04-29 20:06:09,827:INFO:Defining folds
2023-04-29 20:06:09,827:INFO:Declaring metric variables
2023-04-29 20:06:09,828:INFO:Importing untrained model
2023-04-29 20:06:09,828:INFO:Lasso Regression Imported successfully
2023-04-29 20:06:09,828:INFO:Starting cross validation
2023-04-29 20:06:09,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:06:19,543:INFO:Calculating mean and std
2023-04-29 20:06:19,544:WARNING:Processing:  12%|#        | 9/77 [00:26<03:38,  3.21s/it]
2023-04-29 20:06:19,544:INFO:Creating metrics dataframe
2023-04-29 20:06:21,652:WARNING:Processing:  13%|#       | 10/77 [00:28<03:18,  2.97s/it]
2023-04-29 20:06:21,652:INFO:Uploading results into container
2023-04-29 20:06:21,653:INFO:Uploading model into container now
2023-04-29 20:06:21,653:INFO:_master_model_container: 2
2023-04-29 20:06:21,653:INFO:_display_container: 2
2023-04-29 20:06:21,654:INFO:Lasso(random_state=8753)
2023-04-29 20:06:21,654:INFO:create_model() successfully completed......................................
2023-04-29 20:06:21,809:INFO:SubProcess create_model() end ==================================
2023-04-29 20:06:21,809:INFO:Creating metrics dataframe
2023-04-29 20:06:21,818:INFO:Initializing Ridge Regression
2023-04-29 20:06:21,818:INFO:Total runtime is 0.48341156641642247 minutes
2023-04-29 20:06:21,819:INFO:SubProcess create_model() called ==================================
2023-04-29 20:06:21,819:INFO:Initializing create_model()
2023-04-29 20:06:21,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:06:21,819:INFO:Checking exceptions
2023-04-29 20:06:21,819:INFO:Importing libraries
2023-04-29 20:06:21,820:INFO:Copying training dataset
2023-04-29 20:06:21,824:WARNING:Processing:  14%|#1      | 11/77 [00:29<02:30,  2.28s/it]
2023-04-29 20:06:21,824:INFO:Defining folds
2023-04-29 20:06:21,825:INFO:Declaring metric variables
2023-04-29 20:06:21,825:INFO:Importing untrained model
2023-04-29 20:06:21,825:INFO:Ridge Regression Imported successfully
2023-04-29 20:06:21,826:INFO:Starting cross validation
2023-04-29 20:06:21,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:06:31,137:INFO:Calculating mean and std
2023-04-29 20:06:31,137:WARNING:Processing:  17%|#3      | 13/77 [00:38<03:28,  3.26s/it]
2023-04-29 20:06:31,137:INFO:Creating metrics dataframe
2023-04-29 20:06:32,555:WARNING:Processing:  18%|#4      | 14/77 [00:39<02:58,  2.84s/it]
2023-04-29 20:06:32,555:INFO:Uploading results into container
2023-04-29 20:06:32,556:INFO:Uploading model into container now
2023-04-29 20:06:32,556:INFO:_master_model_container: 3
2023-04-29 20:06:32,556:INFO:_display_container: 2
2023-04-29 20:06:32,557:INFO:Ridge(random_state=8753)
2023-04-29 20:06:32,557:INFO:create_model() successfully completed......................................
2023-04-29 20:06:32,674:INFO:SubProcess create_model() end ==================================
2023-04-29 20:06:32,675:INFO:Creating metrics dataframe
2023-04-29 20:06:32,680:INFO:Initializing Elastic Net
2023-04-29 20:06:32,680:INFO:Total runtime is 0.6644494930903116 minutes
2023-04-29 20:06:32,680:INFO:SubProcess create_model() called ==================================
2023-04-29 20:06:32,681:INFO:Initializing create_model()
2023-04-29 20:06:32,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:06:32,681:INFO:Checking exceptions
2023-04-29 20:06:32,681:INFO:Importing libraries
2023-04-29 20:06:32,681:INFO:Copying training dataset
2023-04-29 20:06:32,684:WARNING:Processing:  19%|#5      | 15/77 [00:39<02:15,  2.18s/it]
2023-04-29 20:06:32,684:INFO:Defining folds
2023-04-29 20:06:32,684:INFO:Declaring metric variables
2023-04-29 20:06:32,684:INFO:Importing untrained model
2023-04-29 20:06:32,685:INFO:Elastic Net Imported successfully
2023-04-29 20:06:32,685:INFO:Starting cross validation
2023-04-29 20:06:32,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:06:42,215:INFO:Calculating mean and std
2023-04-29 20:06:42,216:WARNING:Processing:  22%|#7      | 17/77 [00:49<03:14,  3.24s/it]
2023-04-29 20:06:42,216:INFO:Creating metrics dataframe
2023-04-29 20:06:43,237:WARNING:Processing:  23%|#8      | 18/77 [00:50<02:41,  2.74s/it]
2023-04-29 20:06:43,237:INFO:Uploading results into container
2023-04-29 20:06:43,238:INFO:Uploading model into container now
2023-04-29 20:06:43,238:INFO:_master_model_container: 4
2023-04-29 20:06:43,239:INFO:_display_container: 2
2023-04-29 20:06:43,239:INFO:ElasticNet(random_state=8753)
2023-04-29 20:06:43,239:INFO:create_model() successfully completed......................................
2023-04-29 20:06:43,356:INFO:SubProcess create_model() end ==================================
2023-04-29 20:06:43,357:INFO:Creating metrics dataframe
2023-04-29 20:06:43,366:INFO:Initializing Least Angle Regression
2023-04-29 20:06:43,366:INFO:Total runtime is 0.8425422032674154 minutes
2023-04-29 20:06:43,366:INFO:SubProcess create_model() called ==================================
2023-04-29 20:06:43,367:INFO:Initializing create_model()
2023-04-29 20:06:43,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:06:43,367:INFO:Checking exceptions
2023-04-29 20:06:43,367:INFO:Importing libraries
2023-04-29 20:06:43,367:INFO:Copying training dataset
2023-04-29 20:06:43,370:WARNING:Processing:  25%|#9      | 19/77 [00:50<02:01,  2.10s/it]
2023-04-29 20:06:43,371:INFO:Defining folds
2023-04-29 20:06:43,371:INFO:Declaring metric variables
2023-04-29 20:06:43,371:INFO:Importing untrained model
2023-04-29 20:06:43,371:INFO:Least Angle Regression Imported successfully
2023-04-29 20:06:43,371:INFO:Starting cross validation
2023-04-29 20:06:43,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:06:43,490:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,501:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,518:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,529:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,544:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,559:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,574:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:43,589:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:45,489:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:45,503:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:06:53,155:INFO:Calculating mean and std
2023-04-29 20:06:53,156:WARNING:Processing:  27%|##1     | 21/77 [01:00<03:01,  3.25s/it]
2023-04-29 20:06:53,156:INFO:Creating metrics dataframe
2023-04-29 20:06:54,209:WARNING:Processing:  29%|##2     | 22/77 [01:01<02:31,  2.75s/it]
2023-04-29 20:06:54,209:INFO:Uploading results into container
2023-04-29 20:06:54,210:INFO:Uploading model into container now
2023-04-29 20:06:54,210:INFO:_master_model_container: 5
2023-04-29 20:06:54,210:INFO:_display_container: 2
2023-04-29 20:06:54,210:INFO:Lars(random_state=8753)
2023-04-29 20:06:54,211:INFO:create_model() successfully completed......................................
2023-04-29 20:06:54,326:INFO:SubProcess create_model() end ==================================
2023-04-29 20:06:54,327:INFO:Creating metrics dataframe
2023-04-29 20:06:54,331:INFO:Initializing Lasso Least Angle Regression
2023-04-29 20:06:54,331:INFO:Total runtime is 1.0253020167350768 minutes
2023-04-29 20:06:54,331:INFO:SubProcess create_model() called ==================================
2023-04-29 20:06:54,331:INFO:Initializing create_model()
2023-04-29 20:06:54,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:06:54,332:INFO:Checking exceptions
2023-04-29 20:06:54,332:INFO:Importing libraries
2023-04-29 20:06:54,332:INFO:Copying training dataset
2023-04-29 20:06:54,335:WARNING:Processing:  30%|##3     | 23/77 [01:01<01:53,  2.11s/it]
2023-04-29 20:06:54,335:INFO:Defining folds
2023-04-29 20:06:54,335:INFO:Declaring metric variables
2023-04-29 20:06:54,336:INFO:Importing untrained model
2023-04-29 20:06:54,336:INFO:Lasso Least Angle Regression Imported successfully
2023-04-29 20:06:54,336:INFO:Starting cross validation
2023-04-29 20:06:54,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:06:54,452:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,469:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,471:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,484:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,493:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,507:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,522:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:54,540:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:56,430:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:06:56,444:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-29 20:07:03,918:INFO:Calculating mean and std
2023-04-29 20:07:03,919:WARNING:Processing:  32%|##5     | 25/77 [01:11<02:47,  3.21s/it]
2023-04-29 20:07:03,920:INFO:Creating metrics dataframe
2023-04-29 20:07:05,356:WARNING:Processing:  34%|##7     | 26/77 [01:12<02:23,  2.81s/it]
2023-04-29 20:07:05,356:INFO:Uploading results into container
2023-04-29 20:07:05,356:INFO:Uploading model into container now
2023-04-29 20:07:05,357:INFO:_master_model_container: 6
2023-04-29 20:07:05,357:INFO:_display_container: 2
2023-04-29 20:07:05,358:INFO:LassoLars(random_state=8753)
2023-04-29 20:07:05,358:INFO:create_model() successfully completed......................................
2023-04-29 20:07:05,478:INFO:SubProcess create_model() end ==================================
2023-04-29 20:07:05,479:INFO:Creating metrics dataframe
2023-04-29 20:07:05,483:INFO:Initializing Orthogonal Matching Pursuit
2023-04-29 20:07:05,483:INFO:Total runtime is 1.2111642400423686 minutes
2023-04-29 20:07:05,483:INFO:SubProcess create_model() called ==================================
2023-04-29 20:07:05,484:INFO:Initializing create_model()
2023-04-29 20:07:05,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:07:05,484:INFO:Checking exceptions
2023-04-29 20:07:05,484:INFO:Importing libraries
2023-04-29 20:07:05,484:INFO:Copying training dataset
2023-04-29 20:07:05,487:WARNING:Processing:  35%|##8     | 27/77 [01:12<01:47,  2.15s/it]
2023-04-29 20:07:05,488:INFO:Defining folds
2023-04-29 20:07:05,488:INFO:Declaring metric variables
2023-04-29 20:07:05,488:INFO:Importing untrained model
2023-04-29 20:07:05,488:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-29 20:07:05,488:INFO:Starting cross validation
2023-04-29 20:07:05,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:07:05,605:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,625:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,633:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,642:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,664:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,676:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,692:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:05,705:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:07,591:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:07,616:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-29 20:07:14,982:INFO:Calculating mean and std
2023-04-29 20:07:14,983:WARNING:Processing:  38%|###     | 29/77 [01:22<02:34,  3.22s/it]
2023-04-29 20:07:14,983:INFO:Creating metrics dataframe
2023-04-29 20:07:17,004:WARNING:Processing:  39%|###1    | 30/77 [01:24<02:18,  2.95s/it]
2023-04-29 20:07:17,004:INFO:Uploading results into container
2023-04-29 20:07:17,005:INFO:Uploading model into container now
2023-04-29 20:07:17,005:INFO:_master_model_container: 7
2023-04-29 20:07:17,005:INFO:_display_container: 2
2023-04-29 20:07:17,006:INFO:OrthogonalMatchingPursuit()
2023-04-29 20:07:17,006:INFO:create_model() successfully completed......................................
2023-04-29 20:07:17,138:INFO:SubProcess create_model() end ==================================
2023-04-29 20:07:17,138:INFO:Creating metrics dataframe
2023-04-29 20:07:17,142:INFO:Initializing Bayesian Ridge
2023-04-29 20:07:17,143:INFO:Total runtime is 1.405488661924998 minutes
2023-04-29 20:07:17,143:INFO:SubProcess create_model() called ==================================
2023-04-29 20:07:17,143:INFO:Initializing create_model()
2023-04-29 20:07:17,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:07:17,143:INFO:Checking exceptions
2023-04-29 20:07:17,143:INFO:Importing libraries
2023-04-29 20:07:17,143:INFO:Copying training dataset
2023-04-29 20:07:17,147:WARNING:Processing:  40%|###2    | 31/77 [01:24<01:44,  2.26s/it]
2023-04-29 20:07:17,148:INFO:Defining folds
2023-04-29 20:07:17,148:INFO:Declaring metric variables
2023-04-29 20:07:17,148:INFO:Importing untrained model
2023-04-29 20:07:17,148:INFO:Bayesian Ridge Imported successfully
2023-04-29 20:07:17,148:INFO:Starting cross validation
2023-04-29 20:07:17,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:07:26,629:INFO:Calculating mean and std
2023-04-29 20:07:26,630:WARNING:Processing:  43%|###4    | 33/77 [01:33<02:24,  3.28s/it]
2023-04-29 20:07:26,630:INFO:Creating metrics dataframe
2023-04-29 20:07:27,717:WARNING:Processing:  44%|###5    | 34/77 [01:34<01:59,  2.78s/it]
2023-04-29 20:07:27,717:INFO:Uploading results into container
2023-04-29 20:07:27,718:INFO:Uploading model into container now
2023-04-29 20:07:27,718:INFO:_master_model_container: 8
2023-04-29 20:07:27,718:INFO:_display_container: 2
2023-04-29 20:07:27,719:INFO:BayesianRidge()
2023-04-29 20:07:27,719:INFO:create_model() successfully completed......................................
2023-04-29 20:07:27,856:INFO:SubProcess create_model() end ==================================
2023-04-29 20:07:27,856:INFO:Creating metrics dataframe
2023-04-29 20:07:27,861:INFO:Initializing Passive Aggressive Regressor
2023-04-29 20:07:27,861:INFO:Total runtime is 1.5841294248898825 minutes
2023-04-29 20:07:27,862:INFO:SubProcess create_model() called ==================================
2023-04-29 20:07:27,862:INFO:Initializing create_model()
2023-04-29 20:07:27,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:07:27,863:INFO:Checking exceptions
2023-04-29 20:07:27,863:INFO:Importing libraries
2023-04-29 20:07:27,863:INFO:Copying training dataset
2023-04-29 20:07:27,866:WARNING:Processing:  45%|###6    | 35/77 [01:35<01:29,  2.14s/it]
2023-04-29 20:07:27,866:INFO:Defining folds
2023-04-29 20:07:27,866:INFO:Declaring metric variables
2023-04-29 20:07:27,866:INFO:Importing untrained model
2023-04-29 20:07:27,867:INFO:Passive Aggressive Regressor Imported successfully
2023-04-29 20:07:27,867:INFO:Starting cross validation
2023-04-29 20:07:27,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:07:37,222:INFO:Calculating mean and std
2023-04-29 20:07:37,223:WARNING:Processing:  48%|###8    | 37/77 [01:44<02:07,  3.18s/it]
2023-04-29 20:07:37,223:INFO:Creating metrics dataframe
2023-04-29 20:07:38,252:WARNING:Processing:  49%|###9    | 38/77 [01:45<01:45,  2.69s/it]
2023-04-29 20:07:38,252:INFO:Uploading results into container
2023-04-29 20:07:38,253:INFO:Uploading model into container now
2023-04-29 20:07:38,253:INFO:_master_model_container: 9
2023-04-29 20:07:38,253:INFO:_display_container: 2
2023-04-29 20:07:38,254:INFO:PassiveAggressiveRegressor(random_state=8753)
2023-04-29 20:07:38,254:INFO:create_model() successfully completed......................................
2023-04-29 20:07:38,373:INFO:SubProcess create_model() end ==================================
2023-04-29 20:07:38,373:INFO:Creating metrics dataframe
2023-04-29 20:07:38,379:INFO:Initializing Huber Regressor
2023-04-29 20:07:38,379:INFO:Total runtime is 1.7594283143679301 minutes
2023-04-29 20:07:38,379:INFO:SubProcess create_model() called ==================================
2023-04-29 20:07:38,379:INFO:Initializing create_model()
2023-04-29 20:07:38,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:07:38,379:INFO:Checking exceptions
2023-04-29 20:07:38,379:INFO:Importing libraries
2023-04-29 20:07:38,379:INFO:Copying training dataset
2023-04-29 20:07:38,382:WARNING:Processing:  51%|####    | 39/77 [01:45<01:18,  2.07s/it]
2023-04-29 20:07:38,383:INFO:Defining folds
2023-04-29 20:07:38,383:INFO:Declaring metric variables
2023-04-29 20:07:38,383:INFO:Importing untrained model
2023-04-29 20:07:38,383:INFO:Huber Regressor Imported successfully
2023-04-29 20:07:38,383:INFO:Starting cross validation
2023-04-29 20:07:38,384:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:07:38,541:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 20:07:38,545:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 20:07:38,564:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 20:07:38,580:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 20:07:38,646:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 20:07:38,659:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-29 20:07:47,909:INFO:Calculating mean and std
2023-04-29 20:07:47,910:WARNING:Processing:  53%|####2   | 41/77 [01:55<01:54,  3.18s/it]
2023-04-29 20:07:47,911:INFO:Creating metrics dataframe
2023-04-29 20:07:48,912:WARNING:Processing:  55%|####3   | 42/77 [01:56<01:33,  2.68s/it]
2023-04-29 20:07:48,912:INFO:Uploading results into container
2023-04-29 20:07:48,913:INFO:Uploading model into container now
2023-04-29 20:07:48,914:INFO:_master_model_container: 10
2023-04-29 20:07:48,914:INFO:_display_container: 2
2023-04-29 20:07:48,914:INFO:HuberRegressor()
2023-04-29 20:07:48,914:INFO:create_model() successfully completed......................................
2023-04-29 20:07:49,028:INFO:SubProcess create_model() end ==================================
2023-04-29 20:07:49,028:INFO:Creating metrics dataframe
2023-04-29 20:07:49,032:INFO:Initializing K Neighbors Regressor
2023-04-29 20:07:49,032:INFO:Total runtime is 1.9369848330815633 minutes
2023-04-29 20:07:49,033:INFO:SubProcess create_model() called ==================================
2023-04-29 20:07:49,033:INFO:Initializing create_model()
2023-04-29 20:07:49,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:07:49,033:INFO:Checking exceptions
2023-04-29 20:07:49,033:INFO:Importing libraries
2023-04-29 20:07:49,033:INFO:Copying training dataset
2023-04-29 20:07:49,036:WARNING:Processing:  56%|####4   | 43/77 [01:56<01:09,  2.06s/it]
2023-04-29 20:07:49,036:INFO:Defining folds
2023-04-29 20:07:49,036:INFO:Declaring metric variables
2023-04-29 20:07:49,036:INFO:Importing untrained model
2023-04-29 20:07:49,037:INFO:K Neighbors Regressor Imported successfully
2023-04-29 20:07:49,037:INFO:Starting cross validation
2023-04-29 20:07:49,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:07:58,404:INFO:Calculating mean and std
2023-04-29 20:07:58,405:WARNING:Processing:  58%|####6   | 45/77 [02:05<01:40,  3.14s/it]
2023-04-29 20:07:58,405:INFO:Creating metrics dataframe
2023-04-29 20:07:59,426:WARNING:Processing:  60%|####7   | 46/77 [02:06<01:22,  2.66s/it]
2023-04-29 20:07:59,427:INFO:Uploading results into container
2023-04-29 20:07:59,427:INFO:Uploading model into container now
2023-04-29 20:07:59,428:INFO:_master_model_container: 11
2023-04-29 20:07:59,428:INFO:_display_container: 2
2023-04-29 20:07:59,428:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-29 20:07:59,428:INFO:create_model() successfully completed......................................
2023-04-29 20:07:59,545:INFO:SubProcess create_model() end ==================================
2023-04-29 20:07:59,545:INFO:Creating metrics dataframe
2023-04-29 20:07:59,549:INFO:Initializing Decision Tree Regressor
2023-04-29 20:07:59,549:INFO:Total runtime is 2.112266763051351 minutes
2023-04-29 20:07:59,550:INFO:SubProcess create_model() called ==================================
2023-04-29 20:07:59,550:INFO:Initializing create_model()
2023-04-29 20:07:59,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:07:59,550:INFO:Checking exceptions
2023-04-29 20:07:59,550:INFO:Importing libraries
2023-04-29 20:07:59,550:INFO:Copying training dataset
2023-04-29 20:07:59,553:WARNING:Processing:  61%|####8   | 47/77 [02:06<01:01,  2.04s/it]
2023-04-29 20:07:59,553:INFO:Defining folds
2023-04-29 20:07:59,553:INFO:Declaring metric variables
2023-04-29 20:07:59,554:INFO:Importing untrained model
2023-04-29 20:07:59,554:INFO:Decision Tree Regressor Imported successfully
2023-04-29 20:07:59,554:INFO:Starting cross validation
2023-04-29 20:07:59,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:08:09,031:INFO:Calculating mean and std
2023-04-29 20:08:09,032:WARNING:Processing:  64%|#####   | 49/77 [02:16<01:28,  3.15s/it]
2023-04-29 20:08:09,032:INFO:Creating metrics dataframe
2023-04-29 20:08:10,362:WARNING:Processing:  65%|#####1  | 50/77 [02:17<01:13,  2.74s/it]
2023-04-29 20:08:10,362:INFO:Uploading results into container
2023-04-29 20:08:10,363:INFO:Uploading model into container now
2023-04-29 20:08:10,364:INFO:_master_model_container: 12
2023-04-29 20:08:10,364:INFO:_display_container: 2
2023-04-29 20:08:10,364:INFO:DecisionTreeRegressor(random_state=8753)
2023-04-29 20:08:10,365:INFO:create_model() successfully completed......................................
2023-04-29 20:08:10,483:INFO:SubProcess create_model() end ==================================
2023-04-29 20:08:10,484:INFO:Creating metrics dataframe
2023-04-29 20:08:10,494:INFO:Initializing Random Forest Regressor
2023-04-29 20:08:10,494:INFO:Total runtime is 2.294681147734324 minutes
2023-04-29 20:08:10,495:INFO:SubProcess create_model() called ==================================
2023-04-29 20:08:10,495:INFO:Initializing create_model()
2023-04-29 20:08:10,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:08:10,496:INFO:Checking exceptions
2023-04-29 20:08:10,496:INFO:Importing libraries
2023-04-29 20:08:10,496:INFO:Copying training dataset
2023-04-29 20:08:10,504:WARNING:Processing:  66%|#####2  | 51/77 [02:17<00:54,  2.10s/it]
2023-04-29 20:08:10,504:INFO:Defining folds
2023-04-29 20:08:10,504:INFO:Declaring metric variables
2023-04-29 20:08:10,505:INFO:Importing untrained model
2023-04-29 20:08:10,506:INFO:Random Forest Regressor Imported successfully
2023-04-29 20:08:10,506:INFO:Starting cross validation
2023-04-29 20:08:10,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:08:21,542:INFO:Calculating mean and std
2023-04-29 20:08:21,543:WARNING:Processing:  69%|#####5  | 53/77 [02:28<01:24,  3.51s/it]
2023-04-29 20:08:21,543:INFO:Creating metrics dataframe
2023-04-29 20:08:22,807:WARNING:Processing:  70%|#####6  | 54/77 [02:29<01:08,  3.00s/it]
2023-04-29 20:08:22,807:INFO:Uploading results into container
2023-04-29 20:08:22,808:INFO:Uploading model into container now
2023-04-29 20:08:22,808:INFO:_master_model_container: 13
2023-04-29 20:08:22,808:INFO:_display_container: 2
2023-04-29 20:08:22,809:INFO:RandomForestRegressor(n_jobs=-1, random_state=8753)
2023-04-29 20:08:22,809:INFO:create_model() successfully completed......................................
2023-04-29 20:08:22,938:INFO:SubProcess create_model() end ==================================
2023-04-29 20:08:22,939:INFO:Creating metrics dataframe
2023-04-29 20:08:22,943:INFO:Initializing Extra Trees Regressor
2023-04-29 20:08:22,943:INFO:Total runtime is 2.502155844370524 minutes
2023-04-29 20:08:22,943:INFO:SubProcess create_model() called ==================================
2023-04-29 20:08:22,943:INFO:Initializing create_model()
2023-04-29 20:08:22,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:08:22,943:INFO:Checking exceptions
2023-04-29 20:08:22,944:INFO:Importing libraries
2023-04-29 20:08:22,944:INFO:Copying training dataset
2023-04-29 20:08:22,946:WARNING:Processing:  71%|#####7  | 55/77 [02:30<00:50,  2.30s/it]
2023-04-29 20:08:22,946:INFO:Defining folds
2023-04-29 20:08:22,947:INFO:Declaring metric variables
2023-04-29 20:08:22,947:INFO:Importing untrained model
2023-04-29 20:08:22,947:INFO:Extra Trees Regressor Imported successfully
2023-04-29 20:08:22,947:INFO:Starting cross validation
2023-04-29 20:08:22,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:08:33,647:INFO:Calculating mean and std
2023-04-29 20:08:33,648:WARNING:Processing:  74%|#####9  | 57/77 [02:40<01:11,  3.56s/it]
2023-04-29 20:08:33,648:INFO:Creating metrics dataframe
2023-04-29 20:08:34,775:WARNING:Processing:  75%|######  | 58/77 [02:41<00:57,  3.00s/it]
2023-04-29 20:08:34,775:INFO:Uploading results into container
2023-04-29 20:08:34,776:INFO:Uploading model into container now
2023-04-29 20:08:34,776:INFO:_master_model_container: 14
2023-04-29 20:08:34,776:INFO:_display_container: 2
2023-04-29 20:08:34,777:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8753)
2023-04-29 20:08:34,777:INFO:create_model() successfully completed......................................
2023-04-29 20:08:34,932:INFO:SubProcess create_model() end ==================================
2023-04-29 20:08:34,933:INFO:Creating metrics dataframe
2023-04-29 20:08:34,937:INFO:Initializing AdaBoost Regressor
2023-04-29 20:08:34,937:INFO:Total runtime is 2.7020557006200154 minutes
2023-04-29 20:08:34,937:INFO:SubProcess create_model() called ==================================
2023-04-29 20:08:34,937:INFO:Initializing create_model()
2023-04-29 20:08:34,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:08:34,938:INFO:Checking exceptions
2023-04-29 20:08:34,938:INFO:Importing libraries
2023-04-29 20:08:34,938:INFO:Copying training dataset
2023-04-29 20:08:34,941:WARNING:Processing:  77%|######1 | 59/77 [02:42<00:41,  2.31s/it]
2023-04-29 20:08:34,941:INFO:Defining folds
2023-04-29 20:08:34,941:INFO:Declaring metric variables
2023-04-29 20:08:34,941:INFO:Importing untrained model
2023-04-29 20:08:34,942:INFO:AdaBoost Regressor Imported successfully
2023-04-29 20:08:34,942:INFO:Starting cross validation
2023-04-29 20:08:34,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:08:45,577:INFO:Calculating mean and std
2023-04-29 20:08:45,577:WARNING:Processing:  79%|######3 | 61/77 [02:52<00:56,  3.55s/it]
2023-04-29 20:08:45,577:INFO:Creating metrics dataframe
2023-04-29 20:08:47,269:WARNING:Processing:  81%|######4 | 62/77 [02:54<00:46,  3.13s/it]
2023-04-29 20:08:47,270:INFO:Uploading results into container
2023-04-29 20:08:47,270:INFO:Uploading model into container now
2023-04-29 20:08:47,271:INFO:_master_model_container: 15
2023-04-29 20:08:47,271:INFO:_display_container: 2
2023-04-29 20:08:47,271:INFO:AdaBoostRegressor(random_state=8753)
2023-04-29 20:08:47,272:INFO:create_model() successfully completed......................................
2023-04-29 20:08:47,393:INFO:SubProcess create_model() end ==================================
2023-04-29 20:08:47,393:INFO:Creating metrics dataframe
2023-04-29 20:08:47,398:INFO:Initializing Gradient Boosting Regressor
2023-04-29 20:08:47,398:INFO:Total runtime is 2.909753171602885 minutes
2023-04-29 20:08:47,398:INFO:SubProcess create_model() called ==================================
2023-04-29 20:08:47,399:INFO:Initializing create_model()
2023-04-29 20:08:47,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:08:47,399:INFO:Checking exceptions
2023-04-29 20:08:47,399:INFO:Importing libraries
2023-04-29 20:08:47,399:INFO:Copying training dataset
2023-04-29 20:08:47,403:WARNING:Processing:  82%|######5 | 63/77 [02:54<00:33,  2.39s/it]
2023-04-29 20:08:47,403:INFO:Defining folds
2023-04-29 20:08:47,403:INFO:Declaring metric variables
2023-04-29 20:08:47,403:INFO:Importing untrained model
2023-04-29 20:08:47,403:INFO:Gradient Boosting Regressor Imported successfully
2023-04-29 20:08:47,403:INFO:Starting cross validation
2023-04-29 20:08:47,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:08:58,148:INFO:Calculating mean and std
2023-04-29 20:08:58,149:WARNING:Processing:  84%|######7 | 65/77 [03:05<00:43,  3.62s/it]
2023-04-29 20:08:58,149:INFO:Creating metrics dataframe
2023-04-29 20:08:59,158:WARNING:Processing:  86%|######8 | 66/77 [03:06<00:33,  3.03s/it]
2023-04-29 20:08:59,159:INFO:Uploading results into container
2023-04-29 20:08:59,159:INFO:Uploading model into container now
2023-04-29 20:08:59,160:INFO:_master_model_container: 16
2023-04-29 20:08:59,160:INFO:_display_container: 2
2023-04-29 20:08:59,160:INFO:GradientBoostingRegressor(random_state=8753)
2023-04-29 20:08:59,160:INFO:create_model() successfully completed......................................
2023-04-29 20:08:59,281:INFO:SubProcess create_model() end ==================================
2023-04-29 20:08:59,282:INFO:Creating metrics dataframe
2023-04-29 20:08:59,286:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 20:08:59,286:INFO:Total runtime is 3.1078742027282718 minutes
2023-04-29 20:08:59,286:INFO:SubProcess create_model() called ==================================
2023-04-29 20:08:59,286:INFO:Initializing create_model()
2023-04-29 20:08:59,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:08:59,286:INFO:Checking exceptions
2023-04-29 20:08:59,287:INFO:Importing libraries
2023-04-29 20:08:59,287:INFO:Copying training dataset
2023-04-29 20:08:59,289:WARNING:Processing:  87%|######9 | 67/77 [03:06<00:23,  2.32s/it]
2023-04-29 20:08:59,289:INFO:Defining folds
2023-04-29 20:08:59,290:INFO:Declaring metric variables
2023-04-29 20:08:59,290:INFO:Importing untrained model
2023-04-29 20:08:59,291:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 20:08:59,291:INFO:Starting cross validation
2023-04-29 20:08:59,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:09:09,234:INFO:Calculating mean and std
2023-04-29 20:09:09,235:WARNING:Processing:  90%|#######1| 69/77 [03:16<00:27,  3.41s/it]
2023-04-29 20:09:09,235:INFO:Creating metrics dataframe
2023-04-29 20:09:11,042:WARNING:Processing:  91%|#######2| 70/77 [03:18<00:21,  3.05s/it]
2023-04-29 20:09:11,043:INFO:Uploading results into container
2023-04-29 20:09:11,044:INFO:Uploading model into container now
2023-04-29 20:09:11,045:INFO:_master_model_container: 17
2023-04-29 20:09:11,045:INFO:_display_container: 2
2023-04-29 20:09:11,045:INFO:LGBMRegressor(random_state=8753)
2023-04-29 20:09:11,045:INFO:create_model() successfully completed......................................
2023-04-29 20:09:11,182:INFO:SubProcess create_model() end ==================================
2023-04-29 20:09:11,182:INFO:Creating metrics dataframe
2023-04-29 20:09:11,186:INFO:Initializing Dummy Regressor
2023-04-29 20:09:11,187:INFO:Total runtime is 3.30622539917628 minutes
2023-04-29 20:09:11,187:INFO:SubProcess create_model() called ==================================
2023-04-29 20:09:11,187:INFO:Initializing create_model()
2023-04-29 20:09:11,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236EEF88640>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:09:11,187:INFO:Checking exceptions
2023-04-29 20:09:11,187:INFO:Importing libraries
2023-04-29 20:09:11,187:INFO:Copying training dataset
2023-04-29 20:09:11,191:WARNING:Processing:  92%|#######3| 71/77 [03:18<00:14,  2.34s/it]
2023-04-29 20:09:11,191:INFO:Defining folds
2023-04-29 20:09:11,191:INFO:Declaring metric variables
2023-04-29 20:09:11,191:INFO:Importing untrained model
2023-04-29 20:09:11,191:INFO:Dummy Regressor Imported successfully
2023-04-29 20:09:11,192:INFO:Starting cross validation
2023-04-29 20:09:11,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 20:09:21,233:INFO:Calculating mean and std
2023-04-29 20:09:21,234:WARNING:Processing:  95%|#######5| 73/77 [03:28<00:13,  3.44s/it]
2023-04-29 20:09:21,234:INFO:Creating metrics dataframe
2023-04-29 20:09:22,693:WARNING:Processing:  96%|#######6| 74/77 [03:29<00:08,  2.99s/it]
2023-04-29 20:09:22,693:INFO:Uploading results into container
2023-04-29 20:09:22,694:INFO:Uploading model into container now
2023-04-29 20:09:22,694:INFO:_master_model_container: 18
2023-04-29 20:09:22,694:INFO:_display_container: 2
2023-04-29 20:09:22,694:INFO:DummyRegressor()
2023-04-29 20:09:22,694:INFO:create_model() successfully completed......................................
2023-04-29 20:09:22,808:INFO:SubProcess create_model() end ==================================
2023-04-29 20:09:22,809:INFO:Creating metrics dataframe
2023-04-29 20:09:22,814:WARNING:Processing:  97%|#######7| 75/77 [03:30<00:04,  2.29s/it]
2023-04-29 20:09:22,816:INFO:Initializing create_model()
2023-04-29 20:09:22,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8753), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 20:09:22,816:INFO:Checking exceptions
2023-04-29 20:09:22,816:INFO:Importing libraries
2023-04-29 20:09:22,817:INFO:Copying training dataset
2023-04-29 20:09:22,819:INFO:Defining folds
2023-04-29 20:09:22,819:INFO:Declaring metric variables
2023-04-29 20:09:22,820:INFO:Importing untrained model
2023-04-29 20:09:22,820:INFO:Declaring custom model
2023-04-29 20:09:22,820:INFO:Extra Trees Regressor Imported successfully
2023-04-29 20:09:22,821:INFO:Cross validation set to False
2023-04-29 20:09:22,821:INFO:Fitting Model
2023-04-29 20:09:23,627:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8753)
2023-04-29 20:09:23,627:INFO:create_model() successfully completed......................................
2023-04-29 20:09:23,776:WARNING:Processing: 100%|########| 77/77 [03:30<00:00,  1.54s/it]
2023-04-29 20:09:23,777:WARNING:                                                         
2023-04-29 20:09:23,791:INFO:                                    Model     MAE     MSE    RMSE      R2  \
2023-04-29 20:09:23,791:INFO:et                  Extra Trees Regressor  0.1526  0.2141  0.4438  0.9589   
2023-04-29 20:09:23,791:INFO:rf                Random Forest Regressor  0.2091  0.3039  0.5371  0.9409   
2023-04-29 20:09:23,791:INFO:gbr           Gradient Boosting Regressor  0.4054  0.4639  0.6726  0.9079   
2023-04-29 20:09:23,791:INFO:dt                Decision Tree Regressor  0.2233  0.4591  0.6578  0.9069   
2023-04-29 20:09:23,791:INFO:lightgbm  Light Gradient Boosting Machine  0.2841  0.4916  0.6787  0.9057   
2023-04-29 20:09:23,791:INFO:knn                 K Neighbors Regressor  0.4784  1.0200  0.9773  0.8099   
2023-04-29 20:09:23,791:INFO:ada                    AdaBoost Regressor  0.8685  1.1924  1.0892  0.7487   
2023-04-29 20:09:23,791:INFO:br                         Bayesian Ridge  1.1281  2.6207  1.5959  0.4916   
2023-04-29 20:09:23,791:INFO:ridge                    Ridge Regression  1.1311  2.6392  1.6021  0.4865   
2023-04-29 20:09:23,791:INFO:lr                      Linear Regression  1.1316  2.6432  1.6034  0.4854   
2023-04-29 20:09:23,791:INFO:lar                Least Angle Regression  1.1316  2.6432  1.6034  0.4854   
2023-04-29 20:09:23,791:INFO:en                            Elastic Net  1.2700  3.2013  1.7586  0.3848   
2023-04-29 20:09:23,792:INFO:lasso                    Lasso Regression  1.3161  3.4341  1.8217  0.3407   
2023-04-29 20:09:23,792:INFO:huber                     Huber Regressor  1.1449  3.6259  1.8084  0.2488   
2023-04-29 20:09:23,792:INFO:omp           Orthogonal Matching Pursuit  1.6139  4.5572  2.0996  0.1289   
2023-04-29 20:09:23,792:INFO:par          Passive Aggressive Regressor  1.6179  4.5030  2.0845  0.1209   
2023-04-29 20:09:23,792:INFO:llar         Lasso Least Angle Regression  1.6772  5.1934  2.2526 -0.0070   
2023-04-29 20:09:23,792:INFO:dummy                     Dummy Regressor  1.6772  5.1934  2.2526 -0.0070   
2023-04-29 20:09:23,792:INFO:
2023-04-29 20:09:23,792:INFO:           RMSLE    MAPE  TT (Sec)  
2023-04-29 20:09:23,792:INFO:et        0.0721  0.0350     1.070  
2023-04-29 20:09:23,792:INFO:rf        0.0840  0.0458     1.103  
2023-04-29 20:09:23,792:INFO:gbr       0.1195  0.1128     1.074  
2023-04-29 20:09:23,792:INFO:dt        0.1075  0.0497     0.948  
2023-04-29 20:09:23,792:INFO:lightgbm  0.0978  0.0596     0.994  
2023-04-29 20:09:23,792:INFO:knn       0.1557  0.1109     0.937  
2023-04-29 20:09:23,792:INFO:ada       0.2674  0.3747     1.063  
2023-04-29 20:09:23,792:INFO:br        0.3057  0.3982     0.948  
2023-04-29 20:09:23,792:INFO:ridge     0.3057  0.3970     0.931  
2023-04-29 20:09:23,792:INFO:lr        0.3058  0.3969     1.574  
2023-04-29 20:09:23,792:INFO:lar       0.3058  0.3969     0.978  
2023-04-29 20:09:23,792:INFO:en        0.3685  0.5352     0.953  
2023-04-29 20:09:23,792:INFO:lasso     0.3861  0.5712     0.971  
2023-04-29 20:09:23,792:INFO:huber     0.3116  0.4018     0.953  
2023-04-29 20:09:23,792:INFO:omp       0.4244  0.6416     0.949  
2023-04-29 20:09:23,792:INFO:par       0.4142  0.5738     0.935  
2023-04-29 20:09:23,792:INFO:llar      0.4693  0.7525     0.958  
2023-04-29 20:09:23,792:INFO:dummy     0.4693  0.7525     1.004  
2023-04-29 20:09:23,792:INFO:_master_model_container: 18
2023-04-29 20:09:23,792:INFO:_display_container: 2
2023-04-29 20:09:23,793:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8753)
2023-04-29 20:09:23,793:INFO:compare_models() successfully completed......................................
2023-04-29 20:09:23,796:INFO:Initializing predict_model()
2023-04-29 20:09:23,797:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000236E5B16820>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8753), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000236F17B0F70>)
2023-04-29 20:09:23,798:INFO:Checking exceptions
2023-04-29 20:09:23,798:INFO:Preloading libraries
2023-04-29 20:09:23,798:INFO:Set up data.
2023-04-29 20:09:23,802:INFO:Set up index.
2023-04-29 20:09:23,864:INFO:                   Model     MAE  ...  RMSLE    MAPE
2023-04-29 20:09:23,864:INFO:0  Extra Trees Regressor  0.0503  ...  0.054  0.0208
2023-04-29 20:09:23,864:INFO:
2023-04-29 20:09:23,864:INFO:[1 rows x 7 columns]
2023-04-29 23:05:52,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 23:05:52,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 23:05:52,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 23:05:52,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 23:05:54,052:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-30 00:51:50,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-30 00:51:50,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-30 00:51:50,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-30 00:51:50,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-30 00:51:57,503:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-01 10:31:24,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 10:31:24,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 10:31:24,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 10:31:24,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 10:31:36,006:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-01 19:09:30,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 19:09:30,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 19:09:30,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 19:09:30,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-01 19:09:38,353:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-02 09:30:22,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 09:30:22,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 09:30:22,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 09:30:22,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 09:30:34,794:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-02 09:56:57,223:INFO:PyCaret RegressionExperiment
2023-05-02 09:56:57,223:INFO:Logging name: reg-default-name
2023-05-02 09:56:57,223:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-02 09:56:57,223:INFO:version 3.0.0
2023-05-02 09:56:57,223:INFO:Initializing setup()
2023-05-02 09:56:57,223:INFO:self.USI: 6d2c
2023-05-02 09:56:57,223:INFO:self._variable_keys: {'exp_name_log', 'data', 'fold_groups_param', 'USI', 'log_plots_param', 'X_train', 'X_test', '_available_plots', 'y', 'idx', 'html_param', 'y_train', 'exp_id', 'gpu_n_jobs_param', 'seed', 'n_jobs_param', 'memory', 'X', 'fold_generator', 'y_test', 'fold_shuffle_param', 'transform_target_param', 'pipeline', 'logging_param', 'gpu_param', '_ml_usecase', 'target_param'}
2023-05-02 09:56:57,223:INFO:Checking environment
2023-05-02 09:56:57,223:INFO:python_version: 3.9.13
2023-05-02 09:56:57,223:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-05-02 09:56:57,224:INFO:machine: AMD64
2023-05-02 09:56:57,246:INFO:platform: Windows-10-10.0.22000-SP0
2023-05-02 09:56:57,246:INFO:Memory: svmem(total=16935899136, available=5905588224, percent=65.1, used=11030310912, free=5905588224)
2023-05-02 09:56:57,246:INFO:Physical Core: 4
2023-05-02 09:56:57,246:INFO:Logical Core: 8
2023-05-02 09:56:57,246:INFO:Checking libraries
2023-05-02 09:56:57,246:INFO:System:
2023-05-02 09:56:57,246:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-05-02 09:56:57,246:INFO:executable: D:\Anaconda\python.exe
2023-05-02 09:56:57,246:INFO:   machine: Windows-10-10.0.22000-SP0
2023-05-02 09:56:57,246:INFO:PyCaret required dependencies:
2023-05-02 09:56:57,246:INFO:                 pip: 22.2.2
2023-05-02 09:56:57,246:INFO:          setuptools: 63.4.1
2023-05-02 09:56:57,246:INFO:             pycaret: 3.0.0
2023-05-02 09:56:57,246:INFO:             IPython: 7.31.1
2023-05-02 09:56:57,246:INFO:          ipywidgets: 7.6.5
2023-05-02 09:56:57,247:INFO:                tqdm: 4.64.1
2023-05-02 09:56:57,247:INFO:               numpy: 1.21.5
2023-05-02 09:56:57,247:INFO:              pandas: 1.4.4
2023-05-02 09:56:57,247:INFO:              jinja2: 2.11.3
2023-05-02 09:56:57,247:INFO:               scipy: 1.9.1
2023-05-02 09:56:57,247:INFO:              joblib: 1.2.0
2023-05-02 09:56:57,247:INFO:             sklearn: 1.0.2
2023-05-02 09:56:57,247:INFO:                pyod: 1.0.9
2023-05-02 09:56:57,247:INFO:            imblearn: 0.10.1
2023-05-02 09:56:57,247:INFO:   category_encoders: 2.6.0
2023-05-02 09:56:57,247:INFO:            lightgbm: 3.3.5
2023-05-02 09:56:57,247:INFO:               numba: 0.55.1
2023-05-02 09:56:57,247:INFO:            requests: 2.28.1
2023-05-02 09:56:57,247:INFO:          matplotlib: 3.5.2
2023-05-02 09:56:57,247:INFO:          scikitplot: 0.3.7
2023-05-02 09:56:57,247:INFO:         yellowbrick: 1.5
2023-05-02 09:56:57,247:INFO:              plotly: 5.9.0
2023-05-02 09:56:57,247:INFO:             kaleido: 0.2.1
2023-05-02 09:56:57,247:INFO:         statsmodels: 0.13.2
2023-05-02 09:56:57,247:INFO:              sktime: 0.17.1
2023-05-02 09:56:57,247:INFO:               tbats: 1.1.2
2023-05-02 09:56:57,247:INFO:            pmdarima: 2.0.3
2023-05-02 09:56:57,247:INFO:              psutil: 5.9.0
2023-05-02 09:56:57,247:INFO:PyCaret optional dependencies:
2023-05-02 09:56:57,258:INFO:                shap: 0.41.0
2023-05-02 09:56:57,258:INFO:           interpret: Not installed
2023-05-02 09:56:57,258:INFO:                umap: Not installed
2023-05-02 09:56:57,258:INFO:    pandas_profiling: 4.1.2
2023-05-02 09:56:57,258:INFO:  explainerdashboard: Not installed
2023-05-02 09:56:57,258:INFO:             autoviz: Not installed
2023-05-02 09:56:57,258:INFO:           fairlearn: Not installed
2023-05-02 09:56:57,258:INFO:             xgboost: Not installed
2023-05-02 09:56:57,258:INFO:            catboost: Not installed
2023-05-02 09:56:57,258:INFO:              kmodes: Not installed
2023-05-02 09:56:57,258:INFO:             mlxtend: Not installed
2023-05-02 09:56:57,258:INFO:       statsforecast: Not installed
2023-05-02 09:56:57,258:INFO:        tune_sklearn: Not installed
2023-05-02 09:56:57,258:INFO:                 ray: Not installed
2023-05-02 09:56:57,258:INFO:            hyperopt: Not installed
2023-05-02 09:56:57,258:INFO:              optuna: Not installed
2023-05-02 09:56:57,258:INFO:               skopt: Not installed
2023-05-02 09:56:57,258:INFO:              mlflow: 2.2.1
2023-05-02 09:56:57,258:INFO:              gradio: Not installed
2023-05-02 09:56:57,259:INFO:             fastapi: Not installed
2023-05-02 09:56:57,259:INFO:             uvicorn: Not installed
2023-05-02 09:56:57,259:INFO:              m2cgen: Not installed
2023-05-02 09:56:57,259:INFO:           evidently: Not installed
2023-05-02 09:56:57,259:INFO:               fugue: Not installed
2023-05-02 09:56:57,259:INFO:           streamlit: 1.21.0
2023-05-02 09:56:57,259:INFO:             prophet: Not installed
2023-05-02 09:56:57,259:INFO:None
2023-05-02 09:56:57,259:INFO:Set up data.
2023-05-02 09:56:57,263:INFO:Set up train/test split.
2023-05-02 09:56:57,595:INFO:Set up index.
2023-05-02 09:56:57,595:INFO:Set up folding strategy.
2023-05-02 09:56:57,595:INFO:Assigning column types.
2023-05-02 09:56:57,603:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-02 09:56:57,603:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-02 09:56:57,615:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 09:56:57,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 09:56:57,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:57,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:57,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,381:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,397:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,405:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,517:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,519:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-02 09:56:58,524:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,528:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,765:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-02 09:56:58,774:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:58,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 09:56:58,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,023:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-02 09:56:59,087:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-02 09:56:59,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 09:56:59,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,509:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-02 09:56:59,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:56:59,734:INFO:Preparing preprocessing pipeline...
2023-05-02 09:56:59,734:INFO:Set up simple imputation.
2023-05-02 09:56:59,735:INFO:Set up column name cleaning.
2023-05-02 09:56:59,811:INFO:Finished creating preprocessing pipeline.
2023-05-02 09:56:59,851:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-02 09:56:59,852:INFO:Creating final display dataframe.
2023-05-02 09:57:00,022:INFO:Setup _display_container:                     Description             Value
0                    Session id              6797
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              6d2c
2023-05-02 09:57:00,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:57:00,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:57:00,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:57:00,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 09:57:00,277:INFO:setup() successfully completed in 5.34s...............
2023-05-02 09:57:00,313:INFO:Initializing compare_models()
2023-05-02 09:57:00,313:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-02 09:57:00,313:INFO:Checking exceptions
2023-05-02 09:57:00,316:INFO:Preparing display monitor
2023-05-02 09:57:00,326:INFO:Initializing Linear Regression
2023-05-02 09:57:00,327:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-05-02 09:57:00,327:INFO:SubProcess create_model() called ==================================
2023-05-02 09:57:00,328:INFO:Initializing create_model()
2023-05-02 09:57:00,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:57:00,328:INFO:Checking exceptions
2023-05-02 09:57:00,329:INFO:Importing libraries
2023-05-02 09:57:00,329:INFO:Copying training dataset
2023-05-02 09:57:00,340:INFO:Defining folds
2023-05-02 09:57:00,340:INFO:Declaring metric variables
2023-05-02 09:57:00,341:INFO:Importing untrained model
2023-05-02 09:57:00,342:INFO:Linear Regression Imported successfully
2023-05-02 09:57:00,342:INFO:Starting cross validation
2023-05-02 09:57:00,408:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:57:16,099:INFO:Calculating mean and std
2023-05-02 09:57:16,100:INFO:Creating metrics dataframe
2023-05-02 09:57:17,032:INFO:Uploading results into container
2023-05-02 09:57:17,032:INFO:Uploading model into container now
2023-05-02 09:57:17,033:INFO:_master_model_container: 1
2023-05-02 09:57:17,033:INFO:_display_container: 2
2023-05-02 09:57:17,033:INFO:LinearRegression(n_jobs=-1)
2023-05-02 09:57:17,033:INFO:create_model() successfully completed......................................
2023-05-02 09:57:17,197:INFO:SubProcess create_model() end ==================================
2023-05-02 09:57:17,198:INFO:Creating metrics dataframe
2023-05-02 09:57:17,201:INFO:Initializing Lasso Regression
2023-05-02 09:57:17,201:INFO:Total runtime is 0.28125461339950564 minutes
2023-05-02 09:57:17,201:INFO:SubProcess create_model() called ==================================
2023-05-02 09:57:17,201:INFO:Initializing create_model()
2023-05-02 09:57:17,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:57:17,201:INFO:Checking exceptions
2023-05-02 09:57:17,202:INFO:Importing libraries
2023-05-02 09:57:17,202:INFO:Copying training dataset
2023-05-02 09:57:17,206:INFO:Defining folds
2023-05-02 09:57:17,206:INFO:Declaring metric variables
2023-05-02 09:57:17,206:INFO:Importing untrained model
2023-05-02 09:57:17,207:INFO:Lasso Regression Imported successfully
2023-05-02 09:57:17,207:INFO:Starting cross validation
2023-05-02 09:57:17,208:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:57:25,276:INFO:Calculating mean and std
2023-05-02 09:57:25,278:INFO:Creating metrics dataframe
2023-05-02 09:57:26,315:INFO:Uploading results into container
2023-05-02 09:57:26,315:INFO:Uploading model into container now
2023-05-02 09:57:26,316:INFO:_master_model_container: 2
2023-05-02 09:57:26,316:INFO:_display_container: 2
2023-05-02 09:57:26,316:INFO:Lasso(random_state=6797)
2023-05-02 09:57:26,316:INFO:create_model() successfully completed......................................
2023-05-02 09:57:26,466:INFO:SubProcess create_model() end ==================================
2023-05-02 09:57:26,466:INFO:Creating metrics dataframe
2023-05-02 09:57:26,471:INFO:Initializing Ridge Regression
2023-05-02 09:57:26,471:INFO:Total runtime is 0.435750170548757 minutes
2023-05-02 09:57:26,471:INFO:SubProcess create_model() called ==================================
2023-05-02 09:57:26,471:INFO:Initializing create_model()
2023-05-02 09:57:26,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:57:26,472:INFO:Checking exceptions
2023-05-02 09:57:26,472:INFO:Importing libraries
2023-05-02 09:57:26,472:INFO:Copying training dataset
2023-05-02 09:57:26,476:INFO:Defining folds
2023-05-02 09:57:26,478:INFO:Declaring metric variables
2023-05-02 09:57:26,478:INFO:Importing untrained model
2023-05-02 09:57:26,479:INFO:Ridge Regression Imported successfully
2023-05-02 09:57:26,479:INFO:Starting cross validation
2023-05-02 09:57:26,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:57:34,842:INFO:Calculating mean and std
2023-05-02 09:57:34,843:INFO:Creating metrics dataframe
2023-05-02 09:57:35,733:INFO:Uploading results into container
2023-05-02 09:57:35,734:INFO:Uploading model into container now
2023-05-02 09:57:35,735:INFO:_master_model_container: 3
2023-05-02 09:57:35,735:INFO:_display_container: 2
2023-05-02 09:57:35,735:INFO:Ridge(random_state=6797)
2023-05-02 09:57:35,735:INFO:create_model() successfully completed......................................
2023-05-02 09:57:35,873:INFO:SubProcess create_model() end ==================================
2023-05-02 09:57:35,873:INFO:Creating metrics dataframe
2023-05-02 09:57:35,877:INFO:Initializing Elastic Net
2023-05-02 09:57:35,877:INFO:Total runtime is 0.5925208767255148 minutes
2023-05-02 09:57:35,877:INFO:SubProcess create_model() called ==================================
2023-05-02 09:57:35,877:INFO:Initializing create_model()
2023-05-02 09:57:35,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:57:35,877:INFO:Checking exceptions
2023-05-02 09:57:35,878:INFO:Importing libraries
2023-05-02 09:57:35,878:INFO:Copying training dataset
2023-05-02 09:57:35,881:INFO:Defining folds
2023-05-02 09:57:35,881:INFO:Declaring metric variables
2023-05-02 09:57:35,881:INFO:Importing untrained model
2023-05-02 09:57:35,882:INFO:Elastic Net Imported successfully
2023-05-02 09:57:35,882:INFO:Starting cross validation
2023-05-02 09:57:35,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:57:44,113:INFO:Calculating mean and std
2023-05-02 09:57:44,114:INFO:Creating metrics dataframe
2023-05-02 09:57:45,147:INFO:Uploading results into container
2023-05-02 09:57:45,148:INFO:Uploading model into container now
2023-05-02 09:57:45,149:INFO:_master_model_container: 4
2023-05-02 09:57:45,149:INFO:_display_container: 2
2023-05-02 09:57:45,149:INFO:ElasticNet(random_state=6797)
2023-05-02 09:57:45,149:INFO:create_model() successfully completed......................................
2023-05-02 09:57:45,294:INFO:SubProcess create_model() end ==================================
2023-05-02 09:57:45,294:INFO:Creating metrics dataframe
2023-05-02 09:57:45,303:INFO:Initializing Least Angle Regression
2023-05-02 09:57:45,303:INFO:Total runtime is 0.749623731772105 minutes
2023-05-02 09:57:45,304:INFO:SubProcess create_model() called ==================================
2023-05-02 09:57:45,304:INFO:Initializing create_model()
2023-05-02 09:57:45,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:57:45,304:INFO:Checking exceptions
2023-05-02 09:57:45,305:INFO:Importing libraries
2023-05-02 09:57:45,305:INFO:Copying training dataset
2023-05-02 09:57:45,314:INFO:Defining folds
2023-05-02 09:57:45,314:INFO:Declaring metric variables
2023-05-02 09:57:45,315:INFO:Importing untrained model
2023-05-02 09:57:45,316:INFO:Least Angle Regression Imported successfully
2023-05-02 09:57:45,318:INFO:Starting cross validation
2023-05-02 09:57:45,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:57:45,740:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:57:45,740:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:57:47,757:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:57:47,763:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:57:53,890:INFO:Calculating mean and std
2023-05-02 09:57:53,891:INFO:Creating metrics dataframe
2023-05-02 09:57:54,908:INFO:Uploading results into container
2023-05-02 09:57:54,909:INFO:Uploading model into container now
2023-05-02 09:57:54,909:INFO:_master_model_container: 5
2023-05-02 09:57:54,909:INFO:_display_container: 2
2023-05-02 09:57:54,910:INFO:Lars(random_state=6797)
2023-05-02 09:57:54,910:INFO:create_model() successfully completed......................................
2023-05-02 09:57:55,059:INFO:SubProcess create_model() end ==================================
2023-05-02 09:57:55,059:INFO:Creating metrics dataframe
2023-05-02 09:57:55,065:INFO:Initializing Lasso Least Angle Regression
2023-05-02 09:57:55,065:INFO:Total runtime is 0.9123108347256979 minutes
2023-05-02 09:57:55,065:INFO:SubProcess create_model() called ==================================
2023-05-02 09:57:55,065:INFO:Initializing create_model()
2023-05-02 09:57:55,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:57:55,066:INFO:Checking exceptions
2023-05-02 09:57:55,066:INFO:Importing libraries
2023-05-02 09:57:55,066:INFO:Copying training dataset
2023-05-02 09:57:55,070:INFO:Defining folds
2023-05-02 09:57:55,071:INFO:Declaring metric variables
2023-05-02 09:57:55,071:INFO:Importing untrained model
2023-05-02 09:57:55,072:INFO:Lasso Least Angle Regression Imported successfully
2023-05-02 09:57:55,072:INFO:Starting cross validation
2023-05-02 09:57:55,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:57:55,190:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,206:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,223:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,245:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,263:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,271:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,290:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:55,310:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:57,085:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:57:57,160:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 09:58:03,302:INFO:Calculating mean and std
2023-05-02 09:58:03,303:INFO:Creating metrics dataframe
2023-05-02 09:58:04,251:INFO:Uploading results into container
2023-05-02 09:58:04,252:INFO:Uploading model into container now
2023-05-02 09:58:04,252:INFO:_master_model_container: 6
2023-05-02 09:58:04,252:INFO:_display_container: 2
2023-05-02 09:58:04,253:INFO:LassoLars(random_state=6797)
2023-05-02 09:58:04,253:INFO:create_model() successfully completed......................................
2023-05-02 09:58:04,401:INFO:SubProcess create_model() end ==================================
2023-05-02 09:58:04,401:INFO:Creating metrics dataframe
2023-05-02 09:58:04,412:INFO:Initializing Orthogonal Matching Pursuit
2023-05-02 09:58:04,412:INFO:Total runtime is 1.0681044896443685 minutes
2023-05-02 09:58:04,413:INFO:SubProcess create_model() called ==================================
2023-05-02 09:58:04,413:INFO:Initializing create_model()
2023-05-02 09:58:04,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:58:04,413:INFO:Checking exceptions
2023-05-02 09:58:04,413:INFO:Importing libraries
2023-05-02 09:58:04,414:INFO:Copying training dataset
2023-05-02 09:58:04,421:INFO:Defining folds
2023-05-02 09:58:04,422:INFO:Declaring metric variables
2023-05-02 09:58:04,422:INFO:Importing untrained model
2023-05-02 09:58:04,423:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-02 09:58:04,423:INFO:Starting cross validation
2023-05-02 09:58:04,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:58:04,511:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,522:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,535:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,542:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,557:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,578:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,598:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:04,615:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:06,474:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:06,490:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 09:58:12,580:INFO:Calculating mean and std
2023-05-02 09:58:12,581:INFO:Creating metrics dataframe
2023-05-02 09:58:13,592:INFO:Uploading results into container
2023-05-02 09:58:13,593:INFO:Uploading model into container now
2023-05-02 09:58:13,594:INFO:_master_model_container: 7
2023-05-02 09:58:13,594:INFO:_display_container: 2
2023-05-02 09:58:13,594:INFO:OrthogonalMatchingPursuit()
2023-05-02 09:58:13,594:INFO:create_model() successfully completed......................................
2023-05-02 09:58:13,742:INFO:SubProcess create_model() end ==================================
2023-05-02 09:58:13,742:INFO:Creating metrics dataframe
2023-05-02 09:58:13,746:INFO:Initializing Bayesian Ridge
2023-05-02 09:58:13,746:INFO:Total runtime is 1.2236746470133464 minutes
2023-05-02 09:58:13,746:INFO:SubProcess create_model() called ==================================
2023-05-02 09:58:13,747:INFO:Initializing create_model()
2023-05-02 09:58:13,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:58:13,747:INFO:Checking exceptions
2023-05-02 09:58:13,747:INFO:Importing libraries
2023-05-02 09:58:13,747:INFO:Copying training dataset
2023-05-02 09:58:13,750:INFO:Defining folds
2023-05-02 09:58:13,750:INFO:Declaring metric variables
2023-05-02 09:58:13,750:INFO:Importing untrained model
2023-05-02 09:58:13,750:INFO:Bayesian Ridge Imported successfully
2023-05-02 09:58:13,752:INFO:Starting cross validation
2023-05-02 09:58:13,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:58:22,392:INFO:Calculating mean and std
2023-05-02 09:58:22,393:INFO:Creating metrics dataframe
2023-05-02 09:58:23,306:INFO:Uploading results into container
2023-05-02 09:58:23,307:INFO:Uploading model into container now
2023-05-02 09:58:23,307:INFO:_master_model_container: 8
2023-05-02 09:58:23,307:INFO:_display_container: 2
2023-05-02 09:58:23,307:INFO:BayesianRidge()
2023-05-02 09:58:23,307:INFO:create_model() successfully completed......................................
2023-05-02 09:58:23,452:INFO:SubProcess create_model() end ==================================
2023-05-02 09:58:23,452:INFO:Creating metrics dataframe
2023-05-02 09:58:23,456:INFO:Initializing Passive Aggressive Regressor
2023-05-02 09:58:23,456:INFO:Total runtime is 1.3854963739713033 minutes
2023-05-02 09:58:23,457:INFO:SubProcess create_model() called ==================================
2023-05-02 09:58:23,457:INFO:Initializing create_model()
2023-05-02 09:58:23,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:58:23,457:INFO:Checking exceptions
2023-05-02 09:58:23,457:INFO:Importing libraries
2023-05-02 09:58:23,457:INFO:Copying training dataset
2023-05-02 09:58:23,462:INFO:Defining folds
2023-05-02 09:58:23,462:INFO:Declaring metric variables
2023-05-02 09:58:23,462:INFO:Importing untrained model
2023-05-02 09:58:23,463:INFO:Passive Aggressive Regressor Imported successfully
2023-05-02 09:58:23,463:INFO:Starting cross validation
2023-05-02 09:58:23,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:58:31,568:INFO:Calculating mean and std
2023-05-02 09:58:31,569:INFO:Creating metrics dataframe
2023-05-02 09:58:32,492:INFO:Uploading results into container
2023-05-02 09:58:32,492:INFO:Uploading model into container now
2023-05-02 09:58:32,493:INFO:_master_model_container: 9
2023-05-02 09:58:32,493:INFO:_display_container: 2
2023-05-02 09:58:32,493:INFO:PassiveAggressiveRegressor(random_state=6797)
2023-05-02 09:58:32,493:INFO:create_model() successfully completed......................................
2023-05-02 09:58:32,638:INFO:SubProcess create_model() end ==================================
2023-05-02 09:58:32,638:INFO:Creating metrics dataframe
2023-05-02 09:58:32,644:INFO:Initializing Huber Regressor
2023-05-02 09:58:32,644:INFO:Total runtime is 1.5386343757311503 minutes
2023-05-02 09:58:32,644:INFO:SubProcess create_model() called ==================================
2023-05-02 09:58:32,644:INFO:Initializing create_model()
2023-05-02 09:58:32,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:58:32,644:INFO:Checking exceptions
2023-05-02 09:58:32,644:INFO:Importing libraries
2023-05-02 09:58:32,644:INFO:Copying training dataset
2023-05-02 09:58:32,647:INFO:Defining folds
2023-05-02 09:58:32,647:INFO:Declaring metric variables
2023-05-02 09:58:32,648:INFO:Importing untrained model
2023-05-02 09:58:32,648:INFO:Huber Regressor Imported successfully
2023-05-02 09:58:32,648:INFO:Starting cross validation
2023-05-02 09:58:32,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:58:33,254:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 09:58:33,254:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 09:58:33,254:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 09:58:41,197:INFO:Calculating mean and std
2023-05-02 09:58:41,198:INFO:Creating metrics dataframe
2023-05-02 09:58:42,159:INFO:Uploading results into container
2023-05-02 09:58:42,161:INFO:Uploading model into container now
2023-05-02 09:58:42,161:INFO:_master_model_container: 10
2023-05-02 09:58:42,161:INFO:_display_container: 2
2023-05-02 09:58:42,161:INFO:HuberRegressor()
2023-05-02 09:58:42,161:INFO:create_model() successfully completed......................................
2023-05-02 09:58:42,309:INFO:SubProcess create_model() end ==================================
2023-05-02 09:58:42,309:INFO:Creating metrics dataframe
2023-05-02 09:58:42,313:INFO:Initializing K Neighbors Regressor
2023-05-02 09:58:42,313:INFO:Total runtime is 1.69978901942571 minutes
2023-05-02 09:58:42,313:INFO:SubProcess create_model() called ==================================
2023-05-02 09:58:42,314:INFO:Initializing create_model()
2023-05-02 09:58:42,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:58:42,314:INFO:Checking exceptions
2023-05-02 09:58:42,314:INFO:Importing libraries
2023-05-02 09:58:42,314:INFO:Copying training dataset
2023-05-02 09:58:42,317:INFO:Defining folds
2023-05-02 09:58:42,317:INFO:Declaring metric variables
2023-05-02 09:58:42,317:INFO:Importing untrained model
2023-05-02 09:58:42,318:INFO:K Neighbors Regressor Imported successfully
2023-05-02 09:58:42,318:INFO:Starting cross validation
2023-05-02 09:58:42,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:58:50,773:INFO:Calculating mean and std
2023-05-02 09:58:50,774:INFO:Creating metrics dataframe
2023-05-02 09:58:51,700:INFO:Uploading results into container
2023-05-02 09:58:51,701:INFO:Uploading model into container now
2023-05-02 09:58:51,701:INFO:_master_model_container: 11
2023-05-02 09:58:51,702:INFO:_display_container: 2
2023-05-02 09:58:51,702:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-02 09:58:51,702:INFO:create_model() successfully completed......................................
2023-05-02 09:58:51,850:INFO:SubProcess create_model() end ==================================
2023-05-02 09:58:51,850:INFO:Creating metrics dataframe
2023-05-02 09:58:51,854:INFO:Initializing Decision Tree Regressor
2023-05-02 09:58:51,854:INFO:Total runtime is 1.8587941567103066 minutes
2023-05-02 09:58:51,854:INFO:SubProcess create_model() called ==================================
2023-05-02 09:58:51,855:INFO:Initializing create_model()
2023-05-02 09:58:51,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:58:51,855:INFO:Checking exceptions
2023-05-02 09:58:51,855:INFO:Importing libraries
2023-05-02 09:58:51,855:INFO:Copying training dataset
2023-05-02 09:58:51,858:INFO:Defining folds
2023-05-02 09:58:51,858:INFO:Declaring metric variables
2023-05-02 09:58:51,858:INFO:Importing untrained model
2023-05-02 09:58:51,858:INFO:Decision Tree Regressor Imported successfully
2023-05-02 09:58:51,859:INFO:Starting cross validation
2023-05-02 09:58:51,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:59:00,148:INFO:Calculating mean and std
2023-05-02 09:59:00,149:INFO:Creating metrics dataframe
2023-05-02 09:59:01,084:INFO:Uploading results into container
2023-05-02 09:59:01,085:INFO:Uploading model into container now
2023-05-02 09:59:01,085:INFO:_master_model_container: 12
2023-05-02 09:59:01,085:INFO:_display_container: 2
2023-05-02 09:59:01,086:INFO:DecisionTreeRegressor(random_state=6797)
2023-05-02 09:59:01,086:INFO:create_model() successfully completed......................................
2023-05-02 09:59:01,254:INFO:SubProcess create_model() end ==================================
2023-05-02 09:59:01,254:INFO:Creating metrics dataframe
2023-05-02 09:59:01,262:INFO:Initializing Random Forest Regressor
2023-05-02 09:59:01,263:INFO:Total runtime is 2.0156139810880025 minutes
2023-05-02 09:59:01,263:INFO:SubProcess create_model() called ==================================
2023-05-02 09:59:01,264:INFO:Initializing create_model()
2023-05-02 09:59:01,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:59:01,264:INFO:Checking exceptions
2023-05-02 09:59:01,264:INFO:Importing libraries
2023-05-02 09:59:01,264:INFO:Copying training dataset
2023-05-02 09:59:01,269:INFO:Defining folds
2023-05-02 09:59:01,270:INFO:Declaring metric variables
2023-05-02 09:59:01,270:INFO:Importing untrained model
2023-05-02 09:59:01,271:INFO:Random Forest Regressor Imported successfully
2023-05-02 09:59:01,271:INFO:Starting cross validation
2023-05-02 09:59:01,273:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:59:10,682:INFO:Calculating mean and std
2023-05-02 09:59:10,683:INFO:Creating metrics dataframe
2023-05-02 09:59:11,619:INFO:Uploading results into container
2023-05-02 09:59:11,621:INFO:Uploading model into container now
2023-05-02 09:59:11,621:INFO:_master_model_container: 13
2023-05-02 09:59:11,621:INFO:_display_container: 2
2023-05-02 09:59:11,621:INFO:RandomForestRegressor(n_jobs=-1, random_state=6797)
2023-05-02 09:59:11,622:INFO:create_model() successfully completed......................................
2023-05-02 09:59:11,762:INFO:SubProcess create_model() end ==================================
2023-05-02 09:59:11,762:INFO:Creating metrics dataframe
2023-05-02 09:59:11,767:INFO:Initializing Extra Trees Regressor
2023-05-02 09:59:11,767:INFO:Total runtime is 2.1906866947809855 minutes
2023-05-02 09:59:11,767:INFO:SubProcess create_model() called ==================================
2023-05-02 09:59:11,767:INFO:Initializing create_model()
2023-05-02 09:59:11,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:59:11,767:INFO:Checking exceptions
2023-05-02 09:59:11,767:INFO:Importing libraries
2023-05-02 09:59:11,767:INFO:Copying training dataset
2023-05-02 09:59:11,770:INFO:Defining folds
2023-05-02 09:59:11,771:INFO:Declaring metric variables
2023-05-02 09:59:11,771:INFO:Importing untrained model
2023-05-02 09:59:11,771:INFO:Extra Trees Regressor Imported successfully
2023-05-02 09:59:11,772:INFO:Starting cross validation
2023-05-02 09:59:11,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:59:20,916:INFO:Calculating mean and std
2023-05-02 09:59:20,917:INFO:Creating metrics dataframe
2023-05-02 09:59:21,919:INFO:Uploading results into container
2023-05-02 09:59:21,921:INFO:Uploading model into container now
2023-05-02 09:59:21,921:INFO:_master_model_container: 14
2023-05-02 09:59:21,921:INFO:_display_container: 2
2023-05-02 09:59:21,922:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6797)
2023-05-02 09:59:21,922:INFO:create_model() successfully completed......................................
2023-05-02 09:59:22,066:INFO:SubProcess create_model() end ==================================
2023-05-02 09:59:22,066:INFO:Creating metrics dataframe
2023-05-02 09:59:22,070:INFO:Initializing AdaBoost Regressor
2023-05-02 09:59:22,070:INFO:Total runtime is 2.3624041199684145 minutes
2023-05-02 09:59:22,070:INFO:SubProcess create_model() called ==================================
2023-05-02 09:59:22,070:INFO:Initializing create_model()
2023-05-02 09:59:22,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:59:22,070:INFO:Checking exceptions
2023-05-02 09:59:22,070:INFO:Importing libraries
2023-05-02 09:59:22,071:INFO:Copying training dataset
2023-05-02 09:59:22,075:INFO:Defining folds
2023-05-02 09:59:22,075:INFO:Declaring metric variables
2023-05-02 09:59:22,076:INFO:Importing untrained model
2023-05-02 09:59:22,076:INFO:AdaBoost Regressor Imported successfully
2023-05-02 09:59:22,076:INFO:Starting cross validation
2023-05-02 09:59:22,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:59:31,274:INFO:Calculating mean and std
2023-05-02 09:59:31,275:INFO:Creating metrics dataframe
2023-05-02 09:59:32,236:INFO:Uploading results into container
2023-05-02 09:59:32,237:INFO:Uploading model into container now
2023-05-02 09:59:32,238:INFO:_master_model_container: 15
2023-05-02 09:59:32,238:INFO:_display_container: 2
2023-05-02 09:59:32,238:INFO:AdaBoostRegressor(random_state=6797)
2023-05-02 09:59:32,238:INFO:create_model() successfully completed......................................
2023-05-02 09:59:32,400:INFO:SubProcess create_model() end ==================================
2023-05-02 09:59:32,400:INFO:Creating metrics dataframe
2023-05-02 09:59:32,405:INFO:Initializing Gradient Boosting Regressor
2023-05-02 09:59:32,405:INFO:Total runtime is 2.53465238014857 minutes
2023-05-02 09:59:32,405:INFO:SubProcess create_model() called ==================================
2023-05-02 09:59:32,405:INFO:Initializing create_model()
2023-05-02 09:59:32,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:59:32,405:INFO:Checking exceptions
2023-05-02 09:59:32,405:INFO:Importing libraries
2023-05-02 09:59:32,405:INFO:Copying training dataset
2023-05-02 09:59:32,409:INFO:Defining folds
2023-05-02 09:59:32,409:INFO:Declaring metric variables
2023-05-02 09:59:32,410:INFO:Importing untrained model
2023-05-02 09:59:32,410:INFO:Gradient Boosting Regressor Imported successfully
2023-05-02 09:59:32,411:INFO:Starting cross validation
2023-05-02 09:59:32,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:59:41,903:INFO:Calculating mean and std
2023-05-02 09:59:41,903:INFO:Creating metrics dataframe
2023-05-02 09:59:43,040:INFO:Uploading results into container
2023-05-02 09:59:43,041:INFO:Uploading model into container now
2023-05-02 09:59:43,041:INFO:_master_model_container: 16
2023-05-02 09:59:43,042:INFO:_display_container: 2
2023-05-02 09:59:43,042:INFO:GradientBoostingRegressor(random_state=6797)
2023-05-02 09:59:43,042:INFO:create_model() successfully completed......................................
2023-05-02 09:59:43,202:INFO:SubProcess create_model() end ==================================
2023-05-02 09:59:43,202:INFO:Creating metrics dataframe
2023-05-02 09:59:43,212:INFO:Initializing Light Gradient Boosting Machine
2023-05-02 09:59:43,213:INFO:Total runtime is 2.7147632002830506 minutes
2023-05-02 09:59:43,213:INFO:SubProcess create_model() called ==================================
2023-05-02 09:59:43,213:INFO:Initializing create_model()
2023-05-02 09:59:43,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:59:43,214:INFO:Checking exceptions
2023-05-02 09:59:43,214:INFO:Importing libraries
2023-05-02 09:59:43,214:INFO:Copying training dataset
2023-05-02 09:59:43,218:INFO:Defining folds
2023-05-02 09:59:43,218:INFO:Declaring metric variables
2023-05-02 09:59:43,218:INFO:Importing untrained model
2023-05-02 09:59:43,220:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-02 09:59:43,220:INFO:Starting cross validation
2023-05-02 09:59:43,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 09:59:56,022:INFO:Calculating mean and std
2023-05-02 09:59:56,022:INFO:Creating metrics dataframe
2023-05-02 09:59:57,130:INFO:Uploading results into container
2023-05-02 09:59:57,131:INFO:Uploading model into container now
2023-05-02 09:59:57,131:INFO:_master_model_container: 17
2023-05-02 09:59:57,131:INFO:_display_container: 2
2023-05-02 09:59:57,131:INFO:LGBMRegressor(random_state=6797)
2023-05-02 09:59:57,132:INFO:create_model() successfully completed......................................
2023-05-02 09:59:57,304:INFO:SubProcess create_model() end ==================================
2023-05-02 09:59:57,304:INFO:Creating metrics dataframe
2023-05-02 09:59:57,318:INFO:Initializing Dummy Regressor
2023-05-02 09:59:57,318:INFO:Total runtime is 2.9498706658681235 minutes
2023-05-02 09:59:57,319:INFO:SubProcess create_model() called ==================================
2023-05-02 09:59:57,319:INFO:Initializing create_model()
2023-05-02 09:59:57,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C40353F640>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 09:59:57,319:INFO:Checking exceptions
2023-05-02 09:59:57,319:INFO:Importing libraries
2023-05-02 09:59:57,319:INFO:Copying training dataset
2023-05-02 09:59:57,331:INFO:Defining folds
2023-05-02 09:59:57,332:INFO:Declaring metric variables
2023-05-02 09:59:57,333:INFO:Importing untrained model
2023-05-02 09:59:57,333:INFO:Dummy Regressor Imported successfully
2023-05-02 09:59:57,333:INFO:Starting cross validation
2023-05-02 09:59:57,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 10:00:07,176:INFO:Calculating mean and std
2023-05-02 10:00:07,177:INFO:Creating metrics dataframe
2023-05-02 10:00:08,225:INFO:Uploading results into container
2023-05-02 10:00:08,226:INFO:Uploading model into container now
2023-05-02 10:00:08,226:INFO:_master_model_container: 18
2023-05-02 10:00:08,227:INFO:_display_container: 2
2023-05-02 10:00:08,227:INFO:DummyRegressor()
2023-05-02 10:00:08,227:INFO:create_model() successfully completed......................................
2023-05-02 10:00:08,374:INFO:SubProcess create_model() end ==================================
2023-05-02 10:00:08,374:INFO:Creating metrics dataframe
2023-05-02 10:00:08,380:INFO:Initializing create_model()
2023-05-02 10:00:08,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6797), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-02 10:00:08,380:INFO:Checking exceptions
2023-05-02 10:00:08,381:INFO:Importing libraries
2023-05-02 10:00:08,381:INFO:Copying training dataset
2023-05-02 10:00:08,386:INFO:Defining folds
2023-05-02 10:00:08,386:INFO:Declaring metric variables
2023-05-02 10:00:08,387:INFO:Importing untrained model
2023-05-02 10:00:08,387:INFO:Declaring custom model
2023-05-02 10:00:08,387:INFO:Extra Trees Regressor Imported successfully
2023-05-02 10:00:08,390:INFO:Cross validation set to False
2023-05-02 10:00:08,390:INFO:Fitting Model
2023-05-02 10:00:09,436:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6797)
2023-05-02 10:00:09,436:INFO:create_model() successfully completed......................................
2023-05-02 10:00:09,628:INFO:_master_model_container: 18
2023-05-02 10:00:09,629:INFO:_display_container: 2
2023-05-02 10:00:09,629:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6797)
2023-05-02 10:00:09,629:INFO:compare_models() successfully completed......................................
2023-05-02 10:00:09,636:INFO:Initializing predict_model()
2023-05-02 10:00:09,636:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C45E9C7F70>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6797), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C4034E98B0>)
2023-05-02 10:00:09,637:INFO:Checking exceptions
2023-05-02 10:00:09,637:INFO:Preloading libraries
2023-05-02 10:00:09,637:INFO:Set up data.
2023-05-02 10:00:09,645:INFO:Set up index.
2023-05-02 15:59:03,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 15:59:03,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 15:59:03,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 15:59:03,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-02 15:59:18,237:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-02 16:03:22,735:INFO:PyCaret RegressionExperiment
2023-05-02 16:03:22,735:INFO:Logging name: reg-default-name
2023-05-02 16:03:22,735:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-02 16:03:22,736:INFO:version 3.0.0
2023-05-02 16:03:22,736:INFO:Initializing setup()
2023-05-02 16:03:22,736:INFO:self.USI: 05e7
2023-05-02 16:03:22,736:INFO:self._variable_keys: {'idx', 'seed', 'y_train', 'memory', 'X_train', 'X_test', 'X', '_available_plots', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'data', '_ml_usecase', 'gpu_param', 'exp_name_log', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'y_test', 'logging_param', 'log_plots_param', 'transform_target_param', 'USI', 'fold_generator', 'target_param', 'y'}
2023-05-02 16:03:22,736:INFO:Checking environment
2023-05-02 16:03:22,736:INFO:python_version: 3.9.13
2023-05-02 16:03:22,736:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-05-02 16:03:22,736:INFO:machine: AMD64
2023-05-02 16:03:22,761:INFO:platform: Windows-10-10.0.22000-SP0
2023-05-02 16:03:22,761:INFO:Memory: svmem(total=16935899136, available=7465988096, percent=55.9, used=9469911040, free=7465988096)
2023-05-02 16:03:22,762:INFO:Physical Core: 4
2023-05-02 16:03:22,762:INFO:Logical Core: 8
2023-05-02 16:03:22,762:INFO:Checking libraries
2023-05-02 16:03:22,763:INFO:System:
2023-05-02 16:03:22,763:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-05-02 16:03:22,763:INFO:executable: D:\Anaconda\python.exe
2023-05-02 16:03:22,763:INFO:   machine: Windows-10-10.0.22000-SP0
2023-05-02 16:03:22,764:INFO:PyCaret required dependencies:
2023-05-02 16:03:22,764:INFO:                 pip: 22.2.2
2023-05-02 16:03:22,764:INFO:          setuptools: 63.4.1
2023-05-02 16:03:22,765:INFO:             pycaret: 3.0.0
2023-05-02 16:03:22,765:INFO:             IPython: 7.31.1
2023-05-02 16:03:22,765:INFO:          ipywidgets: 7.6.5
2023-05-02 16:03:22,765:INFO:                tqdm: 4.64.1
2023-05-02 16:03:22,765:INFO:               numpy: 1.21.5
2023-05-02 16:03:22,766:INFO:              pandas: 1.4.4
2023-05-02 16:03:22,766:INFO:              jinja2: 2.11.3
2023-05-02 16:03:22,766:INFO:               scipy: 1.9.1
2023-05-02 16:03:22,766:INFO:              joblib: 1.2.0
2023-05-02 16:03:22,766:INFO:             sklearn: 1.0.2
2023-05-02 16:03:22,767:INFO:                pyod: 1.0.9
2023-05-02 16:03:22,767:INFO:            imblearn: 0.10.1
2023-05-02 16:03:22,767:INFO:   category_encoders: 2.6.0
2023-05-02 16:03:22,767:INFO:            lightgbm: 3.3.5
2023-05-02 16:03:22,767:INFO:               numba: 0.55.1
2023-05-02 16:03:22,768:INFO:            requests: 2.28.1
2023-05-02 16:03:22,768:INFO:          matplotlib: 3.5.2
2023-05-02 16:03:22,768:INFO:          scikitplot: 0.3.7
2023-05-02 16:03:22,768:INFO:         yellowbrick: 1.5
2023-05-02 16:03:22,769:INFO:              plotly: 5.9.0
2023-05-02 16:03:22,769:INFO:             kaleido: 0.2.1
2023-05-02 16:03:22,769:INFO:         statsmodels: 0.13.2
2023-05-02 16:03:22,769:INFO:              sktime: 0.17.1
2023-05-02 16:03:22,769:INFO:               tbats: 1.1.2
2023-05-02 16:03:22,770:INFO:            pmdarima: 2.0.3
2023-05-02 16:03:22,770:INFO:              psutil: 5.9.0
2023-05-02 16:03:22,770:INFO:PyCaret optional dependencies:
2023-05-02 16:03:22,809:INFO:                shap: 0.41.0
2023-05-02 16:03:22,809:INFO:           interpret: Not installed
2023-05-02 16:03:22,810:INFO:                umap: Not installed
2023-05-02 16:03:22,810:INFO:    pandas_profiling: 4.1.2
2023-05-02 16:03:22,810:INFO:  explainerdashboard: Not installed
2023-05-02 16:03:22,810:INFO:             autoviz: Not installed
2023-05-02 16:03:22,810:INFO:           fairlearn: Not installed
2023-05-02 16:03:22,810:INFO:             xgboost: Not installed
2023-05-02 16:03:22,811:INFO:            catboost: Not installed
2023-05-02 16:03:22,811:INFO:              kmodes: Not installed
2023-05-02 16:03:22,811:INFO:             mlxtend: Not installed
2023-05-02 16:03:22,811:INFO:       statsforecast: Not installed
2023-05-02 16:03:22,811:INFO:        tune_sklearn: Not installed
2023-05-02 16:03:22,812:INFO:                 ray: Not installed
2023-05-02 16:03:22,812:INFO:            hyperopt: Not installed
2023-05-02 16:03:22,812:INFO:              optuna: Not installed
2023-05-02 16:03:22,812:INFO:               skopt: Not installed
2023-05-02 16:03:22,812:INFO:              mlflow: 2.2.1
2023-05-02 16:03:22,813:INFO:              gradio: Not installed
2023-05-02 16:03:22,813:INFO:             fastapi: Not installed
2023-05-02 16:03:22,813:INFO:             uvicorn: Not installed
2023-05-02 16:03:22,813:INFO:              m2cgen: Not installed
2023-05-02 16:03:22,813:INFO:           evidently: Not installed
2023-05-02 16:03:22,813:INFO:               fugue: Not installed
2023-05-02 16:03:22,814:INFO:           streamlit: 1.21.0
2023-05-02 16:03:22,814:INFO:             prophet: Not installed
2023-05-02 16:03:22,814:INFO:None
2023-05-02 16:03:22,814:INFO:Set up data.
2023-05-02 16:03:22,832:INFO:Set up train/test split.
2023-05-02 16:03:23,158:INFO:Set up index.
2023-05-02 16:03:23,158:INFO:Set up folding strategy.
2023-05-02 16:03:23,159:INFO:Assigning column types.
2023-05-02 16:03:23,168:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-02 16:03:23,169:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-02 16:03:23,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 16:03:23,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 16:03:23,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:23,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:23,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:24,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:24,174:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,190:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,205:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:24,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:24,569:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-02 16:03:24,586:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:24,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:24,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:25,020:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:25,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:25,391:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-02 16:03:25,422:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:25,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:25,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:25,812:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-02 16:03:26,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:26,187:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:26,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:26,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:26,191:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-02 16:03:26,428:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:26,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:26,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:26,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:26,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:27,028:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-02 16:03:27,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:27,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:27,032:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-02 16:03:27,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:27,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:27,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:27,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-02 16:03:27,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:27,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:27,811:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-02 16:03:28,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:28,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:28,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:28,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:28,709:INFO:Preparing preprocessing pipeline...
2023-05-02 16:03:28,709:INFO:Set up simple imputation.
2023-05-02 16:03:28,711:INFO:Set up column name cleaning.
2023-05-02 16:03:28,814:INFO:Finished creating preprocessing pipeline.
2023-05-02 16:03:28,951:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\yashs\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Num_of_Elem', 'Density_calc',
                                             'dHmix', 'dSmix', 'Elect.Diff',
                                             'VEC', 'Phases'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-02 16:03:28,952:INFO:Creating final display dataframe.
2023-05-02 16:03:29,328:INFO:Setup _display_container:                     Description             Value
0                    Session id              2885
1                        Target    Atom.Size.Diff
2                   Target type        Regression
3           Original data shape         (1360, 8)
4        Transformed data shape         (1360, 8)
5   Transformed train set shape          (951, 8)
6    Transformed test set shape          (409, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              05e7
2023-05-02 16:03:29,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:29,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:30,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:30,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-02 16:03:30,152:INFO:setup() successfully completed in 13.84s...............
2023-05-02 16:03:30,209:INFO:Initializing compare_models()
2023-05-02 16:03:30,210:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-02 16:03:30,210:INFO:Checking exceptions
2023-05-02 16:03:30,217:INFO:Preparing display monitor
2023-05-02 16:03:30,233:INFO:Initializing Linear Regression
2023-05-02 16:03:30,233:INFO:Total runtime is 8.285045623779297e-06 minutes
2023-05-02 16:03:30,234:INFO:SubProcess create_model() called ==================================
2023-05-02 16:03:30,236:INFO:Initializing create_model()
2023-05-02 16:03:30,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:03:30,237:INFO:Checking exceptions
2023-05-02 16:03:30,237:INFO:Importing libraries
2023-05-02 16:03:30,237:INFO:Copying training dataset
2023-05-02 16:03:30,277:INFO:Defining folds
2023-05-02 16:03:30,278:INFO:Declaring metric variables
2023-05-02 16:03:30,279:INFO:Importing untrained model
2023-05-02 16:03:30,280:INFO:Linear Regression Imported successfully
2023-05-02 16:03:30,281:INFO:Starting cross validation
2023-05-02 16:03:30,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:04:02,886:INFO:Calculating mean and std
2023-05-02 16:04:02,888:INFO:Creating metrics dataframe
2023-05-02 16:04:07,431:INFO:Uploading results into container
2023-05-02 16:04:07,434:INFO:Uploading model into container now
2023-05-02 16:04:07,435:INFO:_master_model_container: 1
2023-05-02 16:04:07,435:INFO:_display_container: 2
2023-05-02 16:04:07,436:INFO:LinearRegression(n_jobs=-1)
2023-05-02 16:04:07,436:INFO:create_model() successfully completed......................................
2023-05-02 16:04:07,692:INFO:SubProcess create_model() end ==================================
2023-05-02 16:04:07,693:INFO:Creating metrics dataframe
2023-05-02 16:04:07,703:INFO:Initializing Lasso Regression
2023-05-02 16:04:07,704:INFO:Total runtime is 0.6245115518569946 minutes
2023-05-02 16:04:07,704:INFO:SubProcess create_model() called ==================================
2023-05-02 16:04:07,705:INFO:Initializing create_model()
2023-05-02 16:04:07,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:04:07,705:INFO:Checking exceptions
2023-05-02 16:04:07,705:INFO:Importing libraries
2023-05-02 16:04:07,705:INFO:Copying training dataset
2023-05-02 16:04:07,716:INFO:Defining folds
2023-05-02 16:04:07,716:INFO:Declaring metric variables
2023-05-02 16:04:07,717:INFO:Importing untrained model
2023-05-02 16:04:07,718:INFO:Lasso Regression Imported successfully
2023-05-02 16:04:07,719:INFO:Starting cross validation
2023-05-02 16:04:07,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:04:33,538:INFO:Calculating mean and std
2023-05-02 16:04:33,540:INFO:Creating metrics dataframe
2023-05-02 16:04:38,021:INFO:Uploading results into container
2023-05-02 16:04:38,023:INFO:Uploading model into container now
2023-05-02 16:04:38,024:INFO:_master_model_container: 2
2023-05-02 16:04:38,024:INFO:_display_container: 2
2023-05-02 16:04:38,025:INFO:Lasso(random_state=2885)
2023-05-02 16:04:38,026:INFO:create_model() successfully completed......................................
2023-05-02 16:04:38,287:INFO:SubProcess create_model() end ==================================
2023-05-02 16:04:38,287:INFO:Creating metrics dataframe
2023-05-02 16:04:38,303:INFO:Initializing Ridge Regression
2023-05-02 16:04:38,303:INFO:Total runtime is 1.1345042546590167 minutes
2023-05-02 16:04:38,304:INFO:SubProcess create_model() called ==================================
2023-05-02 16:04:38,305:INFO:Initializing create_model()
2023-05-02 16:04:38,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:04:38,305:INFO:Checking exceptions
2023-05-02 16:04:38,305:INFO:Importing libraries
2023-05-02 16:04:38,305:INFO:Copying training dataset
2023-05-02 16:04:38,316:INFO:Defining folds
2023-05-02 16:04:38,316:INFO:Declaring metric variables
2023-05-02 16:04:38,317:INFO:Importing untrained model
2023-05-02 16:04:38,318:INFO:Ridge Regression Imported successfully
2023-05-02 16:04:38,319:INFO:Starting cross validation
2023-05-02 16:04:38,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:05:04,069:INFO:Calculating mean and std
2023-05-02 16:05:04,071:INFO:Creating metrics dataframe
2023-05-02 16:05:08,600:INFO:Uploading results into container
2023-05-02 16:05:08,603:INFO:Uploading model into container now
2023-05-02 16:05:08,604:INFO:_master_model_container: 3
2023-05-02 16:05:08,604:INFO:_display_container: 2
2023-05-02 16:05:08,605:INFO:Ridge(random_state=2885)
2023-05-02 16:05:08,605:INFO:create_model() successfully completed......................................
2023-05-02 16:05:08,882:INFO:SubProcess create_model() end ==================================
2023-05-02 16:05:08,883:INFO:Creating metrics dataframe
2023-05-02 16:05:08,907:INFO:Initializing Elastic Net
2023-05-02 16:05:08,908:INFO:Total runtime is 1.6445897738138833 minutes
2023-05-02 16:05:08,910:INFO:SubProcess create_model() called ==================================
2023-05-02 16:05:08,911:INFO:Initializing create_model()
2023-05-02 16:05:08,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:05:08,912:INFO:Checking exceptions
2023-05-02 16:05:08,912:INFO:Importing libraries
2023-05-02 16:05:08,913:INFO:Copying training dataset
2023-05-02 16:05:08,932:INFO:Defining folds
2023-05-02 16:05:08,932:INFO:Declaring metric variables
2023-05-02 16:05:08,933:INFO:Importing untrained model
2023-05-02 16:05:08,935:INFO:Elastic Net Imported successfully
2023-05-02 16:05:08,936:INFO:Starting cross validation
2023-05-02 16:05:08,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:05:34,863:INFO:Calculating mean and std
2023-05-02 16:05:34,865:INFO:Creating metrics dataframe
2023-05-02 16:05:39,358:INFO:Uploading results into container
2023-05-02 16:05:39,360:INFO:Uploading model into container now
2023-05-02 16:05:39,361:INFO:_master_model_container: 4
2023-05-02 16:05:39,361:INFO:_display_container: 2
2023-05-02 16:05:39,362:INFO:ElasticNet(random_state=2885)
2023-05-02 16:05:39,362:INFO:create_model() successfully completed......................................
2023-05-02 16:05:39,615:INFO:SubProcess create_model() end ==================================
2023-05-02 16:05:39,616:INFO:Creating metrics dataframe
2023-05-02 16:05:39,629:INFO:Initializing Least Angle Regression
2023-05-02 16:05:39,629:INFO:Total runtime is 2.1566017111142477 minutes
2023-05-02 16:05:39,630:INFO:SubProcess create_model() called ==================================
2023-05-02 16:05:39,630:INFO:Initializing create_model()
2023-05-02 16:05:39,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:05:39,631:INFO:Checking exceptions
2023-05-02 16:05:39,631:INFO:Importing libraries
2023-05-02 16:05:39,631:INFO:Copying training dataset
2023-05-02 16:05:39,641:INFO:Defining folds
2023-05-02 16:05:39,641:INFO:Declaring metric variables
2023-05-02 16:05:39,642:INFO:Importing untrained model
2023-05-02 16:05:39,644:INFO:Least Angle Regression Imported successfully
2023-05-02 16:05:39,645:INFO:Starting cross validation
2023-05-02 16:05:39,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:05:40,247:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:05:40,247:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:05:40,247:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:05:40,247:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:05:40,248:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:05:44,861:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:05:44,917:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:06,025:INFO:Calculating mean and std
2023-05-02 16:06:06,028:INFO:Creating metrics dataframe
2023-05-02 16:06:10,724:INFO:Uploading results into container
2023-05-02 16:06:10,727:INFO:Uploading model into container now
2023-05-02 16:06:10,729:INFO:_master_model_container: 5
2023-05-02 16:06:10,729:INFO:_display_container: 2
2023-05-02 16:06:10,730:INFO:Lars(random_state=2885)
2023-05-02 16:06:10,731:INFO:create_model() successfully completed......................................
2023-05-02 16:06:11,013:INFO:SubProcess create_model() end ==================================
2023-05-02 16:06:11,013:INFO:Creating metrics dataframe
2023-05-02 16:06:11,026:INFO:Initializing Lasso Least Angle Regression
2023-05-02 16:06:11,027:INFO:Total runtime is 2.679890708128611 minutes
2023-05-02 16:06:11,027:INFO:SubProcess create_model() called ==================================
2023-05-02 16:06:11,028:INFO:Initializing create_model()
2023-05-02 16:06:11,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:06:11,028:INFO:Checking exceptions
2023-05-02 16:06:11,028:INFO:Importing libraries
2023-05-02 16:06:11,028:INFO:Copying training dataset
2023-05-02 16:06:11,043:INFO:Defining folds
2023-05-02 16:06:11,043:INFO:Declaring metric variables
2023-05-02 16:06:11,044:INFO:Importing untrained model
2023-05-02 16:06:11,045:INFO:Lasso Least Angle Regression Imported successfully
2023-05-02 16:06:11,047:INFO:Starting cross validation
2023-05-02 16:06:11,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:06:11,237:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,271:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,311:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,330:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,380:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,449:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,453:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:11,516:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:16,044:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:16,075:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-02 16:06:37,073:INFO:Calculating mean and std
2023-05-02 16:06:37,075:INFO:Creating metrics dataframe
2023-05-02 16:06:41,735:INFO:Uploading results into container
2023-05-02 16:06:41,737:INFO:Uploading model into container now
2023-05-02 16:06:41,739:INFO:_master_model_container: 6
2023-05-02 16:06:41,739:INFO:_display_container: 2
2023-05-02 16:06:41,740:INFO:LassoLars(random_state=2885)
2023-05-02 16:06:41,740:INFO:create_model() successfully completed......................................
2023-05-02 16:06:42,010:INFO:SubProcess create_model() end ==================================
2023-05-02 16:06:42,011:INFO:Creating metrics dataframe
2023-05-02 16:06:42,025:INFO:Initializing Orthogonal Matching Pursuit
2023-05-02 16:06:42,026:INFO:Total runtime is 3.1965461651484173 minutes
2023-05-02 16:06:42,026:INFO:SubProcess create_model() called ==================================
2023-05-02 16:06:42,027:INFO:Initializing create_model()
2023-05-02 16:06:42,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:06:42,027:INFO:Checking exceptions
2023-05-02 16:06:42,028:INFO:Importing libraries
2023-05-02 16:06:42,028:INFO:Copying training dataset
2023-05-02 16:06:42,039:INFO:Defining folds
2023-05-02 16:06:42,039:INFO:Declaring metric variables
2023-05-02 16:06:42,040:INFO:Importing untrained model
2023-05-02 16:06:42,041:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-02 16:06:42,042:INFO:Starting cross validation
2023-05-02 16:06:42,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:06:42,237:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,277:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,304:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,347:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,376:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,411:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,433:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:42,463:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:47,296:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:06:47,322:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-02 16:07:08,260:INFO:Calculating mean and std
2023-05-02 16:07:08,262:INFO:Creating metrics dataframe
2023-05-02 16:07:12,810:INFO:Uploading results into container
2023-05-02 16:07:12,812:INFO:Uploading model into container now
2023-05-02 16:07:12,813:INFO:_master_model_container: 7
2023-05-02 16:07:12,813:INFO:_display_container: 2
2023-05-02 16:07:12,814:INFO:OrthogonalMatchingPursuit()
2023-05-02 16:07:12,814:INFO:create_model() successfully completed......................................
2023-05-02 16:07:13,066:INFO:SubProcess create_model() end ==================================
2023-05-02 16:07:13,066:INFO:Creating metrics dataframe
2023-05-02 16:07:13,082:INFO:Initializing Bayesian Ridge
2023-05-02 16:07:13,082:INFO:Total runtime is 3.714154020945231 minutes
2023-05-02 16:07:13,083:INFO:SubProcess create_model() called ==================================
2023-05-02 16:07:13,084:INFO:Initializing create_model()
2023-05-02 16:07:13,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:07:13,084:INFO:Checking exceptions
2023-05-02 16:07:13,084:INFO:Importing libraries
2023-05-02 16:07:13,084:INFO:Copying training dataset
2023-05-02 16:07:13,094:INFO:Defining folds
2023-05-02 16:07:13,094:INFO:Declaring metric variables
2023-05-02 16:07:13,095:INFO:Importing untrained model
2023-05-02 16:07:13,096:INFO:Bayesian Ridge Imported successfully
2023-05-02 16:07:13,097:INFO:Starting cross validation
2023-05-02 16:07:13,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:07:39,567:INFO:Calculating mean and std
2023-05-02 16:07:39,569:INFO:Creating metrics dataframe
2023-05-02 16:07:44,158:INFO:Uploading results into container
2023-05-02 16:07:44,164:INFO:Uploading model into container now
2023-05-02 16:07:44,166:INFO:_master_model_container: 8
2023-05-02 16:07:44,166:INFO:_display_container: 2
2023-05-02 16:07:44,167:INFO:BayesianRidge()
2023-05-02 16:07:44,167:INFO:create_model() successfully completed......................................
2023-05-02 16:07:44,427:INFO:SubProcess create_model() end ==================================
2023-05-02 16:07:44,427:INFO:Creating metrics dataframe
2023-05-02 16:07:44,442:INFO:Initializing Passive Aggressive Regressor
2023-05-02 16:07:44,442:INFO:Total runtime is 4.236813235282898 minutes
2023-05-02 16:07:44,443:INFO:SubProcess create_model() called ==================================
2023-05-02 16:07:44,444:INFO:Initializing create_model()
2023-05-02 16:07:44,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:07:44,445:INFO:Checking exceptions
2023-05-02 16:07:44,445:INFO:Importing libraries
2023-05-02 16:07:44,446:INFO:Copying training dataset
2023-05-02 16:07:44,456:INFO:Defining folds
2023-05-02 16:07:44,456:INFO:Declaring metric variables
2023-05-02 16:07:44,457:INFO:Importing untrained model
2023-05-02 16:07:44,459:INFO:Passive Aggressive Regressor Imported successfully
2023-05-02 16:07:44,460:INFO:Starting cross validation
2023-05-02 16:07:44,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:08:11,764:INFO:Calculating mean and std
2023-05-02 16:08:11,766:INFO:Creating metrics dataframe
2023-05-02 16:08:16,238:INFO:Uploading results into container
2023-05-02 16:08:16,240:INFO:Uploading model into container now
2023-05-02 16:08:16,242:INFO:_master_model_container: 9
2023-05-02 16:08:16,242:INFO:_display_container: 2
2023-05-02 16:08:16,242:INFO:PassiveAggressiveRegressor(random_state=2885)
2023-05-02 16:08:16,242:INFO:create_model() successfully completed......................................
2023-05-02 16:08:16,541:INFO:SubProcess create_model() end ==================================
2023-05-02 16:08:16,541:INFO:Creating metrics dataframe
2023-05-02 16:08:16,560:INFO:Initializing Huber Regressor
2023-05-02 16:08:16,560:INFO:Total runtime is 4.772117471694946 minutes
2023-05-02 16:08:16,561:INFO:SubProcess create_model() called ==================================
2023-05-02 16:08:16,562:INFO:Initializing create_model()
2023-05-02 16:08:16,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:08:16,562:INFO:Checking exceptions
2023-05-02 16:08:16,563:INFO:Importing libraries
2023-05-02 16:08:16,563:INFO:Copying training dataset
2023-05-02 16:08:16,575:INFO:Defining folds
2023-05-02 16:08:16,576:INFO:Declaring metric variables
2023-05-02 16:08:16,576:INFO:Importing untrained model
2023-05-02 16:08:16,577:INFO:Huber Regressor Imported successfully
2023-05-02 16:08:16,578:INFO:Starting cross validation
2023-05-02 16:08:16,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:08:17,466:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 16:08:17,466:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 16:08:22,331:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 16:08:22,380:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-02 16:08:41,887:INFO:Calculating mean and std
2023-05-02 16:08:41,888:INFO:Creating metrics dataframe
2023-05-02 16:08:42,898:INFO:Uploading results into container
2023-05-02 16:08:42,900:INFO:Uploading model into container now
2023-05-02 16:08:42,900:INFO:_master_model_container: 10
2023-05-02 16:08:42,900:INFO:_display_container: 2
2023-05-02 16:08:42,901:INFO:HuberRegressor()
2023-05-02 16:08:42,901:INFO:create_model() successfully completed......................................
2023-05-02 16:08:43,036:INFO:SubProcess create_model() end ==================================
2023-05-02 16:08:43,036:INFO:Creating metrics dataframe
2023-05-02 16:08:43,041:INFO:Initializing K Neighbors Regressor
2023-05-02 16:08:43,041:INFO:Total runtime is 5.213466513156891 minutes
2023-05-02 16:08:43,042:INFO:SubProcess create_model() called ==================================
2023-05-02 16:08:43,042:INFO:Initializing create_model()
2023-05-02 16:08:43,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:08:43,042:INFO:Checking exceptions
2023-05-02 16:08:43,042:INFO:Importing libraries
2023-05-02 16:08:43,042:INFO:Copying training dataset
2023-05-02 16:08:43,047:INFO:Defining folds
2023-05-02 16:08:43,048:INFO:Declaring metric variables
2023-05-02 16:08:43,048:INFO:Importing untrained model
2023-05-02 16:08:43,048:INFO:K Neighbors Regressor Imported successfully
2023-05-02 16:08:43,049:INFO:Starting cross validation
2023-05-02 16:08:43,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:08:51,665:INFO:Calculating mean and std
2023-05-02 16:08:51,666:INFO:Creating metrics dataframe
2023-05-02 16:08:52,716:INFO:Uploading results into container
2023-05-02 16:08:52,717:INFO:Uploading model into container now
2023-05-02 16:08:52,718:INFO:_master_model_container: 11
2023-05-02 16:08:52,718:INFO:_display_container: 2
2023-05-02 16:08:52,718:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-02 16:08:52,718:INFO:create_model() successfully completed......................................
2023-05-02 16:08:52,857:INFO:SubProcess create_model() end ==================================
2023-05-02 16:08:52,858:INFO:Creating metrics dataframe
2023-05-02 16:08:52,862:INFO:Initializing Decision Tree Regressor
2023-05-02 16:08:52,862:INFO:Total runtime is 5.37714729309082 minutes
2023-05-02 16:08:52,862:INFO:SubProcess create_model() called ==================================
2023-05-02 16:08:52,863:INFO:Initializing create_model()
2023-05-02 16:08:52,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:08:52,863:INFO:Checking exceptions
2023-05-02 16:08:52,863:INFO:Importing libraries
2023-05-02 16:08:52,863:INFO:Copying training dataset
2023-05-02 16:08:52,866:INFO:Defining folds
2023-05-02 16:08:52,866:INFO:Declaring metric variables
2023-05-02 16:08:52,867:INFO:Importing untrained model
2023-05-02 16:08:52,867:INFO:Decision Tree Regressor Imported successfully
2023-05-02 16:08:52,868:INFO:Starting cross validation
2023-05-02 16:08:52,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:09:01,350:INFO:Calculating mean and std
2023-05-02 16:09:01,351:INFO:Creating metrics dataframe
2023-05-02 16:09:02,305:INFO:Uploading results into container
2023-05-02 16:09:02,306:INFO:Uploading model into container now
2023-05-02 16:09:02,306:INFO:_master_model_container: 12
2023-05-02 16:09:02,306:INFO:_display_container: 2
2023-05-02 16:09:02,307:INFO:DecisionTreeRegressor(random_state=2885)
2023-05-02 16:09:02,307:INFO:create_model() successfully completed......................................
2023-05-02 16:09:02,446:INFO:SubProcess create_model() end ==================================
2023-05-02 16:09:02,446:INFO:Creating metrics dataframe
2023-05-02 16:09:02,454:INFO:Initializing Random Forest Regressor
2023-05-02 16:09:02,454:INFO:Total runtime is 5.5370240370432535 minutes
2023-05-02 16:09:02,454:INFO:SubProcess create_model() called ==================================
2023-05-02 16:09:02,455:INFO:Initializing create_model()
2023-05-02 16:09:02,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:09:02,455:INFO:Checking exceptions
2023-05-02 16:09:02,455:INFO:Importing libraries
2023-05-02 16:09:02,456:INFO:Copying training dataset
2023-05-02 16:09:02,461:INFO:Defining folds
2023-05-02 16:09:02,461:INFO:Declaring metric variables
2023-05-02 16:09:02,461:INFO:Importing untrained model
2023-05-02 16:09:02,462:INFO:Random Forest Regressor Imported successfully
2023-05-02 16:09:02,462:INFO:Starting cross validation
2023-05-02 16:09:02,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:09:12,447:INFO:Calculating mean and std
2023-05-02 16:09:12,448:INFO:Creating metrics dataframe
2023-05-02 16:09:13,447:INFO:Uploading results into container
2023-05-02 16:09:13,448:INFO:Uploading model into container now
2023-05-02 16:09:13,449:INFO:_master_model_container: 13
2023-05-02 16:09:13,449:INFO:_display_container: 2
2023-05-02 16:09:13,450:INFO:RandomForestRegressor(n_jobs=-1, random_state=2885)
2023-05-02 16:09:13,450:INFO:create_model() successfully completed......................................
2023-05-02 16:09:13,600:INFO:SubProcess create_model() end ==================================
2023-05-02 16:09:13,601:INFO:Creating metrics dataframe
2023-05-02 16:09:13,605:INFO:Initializing Extra Trees Regressor
2023-05-02 16:09:13,605:INFO:Total runtime is 5.722868220011393 minutes
2023-05-02 16:09:13,605:INFO:SubProcess create_model() called ==================================
2023-05-02 16:09:13,605:INFO:Initializing create_model()
2023-05-02 16:09:13,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:09:13,605:INFO:Checking exceptions
2023-05-02 16:09:13,605:INFO:Importing libraries
2023-05-02 16:09:13,605:INFO:Copying training dataset
2023-05-02 16:09:13,609:INFO:Defining folds
2023-05-02 16:09:13,610:INFO:Declaring metric variables
2023-05-02 16:09:13,610:INFO:Importing untrained model
2023-05-02 16:09:13,611:INFO:Extra Trees Regressor Imported successfully
2023-05-02 16:09:13,611:INFO:Starting cross validation
2023-05-02 16:09:13,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:09:22,973:INFO:Calculating mean and std
2023-05-02 16:09:22,974:INFO:Creating metrics dataframe
2023-05-02 16:09:23,982:INFO:Uploading results into container
2023-05-02 16:09:23,983:INFO:Uploading model into container now
2023-05-02 16:09:23,984:INFO:_master_model_container: 14
2023-05-02 16:09:23,984:INFO:_display_container: 2
2023-05-02 16:09:23,984:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2885)
2023-05-02 16:09:23,984:INFO:create_model() successfully completed......................................
2023-05-02 16:09:24,122:INFO:SubProcess create_model() end ==================================
2023-05-02 16:09:24,122:INFO:Creating metrics dataframe
2023-05-02 16:09:24,129:INFO:Initializing AdaBoost Regressor
2023-05-02 16:09:24,129:INFO:Total runtime is 5.898267177740733 minutes
2023-05-02 16:09:24,130:INFO:SubProcess create_model() called ==================================
2023-05-02 16:09:24,130:INFO:Initializing create_model()
2023-05-02 16:09:24,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:09:24,130:INFO:Checking exceptions
2023-05-02 16:09:24,130:INFO:Importing libraries
2023-05-02 16:09:24,130:INFO:Copying training dataset
2023-05-02 16:09:24,135:INFO:Defining folds
2023-05-02 16:09:24,135:INFO:Declaring metric variables
2023-05-02 16:09:24,136:INFO:Importing untrained model
2023-05-02 16:09:24,136:INFO:AdaBoost Regressor Imported successfully
2023-05-02 16:09:24,136:INFO:Starting cross validation
2023-05-02 16:09:24,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:09:33,619:INFO:Calculating mean and std
2023-05-02 16:09:33,620:INFO:Creating metrics dataframe
2023-05-02 16:09:34,629:INFO:Uploading results into container
2023-05-02 16:09:34,630:INFO:Uploading model into container now
2023-05-02 16:09:34,631:INFO:_master_model_container: 15
2023-05-02 16:09:34,631:INFO:_display_container: 2
2023-05-02 16:09:34,632:INFO:AdaBoostRegressor(random_state=2885)
2023-05-02 16:09:34,632:INFO:create_model() successfully completed......................................
2023-05-02 16:09:34,772:INFO:SubProcess create_model() end ==================================
2023-05-02 16:09:34,772:INFO:Creating metrics dataframe
2023-05-02 16:09:34,777:INFO:Initializing Gradient Boosting Regressor
2023-05-02 16:09:34,777:INFO:Total runtime is 6.075733323891957 minutes
2023-05-02 16:09:34,777:INFO:SubProcess create_model() called ==================================
2023-05-02 16:09:34,778:INFO:Initializing create_model()
2023-05-02 16:09:34,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:09:34,778:INFO:Checking exceptions
2023-05-02 16:09:34,778:INFO:Importing libraries
2023-05-02 16:09:34,778:INFO:Copying training dataset
2023-05-02 16:09:34,781:INFO:Defining folds
2023-05-02 16:09:34,781:INFO:Declaring metric variables
2023-05-02 16:09:34,782:INFO:Importing untrained model
2023-05-02 16:09:34,783:INFO:Gradient Boosting Regressor Imported successfully
2023-05-02 16:09:34,783:INFO:Starting cross validation
2023-05-02 16:09:34,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:09:43,934:INFO:Calculating mean and std
2023-05-02 16:09:43,935:INFO:Creating metrics dataframe
2023-05-02 16:09:45,033:INFO:Uploading results into container
2023-05-02 16:09:45,034:INFO:Uploading model into container now
2023-05-02 16:09:45,034:INFO:_master_model_container: 16
2023-05-02 16:09:45,034:INFO:_display_container: 2
2023-05-02 16:09:45,035:INFO:GradientBoostingRegressor(random_state=2885)
2023-05-02 16:09:45,035:INFO:create_model() successfully completed......................................
2023-05-02 16:09:45,178:INFO:SubProcess create_model() end ==================================
2023-05-02 16:09:45,178:INFO:Creating metrics dataframe
2023-05-02 16:09:45,182:INFO:Initializing Light Gradient Boosting Machine
2023-05-02 16:09:45,182:INFO:Total runtime is 6.2491534590721125 minutes
2023-05-02 16:09:45,182:INFO:SubProcess create_model() called ==================================
2023-05-02 16:09:45,182:INFO:Initializing create_model()
2023-05-02 16:09:45,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:09:45,183:INFO:Checking exceptions
2023-05-02 16:09:45,183:INFO:Importing libraries
2023-05-02 16:09:45,183:INFO:Copying training dataset
2023-05-02 16:09:45,186:INFO:Defining folds
2023-05-02 16:09:45,186:INFO:Declaring metric variables
2023-05-02 16:09:45,186:INFO:Importing untrained model
2023-05-02 16:09:45,187:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-02 16:09:45,187:INFO:Starting cross validation
2023-05-02 16:09:45,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:09:56,940:INFO:Calculating mean and std
2023-05-02 16:09:56,941:INFO:Creating metrics dataframe
2023-05-02 16:09:57,970:INFO:Uploading results into container
2023-05-02 16:09:57,971:INFO:Uploading model into container now
2023-05-02 16:09:57,972:INFO:_master_model_container: 17
2023-05-02 16:09:57,972:INFO:_display_container: 2
2023-05-02 16:09:57,972:INFO:LGBMRegressor(random_state=2885)
2023-05-02 16:09:57,972:INFO:create_model() successfully completed......................................
2023-05-02 16:09:58,120:INFO:SubProcess create_model() end ==================================
2023-05-02 16:09:58,120:INFO:Creating metrics dataframe
2023-05-02 16:09:58,126:INFO:Initializing Dummy Regressor
2023-05-02 16:09:58,126:INFO:Total runtime is 6.464884062608083 minutes
2023-05-02 16:09:58,126:INFO:SubProcess create_model() called ==================================
2023-05-02 16:09:58,126:INFO:Initializing create_model()
2023-05-02 16:09:58,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027479081A00>, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:09:58,126:INFO:Checking exceptions
2023-05-02 16:09:58,127:INFO:Importing libraries
2023-05-02 16:09:58,127:INFO:Copying training dataset
2023-05-02 16:09:58,132:INFO:Defining folds
2023-05-02 16:09:58,132:INFO:Declaring metric variables
2023-05-02 16:09:58,132:INFO:Importing untrained model
2023-05-02 16:09:58,133:INFO:Dummy Regressor Imported successfully
2023-05-02 16:09:58,134:INFO:Starting cross validation
2023-05-02 16:09:58,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-02 16:10:07,032:INFO:Calculating mean and std
2023-05-02 16:10:07,033:INFO:Creating metrics dataframe
2023-05-02 16:10:08,077:INFO:Uploading results into container
2023-05-02 16:10:08,078:INFO:Uploading model into container now
2023-05-02 16:10:08,079:INFO:_master_model_container: 18
2023-05-02 16:10:08,079:INFO:_display_container: 2
2023-05-02 16:10:08,079:INFO:DummyRegressor()
2023-05-02 16:10:08,079:INFO:create_model() successfully completed......................................
2023-05-02 16:10:08,219:INFO:SubProcess create_model() end ==================================
2023-05-02 16:10:08,219:INFO:Creating metrics dataframe
2023-05-02 16:10:08,227:INFO:Initializing create_model()
2023-05-02 16:10:08,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=2885), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-02 16:10:08,228:INFO:Checking exceptions
2023-05-02 16:10:08,229:INFO:Importing libraries
2023-05-02 16:10:08,229:INFO:Copying training dataset
2023-05-02 16:10:08,240:INFO:Defining folds
2023-05-02 16:10:08,240:INFO:Declaring metric variables
2023-05-02 16:10:08,241:INFO:Importing untrained model
2023-05-02 16:10:08,241:INFO:Declaring custom model
2023-05-02 16:10:08,242:INFO:Extra Trees Regressor Imported successfully
2023-05-02 16:10:08,244:INFO:Cross validation set to False
2023-05-02 16:10:08,244:INFO:Fitting Model
2023-05-02 16:10:09,275:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2885)
2023-05-02 16:10:09,275:INFO:create_model() successfully completed......................................
2023-05-02 16:10:09,435:INFO:_master_model_container: 18
2023-05-02 16:10:09,436:INFO:_display_container: 2
2023-05-02 16:10:09,436:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2885)
2023-05-02 16:10:09,436:INFO:compare_models() successfully completed......................................
2023-05-02 16:10:09,441:INFO:Initializing predict_model()
2023-05-02 16:10:09,441:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002747908DE50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=2885), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027401D318B0>)
2023-05-02 16:10:09,441:INFO:Checking exceptions
2023-05-02 16:10:09,441:INFO:Preloading libraries
2023-05-02 16:10:09,442:INFO:Set up data.
2023-05-02 16:10:09,450:INFO:Set up index.
2023-05-07 22:24:52,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-07 22:24:52,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-07 22:24:52,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-07 22:24:52,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-07 22:25:04,548:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
